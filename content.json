{"meta":{"title":"jack","subtitle":"jackの博客","description":"java | 计算机与网络 | 简书作者","author":"jack","url":"https://mykkto.github.io","root":"/"},"pages":[{"title":"404","date":"2019-08-10T08:41:10.000Z","updated":"2022-01-06T14:09:33.725Z","comments":true,"path":"404.html","permalink":"https://mykkto.github.io/404.html","excerpt":"","text":""},{"title":"","date":"2022-01-06T14:09:33.869Z","updated":"2022-01-06T14:09:33.869Z","comments":true,"path":"baidu_verify_xxxxxxx.html","permalink":"https://mykkto.github.io/baidu_verify_xxxxxxx.html","excerpt":"","text":"wvlc3L96QK"},{"title":"","date":"2022-01-06T14:09:33.871Z","updated":"2022-01-06T14:09:33.871Z","comments":true,"path":"google1xxxxxxx0.html","permalink":"https://mykkto.github.io/google1xxxxxxx0.html","excerpt":"","text":"google-site-verification: google110e5e5e14c8dcf0.html"},{"title":"放松一下","date":"2019-08-10T08:41:10.000Z","updated":"2022-01-06T14:09:33.745Z","comments":true,"path":"List/index.html","permalink":"https://mykkto.github.io/List/index.html","excerpt":"","text":"影音资源共享"},{"title":"archives","date":"2019-10-24T16:00:00.000Z","updated":"2022-01-06T14:09:33.867Z","comments":true,"path":"archives/index.html","permalink":"https://mykkto.github.io/archives/index.html","excerpt":"","text":""},{"title":"统计","date":"2020-10-31T02:11:28.000Z","updated":"2022-01-06T14:09:33.869Z","comments":true,"path":"census/index.html","permalink":"https://mykkto.github.io/census/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-10-24T16:00:00.000Z","updated":"2022-01-06T14:09:33.869Z","comments":true,"path":"categories/index.html","permalink":"https://mykkto.github.io/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2019-10-24T16:00:00.000Z","updated":"2022-01-06T14:09:33.867Z","comments":true,"path":"about/index.html","permalink":"https://mykkto.github.io/about/index.html","excerpt":"","text":""},{"title":"留言板","date":"2022-01-06T15:45:01.231Z","updated":"2022-01-06T15:45:01.231Z","comments":true,"path":"contact/index.html","permalink":"https://mykkto.github.io/contact/index.html","excerpt":"","text":"畅所欲言 在这里可以留下你的足迹，欢迎在下方留言，欢迎交换友链，一起交流学习！ 友链 jackの友链信息 博客名称: jckの博客 博客网址: https://mykkto.github.io/"},{"title":"资源分享","date":"2019-07-19T08:40:27.000Z","updated":"2022-01-06T14:09:33.872Z","comments":true,"path":"resource/index.html","permalink":"https://mykkto.github.io/resource/index.html","excerpt":"","text":""},{"title":"友链","date":"2019-07-19T08:42:10.000Z","updated":"2022-01-06T14:09:33.871Z","comments":true,"path":"friends/index.html","permalink":"https://mykkto.github.io/friends/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-07-19T08:40:27.000Z","updated":"2022-01-06T14:09:33.873Z","comments":true,"path":"tags/index.html","permalink":"https://mykkto.github.io/tags/index.html","excerpt":"","text":""},{"title":"视频","date":"2019-08-10T08:41:10.000Z","updated":"2022-01-06T14:09:33.745Z","comments":true,"path":"List/movies/index.html","permalink":"https://mykkto.github.io/List/movies/index.html","excerpt":"","text":""},{"title":"听听音乐","date":"2019-07-19T08:40:27.000Z","updated":"2022-01-06T14:09:33.746Z","comments":true,"path":"List/music/index.html","permalink":"https://mykkto.github.io/List/music/index.html","excerpt":"","text":""},{"title":"相册","date":"2022-01-08T15:55:11.896Z","updated":"2022-01-06T14:09:33.734Z","comments":true,"path":"List/galleries/index.html","permalink":"https://mykkto.github.io/List/galleries/index.html","excerpt":"","text":""},{"title":"听听音乐","date":"2019-07-19T08:40:27.000Z","updated":"2022-01-06T14:09:33.747Z","comments":true,"path":"List/tools/index.html","permalink":"https://mykkto.github.io/List/tools/index.html","excerpt":"","text":""},{"title":"乖巧小狗","date":"2022-01-06T14:09:33.734Z","updated":"2022-01-06T14:09:33.734Z","comments":true,"path":"List/galleries/乖巧小狗/index.html","permalink":"https://mykkto.github.io/List/galleries/%E4%B9%96%E5%B7%A7%E5%B0%8F%E7%8B%97/index.html","excerpt":"","text":""},{"title":"二次元风","date":"2022-01-06T14:09:33.735Z","updated":"2022-01-06T14:09:33.735Z","comments":true,"path":"List/galleries/二次元风/index.html","permalink":"https://mykkto.github.io/List/galleries/%E4%BA%8C%E6%AC%A1%E5%85%83%E9%A3%8E/index.html","excerpt":"","text":""},{"title":"动漫人物","date":"2022-01-06T14:09:33.736Z","updated":"2022-01-06T14:09:33.736Z","comments":true,"path":"List/galleries/动漫人物/index.html","permalink":"https://mykkto.github.io/List/galleries/%E5%8A%A8%E6%BC%AB%E4%BA%BA%E7%89%A9/index.html","excerpt":"","text":""},{"title":"动漫插画","date":"2022-01-06T14:09:33.737Z","updated":"2022-01-06T14:09:33.737Z","comments":true,"path":"List/galleries/动漫插画/index.html","permalink":"https://mykkto.github.io/List/galleries/%E5%8A%A8%E6%BC%AB%E6%8F%92%E7%94%BB/index.html","excerpt":"","text":""},{"title":"动漫风景","date":"2022-01-06T14:09:33.738Z","updated":"2022-01-06T14:09:33.738Z","comments":true,"path":"List/galleries/动漫风景/index.html","permalink":"https://mykkto.github.io/List/galleries/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%99%AF/index.html","excerpt":"","text":""},{"title":"呆萌猫咪","date":"2022-01-06T14:09:33.738Z","updated":"2022-01-06T14:09:33.738Z","comments":true,"path":"List/galleries/呆萌猫咪/index.html","permalink":"https://mykkto.github.io/List/galleries/%E5%91%86%E8%90%8C%E7%8C%AB%E5%92%AA/index.html","excerpt":"","text":""},{"title":"清新花卉","date":"2022-01-06T14:09:33.740Z","updated":"2022-01-06T14:09:33.740Z","comments":true,"path":"List/galleries/清新花卉/index.html","permalink":"https://mykkto.github.io/List/galleries/%E6%B8%85%E6%96%B0%E8%8A%B1%E5%8D%89/index.html","excerpt":"","text":""},{"title":"城市风光","date":"2022-01-06T14:09:33.739Z","updated":"2022-01-06T14:09:33.739Z","comments":true,"path":"List/galleries/城市风光/index.html","permalink":"https://mykkto.github.io/List/galleries/%E5%9F%8E%E5%B8%82%E9%A3%8E%E5%85%89/index.html","excerpt":"","text":""},{"title":"炫酷跑车","date":"2022-01-08T15:55:21.871Z","updated":"2022-01-06T14:09:33.742Z","comments":true,"path":"List/galleries/炫酷跑车/index.html","permalink":"https://mykkto.github.io/List/galleries/%E7%82%AB%E9%85%B7%E8%B7%91%E8%BD%A6/index.html","excerpt":"","text":""},{"title":"璀璨星空","date":"2022-01-06T14:09:33.743Z","updated":"2022-01-06T14:09:33.743Z","comments":true,"path":"List/galleries/璀璨星空/index.html","permalink":"https://mykkto.github.io/List/galleries/%E7%92%80%E7%92%A8%E6%98%9F%E7%A9%BA/index.html","excerpt":"","text":""},{"title":"甜美食品","date":"2022-01-06T14:09:33.743Z","updated":"2022-01-06T14:09:33.743Z","comments":true,"path":"List/galleries/甜美食品/index.html","permalink":"https://mykkto.github.io/List/galleries/%E7%94%9C%E7%BE%8E%E9%A3%9F%E5%93%81/index.html","excerpt":"","text":""},{"title":"自然风景","date":"2022-01-06T14:09:33.744Z","updated":"2022-01-06T14:09:33.744Z","comments":true,"path":"List/galleries/自然风景/index.html","permalink":"https://mykkto.github.io/List/galleries/%E8%87%AA%E7%84%B6%E9%A3%8E%E6%99%AF/index.html","excerpt":"","text":""}],"posts":[{"title":"随性记录一小点 2021-07-15至未来","slug":"02-informalessay/00_散列随手记","date":"2022-08-05T15:21:33.000Z","updated":"2022-08-05T14:21:09.647Z","comments":true,"path":"posts/cfd1312a.html","link":"","permalink":"https://mykkto.github.io/posts/cfd1312a.html","excerpt":"","text":"————-简书原始地址————-2021年7月15日pl/sql客户端bug 切换的用户的时候，会串掉（意思是显示上切换了，其实并没有）解决方案：必须重启客户端，切换用户 2021年7月26日idea git 小姿势，本地库拖回 2021年7月28日oracle 小知识：不小心删除了一张表数据，怎么办呢？ select * from 表名 as of timestamp sysdate-1/12 //查询两个小时前的删除的某张表 2021年8月22日并行：多个任务在同一时间点发生，并由不同的cpu进行处理，不互相抢占资源并发：多个任务在同一时间点内同时发生了，但由同一个cpu进行处理，互相抢占资源文章推荐：https://www.cnblogs.com/iamqiyue/p/14184769.html 2021年8月30日jsp 用0做字段状态，列表会出问题，会有默认值 2021年9月07日easyUI 嵌套对话框问题，对话框A弹出对话框B，A无法关闭。需要在A的关闭回调 打开B，也就是关闭A不能和打开B 写在一起，必须关闭A调用A的关闭回调之后再打开B。 2021年9月14日oracle 11g分组案例：1、group by user_id,PUNCH_DATE：通过用户id和日期分组2、listagg( TIME_INTERVAL ,’,’) within group (order by id) ：需要展示的字段（没有纳入分组规则的），order by id 通过 id 排序，或者可以自定义一个排序字段 select d.id,u.User_Id,u.User_Name,d.Punch_Date,d.Punch_Time,de.Dept_Name,d.time,d.remark,d.status,d.TIME_INTERVAL,d.PUNCH_STATUS from (select user_id,PUNCH_DATE， listagg( TIME_INTERVAL ,',') within group (order by id) as TIME_INTERVAL, listagg( STATUS,',') within group(order by id) as STATUS, listagg( id ,',') within group(order by id) as id, listagg( REMARK ,',') within group(order by id) as REMARK, listagg( PUNCH_TIME ,',') within group(order by id) as PUNCH_TIME, listagg( PUNCH_STATUS ,',') within group(order by id) as PUNCH_STATUS, listagg( time ,',') within group(order by id) as time from KQ_PUNCH_DAILY group by user_id,PUNCH_DATE) d inner join tbl_sys_user u on d.User_Id=u.USER_ID inner join tbl_sys_department de on de.dept_id=u.dept_id 2021年9月 23日一、oracle 11g 存储过程分割字符串案例：纯分割 测试代码（先运行存储过程代码） SELECT * FROM TABLE( FUNC_ISM_GETSPLITSTR('_FUNC_CTP_LG_GEsss_s_ssssTSPNG_', '_')); 先创建变量 --创建变量 CREATE OR REPLACE TYPE \"ARRYTYPE1\" IS VARRAY(10000) OF VARCHAR(2000); 存储过程代码 CREATE OR REPLACE FUNCTION FUNC_ISM_GETSPLITSTR ( in_str IN VARCHAR2, --需分割的字符串 in_split IN VARCHAR2 --分隔符 ) RETURN arrytype1 AS v_count1 INTEGER; v_count2 INTEGER; v_strlist arrytype1; v_node VARCHAR2 (2000); BEGIN v_count2 := 0; v_strlist := arrytype1 (); IF (in_str IS NULL) OR (LENGTH (in_str) &lt;= 0) THEN RETURN NULL; END IF; FOR v_i IN 1 .. LENGTH (in_str) LOOP v_count1 := INSTRB (in_str, in_split, 1, v_i); v_count2 := INSTRB (in_str, in_split, 1, v_i + 1); v_node := SUBSTRB (in_str, v_count1 + 1, v_count2 - v_count1 - 1); IF v_node IS NULL THEN v_node := ''; END IF; IF (v_count2 = 0) OR (v_count2 IS NULL) THEN EXIT; ELSE v_strlist.EXTEND (); v_strlist (v_i) := v_node; v_node := ''; END IF; END LOOP; RETURN v_strlist; END FUNC_ISM_GETSPLITSTR; 输出结果 二、oracle 11g 存储过程分割字符串案例：分割+判断编写语句 CREATE OR REPLACE FUNCTION FUNC_ISM_GETSPLITSTR2 (-- 最终返回 1 发起部门，2 主办部门，3 协办部门 -- 写法存在一个问题，需要在开始节点和结束节点加上分隔符否则娶不到 -- _FUNC_CTP_LG_GEsss_s_ssssTSPNG_ 类似 这种格式 in_str IN VARCHAR2, --需分割的字符串 in_split IN VARCHAR2 --分隔符 ) RETURN VARCHAR2 AS v_count1 INTEGER; v_count2 INTEGER; v_count3 INTEGER;--计数器 v_node VARCHAR2 (2000); v_result VARCHAR2 (2000); v_resulttep VARCHAR2 (2000); in_strtep VARCHAR2 (2000); BEGIN in_strtep := in_split||in_str||in_split; v_count2 := 0; v_count3 := 0; v_result := '1'; v_resulttep :=''; IF (in_strtep IS NULL) OR (LENGTH (in_strtep) &lt;= 0) THEN RETURN NULL; END IF; FOR v_i IN 1 .. LENGTH (in_strtep) LOOP v_count1 := INSTRB (in_strtep, in_split, 1, v_i); v_count2 := INSTRB (in_strtep, in_split, 1, v_i + 1); v_node := SUBSTRB (in_strtep, v_count1 + 1, v_count2 - v_count1 - 1); IF v_node IS NULL THEN v_node := ''; elsif (v_node= '2') then v_count3 := v_count3 +1 ;-- 记得对节点判空，写在后头 ELSE v_resulttep := v_resulttep || v_node; END IF; IF (v_count2 = 0) OR (v_count2 IS NULL) THEN EXIT; ELSE v_strlist.EXTEND (); v_strlist (v_i) := v_node; v_node := ''; END IF; END LOOP; if ((LENGTH (in_str)-1)/2+1 = v_count3) then v_result := '2';END IF; RETURN v_result; END FUNC_ISM_GETSPLITSTR2; 结果对比输出：如果有一个 1所有都是1 ，如果 所有为 2 才能全部为2 三、单条SQL 映射输出（需要注意的是：不能是多条结果集，这个只是单条，接受类型为 varchar2 ） CREATE OR REPLACE FUNCTION \"FUNC_ISM_GETSPLITSTR2_TODAY2\" (-- 计算加3天后（跳过非同昨日），得到实际的 日期） -- 写法存在一个问题，需要在开始节点和结束节点加上分隔符否则娶不到 -- _FUNC_CTP_LG_GEsss_s_ssssTSPNG_ 类似 这种格式 in_str IN VARCHAR2 --需要被计算的日期 ) RETURN VARCHAR2 AS in_result VARCHAR2 (4000);-- in_temp VARCHAR2 (4000); in_year VARCHAR2 (4000); in_month VARCHAR2 (4000); in_day VARCHAR2 (4000); BEGIN in_temp := SUBSTR(in_str,1,4);sql select ID into in_result from TBL_TASKS_PERSONAL_SIDE WHERE ID='402881e57c968139017c969805df00d9'; RETURN in_temp; END FUNC_ISM_GETSPLITSTR2_TODAY2; 测试代码：SELECT FUNC_ISM_GETSPLITSTR2_TODAY2('2021-04-22') as aaa FROM TBL_TASKS_PERSONAL_MAIN ORACLE 存储过程INTO 多个变量 select f1,f2,f3 into v1,v2,v3 from tab1 2021年9月29日有的时候Java catch 用 e.getStackTrace ( );不出异常栈信息，可以使用e.printStackTrace ( );解决 2021年10月26日（1）oracle 分页 select * from ( select A.*,ROWNUM RN from ( SELECT * from DEP_TASK_VIEW) A where 1=1 and ROWNUM &lt;=10 ) WHERE RN &gt;= 1 （2）不仅如此 RN还可以当做唯一记录数ID使用，因视图合并出来的数据ID不是唯一的 select * from ( select A.*,ROWNUM RN from ( SELECT * from DEP_TASK_VIEW) A where 1=1 and ROWNUM &lt;=10 ) WHERE RN &gt;= 1 and RN in (2,3,5) 2021年10月29日日期期限计算节假日的存储过程，套用两个视图（1）函数 CREATE OR REPLACE FUNCTION \"FUNC_ISM_GETSPLITSTR2_TODAY2\" (-- 计算加3天后（跳过非同昨日），得到实际的 日期）才有该跳的第三条记录获取，而不是日期直接+3，筛选出只有工作日 in_str IN VARCHAR2 --需要被计算的日期 ) RETURN VARCHAR2 AS in_result VARCHAR2 (4000);-- 最终结果 in_temp VARCHAR2 (4000);-- 辅助筛选年 in_temp2 NUMBER;-- 辅助筛选年 +1 in_temp3 VARCHAR2 (4000);-- 辅助筛选月 in_temp33 NUMBER;-- 辅助筛选月 --处理精度 in_temp4 VARCHAR2 (4000);-- 辅助筛选日 in_temp44 NUMBER;-- 辅助筛选日 --处理精度 in_year VARCHAR2 (4000);--计算的年 in_month VARCHAR2 (4000);--计算的月 in_day VARCHAR2 (4000);--计算的日 in_rn1 VARCHAR2 (4000);--先找到词条日历的rownum,然后加3的记录数就是 in_rn12 VARCHAR2 (4000);-- 词条二（最终的），配合视图二 in_rn122 NUMBER; in_time VARCHAR2 (4000);-- 后缀的时间 BEGIN in_temp := SUBSTR(in_str,1,4); in_temp2 := \"TO_NUMBER\"(in_temp)+1; in_temp3 := SUBSTR(in_str,6,2); in_temp33 := \"TO_NUMBER\"(in_temp3); in_temp4 := SUBSTR(in_str,9,2); in_temp44 := \"TO_NUMBER\"(in_temp4); in_time := SUBSTR(in_str,11,99); SELECT RNN into in_rn1 from TASK_TEMP_DAY1 WHERE CALYEAR = in_temp AND CALENDAR_MONTH = in_temp33 AND CALENDAR_DAY = in_temp44; SELECT RNN2 into in_rn12 from TASK_TEMP_DAY2 WHERE RNN = in_rn1; in_rn122 := \"TO_NUMBER\"(in_rn12)+3; SELECT CALYEAR,CALENDAR_MONTH,CALENDAR_DAY into in_year,in_month,in_day from TASK_TEMP_DAY2 WHERE RNN2 = in_rn122; in_result := in_year||'-'; IF(in_month&lt;10) THEN in_result := in_result || '0'||in_month||'-'; ELSE in_result := in_result ||in_month||'-'; END IF; IF(in_day&lt;10) THEN in_result := in_result || '0'||in_day; ELSE in_result := in_result ||in_day; END IF; in_result := in_result ||in_time; RETURN in_result; END FUNC_ISM_GETSPLITSTR2_TODAY2; （2）TASK_TEMP_DAY1 SELECT ROWNUM RNN, \"CALYEAR\", \"ID\", \"CALENDAR_ID\", \"CALENDAR_MONTH\", \"CALENDAR_DAY\", \"CALENDAR_DATE_TYPE\", \"CALENDAR_MODIFY_PERSON\", \"CALENDAR_MODIFY_TIME\", \"BLANK0\", \"BLANK1\" FROM ( SELECT DE.*, CA.CALENDAR_YEAR CALYEAR FROM KQ_CALENDAR CA INNER JOIN KQ_CALENDAR_DETAIL DE ON CA.CALENDAR_ID = DE.CALENDAR_ID WHERE 1 = 1 AND CA.CALENDAR_CREATOR = '4028811d7057520301705756b3ca0050' ORDER BY CA.CALENDAR_YEAR ASC, DE.CALENDAR_MONTH ASC, DE.CALENDAR_DAY ASC ) -- 工作任务逾期计算节假日配合函数的视图(被查询的视图) （3）TASK_TEMP_DAY2 SELECT ROWNUM RNN2, \"RNN\", \"CALYEAR\", \"ID\", \"CALENDAR_ID\", \"CALENDAR_MONTH\", \"CALENDAR_DAY\", \"CALENDAR_DATE_TYPE\", \"CALENDAR_MODIFY_PERSON\", \"CALENDAR_MODIFY_TIME\", \"BLANK0\", \"BLANK1\" FROM TASK_TEMP_DAY1 WHERE CALENDAR_DATE_TYPE = '0' -- 工作任务逾期计算节假日配合函数的视图(被计算的视图) 2021年11月4日oracle 11g 写存储过程报错：ORA-00972 identifier is too long原因存储过程的命名过长，改短即可。 2021年11月5日oracle 11g 写存储过程 拼接单引号转义问题： in_str := '1'; -- 输出 1 in_str := '''1'''; -- 输出 '1' 2021年11月5日oracle 11g 写存储过程 SQL字符串 运行后赋值： v_idsaaa := SUBSTR(v_idsaaa,1,\"LENGTH\"(v_idsaaa)-1); in_timesiov := 'SELECT createTe_ from (SELECT listagg (createTe_, '','') WITHIN GROUP (ORDER BY ID_) AS createTe_ from ( select TO_CHAR ( create_, ''yyyy-mm-dd hh24:mi:ss'' ) createTe_ ,COMMITUSERID_,BUSINESSID_,NAME_,ID_ from jbpm_taskinstance WHERE BUSINESSID_=''402881f47ce4b52d017ce4bc73d30026'' and NAME_ =''进程1'' and COMMITUSERID_ in ('||v_idsaaa||')) GROUP BY BUSINESSID_,NAME_)' ; execute immediate in_timesiov into v_flag; -- execute immediate 用于执行 SQL语句 -- in_timesiov 是拼接出来的SQL语句 -- v_flag 接收语句返回的数据 2021年11月15日记录一个 echarts 柱形图的坑（1）渲染key的时候如果是整个数组过来，就会变成一坨 xAxis: { //data: [\"一般\",\"好\",\"非常好\"] data: dataKeyList }, （2）所以要使用遍历出来 xAxis: { data: [\"一般\",\"好\",\"非常好\"] }, 2021年11月30日SQL 自定义排序 select * from tbl_duty_user decode(u.postType,'1',4,'2',3,'3',2,'4',1) asc oracle 字段已逗号隔开分解为多条数据 https://blog.csdn.net/sofeien/article/details/80534557 No row with the given identifier exists: [com.jh.jcs.business.duty.model.TblDutyDetail#402881e57c7df2e5017c7df8d7c20138] HQL多對一脏数据问题 2021年12月13日关于SQL 搜索时间日期范围不可用 or String hql2 = \"from KqPunchDaily where punchDate like '%\" + DailyUtil.sameMonth ( )+ \"%' or punchDate like '%\" + DailyUtil.lastMonth ( )+ \"%' and punchStatus !=0 and userId in (\"+idstemp+\") \"; 以上3w数据要用 beginTime ，或者 &gt;, &lt;锁定范围时间 String hql1 = \"from KqLeaveForm where beginTime BETWEEN '\" + DailyUtil.sameMonth ( ) + \"' and '\" + DailyUtil.lastMonth ( ) + \"' and status ='1' and deptId = '\"+deptId+\"' \"; 2021年12月17日pl/SQL客户端乱码https://blog.csdn.net/gm371200587/article/details/81381825 2021年12月17日oracle合并表函数 Union：对两个结果集进行并集操作，不包括重复行，同时进行默认规则的排序； Union All：对两个结果集进行并集操作，包括重复行，不进行排序； Intersect：对两个结果集进行交集操作，不包括重复行，同时进行默认规则的排序； Minus：对两个结果集进行差操作，不包括重复行，同时进行默认规则的排序。 2021年12月20日定制排序：表，学生根据性别排序，如果是男的根据年龄升序，如果是女的根据体重desc，男的排在女的前面 order by 性别，case when 性别=男 then 年龄 end,case when 性别=女 then 体重 end desc ###参考博客https://www.cnblogs.com/sunice/p/10436725.html 2022-08-01dea sql 未连接检查 爆红取消样式配置：https://blog.csdn.net/a907691592/article/details/94724090 idea 自动生成序列号：https://www.jianshu.com/p/b4807c3efcb6 idea 配置 包排序– sort by type idea 书签技巧：https://www.studyweb.cn/detail/java_174180.html oracle 字符串分割：https://blog.csdn.net/qq_40230848/article/details/123417714","categories":[{"name":"docker","slug":"docker","permalink":"https://mykkto.github.io/categories/docker/"}],"tags":[{"name":"技术","slug":"技术","permalink":"https://mykkto.github.io/tags/%E6%8A%80%E6%9C%AF/"},{"name":"记录","slug":"记录","permalink":"https://mykkto.github.io/tags/%E8%AE%B0%E5%BD%95/"}],"author":"mykk"},{"title":"k8s","slug":"03-java分布式/02容器/04_k8s","date":"2022-08-01T14:11:13.000Z","updated":"2022-08-01T14:18:08.339Z","comments":true,"path":"posts/655061ae.html","link":"","permalink":"https://mykkto.github.io/posts/655061ae.html","excerpt":"","text":"Ⅰ、复杂安装（主从搭建）一、Mysql主从二、Redis集群Ⅱ、轻量可视化 PortainerⅢ、Docker容器监控（CAdvisor+InfluxDB+Granfana）参考地址 ↓1、docker 加速（博主简书）url：https://www.jianshu.com/p/f554c85b25c1","categories":[{"name":"docker","slug":"docker","permalink":"https://mykkto.github.io/categories/docker/"}],"tags":[{"name":"集群","slug":"集群","permalink":"https://mykkto.github.io/tags/%E9%9B%86%E7%BE%A4/"},{"name":"主从","slug":"主从","permalink":"https://mykkto.github.io/tags/%E4%B8%BB%E4%BB%8E/"},{"name":"可视化","slug":"可视化","permalink":"https://mykkto.github.io/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/"}],"author":"mykk"},{"title":"docker 部署篇","slug":"03-java分布式/02容器/03_docker部署篇","date":"2022-07-20T13:17:13.000Z","updated":"2022-07-20T13:55:23.775Z","comments":true,"path":"posts/caff0950.html","link":"","permalink":"https://mykkto.github.io/posts/caff0950.html","excerpt":"","text":"————————— Docker 实操篇 ————————–Ⅰ、复杂安装（主从搭建）一、Mysql主从二、Redis集群Ⅱ、轻量可视化 PortainerⅢ、Docker容器监控（CAdvisor+InfluxDB+Granfana）参考地址 ↓1、docker 加速（博主简书）url：https://www.jianshu.com/p/f554c85b25c1","categories":[{"name":"docker","slug":"docker","permalink":"https://mykkto.github.io/categories/docker/"}],"tags":[{"name":"集群","slug":"集群","permalink":"https://mykkto.github.io/tags/%E9%9B%86%E7%BE%A4/"},{"name":"主从","slug":"主从","permalink":"https://mykkto.github.io/tags/%E4%B8%BB%E4%BB%8E/"},{"name":"可视化","slug":"可视化","permalink":"https://mykkto.github.io/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/"}],"author":"mykk"},{"title":"docker 操作篇","slug":"03-java分布式/02容器/02_docker实操篇","date":"2022-07-05T15:17:13.000Z","updated":"2022-07-20T14:39:41.754Z","comments":true,"path":"posts/abdfa13a.html","link":"","permalink":"https://mykkto.github.io/posts/abdfa13a.html","excerpt":"","text":"————————— Docker 部署篇 ————————–〇、本章源代码https://gitee.com/TK_LIMR/springcloud2021To2021.git Ⅰ、DockerFile一、是什么1、官网https://docs.docker.com/engine/reference/builder 2、概述Dockerfile是用来构建Docker镜像的文本文件，是由一条条构建镜像所需的指令和参数构成的脚本。 3、步骤 编写Dockerfile文件 docker build命令构建镜像 docker run依镜像运行容器实例 二、DockerFile构建过程解析1、Dockerfile内容基础知识 每条保留字指令都必须为大写字母且后面要跟随至少一个参数 指令按照从上到下，顺序执行 #表示注释 每条指令都会创建一个新的镜像层并对镜像进行提交 2、Docker执行Dockerfile的大致流程 docker从基础镜像运行一个容器 执行一条指令并对容器作出修改 执行类似docker commit的操作提交一个新的镜像层 docker再基于刚提交的镜像运行一个新容器 执行dockerfile中的下一条指令直到所有指令都执行完成 3、小总结从应用软件的角度来看，Dockerfile、Docker镜像与Docker容器分别代表软件的三个不同阶段， Dockerfile是软件的原材料 Docker镜像是软件的交付品 Docker容器则可以认为是软件镜像的运行态，也即依照镜像运行的容器实例 Dockerfile面向开发，Docker镜像成为交付标准，Docker容器则涉及部署与运维，三者缺一不可，合力充当Docker体系的基石。 Dockerfile，需要定义一个Dockerfile，Dockerfile定义了进程需要的一切东西。Dockerfile涉及的内容包括执行代码或者是文件、环境变量、依赖包、运行时环境、动态链接库、操作系统的发行版、服务进程和内核进程(当应用进程需要和系统服务和内核进程打交道，这时需要考虑如何设计namespace的权限控制)等等; Docker镜像，在用Dockerfile定义一个文件之后，docker build时会产生一个Docker镜像，当运行 Docker镜像时会真正开始提供服务; Docker容器，容器是直接提供服务的。 三、DockerFile常用保留字指令 FROM：基础镜像，当前新镜像是基于哪个镜像的，指定一个已经存在的镜像作为模板，第一条必须是from MAINTAINER：镜像维护者的姓名和邮箱地址 RUN：容器构建时需要运行的命令，RUN是在 docker build时运行 shell格式：RUN yum -y install vim exec格式： EXPOSE：当前容器对外暴露出的端口 WORKDIR：指定在创建容器后，终端默认登陆的进来工作目录，一个落脚点 USER：指定该镜像以什么样的用户去执行，如果都不指定，默认是root ENV：用来在构建镜像过程中设置环境变量 ENV MY_PATH /usr/mytest 这个环境变量可以在后续的任何RUN指令中使用，这就如同在命令前面指定了环境变量前缀一样；也可以在其它指令中直接使用这些环境变量 比如：WORKDIR $MY_PATH ADD：将宿主机目录下的文件拷贝进镜像且会自动处理URL和解压tar压缩包 COPY：类似ADD，拷贝文件和目录到镜像中。将从构建上下文目录中 &lt;源路径&gt; 的文件/目录复制到新的一层的镜像内的 &lt;目标路径&gt; 位置 COPY src dest COPY [“src”, “dest”] &lt;src源路径&gt;：源文件或者源目录 &lt;dest目标路径&gt;：容器内的指定路径，该路径不用事先建好，路径不存在的话，会自动创建。 VOLUME：容器数据卷，用于数据保存和持久化工作 CMD：指定容器启动后的要干的事情 注意： Dockerfile 中可以有多个 CMD 指令，但只有最后一个生效，CMD 会被 docker run 之后的参数替换 它和前面RUN命令的区别 CMD是在docker run 时运行。 RUN是在 docker build时运行。 ENTRYPOINT：也是用来指定一个容器启动时要运行的命令 类似于 CMD 指令，但是ENTRYPOINT不会被docker run后面的命令覆盖，而且这些命令行参数会被当作参数送给 ENTRYPOINT 指令指定的程序 小总结 四、案例1、自定义镜像myCentosJava81、要求Centos7镜像具备vim+ifconfig+jdk8 准备：JDK8下载位置 https://mirrors.yangxingzhen.com/jdk/ 2、编写FROM centos:7 MAINTAINER jack&lt;mykkto.cn&gt; ENV MYPATH /usr/local WORKDIR $MYPATH #安装vim编辑器 RUN yum -y install vim #安装ifconfig命令查看网络IP RUN yum -y install net-tools #安装java8及lib库 RUN yum -y install glibc.i686 RUN mkdir /usr/local/java #ADD 是相对路径jar,把jdk-8u171-linux-x64.tar.gz添加到容器中,安装包必须要和Dockerfile文件在同一位置 ADD jdk-8u171-linux-x64.tar.gz /usr/local/java/ #配置java环境变量 ENV JAVA_HOME /usr/local/java/jdk1.8.0_171 ENV JRE_HOME $JAVA_HOME/jre ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATH ENV PATH $JAVA_HOME/bin:$PATH EXPOSE 80 CMD echo $MYPATH CMD echo \"success--------------ok\" CMD /bin/bash 3、构建docker build -t 新镜像名字:TAG docker build -t centosjava8:1.5 . 注意：上面TAG后面有个空格，有个点 命令： 成功： 4、运行docker run -it 新镜像名字:TAG docker run -it centosjava8:1.5 /bin/bash 5、总结UnionFS（联合文件系统）：Union文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下(unite several directories into a single virtual filesystem)。Union 文件系统是 Docker 镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。 特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录 2、虚悬镜像1、是什么仓库名、标签都是的镜像，俗称dangling image 写一个 2、查看docker image ls -f dangling=true 3、删除docker image prune 虚悬镜像已经失去存在价值，可以删 五、总结 Ⅱ、Docker 网络一、是什么1、默认docker不启动，默认网络情况 2、启动docker启动后，网络情况 二、命令1、All命令 2、主查看网络docker network ls 3、查看网络源数据docker network inspect XXX网络名字 4、删除网络docker network rm XXX网络名字 5、案例 三、能干嘛 容器间的互联和通信以及端口映射 容器IP变动时候可以通过服务名直接网络通信而不受到影响 四、网络模式1、列表1、是什么 bridge模式：使用–network bridge指定，默认使用docker0 host模式：使用–network host指定 none模式：使用–network none指定 container模式：使用–network container:NAME或者容器ID指定 2、规则docker容器内部的ip是有可能会发生改变的 说明 1、启动两个容器说明 2、docker inspect 容器ID or 容器名字 3、案例：3-1、bridge1、是什么Docker 服务默认会创建一个 docker0 网桥（其上有一个 docker0 内部接口），该桥接网络的名称为docker0，它在内核层连通了其他的物理或虚拟网卡，这就将所有容器和本地主机都放到同一个物理网络。Docker 默认指定了 docker0 接口 的 IP 地址和子网掩码，让主机和容器之间可以通过网桥相互通信。 #查看 bridge 网络的详细信息，并通过 grep 获取名称项 docker network inspect bridge | grep name ifconfig | grep docker 2、案例(1）说明： Docker使用Linux桥接，在宿主机虚拟一个Docker容器网桥(docker0)，Docker启动一个容器时会根据Docker网桥的网段分配给容器一个IP地址，称为Container-IP，同时Docker网桥是每个容器的默认网关。因为在同一宿主机内的容器都接入同一个网桥，这样容器之间就能够通过容器的Container-IP直接通信。 docker run 的时候，没有指定network的话默认使用的网桥模式就是bridge，使用的就是docker0。在宿主机ifconfig,就可以看到docker0和自己create的network(后面讲)eth0，eth1，eth2……代表网卡一，网卡二，网卡三……，lo代表127.0.0.1，即localhost，inet addr用来表示网卡的IP地址 网桥docker0创建一对对等虚拟设备接口一个叫veth，另一个叫eth0，成对匹配。 3.1 整个宿主机的网桥模式都是docker0，类似一个交换机有一堆接口，每个接口叫veth，在本地主机和容器内分别创建一个虚拟接口，并让他们彼此联通（这样一对接口叫veth pair）； 3.2 每个容器实例内部也有一块网卡，每个接口叫eth0； 3.3 docker0上面的每个veth匹配某个容器实例内部的eth0，两两配对，一一匹配。 通过上述，将宿主机上的所有容器都连接到这个内部网络上，两个容器在同一个网络下,会从这个网关下各自拿到分配的ip，此时两个容器的网络是互通的。 (2）命令： docker run -d -p 8081:8080 --name tomcat81 billygoo/tomcat8-jdk8 docker run -d -p 8082:8080 --name tomcat82 billygoo/tomcat8-jdk8 (3）验证： [root@VM-0-13-centos ~]# ip addr| tail -n 8 3-2、1、是什么直接使用宿主机的 IP 地址与外界进行通信，不再需要额外进行NAT 转换。 2、案例(1)说明 容器将不会获得一个独立的Network Namespace， 而是和宿主机共用一个Network Namespace。容器将不会虚拟出自己的网卡而是使用宿主机的IP和端口。 （2）命令 docker run -d --network host --name tomcat83 billygoo/tomcat8-jdk8 (3)无之前的配对显示了，看容器实例内部 (4)没有设置-p的端口映射了，如何访问启动的tomcat83 ? 就是默认端口，http://宿主机IP:8080/ 比如：tomcat 是 8080，nginx 是 80 ，mysql 是3306 3-3、none1、是什么禁用网络功能，只有lo标识(就是127.0.0.1表示本地回环) 2、案例docker run -d -p 8084:8080 --network none --name tomcat84 billygoo/tomcat8-jdk8 3-4、container1、是什么新建的容器和已经存在的一个容器共享一个网络ip配置而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的IP，而是和一个指定的容器共享IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。 2、案例Alpine Linux 是一款独立的、非商业的通用 Linux 发行版，专为追求安全性、简单性和资源效率的用户而设计。 可能很多人没听说过这个 Linux 发行版本，但是经常用 Docker 的朋友可能都用过，因为他小，简单，安全而著称，所以作为基础镜像是非常好的一个选择，可谓是麻雀虽小但五脏俱全，镜像非常小巧，不到 6M的大小，所以特别适合容器打包。 docker run -it -d --name alpine1 alpine /bin/sh docker run -it -d --network container:alpine1 --name alpine2 alpine /bin/sh 关闭alpine1，再看看alpine2 3-5、★ 自定义网络1、是什么字面意思，自定义的网络 2、案例一类：before docker run -d -p 8081:8080 --name tomcat81 billygoo/tomcat8-jdk8 docker run -d -p 8082:8080 --name tomcat82 billygoo/tomcat8-jdk8 上述成功启动并用docker exec进入各自容器实例内部 存在的问题：可以按照IP ping 通，但是无法用服务名 ping 通 二类：after 1、新建桥接网络 docker network create jack_network 2、新建容器加入上一步新建的自定义网络 docker run -d -p 8081:8080 --network jack_network --name tomcat81 billygoo/tomcat8-jdk8 docker run -d -p 8082:8080 --network jack_network --name tomcat82 billygoo/tomcat8-jdk8 3、测试互 ping 4、结论 自定义网络本身就维护好了主机名和ip的对应关系（ip和域名都能通） 五、Docker架构图解从其架构和运行流程来看，Docker 是一个 C/S 模式的架构，后端是一个松耦合架构，众多模块各司其职。 Docker 运行的基本流程为： 1 用户是使用 Docker Client 与 Docker Daemon 建立通信，并发送请求给后者。2 Docker Daemon 作为 Docker 架构中的主体部分，首先提供 Docker Server 的功能使其可以接受 Docker Client 的请求。3 Docker Engine 执行 Docker 内部的一系列工作，每一项工作都是以一个 Job 的形式的存在。4 Job 的运行过程中，当需要容器镜像时，则从 Docker Registry 中下载镜像，并通过镜像管理驱动 Graph driver将下载镜像以Graph的形式存储。5 当需要为 Docker 创建网络环境时，通过网络管理驱动 Network driver 创建并配置 Docker 容器网络环境。6 当需要限制 Docker 容器运行资源或执行用户指令等操作时，则通过 Execdriver 来完成。7 Libcontainer是一项独立的容器管理包，Network driver以及Exec driver都是通过Libcontainer来实现具体对容器进行的操作。 Ⅲ、Docker微服务实战一、创建一个普通模块1、建modeldocker_boot 2、改pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.5.6&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;docker_boot&lt;/artifactId&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt; &lt;lombok.version&gt;1.16.18&lt;/lombok.version&gt; &lt;mysql.version&gt;5.1.47&lt;/mysql.version&gt; &lt;druid.version&gt;1.1.16&lt;/druid.version&gt; &lt;mapper.version&gt;4.1.5&lt;/mapper.version&gt; &lt;mybatis.spring.boot.version&gt;1.3.0&lt;/mybatis.spring.boot.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--SpringBoot通用依赖模块--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--test--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- &lt;build &gt; 主要用于编译设置 --&gt; &lt;build&gt; &lt;!-- 定义打包成jar的名字 --&gt; &lt;!-- 这里如果不定义 , 打包成的jar名字格式为 : &lt;artifactId&gt; + &lt;version&gt; --&gt; &lt;finalName&gt;docker_jar&lt;/finalName&gt; &lt;plugins&gt; &lt;!--SpringBoot maven插件--&gt; &lt;!-- 可以将应用打成一个可执行的jar包 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;!-- 设置启动入口 --&gt; &lt;!-- manClass即使不配置 , SprinBoot也在打包的时候也清楚入口是哪个 , 其实不用配置 --&gt; &lt;configuration&gt; &lt;mainClass&gt;com.kk.DockerBootApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 3、写ymlserver: port: 6001 4、主启动package com.kk; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class DockerBootApplication { public static void main(String[] args) { SpringApplication.run (DockerBootApplication.class, args); } } 5、业务类package com.kk.controller; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.RestController; import java.util.UUID; @RestController public class OrderController { @Value(\"${server.port}\") private String port; @RequestMapping(\"/order/docker\") public String helloDocker() { return \"hello docker\" + \"\\t\" + port + \"\\t\" + UUID.randomUUID ( ).toString ( ); } @RequestMapping(value = \"/order/index\", method = RequestMethod.GET) public String index() { return \"服务端口号: \" + \"\\t\" + port + \"\\t\" + UUID.randomUUID ( ).toString ( ); } } 二、打 jar + dockerfile1、打包 2、编写Dockerfile# 基础镜像使用java FROM java:8 # 作者 MAINTAINER jack # VOLUME 指定临时文件目录为/tmp，在主机/var/lib/docker目录下创建了一个临时文件并链接到容器的/tmp VOLUME /tmp # 将jar包添加到容器中并更名为 jack_docker.jar ADD docker_jar.jar jack_docker.jar # 运行jar包 RUN bash -c 'touch /jack_docker.jar' ENTRYPOINT [\"java\",\"-jar\",\"/jack_docker.jar\"] #暴露6001端口作为微服务 EXPOSE 6001 3、构建镜像docker build -t jack_docker:1.6 . 4、运行容器docker run -d -p 6001:6001 jack_docker:1.6 5、访问测试 Ⅳ、Docker-compose容器编排一、概述1、是什么Docker-Compose是Docker官方的开源项目，快速构建多个容器，负责实现对Docker容器集群的快速编排。 2、安装1、下载：快速国内镜像 sudo curl -L https://get.daocloud.io/docker/compose/releases/download/1.25.1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose 2、安装 sudo chmod +x /usr/local/bin/docker-compose 3、测试 docker-compose --version 3、核心1、文件 docker-compose.yml 2、服务（service） 一个个应用容器实例，比如订单微服务、库存微服务、mysql容器、nginx容器或者redis容器 3、工程（project） 由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 二、步骤 编写Dockerfile定义各个微服务应用并构建出对应的镜像文件 使用 docker-compose.yml 定义一个完整业务单元，安排好整体应用中的各个容器服务。 最后，执行docker-compose up命令 来启动并运行整个应用程序，完成一键部署上线 三、命令 Compose常用命令docker-compose -h # 查看帮助docker-compose up # 启动所有docker-compose服务docker-compose up -d # 启动所有docker-compose服务并后台运行docker-compose down # 停止并删除容器、网络、卷、镜像。docker-compose exec yml里面的服务id # 进入容器实例内部 docker-compose exec docker-compose.yml文件中写的服务id /bin/bashdocker-compose ps # 展示当前docker-compose编排过的运行的所有容器docker-compose top # 展示当前docker-compose编排过的容器进程docker-compose logs yml里面的服务id # 查看容器输出日志docker-compose config # 检查配置docker-compose config -q # 检查配置，有问题才有输出docker-compose restart # 重启服务docker-compose start # 启动服务docker-compose stop # 停止服务 四、案例1、改造微服务1、建表 CREATE TABLE `t_user` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `username` varchar(50) NOT NULL DEFAULT '' COMMENT '用户名', `password` varchar(50) NOT NULL DEFAULT '' COMMENT '密码', `sex` tinyint(4) NOT NULL DEFAULT '0' COMMENT '性别 0=女 1=男 ', `deleted` tinyint(4) unsigned NOT NULL DEFAULT '0' COMMENT '删除标志，默认0不删除，1删除', `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间', `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间', PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT='用户表' 2、改pom &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.5.6&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;docker_boot&lt;/artifactId&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt; &lt;lombok.version&gt;1.16.18&lt;/lombok.version&gt; &lt;mysql.version&gt;5.1.47&lt;/mysql.version&gt; &lt;druid.version&gt;1.1.16&lt;/druid.version&gt; &lt;mapper.version&gt;4.1.5&lt;/mapper.version&gt; &lt;mybatis.spring.boot.version&gt;1.3.0&lt;/mybatis.spring.boot.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--guava Google 开源的 Guava 中自带的布隆过滤器--&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;23.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- redisson --&gt; &lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.13.4&lt;/version&gt; &lt;/dependency&gt; &lt;!--SpringBoot通用依赖模块--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--swagger2--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--SpringBoot与Redis整合依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--springCache--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--springCache连接池依赖包--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- jedis --&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--Mysql数据库驱动--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;!--SpringBoot集成druid连接池--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;${druid.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--mybatis和springboot整合--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${mybatis.spring.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 添加springboot对amqp的支持 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-codec&lt;/groupId&gt; &lt;artifactId&gt;commons-codec&lt;/artifactId&gt; &lt;version&gt;1.10&lt;/version&gt; &lt;/dependency&gt; &lt;!--通用基础配置junit/devtools/test/log4j/lombok/hutool--&gt; &lt;!--hutool--&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;5.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;${junit.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;${log4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;${lombok.version}&lt;/version&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!--persistence--&gt; &lt;dependency&gt; &lt;groupId&gt;javax.persistence&lt;/groupId&gt; &lt;artifactId&gt;persistence-api&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--通用Mapper--&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;version&gt;${mapper.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- &lt;build &gt; 主要用于编译设置 --&gt; &lt;build&gt; &lt;!-- 定义打包成jar的名字 --&gt; &lt;!-- 这里如果不定义 , 打包成的jar名字格式为 : &lt;artifactId&gt; + &lt;version&gt; --&gt; &lt;finalName&gt;docker_jar&lt;/finalName&gt; &lt;plugins&gt; &lt;!--SpringBoot maven插件--&gt; &lt;!-- 可以将应用打成一个可执行的jar包 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;!-- 设置启动入口 --&gt; &lt;!-- manClass即使不配置 , SprinBoot也在打包的时候也清楚入口是哪个 , 其实不用配置 --&gt; &lt;configuration&gt; &lt;mainClass&gt;com.kk.DockerBootApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 3、application.properties.properties server.port=6001 # ========================alibaba.druid相关配置===================== spring.datasource.type=com.alibaba.druid.pool.DruidDataSource spring.datasource.driver-class-name=com.mysql.jdbc.Driver spring.datasource.url=jdbc:mysql://106.52.23.202:3306/db2022?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false spring.datasource.username=root spring.datasource.password=root spring.datasource.druid.test-while-idle=false # ========================redis相关配置===================== spring.redis.database=0 spring.redis.host=106.12.159.22 spring.redis.port=6379 spring.redis.password= spring.redis.lettuce.pool.max-active=8 spring.redis.lettuce.pool.max-wait=-1ms spring.redis.lettuce.pool.max-idle=8 spring.redis.lettuce.pool.min-idle=0 # ========================mybatis相关配置=================== mybatis.mapper-locations=classpath:mapper/*.xml mybatis.type-aliases-package=com.kk.docker.entities # ========================swagger===================== spring.swagger2.enabled=true 4、主启动 package com.kk; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import tk.mybatis.spring.annotation.MapperScan; @SpringBootApplication @MapperScan(\"com.kk.docker.mapper\") public class DockerBootApplication { public static void main(String[] args) { SpringApplication.run (DockerBootApplication.class, args); } } 5、业务类 5-1、config配置类 RedisConfig package com.kk.docker.config; import lombok.extern.slf4j.Slf4j; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer; import org.springframework.data.redis.serializer.StringRedisSerializer; import java.io.Serializable; @Configuration @Slf4j public class RedisConfig { /** * @param lettuceConnectionFactory * @return redis序列化的工具配置类，下面这个请一定开启配置 * 127.0.0.1:6379&gt; keys * * 1) \"ord:102\" 序列化过 * 2) \"\\xac\\xed\\x00\\x05t\\x00\\aord:102\" 野生，没有序列化过 */ @Bean public RedisTemplate&lt;String, Serializable&gt; redisTemplate(LettuceConnectionFactory lettuceConnectionFactory) { RedisTemplate&lt;String, Serializable&gt; redisTemplate = new RedisTemplate&lt;&gt; ( ); redisTemplate.setConnectionFactory (lettuceConnectionFactory); //设置key序列化方式string redisTemplate.setKeySerializer (new StringRedisSerializer ( )); //设置value的序列化方式json redisTemplate.setValueSerializer (new GenericJackson2JsonRedisSerializer ( )); redisTemplate.setHashKeySerializer (new StringRedisSerializer ( )); redisTemplate.setHashValueSerializer (new GenericJackson2JsonRedisSerializer ( )); redisTemplate.afterPropertiesSet ( ); return redisTemplate; } } SwaggerConfig package com.kk.docker.config; import org.springframework.beans.factory.annotation.Value; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import springfox.documentation.builders.ApiInfoBuilder; import springfox.documentation.builders.PathSelectors; import springfox.documentation.builders.RequestHandlerSelectors; import springfox.documentation.service.ApiInfo; import springfox.documentation.spi.DocumentationType; import springfox.documentation.spring.web.plugins.Docket; import springfox.documentation.swagger2.annotations.EnableSwagger2; import java.text.SimpleDateFormat; import java.util.Date; @Configuration @EnableSwagger2 public class SwaggerConfig { @Value(\"${spring.swagger2.enabled}\") private Boolean enabled; @Bean public Docket createRestApi() { return new Docket (DocumentationType.SWAGGER_2) .apiInfo (apiInfo ( )) .enable (enabled) .select ( ) .apis (RequestHandlerSelectors.basePackage (\"com.kk.docker\")) //你自己的package .paths (PathSelectors.any ( )) .build ( ); } public ApiInfo apiInfo() { return new ApiInfoBuilder ( ) .title (\"java 学习 docker\" + \"\\t\" + new SimpleDateFormat (\"yyyy-MM-dd\").format (new Date ( ))) .description (\"docker-compose\") .version (\"1.0\") .termsOfServiceUrl (\"https://www.mykkto.cn\") .build ( ); } } 5-2、新建entity User package com.kk.docker.entirys; import javax.persistence.Column; import javax.persistence.GeneratedValue; import javax.persistence.Id; import javax.persistence.Table; import java.util.Date; @Table(name = \"t_user\") public class User { @Id @GeneratedValue(generator = \"JDBC\") private Integer id; /** * 用户名 */ private String username; /** * 密码 */ private String password; /** * 性别 0=女 1=男 */ private Byte sex; /** * 删除标志，默认0不删除，1删除 */ private Byte deleted; /** * 更新时间 */ @Column(name = \"update_time\") private Date updateTime; /** * 创建时间 */ @Column(name = \"create_time\") private Date createTime; /** * @return id */ public Integer getId() { return id; } /** * @param id */ public void setId(Integer id) { this.id = id; } /** * 获取用户名 * * @return username - 用户名 */ public String getUsername() { return username; } /** * 设置用户名 * * @param username 用户名 */ public void setUsername(String username) { this.username = username; } /** * 获取密码 * * @return password - 密码 */ public String getPassword() { return password; } /** * 设置密码 * * @param password 密码 */ public void setPassword(String password) { this.password = password; } /** * 获取性别 0=女 1=男 * * @return sex - 性别 0=女 1=男 */ public Byte getSex() { return sex; } /** * 设置性别 0=女 1=男 * * @param sex 性别 0=女 1=男 */ public void setSex(Byte sex) { this.sex = sex; } /** * 获取删除标志，默认0不删除，1删除 * * @return deleted - 删除标志，默认0不删除，1删除 */ public Byte getDeleted() { return deleted; } /** * 设置删除标志，默认0不删除，1删除 * * @param deleted 删除标志，默认0不删除，1删除 */ public void setDeleted(Byte deleted) { this.deleted = deleted; } /** * 获取更新时间 * * @return update_time - 更新时间 */ public Date getUpdateTime() { return updateTime; } /** * 设置更新时间 * * @param updateTime 更新时间 */ public void setUpdateTime(Date updateTime) { this.updateTime = updateTime; } /** * 获取创建时间 * * @return create_time - 创建时间 */ public Date getCreateTime() { return createTime; } /** * 设置创建时间 * * @param createTime 创建时间 */ public void setCreateTime(Date createTime) { this.createTime = createTime; } } UserDTO package com.kk.docker.entirys; import io.swagger.annotations.ApiModel; import io.swagger.annotations.ApiModelProperty; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; import lombok.ToString; import java.io.Serializable; import java.util.Date; @NoArgsConstructor @AllArgsConstructor @Data @ApiModel(value = \"用户信息\") @ToString public class UserDTO implements Serializable { @ApiModelProperty(value = \"用户ID\") private Integer id; @ApiModelProperty(value = \"用户名\") private String username; @ApiModelProperty(value = \"密码\") private String password; @ApiModelProperty(value = \"性别 0=女 1=男 \") private Byte sex; @ApiModelProperty(value = \"删除标志，默认0不删除，1删除\") private Byte deleted; @ApiModelProperty(value = \"更新时间\") private Date updateTime; @ApiModelProperty(value = \"创建时间\") private Date createTime; /** * @return id */ public Integer getId() { return id; } /** * @param id */ public void setId(Integer id) { this.id = id; } /** * 获取用户名 * * @return username - 用户名 */ public String getUsername() { return username; } /** * 设置用户名 * * @param username 用户名 */ public void setUsername(String username) { this.username = username; } /** * 获取密码 * * @return password - 密码 */ public String getPassword() { return password; } /** * 设置密码 * * @param password 密码 */ public void setPassword(String password) { this.password = password; } /** * 获取性别 0=女 1=男 * * @return sex - 性别 0=女 1=男 */ public Byte getSex() { return sex; } /** * 设置性别 0=女 1=男 * * @param sex 性别 0=女 1=男 */ public void setSex(Byte sex) { this.sex = sex; } /** * 获取删除标志，默认0不删除，1删除 * * @return deleted - 删除标志，默认0不删除，1删除 */ public Byte getDeleted() { return deleted; } /** * 设置删除标志，默认0不删除，1删除 * * @param deleted 删除标志，默认0不删除，1删除 */ public void setDeleted(Byte deleted) { this.deleted = deleted; } /** * 获取更新时间 * * @return update_time - 更新时间 */ public Date getUpdateTime() { return updateTime; } /** * 设置更新时间 * * @param updateTime 更新时间 */ public void setUpdateTime(Date updateTime) { this.updateTime = updateTime; } /** * 获取创建时间 * * @return create_time - 创建时间 */ public Date getCreateTime() { return createTime; } /** * 设置创建时间 * * @param createTime 创建时间 */ public void setCreateTime(Date createTime) { this.createTime = createTime; } } 5-3 新建mapper 新建接口UserMapper package com.kk.docker.mapper; import com.kk.docker.entirys.User; import tk.mybatis.mapper.common.Mapper; public interface UserMapper extends Mapper&lt;User&gt; { } src\\main\\resources路径下新建mapper文件夹并新增UserMapper.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;mapper namespace=\"com.atguigu.docker.mapper.UserMapper\"&gt; &lt;resultMap id=\"BaseResultMap\" type=\"com.kk.docker.entirys.User\"&gt; &lt;!-- WARNING - @mbg.generated --&gt; &lt;id column=\"id\" jdbcType=\"INTEGER\" property=\"id\"/&gt; &lt;result column=\"username\" jdbcType=\"VARCHAR\" property=\"username\"/&gt; &lt;result column=\"password\" jdbcType=\"VARCHAR\" property=\"password\"/&gt; &lt;result column=\"sex\" jdbcType=\"TINYINT\" property=\"sex\"/&gt; &lt;result column=\"deleted\" jdbcType=\"TINYINT\" property=\"deleted\"/&gt; &lt;result column=\"update_time\" jdbcType=\"TIMESTAMP\" property=\"updateTime\"/&gt; &lt;result column=\"create_time\" jdbcType=\"TIMESTAMP\" property=\"createTime\"/&gt; &lt;/resultMap&gt; &lt;/mapper&gt; 5-4 新建service package com.kk.docker.service; import com.kk.docker.entirys.User; import com.kk.docker.mapper.UserMapper; import lombok.extern.slf4j.Slf4j; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.stereotype.Service; import javax.annotation.Resource; @Service @Slf4j public class UserService { public static final String CACHE_KEY_USER = \"user:\"; @Resource private UserMapper userMapper; @Resource private RedisTemplate redisTemplate; /** * addUser * * @param user */ public void addUser(User user) { //1 先插入mysql并成功 int i = userMapper.insertSelective (user); if (i &gt; 0) { //2 需要再次查询一下mysql将数据捞回来并ok user = userMapper.selectByPrimaryKey (user.getId ( )); //3 将捞出来的user存进redis，完成新增功能的数据一致性。 String key = CACHE_KEY_USER + user.getId ( ); redisTemplate.opsForValue ( ).set (key, user); } } /**F * findUserById * * @param id * @return */ public User findUserById(Integer id) { User user = null; String key = CACHE_KEY_USER + id; //1 先从redis里面查询，如果有直接返回结果，如果没有再去查询mysql user = (User) redisTemplate.opsForValue ( ).get (key); if (user == null) { //2 redis里面无，继续查询mysql user = userMapper.selectByPrimaryKey (id); if (user == null) { //3.1 redis+mysql 都无数据 //你具体细化，防止多次穿透，我们规定，记录下导致穿透的这个key回写redis return user; } else { //3.2 mysql有，需要将数据写回redis，保证下一次的缓存命中率 redisTemplate.opsForValue ( ).set (key, user); } } return user; } public void deleteUser(Integer id) { } public void updateUser(User user) { } public User findUserById2(Integer id) { return null; } } 5-5 新建controller package com.kk.docker.controller; import cn.hutool.core.util.IdUtil; import com.kk.docker.entirys.User; import com.kk.docker.entirys.UserDTO; import com.kk.docker.service.UserService; import io.swagger.annotations.Api; import io.swagger.annotations.ApiOperation; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.BeanUtils; import org.springframework.web.bind.annotation.*; import javax.annotation.Resource; import java.util.Random; @Api(description = \"用户User接口\") @RestController @Slf4j public class UserController { @Resource private UserService userService; @ApiOperation(\"数据库新增3条记录\") @RequestMapping(value = \"/user/add\", method = RequestMethod.POST) public void addUser() { for (int i = 1; i &lt;= 3; i++) { User user = new User ( ); user.setUsername (\"jack\" + i); user.setPassword (IdUtil.simpleUUID ( ).substring (0, 6)); user.setSex ((byte) new Random ( ).nextInt (2)); userService.addUser (user); } } @ApiOperation(\"删除1条记录\") @RequestMapping(value = \"/user/delete/{id}\", method = RequestMethod.POST) public void deleteUser(@PathVariable Integer id) { userService.deleteUser (id); } @ApiOperation(\"修改1条记录\") @RequestMapping(value = \"/user/update\", method = RequestMethod.POST) public void updateUser(@RequestBody UserDTO userDTO) { User user = new User ( ); BeanUtils.copyProperties (userDTO, user); userService.updateUser (user); } @ApiOperation(\"查询1条记录\") @RequestMapping(value = \"/user/find/{id}\", method = RequestMethod.GET) public User findUserById(@PathVariable Integer id) { return userService.findUserById2 (id); } } 6、打包 7、编写 Dockerfile # 基础镜像使用java FROM java:8 # 作者 MAINTAINER jack # VOLUME 指定临时文件目录为/tmp，在主机/var/lib/docker目录下创建了一个临时文件并链接到容器的/tmp VOLUME /tmp # 将jar包添加到容器中并更名为 jack_docker.jar ADD docker_jar.jar jack_docker.jar # 运行jar包 RUN bash -c 'touch /jack_docker.jar' ENTRYPOINT [\"java\",\"-jar\",\"/jack_docker.jar\"] #暴露6001端口作为微服务 EXPOSE 6001 8、构建镜像 docker build -t jack_docker:1.7 . 9、运行 docker run -d -p 6001:6001 --name jackto17 jack_docker:1.7 10、访问 swageer http://106.XX.XX.XXX:6001/swagger-ui.html 2、不用Compose 单独启动容器 redis 单独启动容器 mysql 单独启动容器 微服务 3、存在的问题 先后顺序要求固定，先mysql+redis才能微服务访问成功 多个run命令…… 容器间的启停或宕机，有可能导致IP地址对应的容器实例变化，映射出错，要么生产IP写死(可以但是不推荐)，要么通过服务调用 4、使用Compose1、编写 docker-compose.yml文件 version: \"3\" services: microService: image: jack_docker:1.8 container_name: ms01 ports: - \"6001:6001\" volumes: - /app/microService:/data networks: - mykk_net depends_on: - redis - mysql redis: image: redis:6.0.8 ports: - \"6379:6379\" volumes: - /app/redis/redis.conf:/etc/redis/redis.conf - /app/redis/data:/data networks: - mykk_net command: redis-server /etc/redis/redis.conf mysql: image: mysql:5.7 environment: MYSQL_ROOT_PASSWORD: 'a1b2c3' MYSQL_ALLOW_EMPTY_PASSWORD: 'no' MYSQL_DATABASE: 'db2022' MYSQL_USER: 'jack' MYSQL_PASSWORD: 'a1b2c3' ports: - \"3306:3306\" volumes: - /app/mysql/db:/var/lib/mysql - /app/mysql/conf/my.cnf:/etc/my.cnf - /app/mysql/init:/docker-entrypoint-initdb.d networks: - mykk_net command: --default-authentication-plugin=mysql_native_password #解决外部无法访问 networks: mykk_net: 2、第二次修改微服务工程 docker_boot 2-1 改 YML：通过服务名访问，IP无关 2-2 打包，编写 Dockerfile 2-3 构建镜像 docker build -t jack_docker:1.8 . 3、执行 docker-compose 执行 docker-compose up或者执行 docker-compose up -d 4、创建表 docker exec -it 容器实例id /bin/bash mysql -uroot -p create database db2022; use db2022; CREATE TABLE t_user ( id INT(10) UNSIGNED NOT NULL AUTO_INCREMENT, username VARCHAR(50) NOT NULL DEFAULT ‘’ COMMENT ‘用户名’, password VARCHAR(50) NOT NULL DEFAULT ‘’ COMMENT ‘密码’, sex TINYINT(4) NOT NULL DEFAULT ‘0’ COMMENT ‘性别 0=女 1=男 ‘, deleted TINYINT(4) UNSIGNED NOT NULL DEFAULT ‘0’ COMMENT ‘删除标志，默认0不删除，1删除’, update_time TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT ‘更新时间’, create_time TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT ‘创建时间’, PRIMARY KEY (id)) ENGINE=INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4 COMMENT=’用户表’; 5、关停docker-compose stop 五、命令(docker-compose) Compose常用命令docker-compose -h # 查看帮助docker-compose up # 启动所有docker-compose服务docker-compose up -d # 启动所有docker-compose服务并后台运行docker-compose down # 停止并删除容器、网络、卷、镜像。docker-compose exec yml里面的服务id # 进入容器实例内部 docker-compose exec docker-compose.yml文件中写的服务id /bin/bashdocker-compose ps # 展示当前docker-compose编排过的运行的所有容器docker-compose top # 展示当前docker-compose编排过的容器进程docker-compose logs yml里面的服务id # 查看容器输出日志dokcer-compose config # 检查配置dokcer-compose config -q # 检查配置，有问题才有输出docker-compose restart # 重启服务docker-compose start # 启动服务docker-compose stop # 停止服务 参考地址 ↓1、docker 加速（博主简书）url：https://www.jianshu.com/p/f554c85b25c1 2、DockerBuild报错：The command ‘/bin/sh -c yum install -y vim‘ returned a non-zero code: 1url：https://blog.csdn.net/weixin_53402685/article/details/125296621 3、docker-compose 日志输出url：https://www.cnblogs.com/sunstudy/articles/16340509.html","categories":[{"name":"docker","slug":"docker","permalink":"https://mykkto.github.io/categories/docker/"}],"tags":[{"name":"docker-compose","slug":"docker-compose","permalink":"https://mykkto.github.io/tags/docker-compose/"},{"name":"dockerfile","slug":"dockerfile","permalink":"https://mykkto.github.io/tags/dockerfile/"},{"name":"docker网络","slug":"docker网络","permalink":"https://mykkto.github.io/tags/docker%E7%BD%91%E7%BB%9C/"}],"author":"mykk"},{"title":"大数据-Flink流式计算框架(JAVA)","slug":"13-大数据/01Flink/01_Flink技术栈","date":"2022-05-17T14:17:13.000Z","updated":"2022-06-09T14:02:31.652Z","comments":true,"path":"posts/1b79564d.html","link":"","permalink":"https://mykkto.github.io/posts/1b79564d.html","excerpt":"","text":"​ 0️⃣代码地址https://github.com/mykkTo/Flink_java.git Ⅰ、Flink 初识一、基本概述1、概述Flink 是 Apache 基金会旗下的一个开源大数据处理框架。目前，Flink 已经成为各大公司 大数据实时处理的发力重点，特别是国内以阿里为代表的一众互联网大厂都在全力投入，为 Flink 社区贡献了大量源码。如今 Flink 已被很多人认为是大数据实时处理的方向和未来，许多 公司也都在招聘和储备掌握 Flink 技术的人才。 2、源起和设计理念Flink 起源于一个叫作 Stratosphere 的项目，它是由 3 所地处柏林的大学和欧洲其他一些大 学在 2010~2014 年共同进行的研究项目，由柏林理工大学的教授沃克尔·马尔科（Volker Markl） 领衔开发。2014 年 4 月，Stratosphere 的代码被复制并捐赠给了 Apache 软件基金会，Flink 就 是在此基础上被重新设计出来的。 在德语中，“flink”一词表示“快速、灵巧”。项目的 logo 是一只彩色的松鼠，当然了， 这不仅是因为 Apache 大数据项目对动物的喜好（是否联想到了 Hadoop、Hive？），更是因为 松鼠这种小动物完美地体现了“快速、灵巧”的特点。关于 logo 的颜色，还一个有趣的缘由： 柏林当地的松鼠非常漂亮，颜色是迷人的红棕色；而 Apache 软件基金会的 logo，刚好也是一 根以红棕色为主的渐变色羽毛。于是，Flink 的松鼠 Logo 就设计成了红棕色，而且拥有一个漂 亮的渐变色尾巴，尾巴的配色与 Apache 软件基金会的 logo 一致。这只松鼠色彩炫目，既呼应 了 Apache 的风格，似乎也预示着 Flink 未来将要大放异彩。 二、Flink 的应用Flink 是一个大数据流处理引擎，它可以为不同的行业提供大数据实时处理的解决方案。 随着 Flink 的快速发展完善，如今在世界范围许多公司都可以见到 Flink 的身影。 目前在全球范围内，北美、欧洲和金砖国家均是 Flink 的应用热门区域。当然，这些地区 其实也就是 IT、互联网行业较发达的地区。 Flink 在国内热度尤其高，一方面是因为阿里的贡献和带头效应，另一方面也跟中国的应 用场景密切相关。中国的人口规模与互联网使用普及程度，决定了对大数据处理的速度要求越 来越高，也迫使中国的互联网企业去追逐更高的数据处理效率。试想在中国，一个网站可能要 面对数亿的日活用户、每秒数亿次的计算峰值，这对很多国外的公司来说是无法想象的。而 Flink 恰好给我们高速准确的处理海量流式数据提供了可能。 1、企业中的应用Flink 为全球许多公司和企业的关键业务应用提供了强大的支持。 对于数据处理而言，任何行业、任何公司的需求其实都是一样的：数据规模大、实时性要 求高、确保结果准确、方便扩展、故障后可恢复——而这些要求，作为新一代大数据流式处理 引擎的 Flink 统统可以满足！这也正是 Flink 在全世界范围得到广泛应用的原因。 2、主要的应用场景 电商和市场营销 举例：实时数据报表、广告投放、实时推荐 在电商行业中，网站点击量是统计 PV、UV 的重要来源，也是如今“流量经济”的最主要 数据指标。很多公司的营销策略，比如广告的投放，也是基于点击量来决定的。另外，在网站上提供给用户的实时推荐，往往也是基于当前用户的点击行为做出的。 网站获得的点击数据可能是连续且不均匀的，还可能在同一时间大量产生，这是典型的数 据流。如果我们希望把它们全部收集起来，再去分析处理，就会面临很多问题：首先，我们需 要很大的空间来存储数据；其次，收集数据的过程耗去了大量时间，统计分析结果的实时性就 大大降低了；另外，分布式处理无法保证数据的顺序，如果我们只以数据进入系统的时间为准， 可能导致最终结果计算错误。 我们需要的是直接处理数据流，而 Flink 就可以做到这一点。 物联网（IOT） 举例：传感器实时数据采集和显示、实时报警，交通运输业 物联网是流数据被普遍应用的领域。各种传感器不停获得测量数据，并将它们以流的形式 传输至数据中心。而数据中心会将数据处理分析之后，得到运行状态或者报警信息，实时地显 示在监控屏幕上。所以在物联网中，低延迟的数据传输和处理，以及准确的数据分析通常很关 键。 交通运输业也体现了流处理的重要性。比如说，如今高铁运行主要就是依靠传感器检测数 据，测量数据包括列车的速度和位置，以及轨道周边的状况。这些数据会从轨道传给列车，再 从列车传到沿途的其他传感器；与此同时，数据报告也被发送回控制中心。因为列车处于高速 行驶状态，因此数据处理的实时性要求是极高的。如果流数据没有被及时正确处理，调整意见 和警告就不能相应产生，后果可能会非常严重。 物流配送和服务业 举例：订单状态实时更新、通知信息推送 在很多服务型应用中，都会涉及订单状态的更新和通知的推送。这些信息基于事件触发， 不均匀地连续不断生成，处理之后需要及时传递给用户。这也是非常典型的数据流的处理。 银行和金融业 举例：实时结算和通知推送，实时检测异常行为 银行和金融业是另一个典型的应用行业。用户的交易行为是连续大量发生的，银行面对的 是海量的流式数据。由于要处理的交易数据量太大，以前的银行是按天结算的，汇款一般都要 隔天才能到账。所以有一个说法叫作“银行家工作时间”，说的就是银行家不仅不需要 996，甚 至下午早早就下班了：因为银行需要早点关门进行结算，这样才能保证第二天营业之前算出准 确的账。这显然不能满足我们快速交易的需求。在全球化经济中，能够提供 24 小时服务变得 越来越重要。现在交易和报表都会快速准确地生成，我们跨行转账也可以做到瞬间到账，还可以接到实时的推送通知。这就需要我们能够实时处理数据流。 另外，信用卡欺诈的检测也需要及时的监控和报警。一些金融交易市场，对异常交易行为 的及时检测可以更好地进行风险控制；还可以对异常登录进行检测，从而发现钓鱼式攻击，从 而避免巨大的损失。 三、流式计算演变我们已经了解，Flink 的主要应用场景，就是 处理大规模的数据流。那为什么一定要用 Flink 呢？数据处理还有没有其他的方式？要解答这个疑惑，我们就需要先从流处理和批处理的概念 讲起。 1、流处理和批处理数据处理有不同的方式。 对于具体应用来说，有些场景数据是一个一个来的，是一组有序的数据序列，我们把它叫作“数据流”；而有些场景的数据，本身就是一批同时到来，是一个有限的数据集，这就是批量数据（有时也直接叫数据集）。 容易想到，处理数据流，当然应该“来一个就处理一个”，这种数据处理模式就叫作流处理；因为这种处理是即时的，所以也叫实时处理。与之对应，处理批量数据自然就应该一批读入、一起计算，这种方式就叫作批处理，也叫作离线处理。 那真实的应用场景中，到底是数据流更常见、还是批量数据更常见呢？ 生活中，这两种形式的数据都有，如图 1-4 所示。比如我们日常发信息，可以一句一句地 说，也可以写一大段一起发过去。一句一句的信息，就是一个一个的数据，它们构成的序列就是一个数据流；而一大段信息，是一组数据的集合，对应就是批量数据（数据集）。 当然，有经验的人都会知道，一句一句地发，你一言我一语，有来有往这才叫聊天；一大 段信息直接砸过去，别人看着都眼晕，很容易就没下文了——如果是很重要的整篇内容（比如 表白信），写成文档或者邮件发过去可能效果会更好。 所以我们看到，“聊天”这个生活场景，数据的生成、传递和接收处理，都是流式的；而 “写信”的场景，数据的生成尽管应该也是流式的（字总得一个个写），但我们可以把它们收集起来，统一传输、统一处理（当然我们还可以进一步较真：处理也是流式的，字得一个一个读）。 不论传输处理的方式是怎样的，数据的生成，一般都是流式的。 2、传统事务处理IT 互联网公司往往会用不同的应用程序来处理各种业务。比如内部使用的企业资源规划 （ERP）系统、客户关系管理（CRM）系统，还有面向客户的 Web 应用程序。这些系统一般都 会进行分层设计：“计算层”就是应用程序本身，用于数据计算和处理；而“存储层”往往是传统的关系型数据库，用于数据存储，如图 我们发现，这里的应用程序在处理数据的模式上有共同之处：接收的数据是持续生成的事 件，比如用户的点击行为，客户下的订单，或者操作人员发出的请求。处理事件时，应用程序 需要先读取远程数据库的状态，然后按照处理逻辑得到结果，将响应返回给用户，并更新数据库状态。一般来说，一个数据库系统可以服务于多个应用程序，它们有时会访问相同的数据库或表 对于各种事件请求，事务处理的方式能够保证实时响应，好处是一目了然的。但是我们知道，这样的架构对表和数据库的设计要求很高；当数据规模越来越庞大、系统越来越复杂时，可能需要对表进行重构，而且一次联表查询也会花费大量的时间，甚至不能及时得到返回结果。于是，作为程序员就只好将更多的精力放在表的设计和重构，以及 SQL 的调优上，而无法专注于业务逻辑的实现了——我们都知道，这种工作费力费时，却没法直接体现在产品上给老板看，简直就是噩梦。 那有没有更合理、更高效的处理架构呢？↓ 3、有状态的流处理不难想到，如果我们对于事件流的处理非常简单，例如收到一条请求就返回一个“收到”，那就可以省去数据库的查询和更新了。但是这样的处理是没什么实际意义的。在现实的应用中，往往需要还其他一些额外数据。我们可以把需要的额外数据保存成一个“状态”，然后针对这条数据进行处理，并且更新状态。在传统架构中，这个状态就是保存在数据库里的。这就是所谓的“有状态的流处理”。 为了加快访问速度，我们可以直接将状态保存在本地内存，如图所示。 当应用收到一个新事件时，它可以从状态中读取数据，也可以更新状态。而当状态是从内存中读写的时候，这就和访问本地变量没什么区别了，实时性可以得到极大的提升。 另外，数据规模增大时，我们也不需要做重构，只需要构建分布式集群，各自在本地计算就可以了，可扩展性也变得更好。 因为采用的是一个分布式系统，所以还需要保护本地状态，防止在故障时数据丢失。我们可以定期地将应用状态的一致性检查点（checkpoint）存盘，写入远程的持久化存储，遇到故障时再去读取进行恢复，这样就保证了更好的容错性。 4、有状态流架构1、事件驱动型（Event-Driven）应用 事件驱动型应用是一类具有状态的应用，它从一个或多个事件流提取数据，并根据到来的 事件触发计算、状态更新或其他外部动作。比较典型的就是以 Kafka 为代表的消息队列几乎都 是事件驱动型应用。 这其实跟传统事务处理本质上是一样的，区别在于基于有状态流处理的事件驱动应用，不 再需要查询远程数据库，而是在本地访问它们的数据，如图上所示，这样在吞吐量和延迟方 面就可以有更好的性能。 另外远程持久性存储的检查点保证了应用可以从故障中恢复。检查点可以异步和增量地完 成，因此对正常计算的影响非常小 2、数据分析（Data Analysis）型应用 所谓的数据分析，就是从原始数据中提取信息和发掘规律。传统上，数据分析一般是先将 数据复制到数据仓库（Data Warehouse），然后进行批量查询。如果数据有了更新，必须将最 新数据添加到要分析的数据集中，然后重新运行查询或应用程序。 如今，Apache Hadoop 生态系统的组件，已经是许多企业大数据架构中不可或缺的组成部 分。现在的做法一般是将大量数据（如日志文件）写入 Hadoop 的分布式文件系统（HDFS）、 S3 或 HBase 等批量存储数据库，以较低的成本进行大容量存储。然后可以通过 SQL-on-Hadoop 类的引擎查询和处理数据，比如大家熟悉的 Hive。这种处理方式，是典型的批处理，特点是 可以处理海量数据，但实时性较差，所以也叫离线分析。 如果我们有了一个复杂的流处理引擎，数据分析其实也可以实时执行。流式查询或应用程 序不是读取有限的数据集，而是接收实时事件流，不断生成和更新结果。结果要么写入外部数 据库，要么作为内部状态进行维护。 Apache Flink 同时支持流式与批处理的数据分析应用 与批处理分析相比，流处理分析最大的优势就是低延迟，真正实现了实时。另外，流处理 不需要去单独考虑新数据的导入和处理，实时更新本来就是流处理的基本模式。当前企业对流 式数据处理的一个热点应用就是实时数仓，很多公司正是基于 Flink 来实现的。 3、数据管道（Data Pipeline）型应用 如图，ETL 与数据管道之间的区别 ETL 也就是数据的提取、转换、加载，是在存储系统之间转换和移动数据的常用方法。 在数据分析的应用中，通常会定期触发 ETL 任务，将数据从事务数据库系统复制到分析数据 库或数据仓库。 所谓数据管道的作用与 ETL 类似。它们可以转换和扩展数据，也可以在存储系统之间移 动数据。不过如果我们用流处理架构来搭建数据管道，这些工作就可以连续运行，而不需要再 去周期性触发了。比如，数据管道可以用来监控文件系统目录中的新文件，将数据写入事件日 志。连续数据管道的明显优势是减少了将数据移动到目的地的延迟，而且更加通用，可以用于 更多的场景。 4、Lambda 架构 对于有状态的流处理，当数据越来越多时，我们必须用分布式的集群架构来获取更大的吞 吐量。但是分布式架构会带来另一个问题：怎样保证数据处理的顺序是正确的呢？ 对于批处理来说，这并不是一个问题。因为所有数据都已收集完毕，我们可以根据需要选 择、排列数据，得到想要的结果。可如果我们采用“来一个处理一个”的流处理，就可能出现 “乱序”的现象：本来先发生的事件，因为分布处理的原因滞后了。怎么解决这个问题呢？ 以 Storm 为代表的第一代分布式开源流处理器，主要专注于具有毫秒延迟的事件处理，特 点就是一个字“快”；而对于准确性和结果的一致性，是不提供内置支持的，因为结果有可能 取决于到达事件的时间和顺序。另外，第一代流处理器通过检查点来保证容错性，但是故障恢 复的时候，即使事件不会丢失，也有可能被重复处理——所以无法保证 exactly-once。 与批处理器相比，可以说第一代流处理器牺牲了结果的准确性，用来换取更低的延迟。而 批处理器恰好反过来，牺牲了实时性，换取了结果的准确 我们自然想到，如果可以让二者做个结合，不就可以同时提供快速和准确的结果了吗？正 是基于这样的思想，Lambda 架构被设计出来，如上图。我们可以认为这是第二代流处 理架构，但事实上，它只是第一代流处理器和批处理器的简单合并。 5、新一代流处理器 之前的分布式流处理架构，都有明显的缺陷，人们也一直没有放弃对流处理器的改进和完 善。终于，在原有流处理器的基础上，新一代分布式开源流处理器诞生了。为了与之前的系统 区分，我们一般称之为第三代流处理器，代表当然就是 Flink。 第三代流处理器通过巧妙的设计，完美解决了乱序数据对结果正确性的影响。这一代系统 还做到了精确一次（exactly-once）的一致性保障，是第一个具有一致性和准确结果的开源流 处理器。另外，先前的流处理器仅能在高吞吐和低延迟中二选一，而新一代系统能够同时提供 这两个特性。所以可以说，这一代流处理器仅凭一套系统就完成了 Lambda 架构两套系统的工 作，它的出现使得 Lambda 架构黯然失色。 除了低延迟、容错和结果准确性之外，新一代流处理器还在不断添加新的功能，例如高可 用的设置，以及与资源管理器（如 YARN 或 Kubernetes）的紧密集成等等。 四、Flink 的特性总结Flink 是第三代分布式流处理器，它的功能丰富而强大。 1、核心特性 高吞吐和低延迟。每秒处理数百万个事件，毫秒级延迟。 结果的准确性。Flink 提供了事件时间（event-time）和处理时间（processing-time） 语义。对于乱序事件流，事件时间语义仍然能提供一致且准确的结果。 精确一次（exactly-once）的状态一致性保证。 可以连接到最常用的存储系统，如 Apache Kafka、Apache Cassandra、Elasticsearch、 JDBC、Kinesis 和（分布式）文件系统，如 HDFS 和 S3。 高可用。本身高可用的设置，加上与 K8s，YARN 和 Mesos 的紧密集成，再加上从故 障中快速恢复和动态扩展任务的能力，Flink 能做到以极少的停机时间 7×24 全天候 运行 能够更新应用程序代码并将作业（jobs）迁移到不同的 Flink 集群，而不会丢失应用 程序的状态。 2、分层 API除了上述这些特性之外，Flink 还是一个非常易于开发的框架，因为它拥有易于使用的分层 API，整体 API 分层如图： 最底层级的抽象仅仅提供了有状态流，它将处理函数（Process Function）嵌入到了 DataStream API 中。底层处理函数（Process Function）与 DataStream API 相集成，可以对某 些操作进行抽象，它允许用户可以使用自定义状态处理来自一个或多个数据流的事件，且状态 具有一致性和容错保证。除此之外，用户可以注册事件时间并处理时间回调，从而使程序可以 处理复杂的计算。 实际上，大多数应用并不需要上述的底层抽象，而是直接针对核心 API（Core APIs） 进 行编程，比如 DataStream API（用于处理有界或无界流数据）以及 DataSet API（用于处理有界 数据集）。这些 API 为数据处理提供了通用的构建模块，比如由用户定义的多种形式的转换 （transformations）、连接（joins）、聚合（aggregations）、窗口（windows）操作等。 五、Flink vs Spark1、数据处理架构我们已经知道，数据处理的基本方式，可以分为批处理和流处理两种。 批处理针对的是有界数据集，非常适合需要访问海量的全部数据才能完成的计算工作，一 般用于离线统计。 流处理主要针对的是数据流，特点是无界、实时, 对系统传输的每个数据依次执行操作， 一般用于实时统计。 从根本上说，Spark 和 Flink 采用了完全不同的数据处理方式。可以说，两者的世界观是 截然相反的。 Spark 以批处理为根本，并尝试在批处理之上支持流计算；在 Spark 的世界观中，万物皆批次，离线数据是一个大批次，而实时数据则是由一个一个无限的小批次组成的。所以对于流处理框架 Spark Streaming 而言，其实并不是真正意义上的“流”处理，而是“微批次” （micro-batching）处理 1.无界数据流所谓无界数据流，就是有头没尾，数据的生成和传递会开始但永远不会结束，我们无法等待所有数据都到达，因为输入是无界的，永无止境，数据没有“都到达”的 时候。所以对于无界数据流，必须连续处理，也就是说必须在获取数据后立即处理。在处理无界流时，为了保证结果的正确性，我们必须能够做到按照顺序处理数据。 2.无界数据流有界数据流有明确定义的开始和结束，所以我们可以通过获取所有数据来处理有界流。处理有界流就不需要严格保证数据的顺序了，因为总可以对有界数据集进行排序。有界流的处理也就是批处理。 正因为这种架构上的不同，Spark 和 Flink 在不同的应用领域上表现会有差别。一般来说，Spark 基于微批处理的方式做同步总有一个“攒批”的过程，所以会有额外开销，因此无法在流处理的低延迟上做到极致。在低延迟流处理场景，Flink 已经有明显的优势。而在海量数据的批处理领域，Spark 能够处理的吞吐量更大，加上其完善的生态和成熟易用的 API，目前同样优势比较明显。 2、数据模型和运行架构 除了三观不合，Spark 和 Flink 在底层实现最主要的差别就在于数据模型不同。 Spark 底层数据模型是弹性分布式数据集（RDD），Spark Streaming 进行微批处理的底层 接口 DStream，实际上处理的也是一组组小批数据 RDD 的集合。可以看出，Spark 在设计上本 身就是以批量的数据集作为基准的，更加适合批处理的场景。 而 Flink 的基本数据模型是数据流（DataFlow），以及事件（Event）序列。Flink 基本上是 完全按照 Google 的 DataFlow 模型实现的，所以从底层数据模型上看，Flink 是以处理流式数 据作为设计目标的，更加适合流处理的场景。 数据模型不同，对应在运行处理的流程上，自然也会有不同的架构。Spark 做批计算，需 要将任务对应的 DAG 划分阶段（Stage），一个完成后经过 shuffle 再进行下一阶段的计算。而 Flink 是标准的流式执行模式，一个事件在一个节点处理完后可以直接发往下一个节点进行处理。 3、Spark 还是 FlinkSpark 和 Flink 可以说目前是各擅胜场，批处理领域 Spark 称王，而在流处理方面 Flink 当仁不让。具体到项目应用中，不仅要看是流处理还是 批处理，还需要在延迟、吞吐量、可靠性，以及开发容易度等多个方面进行权衡。 如果在工作中需要从 Spark 和 Flink 这两个主流框架中选择一个来进行实时流处理，我们更加推荐使用 Flink，主要的原因有： Flink 的延迟是毫秒级别，而 Spark Streaming 的延迟是秒级延迟。 Flink 提供了严格的精确一次性语义保证。 Flink 的窗口 API 更加灵活、语义更丰富。 Flink 提供事件时间语义，可以正确处理延迟数据。 Flink 提供了更加灵活的对状态编程的 API。 Ⅱ、Flink 部署一、Flink 快速上手1、创建项目(1.8)1、maven在项目的 pom 文件中，增加标签设置属性，然后增加标签引入需要的依赖。我们需要添加的依赖最重要的就是 Flink 的相关组件，包括 flink-java、 flink-streaming-java，以及 flink-clients（客户端，也可以省略）。另外，为了方便查看运行日志， 我们引入 slf4j 和 log4j 进行日志理。 &lt;properties&gt; &lt;flink.version&gt;1.13.0&lt;/flink.version&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;scala.binary.version&gt;2.12&lt;/scala.binary.version&gt; &lt;slf4j.version&gt;1.7.30&lt;/slf4j.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- 引入 Flink 相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-java&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-streaming-java_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-clients_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 引入日志管理相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-to-slf4j&lt;/artifactId&gt; &lt;version&gt;2.14.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 在属性中，我们定义了&lt;scala.binary.version&gt;，这指代的是所依赖的 Scala 版本。这有一点奇怪：Flink 底层是 Java，而且我们也只用 Java API，为什么还会依赖 Scala 呢？这是因为 Flink的架构中使用了 Akka 来实现底层的分布式通信，而 Akka 是用 Scala 开发的 2、配置日志管理在目录 src/main/resources 下添加文件:log4j.properties，内容配置如下： log4j.rootLogger=error, stdout log4j.appender.stdout=org.apache.log4j.ConsoleAppender log4j.appender.stdout.layout=org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern=%-4r [%t] %-5p %c %x - %m%n 2、编写代码搭好项目框架，接下来就是我们的核心工作——往里面填充代码。我们会用一个最简单的示例来说明 Flink 代码怎样编写：统计一段文字中，每个单词出现的频次。这就是传说中的 WordCount 程序——它是大数据领域非常经典的入门案例，地位等同于初学编程语言时的Hello World。 1、批处理 1、根目录下创建一个 txt文件，内容如下 hello world hello flink hello java 2、思路 先逐行读入文件数据，然后将每一行文字拆分成单词；接着按照单词分组，统计每组数据的个数，就是对应单词的频次。 3、Java 类 BatchWordCount package com.kk.wc; import org.apache.flink.api.common.typeinfo.Types; import org.apache.flink.api.java.ExecutionEnvironment; import org.apache.flink.api.java.operators.AggregateOperator; import org.apache.flink.api.java.operators.DataSource; import org.apache.flink.api.java.operators.FlatMapOperator; import org.apache.flink.api.java.operators.UnsortedGrouping; import org.apache.flink.api.java.tuple.Tuple2; import org.apache.flink.util.Collector; public class BatchWordCount { public static void main(String[] args) throws Exception { // 1. 创建执行环境 ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment ( ); // 2. 从文件读取数据 按行读取(存储的元素就是每行的文本) DataSource&lt;String&gt; listDateSource = env.readTextFile (\"input/words.txt\"); // 3. 将每行数据进行分词，转换成二元组类型 // Collector: flink 定义的收集器 // Tuple: 二元组类型 &lt;String,Long&gt;,K 就是具体的单词，V 就是个数 FlatMapOperator&lt;String, Tuple2&lt;String, Long&gt;&gt; wordAndOneTuple = listDateSource.flatMap ((String line, Collector&lt;Tuple2&lt;String, Long&gt;&gt; out) -&gt; { // 每行根据空格分隔出，单词 String[] words = line.split (\" \"); // out.collect 就是输出的意思 for (String word : words) { // Tuple2.of 构建二元组实例 out.collect (Tuple2.of (word, 1L)); } }) // returns 解决 scala 泛型擦除问题 .returns (Types.TUPLE (Types.STRING, Types.LONG)); // 根据转换得到的运算子 wordAndOneTuple // 4. 按照 word 进行分组, 0 表示第 1 个字段索引，就是上面泛型&lt;k,v&gt; 中的 k 为 word 字段 UnsortedGrouping&lt;Tuple2&lt;String, Long&gt;&gt; wordAndOneGroup = wordAndOneTuple.groupBy (0); // 5. 分组进行聚合(求和)统计，1 表示第 2 个字段索引，就是上面泛型&lt;k,v&gt; 中的 v 为 1L 数值的字段 AggregateOperator&lt;Tuple2&lt;String, Long&gt;&gt; sum = wordAndOneGroup.sum (1); // 6. 打印 sum.print ( ); } } 2、流处理（有界）package com.kk.wc; import org.apache.flink.api.common.typeinfo.Types; import org.apache.flink.api.java.tuple.Tuple2; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.datastream.KeyedStream; import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; import org.apache.flink.util.Collector; /* * @Description: 流处理有界流 * @Author: 阿K * @CreateDate: 2022/5/19 21:14 * @Param: * @Return: **/ public class BoundedStreamWordCount { public static void main(String[] args) throws Exception{ // 1. 创建流式执行环境 StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); // 2. 从文件读取数据 按行读取(存储的元素就是每行的文本) DataStreamSource&lt;String&gt; listDateSource = env.readTextFile (\"input/words.txt\"); // 3. 将每行数据进行分词，转换成二元组类型 SingleOutputStreamOperator&lt;Tuple2&lt;String, Long&gt;&gt; wordAndOne = listDateSource.flatMap ((String line, Collector&lt;Tuple2&lt;String,Long&gt;&gt; out) -&gt; { String[] words = line.split (\" \"); for (String word : words) { out.collect (Tuple2.of (word,1L)); } }).returns (Types.TUPLE (Types.STRING, Types.LONG)); // 4. 分组(keyBy 按照 key 分组 KeyedStream&lt;Tuple2&lt;String, Long&gt;, String&gt; wordAndOneKS = wordAndOne.keyBy (data -&gt; data.f0); // 5. 求和 SingleOutputStreamOperator&lt;Tuple2&lt;String, Long&gt;&gt; result = wordAndOneKS.sum (1); // 6. 打印 result.print (); // 7. 执行 env.execute (); } } 3、流处理（无界）利用 nc 模拟实时推送，可以参考底下 【5】 package com.kk.wc; import org.apache.flink.api.common.typeinfo.Types; import org.apache.flink.api.java.tuple.Tuple2; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.datastream.KeyedStream; import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; import org.apache.flink.util.Collector; /* * @Description: 流式计算（nc 测试无界流） * @Author: 阿K * @CreateDate: 2022/5/19 22:43 * @Param: * @Return: **/ public class StreamWordCount { public static void main(String[] args) throws Exception{ // 1. 创建流式执行环境 StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); // 2. 读取文本流(远程机) DataStreamSource&lt;String&gt; lineDataStream = env.socketTextStream (\"101.34.180.133\", 7777); // 3. 将每行数据进行分词，转换成二元组类型 SingleOutputStreamOperator&lt;Tuple2&lt;String, Long&gt;&gt; wordAndOne = lineDataStream.flatMap ((String line, Collector&lt;Tuple2&lt;String,Long&gt;&gt; out) -&gt; { String[] words = line.split (\" \"); for (String word : words) { out.collect (Tuple2.of (word,1L)); } }).returns (Types.TUPLE (Types.STRING, Types.LONG)); // 4. 分组(keyBy 按照 key 分组 KeyedStream&lt;Tuple2&lt;String, Long&gt;, String&gt; wordAndOneKS = wordAndOne.keyBy (data -&gt; data.f0); // 5. 求和 SingleOutputStreamOperator&lt;Tuple2&lt;String, Long&gt;&gt; result = wordAndOneKS.sum (1); // 6. 打印 result.print (); // 7. 执行 env.execute (); } } 测试上面可以用 nc 测试（实时模拟数据发送） 二、作业部署1、搭建FlinkFlink 是一个分布式的流处理框架，所以实际应用一般都需要搭建集群环境。作者初学就搭建单机好了 有条件就用 docker 快速占用小，可以参考下面第六 1.官网下载flink-1.13.0-bin-scala_2.12.tgz 2.解压mkdir /opt/module/ tar -zxvf flink-1.13.0-bin-scala_2.12.tgz -C /opt/module/ 3.启动cd flink-1.13.0/ # 启动 bin/start-cluster.sh # 停止 bin/stop-cluster.sh 2、打包&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;FlinkTutorial&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;flink.version&gt;1.13.0&lt;/flink.version&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;scala.binary.version&gt;2.12&lt;/scala.binary.version&gt; &lt;slf4j.version&gt;1.7.30&lt;/slf4j.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- 引入Flink相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-java&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-streaming-java_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-clients_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-kafka_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.bahir&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-redis_2.11&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-elasticsearch6_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-jdbc_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-statebackend-rocksdb_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;1.13.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-table-api-java-bridge_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-table-planner-blink_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-streaming-scala_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-csv&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-cep_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 引入日志管理相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-to-slf4j&lt;/artifactId&gt; &lt;version&gt;2.14.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt; &lt;version&gt;2.7.5&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;${java.version}&lt;/source&gt; &lt;target&gt;${java.version}&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 会生成两个 jar ，一个有 flink依赖的比较大，一个没有依赖的比较小 3、提交作业1、选择一个 jar 小的那个没有依赖的 2、上传，登录UI面板：http://101.34.180.133:8081/ 3、配置启动类 一个节点选择 1，两个节点选择 2 4、启动 nc 模拟 5、任务提交成功之后，可点击左侧导航栏的“Running Jobs”查看程序运行列表情况 Ⅲ、DataStream API一、概念DataStream（数据流）本身是 Flink 中一个用来表示数据集合的类，这套核心 API 可以做流处理以及批处理,这套API 主要做的是数据的转换 一个 Flink 程序，其实就是对 DataStream 的各种转换。具体来说，代码基本上都由以下几部分构成 获取执行环境 读取数据源 定义基于数据的转换操作 定义计算结果的输出位置 触发程序执行 二、执行环境运行环境：本地 JVM 中执行程序，也可以提交到远程集群上运行。 1、创建执行环境我 们 要 获 取 的 执 行 环 境 ， 是 StreamExecutionEnvironment 类的对象，这是所有 Flink 程序的基础。 创建执行环境的方式，就是调用这个类的静态方法，具体有以下三种： getExecutionEnvironment StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); - 智能判断：如果当前程序是独立运行，则返回一个本地环境；如果是集群环境，则返回集群环境 - **createLocalEnvironment** - ```java StreamExecutionEnvironment localEnv = StreamExecutionEnvironment.createLocalEnvironment ( ); 这个方法返回一个本地执行环境。可以在调用时传入一个参数，指定默认的并行度；如果不传入，则默认并行度就是本地的 CPU 核心数。 createRemoteEnvironment StreamExecutionEnvironment remoteEnv = StreamExecutionEnvironment .createRemoteEnvironment ( \"host\", // JobManager 主机名 1234, // JobManager 进程端口号 \"path/to/jarFile.jar\" // 提交给 JobManager 的 JAR 包 ); - 在获取到程序执行环境后，还可以对执行环境进行灵活的设置。比如可以全局设置程序的并行度、禁用算子链，还可以定义程序的时间语义、配置容错机制。关于时间语义和容错机制 #### 2、执行模式 ```java // 批处理环境 ExecutionEnvironment batchEnv = ExecutionEnvironment.getExecutionEnvironment ( ); // 流处理环境 StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); 3、触发程序执行1、当 main()方法被调用时，其实只是定义了作业的每个执行操作，然后添加到数据流图中；这时并没有真正处理数据【因为数据可能还没来】 2、只有等到数据到来，才会触发真正的计算，这也被称为“延迟执行”或“懒执行” 3、所以我们需要显式地调用执行环境的 execute()方法，来触发程序执行。execute()方法将一直等待作业完成，然后返回一个执行结果 env.execute(); 三、源算子1、准备工作为了更好地理解，我们先构建一个实际应用场景。比如网站的访问操作，可以抽象成一个三元组（用户名，用户访问的 urrl，用户访问 url 的时间戳），所以在这里，我们可以创建一个类 Event，将用户行为包装成它的一个对象。Event 包含了以下一些字段 字段名 数据类型 说明 user String 用户名 url String 用户访问的url timeStamp Long 用户访问url的时间戳 package com.kk.model2.pojo; import lombok.AllArgsConstructor; import lombok.NoArgsConstructor; import lombok.ToString; @NoArgsConstructor @AllArgsConstructor @ToString public class Event { public String user; public String url; public Long timestamp; } 这里需要注意，我们定义的 Event，有这样几个特点： 类是公有（public）的 有一个无参的构造方法 所有属性都是公有（public）的 所有属性的类型都是可以序列化的 Flink 会把这样的类作为一种特殊的 POJO 数据类型来对待，方便数据的解析和序列化。 2、常规读数据集合读数据-文件读数据-Socket 读数据 package com.kk.model2; import com.kk.model2.pojo.Event; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; import java.util.ArrayList; /* * @Description: 集合中读取数据 * @Author: 阿K * @CreateDate: 2022/5/24 22:04 * @Param: * @Return: **/ public class SourceTest1 { public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); // 设置并行度为 1 ，保证有序运行 env.setParallelism (1); // 1.从文件中读取数据 DataStreamSource&lt;String&gt; stream1 = env.readTextFile (\"input/clicks.csv\"); // 2.从集合中读取数据 ArrayList&lt;Integer&gt; nums = new ArrayList&lt;&gt; ( ); nums.add (2); nums.add (5); DataStreamSource&lt;Integer&gt; numStream = env.fromCollection (nums); ArrayList&lt;Event&gt; events = new ArrayList&lt;&gt; ( ); events.add (new Event (\"Mary\", \"./home\", 1000L)); events.add (new Event (\"Bob\", \"./cart\", 2000L)); DataStreamSource&lt;Event&gt; stream2 = env.fromCollection (events); // 3.从元素读取数据 DataStreamSource&lt;Event&gt; stream3 = env.fromElements ( new Event (\"Mary\", \"./home\", 1000L), new Event (\"Bob\", \"./cart\", 2000L) ); // 从Socket文本流读取 DataStreamSource&lt;String&gt; stream4 = env.socketTextStream (\"localhost\", 7777); // stream1.print(\"1\"); // numStream.print(\"nums\"); // stream2.print(\"2\"); // stream3.print(\"3\"); stream4.print (\"4\"); env.execute ( ); } } 3、Kafka 读数据 ★Flink 官方提供的是一个通用的 Kafka 连接器，它会自动跟踪最新版本的 Kafka 客户端 &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-kafka_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; 然后调用 env.addSource()，传入 FlinkKafkaConsumer 的对象实例就可以了 package com.kk.model2; import org.apache.flink.api.common.serialization.SimpleStringSchema; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer; import java.util.Properties; public class SourceKafkaTest { public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.setParallelism (1); Properties properties = new Properties ( ); properties.setProperty (\"bootstrap.servers\", \"106.12.159.22:9092\"); // properties.setProperty(\"group.id\", \"consumer-group\"); // properties.setProperty(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); // properties.setProperty(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); // properties.setProperty(\"auto.offset.reset\", \"latest\"); DataStreamSource&lt;String&gt; stream = env.addSource (new FlinkKafkaConsumer&lt;String&gt; ( \"sun\", new SimpleStringSchema ( ), properties )); stream.print ( ); env.execute ( ); } } 创建 FlinkKafkaConsumer 时需要传入三个参数： ⚫ 第一个参数 topic，定义了从哪些主题中读取数据。可以是一个 topic，也可以是 topic列表，还可以是匹配所有想要读取的 topic 的正则表达式。当从多个 topic 中读取数据时，Kafka 连接器将会处理所有 topic 的分区，将这些分区的数据放到一条流中去。 ⚫ 第二个参数是一个 DeserializationSchema 或者 KeyedDeserializationSchema。Kafka 消息被存储为原始的字节数据，所以需要反序列化成 Java 或者 Scala 对象。上面代码中使用的 SimpleStringSchema，是一个内置的 DeserializationSchema，它只是将字节数组简单地反序列化成字符串。DeserializationSchema 和 KeyedDeserializationSchema 是公共接口，所以我们也可以自定义反序列化逻辑。 ⚫ 第三个参数是一个 Properties 对象，设置了 Kafka 客户端的一些属性。 结果： 4、自定义 Source想要读取的数据源来自某个外部系统，而 flink 既没有预实现的方法、也没有提供连接器， 我们创建一个自定义的数据源，实现 SourceFunction 接口 ⚫ run()方法：使用运行时上下文对象（SourceContext）向下游发送数据； ⚫ cancel()方法：通过标识位控制退出循环，来达到中断数据源的效果。 package com.kk.model2; import com.kk.model2.pojo.Event; import org.apache.flink.streaming.api.functions.source.SourceFunction; import java.util.Calendar; import java.util.Random; public class ClickSource implements SourceFunction&lt;Event&gt; { // 声明一个布尔变量，作为控制数据生成的标识位 private Boolean running = true; @Override public void run(SourceContext&lt;Event&gt; ctx) throws Exception { // 在指定的数据集中随机选取数据 Random random = new Random ( ); String[] users = {\"Mary\", \"Alice\", \"Bob\", \"Cary\"}; String[] urls = {\"./home\", \"./cart\", \"./fav\", \"./prod?id=1\", \"./prod?id=2\"}; while (running) { ctx.collect (new Event ( users[random.nextInt (users.length)], urls[random.nextInt (urls.length)], Calendar.getInstance ( ).getTimeInMillis ( ) )); // 隔 1 秒生成一个点击事件，方便观测 Thread.sleep (1000); } } @Override public void cancel() { running = false; } } 这个数据源，我们后面会频繁使用，所以在后面的代码中涉及到 ClickSource()数据源，使用上面的代码就可以了。 下面的代码我们来读取一下自定义的数据源。有了自定义的 source function，接下来只要调用 addSource()就可以了 public static void main(String[] args) throws Exception{ StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.setParallelism (1); // 有了自定义的 source function，调用 addSource 方法 DataStreamSource&lt;Event&gt; stream = env.addSource(new ClickSource()); stream.print(\"SourceCustom\"); env.execute(); } 所以如果我们想要自定义并行的数据源的话，需要使用 ParallelSourceFunction public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.addSource (new CustomSource ( )).setParallelism (2).print ( ); env.execute ( ); } public static class CustomSource implements ParallelSourceFunction&lt;Integer&gt; { private boolean running = true; private Random random = new Random ( ); @Override public void run(SourceContext&lt;Integer&gt; sourceContext) throws Exception { while (running) { sourceContext.collect (random.nextInt ( )); } } @Override public void cancel() { running = false; } } 5、Flink 支持的数据类型1. Flink 的类型系统Flink 有自己一整套类型系统。Flink 使用“类型信息” （TypeInformation）来统一表示数据类型。TypeInformation 类是 Flink 中所有类型描述符的基类。 它涵盖了类型的一些基本属性，并为每个数据类型生成特定的序列化器、反序列化器和比较器。 2. Flink 支持的数据类型（1）基本类型 所有 Java 基本类型及其包装类，再加上 Void、String、Date、BigDecimal 和 BigInteger。 （2）数组类型 包括基本类型数组（PRIMITIVE_ARRAY）和对象数组(OBJECT_ARRAY) （3）复合数据类型 ⚫ Java 元组类型（TUPLE）：这是 Flink 内置的元组类型，是 Java API 的一部分。最多 25 个字段，也就是从 Tuple0~Tuple25，不支持空字段 ⚫ Scala 样例类及 Scala 元组：不支持空字段 ⚫ 行类型（ROW）：可以认为是具有任意个字段的元组,并支持空字段 ⚫ POJO：Flink 自定义的类似于 Java bean 模式的类 （4）辅助类型 Option、Either、List、Map 等 （5）泛型类型（GENERIC） Flink 支持所有的 Java 类和 Scala 类。不过如果没有按照上面 POJO 类型的要求来定义，就会被 Flink 当作泛型类来处理。Flink 会把泛型类型当作黑盒，无法获取它们内部的属性；它们也不是由 Flink 本身序列化的，而是由 Kryo 序列化的。在这些类型中，元组类型和 POJO 类型最为灵活，因为它们支持创建复杂类型。而相比之下，POJO 还支持在键（key）的定义中直接使用字段名，这会让我们的代码可读性大大增加。所以，在项目实践中，往往会将流处理程序中的元素类型定为 Flink 的 POJO 类型。 Flink 对 POJO 类型的要求如下： ⚫ 类是公共的（public）和独立的（standalone，也就是说没有非静态的内部类）； ⚫ 类有一个公共的无参构造方法； ⚫ 类中的所有字段是 public 且非 final 的；或者有一个公共的 getter 和 setter 方法，这些方法需要符合 Java bean 的命名规范。 所以我们看到，之前的 UserBehavior，就是我们创建的符合 Flink POJO 定义的数据类型。 3. 类型提示（Type Hints）由于 Java 中泛型擦除的存在，在某些特殊情况下（比如 Lambda 表达式中），为了解决这类问题，Java API 提供了专门的“类型提示”（type hints） .map(word -&gt; Tuple2.of(word, 1L)) .returns(Types.TUPLE(Types.STRING, Types.LONG)); --------------------------------------------------------------------------- returns(new TypeHint&lt;Tuple2&lt;Integer, SomeType&gt;&gt;(){}) 四、转换算子 1、基本转换算子1. 映射（map）主要用于将数据流中的数据进行转换，形成新的数据流。简单来说，消费一个元素就产出一个元素 我们只需要基于 DataStrema 调用 map()方法就可以进行转换处理。方法需要传入的参数是接口 MapFunction 的实现；返回值类型还是 DataStream eg：提取 Event 中的 user 字段的功能 package com.kk.model2; import com.kk.model2.pojo.Event; import org.apache.flink.api.common.functions.MapFunction; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; public class TransMapTest { public static void main(String[] args) throws Exception { // 创造执行环境 // 并行为 1 StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.setParallelism (1); // 构建数据 DataStreamSource&lt;Event&gt; stream = env.fromElements ( new Event (\"Mary\", \"./home\", 1000L), new Event (\"Bob\", \"./cart\", 2000L) ); // 写法一：传入匿名类，实现 MapFunction stream.map (new MapFunction&lt;Event, String&gt; ( ) { @Override public String map(Event e) throws Exception { return e.user; } }).print ( ); // 写法二： 传入 MapFunction 的实现类 //stream.map (new UserExtractor ()).print (); env.execute ( ); } public static class UserExtractor implements MapFunction&lt;Event, String&gt; { @Override public String map(Event e) throws Exception { return e.user; } } } 上面代码中，MapFunction 实现类的泛型类型，与输入数据类型和输出数据的类型有关。在实现 MapFunction 接口的时候，需要指定两个泛型，分别是输入事件和输出事件的类型，还需要重写一个 map()方法，定义从一个输入事件转换为另一个输出事件的具体逻辑。 2. 过滤（filter）filter 转换操作，顾名思义是对数据流执行一个过滤，通过一个布尔条件表达式设置过滤条件，对于每一个流内元素进行判断，若为 true 则元素正常输出，若为 false 则元素被过滤掉 package com.kk.model2; import com.kk.model2.pojo.Event; import org.apache.flink.api.common.functions.FilterFunction; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; public class TransFilterTest { public static void main(String[] args) throws Exception { // 创造执行环境 // 并行为 1 StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.setParallelism (1); // 构建数据 DataStreamSource&lt;Event&gt; stream = env.fromElements ( new Event (\"Mary\", \"./home\", 1000L), new Event (\"Bob\", \"./cart\", 2000L) ); // 写法一：传入匿名类实现 FilterFunction stream.filter (new FilterFunction&lt;Event&gt; ( ) { @Override public boolean filter(Event e) throws Exception { return e.user.equals (\"Bob\"); } }).print ( ); // 写法二：传入 FilterFunction 实现类 stream.filter (new UserFilter ( )).print ( ); env.execute ( ); } public static class UserFilter implements FilterFunction&lt;Event&gt; { @Override public boolean filter(Event e) throws Exception { return e.user.equals (\"Mary\"); } } } 进行 filter 转换之后的新数据流的数据类型与原数据流是相同的。filter 转换需要传入的参数需要实现 FilterFunction 接口，而 FilterFunction 内要实现 filter()方法，就相当于一个返回布尔类型的条件表达式。 3、扁平映射（flatMap）flatMap 操作又称为扁平映射，主要是将数据流中的整体（一般是集合类型）拆分成一个一个的个体使用。消费一个元素，可以产生 0 到多个元素,也就是先按照某种规则对数据进行打散拆分，再对拆分后的元素做转换处理 package com.kk.model2; import com.kk.model2.pojo.Event; import org.apache.flink.api.common.functions.FlatMapFunction; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; import org.apache.flink.util.Collector; public class TransFlatmapTest { public static void main(String[] args) throws Exception { // 创造执行环境 // 并行为 1 StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.setParallelism (1); // 构建数据 DataStreamSource&lt;Event&gt; stream = env.fromElements ( new Event (\"Mary\", \"./home\", 1000L), new Event (\"Bob\", \"./cart\", 2000L) ); stream.flatMap (new FlatMapFunction&lt;Event, String&gt; ( ) { @Override public void flatMap(Event e, Collector&lt;String&gt; collector) throws Exception { if (e.user.equals (\"Mary\")) { collector.collect (e.user); } else if (e.user.equals (\"Bob\")) { collector.collect (e.user); collector.collect (e.url); } } }).print ( );// print () 打印 // 执行 env.execute ( ); } } flatMap 操作会应用在每一个输入事件上面，FlatMapFunction 接口中定义了 flatMap 方法， 用户可以重写这个方法，在这个方法中对输入数据进行处理，并决定是返回 0 个、1 个或多个结果数据。因此 flatMap 并没有直接定义返回值类型，而是通过一个“收集器”（Collector）来指定输出。希望输出结果时，只要调用收集器的.collect()方法就可以了；这个方法可以多次调用，也可以不调用。所以 flatMap 方法也可以实现 map 方法和 filter 方法的功能，当返回结果是 0 个的时候，就相当于对数据进行了过滤，当返回结果是 1 个的时候，相当于对数据进行了简单的转换操作。 2、聚合算子1. 按键分区keyBy 是聚合前必须要用到的一个算子。keyBy 通过指定键（key），可以将一条流从逻辑上划分成不同的分区（partitions）。这里所说的分区，其实就是并行处理的子任务，也就对应着任务槽 package com.kk.model2; import com.kk.model2.pojo.Event; import org.apache.flink.streaming.api.datastream.DataStreamSink; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; public class TransKeyByTest { public static void main(String[] args) throws Exception { // 创造执行环境 // 并行为 1 StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.setParallelism (1); // 构建数据 DataStreamSource&lt;Event&gt; stream = env.fromElements ( new Event (\"Mary\", \"./home\", 1000L), new Event (\"Bob\", \"./cart\", 2000L) ); // lambda DataStreamSink&lt;Event&gt; byKeyStream = stream.keyBy (e -&gt; e.user).print ( ); env.execute ( ); } } 2. 简单聚合⚫ sum()：在输入流上，对指定的字段做叠加求和的操作。 ⚫ min()：在输入流上，对指定的字段求最小值。 ⚫ max()：在输入流上，对指定的字段求最大值。 ⚫ minBy()：与 min()类似，在输入流上针对指定字段求最小值。不同的是，min()只计算指定字段的最小值，其他字段会保留最初第一个数据的值；而 minBy()则会返回包 含字段最小值的整条数据。 ⚫ maxBy()：与 max()类似，在输入流上针对指定字段求最大值。两者区别与 min()/minBy()完全一致。 package com.kk.model2; import org.apache.flink.api.java.tuple.Tuple2; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; public class TransTupleAggreationTest { public static void main(String[] args) throws Exception { // 创造执行环境 // 并行为 1 StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.setParallelism (1); // 构建数据 DataStreamSource&lt;Tuple2&lt;String, Integer&gt;&gt; stream = env.fromElements ( Tuple2.of (\"a\", 1), Tuple2.of (\"a\", 5), Tuple2.of (\"a\", 3), Tuple2.of (\"b\", 4), Tuple2.of (\"b\", 5), Tuple2.of (\"b\", 2) ); // stream.keyBy(r -&gt; r.f0).sum(1).print(\"SUM:\"); // stream.keyBy(r -&gt; r.f0).sum(\"f1\").print(); stream.keyBy(r -&gt; r.f0).max(1).print(\"MAX\"); // stream.keyBy(r -&gt; r.f0).max(\"f1\").print(); // stream.keyBy(r -&gt; r.f0).min(1).print(); // stream.keyBy(r -&gt; r.f0).min(\"f1\").print(); // stream.keyBy(r -&gt; r.f0).maxBy(1).print(); // stream.keyBy(r -&gt; r.f0).maxBy(\"f1\").print(); // stream.keyBy(r -&gt; r.f0).minBy(1).print(); // stream.keyBy(r -&gt; r.f0).minBy(\"f1\").print(); env.execute (); } } 而如果数据流的类型是 POJO 类，那么就只能通过字段名称来指定，不能通过位置来指定了 3. 归约聚合（reduce）3、自定义函数4、物理分区五、输出算子1、2、3、4、5、参考地址 ↓1、docker 加速（博主简书）url：https://www.jianshu.com/p/f554c85b25c1 2、Hadoop 单机安装url：https://blog.51cto.com/u_15187242/4760802 docker run -i -t --network host -p 50070:50070 -p 9000:9000 -p 8088:8088 -p 8040:8040 -p 8042:8042 -p 49707:49707 -p 50010:50010 -p 50075:50075 -p 50090:50090 sequenceiq/hadoop-docker:2.7.0 /etc/bootstrap.sh -bash 3、Hadoop集群url：https://dhcp.cn/k8s/docker/deploy_hadoop.html#reference 4、Hadoop常用端口url：https://blog.csdn.net/qq_36816848/article/details/113106441 5、nc -lk 模拟实时数据url：https://www.csdn.net/tags/MtzakgwsODA4NjktYmxvZwO0O0OO0O0O.html 6、Flink（docker）快速搭建url：https://blog.csdn.net/weixin_42357472/article/details/118223101 7、Zookeeper(docker)快速搭建拉取url：https://blog.csdn.net/u010416101/article/details/122803105 启动url：https://www.cnblogs.com/shanfeng1000/p/14488665.html 8、kafka(docker)快速搭建搭建url：https://www.cnblogs.com/shanfeng1000/p/14638455.html 使用url：https://blog.csdn.net/qq_22041375/article/details/106180415","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mykkto.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"Flink","slug":"Flink","permalink":"https://mykkto.github.io/tags/Flink/"},{"name":"hadoop","slug":"hadoop","permalink":"https://mykkto.github.io/tags/hadoop/"},{"name":"kafka","slug":"kafka","permalink":"https://mykkto.github.io/tags/kafka/"}],"author":"mykk"},{"title":"项目-尚融宝-02-金融项目组件周边搭建","slug":"08-项目/01尚融宝/02_金融项目组件周边搭建","date":"2022-05-09T15:17:13.000Z","updated":"2022-06-20T15:27:32.909Z","comments":true,"path":"posts/4578729a.html","link":"","permalink":"https://mykkto.github.io/posts/4578729a.html","excerpt":"","text":"〇、主目录总纲Ⅰ、数据字典一、数据字典的设计1、什么是数据字典何为数据字典？数据字典负责管理系统常用的分类数据或者一些固定数据，例如：省市区三级联动数据、民族数据、行业数据、学历数据等，数据字典帮助我们方便的获取和适用这些通用数据。 2、数据字典的设计 parent_id：上级id，通过id与parent_id构建上下级关系，例如：我们要获取所有行业数据，那么只需要查询parent_id=20000的数据 name：名称，例如：填写用户信息，我们要select标签选择民族，“汉族”就是数据字典的名称 value：值，例如：填写用户信息，我们要select标签选择民族，“1”（汉族的标识）就是数据字典的值 dict_code：编码，编码是我们自定义的，全局唯一，例如：我们要获取行业数据，我们可以通过parent_id获取，但是parent_id是不确定的，所以我们可以根据编码来获取行业数据 二、Excle 数据批量导入1、后端接口1、添加依赖core中添加如下依赖&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;easyexcel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.xmlbeans&lt;/groupId&gt; &lt;artifactId&gt;xmlbeans&lt;/artifactId&gt; &lt;/dependency&gt; 2、创建Excel实体类package com.kk.srb.core.pojo.dto; @Data public class ExcelDictDTO { @ExcelProperty(\"id\") private Long id; @ExcelProperty(\"上级id\") private Long parentId; @ExcelProperty(\"名称\") private String name; @ExcelProperty(\"值\") private Integer value; @ExcelProperty(\"编码\") private String dictCode; } 3、创建监听器package com.kk.srb.core.listener; @Slf4j //@AllArgsConstructor //全参 @NoArgsConstructor //无参 public class ExcelDictDTOListener extends AnalysisEventListener&lt;ExcelDictDTO&gt; { /** * 每隔5条存储数据库，实际使用中可以3000条，然后清理list ，方便内存回收 */ private static final int BATCH_COUNT = 5; List&lt;ExcelDictDTO&gt; list = new ArrayList(); private DictMapper dictMapper; //传入mapper对象 public ExcelDictDTOListener(DictMapper dictMapper) { this.dictMapper = dictMapper; } /** *遍历每一行的记录 * @param data * @param context */ @Override public void invoke(ExcelDictDTO data, AnalysisContext context) { log.info(\"解析到一条记录: {}\", data); list.add(data); // 达到BATCH_COUNT了，需要去存储一次数据库，防止数据几万条数据在内存，容易OOM if (list.size() &gt;= BATCH_COUNT) { saveData(); // 存储完成清理 list list.clear(); } } /** * 所有数据解析完成了 都会来调用 */ @Override public void doAfterAllAnalysed(AnalysisContext context) { // 这里也要保存数据，确保最后遗留的数据也存储到数据库 saveData(); log.info(\"所有数据解析完成！\"); } /** * 加上存储数据库 */ private void saveData() { log.info(\"{}条数据，开始存储数据库！\", list.size()); dictMapper.insertBatch(list); //批量插入 log.info(\"存储数据库成功！\"); } } 4、Mapper层批量插入接口：DictMapper void insertBatch(List&lt;ExcelDictDTO&gt; list); xml：DictMapper.xml &lt;insert id=\"insertBatch\"&gt; insert into dict ( id , parent_id , name , value , dict_code ) values &lt;foreach collection=\"list\" item=\"item\" index=\"index\" separator=\",\"&gt; ( #{item.id} , #{item.parentId} , #{item.name} , #{item.value} , #{item.dictCode} ) &lt;/foreach&gt; &lt;/insert&gt; 5、Service层创建监听器实例接口 DictService void importData(InputStream inputStream); 实现：DictServiceImpl 注意：此处添加了事务处理，默认情况下rollbackFor = RuntimeException.class @Transactional(rollbackFor = {Exception.class}) @Override public void importData(InputStream inputStream) { // 这里 需要指定读用哪个class去读，然后读取第一个sheet 文件流会自动关闭 EasyExcel.read(inputStream, ExcelDictDTO.class, new ExcelDictDTOListener(baseMapper)).sheet().doRead(); log.info(\"importData finished\"); } 6、Controller层接收客户端上传package com.kk.srb.core.controller.admin; @Api(tags = \"数据字典管理\") @RestController @RequestMapping(\"/admin/core/dict\") @Slf4j @CrossOrigin public class AdminDictController { @Resource private DictService dictService; @ApiOperation(\"Excel批量导入数据字典\") @PostMapping(\"/import\") public R batchImport( @ApiParam(value = \"Excel文件\", required = true) @RequestParam(\"file\") MultipartFile file) { try { InputStream inputStream = file.getInputStream ( ); dictService.importData (inputStream); return R.ok ( ).message (\"批量导入成功\"); } catch (Exception e) { //UPLOAD_ERROR(-103, \"文件上传错误\"), throw new BusinessException (ResponseEnum.UPLOAD_ERROR, e); } } } 7、添加mapper发布配置注意：因为maven工程在默认情况下src/main/java目录下的所有资源文件是不发布到target目录下的，因此我们需要在pom.xml中添加xml配置文件发布配置 &lt;build&gt; &lt;!-- 项目打包时会将java目录中的*.xml文件也进行打包 --&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; 2、前端调用1.创建页面组件创建 src/views/core/dict/list.vue &lt;template&gt; &lt;div class=\"app-container\"&gt; &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { } &lt;/script&gt; 2.配置路由{ path: '/core', component: Layout, redirect: '/core/dict/list', name: 'coreDict', meta: { title: '系统设置', icon: 'el-icon-setting' }, alwaysShow: true, children: [ { path: 'dict/list', name: '数据字典', component: () =&gt; import('@/views/core/dict/list'), meta: { title: '数据字典' } } ] }, 3.实现数据导入&lt;template&gt; &lt;div class=\"app-container\"&gt; &lt;div style=\"margin-bottom: 10px\"&gt; &lt;el-button type=\"primary\" size=\"mini\" icon=\"el-icon-download\" @click=\"dialogVisible = true\" &gt; 导入Excel &lt;/el-button&gt; &lt;/div&gt; &lt;el-dialog title=\"数据字典导入\" :visible.sync=\"dialogVisible\" width=\"30%\"&gt; &lt;el-form&gt; &lt;el-form-item label=\"请选择Excel文件\"&gt; &lt;el-upload :auto-upload=\"true\" :multiple=\"false\" :limit=\"1\" :on-exceed=\"fileUploadExceed\" :on-success=\"fileUploadSuccess\" :on-error=\"fileUploadError\" :action=\"BASE_API + '/admin/core/dict/import'\" name=\"file\" accept=\"application/vnd.ms-excel,application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\" &gt; &lt;el-button size=\"small\" type=\"primary\"&gt;点击上传&lt;/el-button&gt; &lt;/el-upload&gt; &lt;/el-form-item&gt; &lt;/el-form&gt; &lt;div slot=\"footer\" class=\"dialog-footer\"&gt; &lt;el-button @click=\"dialogVisible = false\"&gt;取消&lt;/el-button&gt; &lt;/div&gt; &lt;/el-dialog&gt; &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { // 定义数据 data() { return { dialogVisible: false, // 文件上传对话框是否显示 BASE_API: process.env.VUE_APP_BASE_API // 获取后端接口地址 } }, methods: { // 上传多于一个文件时 fileUploadExceed() { this.$message.warning('只能选取一个文件') }, // 上传成功回调 fileUploadSuccess(response) { if (response.code === 0) { this.$message.success('数据导入成功') this.dialogVisible = false } else { this.$message.error(response.message) } }, // 上传失败回调 // eslint-disable-next-line handle-callback-err fileUploadError(error) { this.$message.error('数据导入失败') } } } &lt;/script&gt; 三、Excle 数据导出1、后端接口1.Service层解析Excel数据接口：DictService List&lt;ExcelDictDTO&gt; listDictData(); 实现：DictServiceImpl @Override public List&lt;ExcelDictDTO&gt; listDictData() { List&lt;Dict&gt; dictList = baseMapper.selectList(null); //创建ExcelDictDTO列表，将Dict列表转换成ExcelDictDTO列表 ArrayList&lt;ExcelDictDTO&gt; excelDictDTOList = new ArrayList&lt;&gt;(dictList.size()); dictList.forEach(dict -&gt; { ExcelDictDTO excelDictDTO = new ExcelDictDTO(); BeanUtils.copyProperties(dict, excelDictDTO); excelDictDTOList.add(excelDictDTO); }); return excelDictDTOList; } 2.Controller层接收客户端请求@ApiOperation(\"Excel数据的导出\") @GetMapping(\"/export\") public void export(HttpServletResponse response){ try { // 这里注意 有同学反应使用swagger 会导致各种问题，请直接用浏览器或者用postman response.setContentType(\"application/vnd.ms-excel\"); response.setCharacterEncoding(\"utf-8\"); // 这里URLEncoder.encode可以防止中文乱码 当然和easyexcel没有关系 String fileName = URLEncoder.encode(\"mydict\", \"UTF-8\").replaceAll(\"\\\\+\", \"%20\"); response.setHeader(\"Content-disposition\", \"attachment;filename*=utf-8''\" + fileName + \".xlsx\"); EasyExcel.write(response.getOutputStream(), ExcelDictDTO.class).sheet(\"数据字典\").doWrite(dictService.listDictData()); } catch (IOException e) { //EXPORT_DATA_ERROR(104, \"数据导出失败\"), throw new BusinessException(ResponseEnum.EXPORT_DATA_ERROR, e); } } 2、前端调用1.前端调用&lt;el-button @click=\"exportData\" type=\"primary\" size=\"mini\" icon=\"el-icon-upload2\" &gt;导出Excel&lt;/el-button&gt; 2.添加导出方法//Excel数据导出 exportData() { window.location.href = this.BASE_API + '/admin/core/dict/export' } 四、数据字典列表1、后端接口1.实体类添加属性Dict中添加属性 @ApiModelProperty(value = \"是否包含子节点\") @TableField(exist = false)//在数据库表中忽略此列 private boolean hasChildren; 2.Service层实现数据查询接口：DictService List&lt;Dict&gt; listByParentId(Long parentId); 实现：DictServiceImpl @Override public List&lt;Dict&gt; listByParentId(Long parentId) { QueryWrapper&lt;Dict&gt; wrapper = new QueryWrapper&lt;Dict&gt; ( ).eq (\"parent_id\", parentId); List&lt;Dict&gt; dictList = baseMapper.selectList (wrapper); dictList.forEach (dict -&gt; { // 如果有子节点，则是非叶子节点 boolean children = hasChildren (dict.getId ( )); dict.setHasChildren (children); }); return dictList; } /** * 判断该节点是否有子节点 */ private boolean hasChildren(Long id) { QueryWrapper&lt;Dict&gt; wrapper = new QueryWrapper&lt;Dict&gt; ( ).eq (\"parent_id\", id); Integer count = baseMapper.selectCount (wrapper); return count &gt; 0; } 3.Controller层接收前端请求@ApiOperation(\"根据上级id获取子节点数据列表\") @GetMapping(\"/listByParentId/{parentId}\") public R listByParentId( @ApiParam(value = \"上级节点id\", required = true) @PathVariable Long parentId) { List&lt;Dict&gt; dictList = dictService.listByParentId(parentId); return R.ok().data(\"list\", dictList); } 2、前端调用1.api创建 src/api/core/dict.js import request from '@/utils/request' export default { listByParentId(parentId) { return request({ url: `/admin/core/dict/listByParentId/${parentId}`, method: 'get' }) } } 2.组件脚本src\\views\\core\\dict\\list.vue 定义data list: [] // 数据字典列表 生命周期函数 created() { this.fetchData() }, 获取数据的方法 import dictApi from '@/api/core/dict' // 调用api层获取数据库中的数据 fetchData() { dictApi.listByParentId(1).then(response =&gt; { this.list = response.data.list }) }, //延迟加载子节点 getChildren(row, treeNode, resolve) { dictApi.listByParentId(row.id).then(response =&gt; { //负责将子节点数据展示在展开的列表中 resolve(response.data.list) }) }, 3.组件模板src\\views\\core\\dict\\list.vue &lt;el-table :data=\"list\" border row-key=\"id\" lazy :load=\"load\"&gt; &lt;el-table-column label=\"名称\" align=\"left\" prop=\"name\" /&gt; &lt;el-table-column label=\"编码\" prop=\"dictCode\" /&gt; &lt;el-table-column label=\"值\" align=\"left\" prop=\"value\" /&gt; &lt;/el-table&gt; 4.流程优化src\\views\\core\\dict\\list.vue 数据导入后刷新页面的数据列表 //上传成功回调 fileUploadSuccess(response) { if (response.code === 0) { this.$message.success('数据导入成功') this.dialogVisible = false this.fetchData() } else { this.$message.error(response.message) } }, Ⅱ、Redis(短信)一、集成 Redis1、简介1.场景由于数据字典的变化不是很频繁，而且系统对数据字典的访问较频繁，所以我们有必要把数据字典的数据存入缓存，减少数据库压力和提高访问速度。这里，我们使用Redis作为系统的分布式缓存中间件。 2.RedisTemplate在Spring Boot项目中中，默认集成Spring Data Redis，Spring Data Redis针对Redis提供了非常方便的操作模版RedisTemplate，并且可以进行连接池自动管理。 2、引入 Redis1.项目中集成Redisservice-base 模块中添加redis依赖，Spring Boot 2.0以上默认通过commons-pool2 连接池连接Redis &lt;!-- spring boot redis缓存引入 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 缓存连接池--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- redis 存储 json序列化 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.datatype&lt;/groupId&gt; &lt;artifactId&gt;jackson-datatype-jsr310&lt;/artifactId&gt; &lt;/dependency&gt; 2.添加Redis连接配置service-core 的 application.yml 中添加如下配置 #spring: redis: host: 192.168.100.100 port: 6379 database: 0 password: 123456 #默认为空 timeout: 3000ms #最大等待时间，超时则抛出异常，否则请求一直等待 lettuce: pool: max-active: 20 #最大连接数，负值表示没有限制，默认8 max-wait: -1 #最大阻塞等待时间，负值表示没限制，默认-1 max-idle: 8 #最大空闲连接，默认8 min-idle: 0 #最小空闲连接，默认0 3、测试 RedisTemplate1.存值测试test中创建测试类 RedisTemplateTests package com.kk.srb.core; @SpringBootTest @RunWith(SpringRunner.class) public class RedisTemplateTests { @Resource private RedisTemplate redisTemplate; @Resource private DictMapper dictMapper; @Test public void saveDict(){ Dict dict = dictMapper.selectById(1); //向数据库中存储string类型的键值对, 过期时间5分钟 redisTemplate.opsForValue().set(\"dict\", dict, 5, TimeUnit.MINUTES); } } 发现RedisTemplate默认使用了JDK的序列化方式存储了key和value 2.Redis 配置文件service-base 中添加RedisConfig，我们可以在这个配置文件中配置 Redis 序列化方案 package com.kk.srb.base.config; @Configuration public class RedisConfig { @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(LettuceConnectionFactory redisConnectionFactory) { RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;&gt; ( ); redisTemplate.setConnectionFactory (redisConnectionFactory); //首先解决key的序列化方式 StringRedisSerializer stringRedisSerializer = new StringRedisSerializer ( ); redisTemplate.setKeySerializer (stringRedisSerializer); //解决value的序列化方式 Jackson2JsonRedisSerializer&lt;Object&gt; jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer&lt;&gt; (Object.class); //序列化时将类的数据类型存入json，以便反序列化的时候转换成正确的类型 ObjectMapper objectMapper = new ObjectMapper ( ); //objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); objectMapper.activateDefaultTyping (LaissezFaireSubTypeValidator.instance, ObjectMapper.DefaultTyping.NON_FINAL); // 解决jackson2无法反序列化LocalDateTime的问题 objectMapper.disable (SerializationFeature.WRITE_DATES_AS_TIMESTAMPS); objectMapper.registerModule (new JavaTimeModule ( )); jackson2JsonRedisSerializer.setObjectMapper (objectMapper); redisTemplate.setValueSerializer (jackson2JsonRedisSerializer); return redisTemplate; } } 再次测试，key使用了字符串存储，value使用了json存储 3.取值测试@Test public void getDict(){ Dict dict = (Dict)redisTemplate.opsForValue().get(\"dict\"); System.out.println(dict); } 二、使用 RedisDictServiceImpl 注意：当redis服务器宕机时，我们不要抛出异常，要正常的执行后面的流程，使业务可以正常的运行 @Resource private RedisTemplate redisTemplate; @Override public List&lt;Dict&gt; listByParentId(Long parentId) { //先查询redis中是否存在数据列表 List&lt;Dict&gt; dictList = null; try { dictList = (List&lt;Dict&gt;)redisTemplate.opsForValue().get(\"srb:core:dictList:\" + parentId); if(dictList != null){ log.info(\"从redis中取值\"); return dictList; } } catch (Exception e) { log.error(\"redis服务器异常：\" + ExceptionUtils.getStackTrace(e));//此处不抛出异常，继续执行后面的代码 } log.info(\"从数据库中取值\"); dictList = baseMapper.selectList(new QueryWrapper&lt;Dict&gt;().eq(\"parent_id\", parentId)); dictList.forEach(dict -&gt; { //如果有子节点，则是非叶子节点 boolean hasChildren = this.hasChildren(dict.getId()); dict.setHasChildren(hasChildren); }); //将数据存入redis try { redisTemplate.opsForValue().set(\"srb:core:dictList:\" + parentId, dictList, 5, TimeUnit.MINUTES); log.info(\"数据存入redis\"); } catch (Exception e) { log.error(\"redis服务器异常：\" + ExceptionUtils.getStackTrace(e));//此处不抛出异常，继续执行后面的代码 } return dictList; } 三、使用短信服务流程图 1、创建项目1.创建模块service-sms 2.配置 pom.xml&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;service-base&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--lombok用来简化实体类：需要安装lombok插件--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--阿里云短信--&gt; &lt;dependency&gt; &lt;groupId&gt;com.aliyun&lt;/groupId&gt; &lt;artifactId&gt;aliyun-java-sdk-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 3.application.ymlresources目录下创建文件 server: port: 8120 # 服务端口 spring: profiles: active: dev # 环境设置 application: name: service-sms # 服务名 #spring: redis: host: 192.168.100.100 port: 6379 database: 0 password: 123456 #默认为空 timeout: 3000ms #最大等待时间，超时则抛出异常，否则请求一直等待 lettuce: pool: max-active: 20 #最大连接数，负值表示没有限制，默认8 max-wait: -1 #最大阻塞等待时间，负值表示没限制，默认-1 max-idle: 8 #最大空闲连接，默认8 min-idle: 0 #最小空闲连接，默认0 #阿里云短信 aliyun: sms: region-id: cn-hangzhou key-id: 你的keyid key-secret: 你的keysecret template-code: 你的短信模板code sign-name: 你的短信模板签名 4.logback-spring.xml可以参考之前写的配置修改 5.创建SpringBoot启动类package com.kk.srb.sms; @SpringBootApplication @ComponentScan({\"com.kk.srb\", \"com.kk.common\"}) public class ServiceSmsApplication { public static void main(String[] args) { SpringApplication.run(ServiceSmsApplication.class, args); } } 2、自定义配置1.从配置文件读取常量创建常量读取工具类：SmsProperties.java package com.kk.srb.sms.util; @Setter @Getter //idea2020.2.3版配置文件自动提示需要这个 @Component //注意prefix要写到最后一个 \".\" 符号之前 //调用setter为成员赋值 @ConfigurationProperties(prefix = \"aliyun.sms\") public class SmsProperties implements InitializingBean { private String regionId; private String keyId; private String keySecret; private String templateCode; private String signName; public static String REGION_Id; public static String KEY_ID; public static String KEY_SECRET; public static String TEMPLATE_CODE; public static String SIGN_NAME; //当私有成员被赋值后，此方法自动被调用，从而初始化常量 @Override public void afterPropertiesSet() throws Exception { REGION_Id = regionId; KEY_ID = keyId; KEY_SECRET = keySecret; TEMPLATE_CODE = templateCode; SIGN_NAME = signName; } } 2.配置自动提示 step1：添加依赖 &lt;!-- 配置文件处理器 --&gt; &lt;!--让自定义的配置在application.yaml进行自动提示--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; step2：启动processor step3：重新编译模块 step4：这样就可以在yml文件中有自定义配置的提示信息啦 3、测试工具类创建测试类 UtilsTests，测试配置信息是否能正常获取 package com.kk.srb.sms; @SpringBootTest @RunWith(SpringRunner.class) public class UtilsTests { @Test public void testProperties(){ System.out.println(SmsProperties.KEY_ID); System.out.println(SmsProperties.KEY_SECRET); System.out.println(SmsProperties.REGION_Id); } } 3、发送短信1.短信发送业务接口：创建 SmsService package com.kk.srb.sms.service; public interface SmsService { void send(String mobile, String templateCode, Map&lt;String,Object&gt; param); } 实现：创建 SmsServiceImpl package com.kk.srb.sms.service.impl; @Service @Slf4j public class SmsServiceImpl implements SmsService { @Override public void send(String mobile, String templateCode, Map&lt;String,Object&gt; param) { //创建远程连接客户端对象 DefaultProfile profile = DefaultProfile.getProfile( SmsProperties.REGION_Id, SmsProperties.KEY_ID, SmsProperties.KEY_SECRET); IAcsClient client = new DefaultAcsClient(profile); //创建远程连接的请求参数 CommonRequest request = new CommonRequest(); request.setSysMethod(MethodType.POST); request.setSysDomain(\"dysmsapi.aliyuncs.com\"); request.setSysVersion(\"2017-05-25\"); request.setSysAction(\"SendSms\"); request.putQueryParameter(\"RegionId\", SmsProperties.REGION_Id); request.putQueryParameter(\"PhoneNumbers\", mobile); request.putQueryParameter(\"SignName\", SmsProperties.SIGN_NAME); request.putQueryParameter(\"TemplateCode\", templateCode); Gson gson = new Gson(); String json = gson.toJson(param); request.putQueryParameter(\"TemplateParam\", json); try { //使用客户端对象携带请求对象发送请求并得到响应结果 CommonResponse response = client.getCommonResponse(request); boolean success = response.getHttpResponse().isSuccess(); //ALIYUN_RESPONSE_FAIL(-501, \"阿里云响应失败\"), Assert.isTrue(success, ResponseEnum.ALIYUN_RESPONSE_FAIL); String data = response.getData(); HashMap&lt;String, String&gt; resultMap = gson.fromJson(data, HashMap.class); String code = resultMap.get(\"Code\"); String message = resultMap.get(\"Message\"); log.info(\"阿里云短信发送响应结果：\"); log.info(\"code：\" + code); log.info(\"message：\" + message); //ALIYUN_SMS_LIMIT_CONTROL_ERROR(-502, \"短信发送过于频繁\"),//业务限流 Assert.notEquals(\"isv.BUSINESS_LIMIT_CONTROL\", code, ResponseEnum.ALIYUN_SMS_LIMIT_CONTROL_ERROR); //ALIYUN_SMS_ERROR(-503, \"短信发送失败\"),//其他失败 Assert.equals(\"OK\", code, ResponseEnum.ALIYUN_SMS_ERROR); } catch (ServerException e) { log.error(\"阿里云短信发送SDK调用失败：\"); log.error(\"ErrorCode=\" + e.getErrCode()); log.error(\"ErrorMessage=\" + e.getErrMsg()); throw new BusinessException(ResponseEnum.ALIYUN_SMS_ERROR , e); } catch (ClientException e) { log.error(\"阿里云短信发送SDK调用失败：\"); log.error(\"ErrorCode=\" + e.getErrCode()); log.error(\"ErrorMessage=\" + e.getErrMsg()); throw new BusinessException(ResponseEnum.ALIYUN_SMS_ERROR , e); } } } 2.引入工具类 kk-common中创建util包，引入工具类： RandomUtils.java：生成四位或六位的验证码 RegexValidateUtils.java：常用正则表达式验证，这里提供了手机号码验证 3.创建controller创建controller.api包，创建类ApiSmsController package com.kk.srb.sms.controller.api; @RestController @RequestMapping(\"/api/sms\") @Api(tags = \"短信管理\") @CrossOrigin //跨域 @Slf4j public class ApiSmsController { @Resource private SmsService smsService; @Resource private RedisTemplate redisTemplate; @ApiOperation(\"获取验证码\") @GetMapping(\"/send/{mobile}\") public R send( @ApiParam(value = \"手机号\", required = true) @PathVariable String mobile){ //MOBILE_NULL_ERROR(-202, \"手机号不能为空\"), Assert.notEmpty(mobile, ResponseEnum.MOBILE_NULL_ERROR); //MOBILE_ERROR(-203, \"手机号不正确\"), Assert.isTrue(RegexValidateUtils.checkCellphone(mobile), ResponseEnum.MOBILE_ERROR); //生成验证码 String code = RandomUtils.getFourBitRandom(); //组装短信模板参数 Map&lt;String,Object&gt; param = new HashMap&lt;&gt;(); param.put(\"code\", code); //发送短信 smsService.send(mobile, SmsProperties.TEMPLATE_CODE, param); //将验证码存入redis redisTemplate.opsForValue().set(\"srb:sms:code:\" + mobile, code, 5, TimeUnit.MINUTES); return R.ok().message(\"短信发送成功\"); } } 4、swagger 配置service-base中添加网站端api的配置 @Bean public Docket apiConfig(){ return new Docket(DocumentationType.SWAGGER_2) .groupName(\"api\") .apiInfo(apiInfo()) .select() //只显示admin路径下的页面 .paths(Predicates.and(PathSelectors.regex(\"/api/.*\"))) .build(); } private ApiInfo apiInfo(){ return new ApiInfoBuilder() .title(\"尚融宝-API文档\") .description(\"本文档描述了尚融宝接口\") .version(\"1.0\") .contact(new Contact(\"Helen\", \"http://mykk.com\", \"55317332@qq.com\")) .build(); } Ⅲ、OSS对象存储一、SDK使用OSS1、导入依赖&lt;dependencies&gt; &lt;!--aliyunOSS--&gt; &lt;dependency&gt; &lt;groupId&gt;com.aliyun.oss&lt;/groupId&gt; &lt;artifactId&gt;aliyun-sdk-oss&lt;/artifactId&gt; &lt;version&gt;3.10.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 2、创建Bucket(test)package com.kk.aliyunoss; public class OSSTest { // Endpoint以杭州为例，其它Region请按实际情况填写。 String endpoint = \"your endpoint\"; // 阿里云主账号AccessKey拥有所有API的访问权限，风险很高。强烈建议您创建并使用RAM账号进行API访问或日常运维，请登录 https://ram.console.aliyun.com 创建RAM账号。 String accessKeyId = \"your accessKeyId\"; String accessKeySecret = \"your accessKeySecret\"; String bucketName = \"srb-file\"; @Test public void testCreateBucket() { // 创建OSSClient实例。 OSS ossClient = new OSSClientBuilder().build(endpoint, accessKeyId, accessKeySecret); // 创建存储空间。 ossClient.createBucket(bucketName); // 关闭OSSClient。 ossClient.shutdown(); } } 3、判断bucket是否存在(test)@Test public void testExist() { // 创建OSSClient实例。 OSS ossClient = new OSSClientBuilder().build(endpoint, accessKeyId, accessKeySecret); boolean exists = ossClient.doesBucketExist(bucketName); System.out.println(exists); // 关闭OSSClient。 ossClient.shutdown(); } 4、设置bucket访问权限(test)@Test public void testAccessControl() { // 创建OSSClient实例。 OSS ossClient = new OSSClientBuilder().build(endpoint, accessKeyId, accessKeySecret); // 设置存储空间的访问权限为：公共读。 ossClient.setBucketAcl(bucketName, CannedAccessControlList.PublicRead); // 关闭OSSClient。 ossClient.shutdown(); } 二、创建 OSS微服务1、新建云存储微服务1.创建模块service-oss 2.配置pom.xml&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;service-base&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--lombok用来简化实体类：需要安装lombok插件--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--aliyunOSS--&gt; &lt;dependency&gt; &lt;groupId&gt;com.aliyun.oss&lt;/groupId&gt; &lt;artifactId&gt;aliyun-sdk-oss&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 日期工具栏依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;joda-time&lt;/groupId&gt; &lt;artifactId&gt;joda-time&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--让自定义的配置在application.yaml进行自动提示--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 3.配置application.ymlserver: port: 8130 # 服务端口 spring: profiles: active: dev # 环境设置 application: name: service-oss # 服务名 aliyun: oss: endpoint: 你的endponit keyId: 你的阿里云keyid keySecret: 你的阿里云keysecret bucketName: srb-file 4.logback-spring.xml修改日志路径为 srb_log/oss 5.创建启动类创建ServiceOssApplication.java package com.kk.srb.oss; @SpringBootApplication @ComponentScan({\"com.kk.srb\", \"com.kk.common\"}) public class ServiceOssApplication { public static void main(String[] args) { SpringApplication.run(ServiceOssApplication.class, args); } } 2、实现文件上传1.从配置文件读取常量创建常量读取工具类：OssProperties.java package com.kk.srb.oss.util; @Setter @Getter @Component @ConfigurationProperties(prefix = \"aliyun.oss\") public class OssProperties implements InitializingBean { private String endpoint; private String keyId; private String keySecret; private String bucketName; public static String ENDPOINT; public static String KEY_ID; public static String KEY_SECRET; public static String BUCKET_NAME; //当私有成员被赋值后，此方法自动被调用，从而初始化常量 @Override public void afterPropertiesSet() throws Exception { ENDPOINT = endpoint; KEY_ID = keyId; KEY_SECRET = keySecret; BUCKET_NAME = bucketName; } } 2.文件上传业务创建Service接口：FileService.java package com.kk.srb.oss.service; public interface FileService { /** * 文件上传至阿里云 */ String upload(InputStream inputStream, String module, String fileName); } 实现 package com.k.srb.oss.service.impl; @Service public class FileServiceImpl implements FileService { /** * 文件上传至阿里云 */ @Override public String upload(InputStream inputStream, String module, String fileName) { // 创建OSSClient实例。 OSS ossClient = new OSSClientBuilder().build( OssProperties.ENDPOINT, OssProperties.KEY_ID, OssProperties.KEY_SECRET); //判断oss实例是否存在：如果不存在则创建，如果存在则获取 if(!ossClient.doesBucketExist(OssProperties.BUCKET_NAME)){ //创建bucket ossClient.createBucket(OssProperties.BUCKET_NAME); //设置oss实例的访问权限：公共读 ossClient.setBucketAcl(OssProperties.BUCKET_NAME, CannedAccessControlList.PublicRead); } //构建日期路径：avatar/2019/02/26/文件名 String folder = new DateTime().toString(\"yyyy/MM/dd\"); //文件名：uuid.扩展名 fileName = UUID.randomUUID().toString() + fileName.substring(fileName.lastIndexOf(\".\")); //文件根路径 String key = module + \"/\" + folder + \"/\" + fileName; //文件上传至阿里云 ossClient.putObject(OssProperties.BUCKET_NAME, key, inputStream); // 关闭OSSClient。 ossClient.shutdown(); //阿里云文件绝对路径 return \"https://\" + OssProperties.BUCKET_NAME + \".\" + OssProperties.ENDPOINT + \"/\" + key; } } 3.控制层创建controller.admin：FileController.java package com.kk.srb.oss.controller.api; @Api(tags = \"阿里云文件管理\") @CrossOrigin //跨域 @RestController @RequestMapping(\"/api/oss/file\") public class FileController { @Resource private FileService fileService; /** * 文件上传 */ @ApiOperation(\"文件上传\") @PostMapping(\"/upload\") public R upload( @ApiParam(value = \"文件\", required = true) @RequestParam(\"file\") MultipartFile file, @ApiParam(value = \"模块\", required = true) @RequestParam(\"module\") String module) { try { InputStream inputStream = file.getInputStream(); String originalFilename = file.getOriginalFilename(); String uploadUrl = fileService.upload(inputStream, module, originalFilename); //返回r对象 return R.ok().message(\"文件上传成功\").data(\"url\", uploadUrl); } catch (IOException e) { throw new BusinessException(ResponseEnum.UPLOAD_ERROR, e); } } } 3、实现文件删除1.业务层Service接口：FileService.java /** * 根据路径删除文件 * @param url */ void removeFile(String url); 实现：FileServiceImpl.java /** * 根据路径删除文件 * @param url */ @Override public void removeFile(String url) { // 创建OSSClient实例。 OSS ossClient = new OSSClientBuilder().build( OssProperties.ENDPOINT, OssProperties.KEY_ID, OssProperties.KEY_SECRET); //文件名（服务器上的文件路径） String host = \"https://\" + OssProperties.BUCKET_NAME + \".\" + OssProperties.ENDPOINT + \"/\"; String objectName = url.substring(host.length()); // 删除文件。 ossClient.deleteObject(OssProperties.BUCKET_NAME, objectName); // 关闭OSSClient。 ossClient.shutdown(); } 2.控制层@ApiOperation(\"删除OSS文件\") @DeleteMapping(\"/remove\") public R remove( @ApiParam(value = \"要删除的文件路径\", required = true) @RequestParam(\"url\") String url) { fileService.removeFile(url); return R.ok().message(\"删除成功\"); } Ⅳ、单点登录(令牌)一、单点登录1、单一服务器模式1.一般过程如下： 用户向服务器发送用户名和密码。 验证服务器后，相关数据（如用户名，用户角色等）将保存在当前会话（session）中。 服务器向用户返回session_id，session信息都会写入到用户的Cookie。 用户的每个后续请求都将通过在Cookie中取出session_id传给服务器。 服务器收到session_id并对比之前保存的数据，确认用户的身份。 2.缺点： 单点性能压力，无法扩展。 分布式架构中，需要session共享方案，session共享方案存在性能瓶颈。 3.session共享方案：session广播：性能瓶颈，不推荐 redis代替session：推荐，性能高 2、SSO模式CAS单点登录、OAuth2 1.概述分布式，SSO(single sign on)模式：单点登录英文全称Single Sign On，简称就是SSO。它的解释是：在多个应用系统中，只需要登录一次，就可以访问其他相互信任的应用系统。 如图所示，图中有3个系统，分别是业务A、业务B、和SSO。 业务A、业务B没有登录模块。 而SSO只有登录模块，没有其他的业务模块。 2.一般过程如下： 当业务A、业务B需要登录时，将跳到SSO系统。 SSO从用户信息数据库中获取用户信息并校验用户信息，SSO系统完成登录。 然后将用户信息存入缓存（例如redis）。 当用户访问业务A或业务B，需要判断用户是否登录时，将跳转到SSO系统中进行用户身份验证，SSO判断缓存中是否存在用户身份信息。 这样，只要其中一个系统完成登录，其他的应用系统也就随之登录了。这就是单点登录（SSO）的定义。 3.优点 ：用户身份信息独立管理，更好的分布式管理。可以自己扩展安全策略 4.缺点认证服务器访问压力较大。 3、Token模式1.图解 2.优点： 无状态： token是无状态，session是有状态的 基于标准化：你的API可以采用标准化的 JSON Web Token (JWT) 3.缺点： 占用带宽 无法在服务器端销毁 二、JWT令牌1、访问令牌的类型 2、JWT令牌JWT是JSON Web Token的缩写，即JSON Web令牌，是一种自包含令牌。 JWT的使用场景： 一种情况是webapi，类似之前的阿里云播放凭证的功能 另一种情况是多web服务器下实现无状态分布式身份验证 JWT的作用： JWT 最重要的作用就是对 token信息的防伪作用 JWT的原理： 一个JWT由三个部分组成：JWT头、有效载荷、签名哈希 最后由这三者组合进行base64编码得到JWT 3、JWT令牌的组成https://jwt.io/ 该对象为一个很长的字符串，字符之间通过”.”分隔符分为三个子串。 每一个子串表示了一个功能块，总共有以下三个部分：JWT头、有效载荷和签名 1. JWT头JWT头部分是一个描述JWT元数据的JSON对象，通常如下所示。 { \"alg\": \"HS256\", \"typ\": \"JWT\" } 在上面的代码中，alg属性表示签名使用的算法，默认为HMAC SHA256（写为HS256）；typ属性表示令牌的类型，JWT令牌统一写为JWT。最后，使用Base64 URL算法将上述JSON对象转换为字符串保存。 2. 有效载荷有效载荷部分，是JWT的主体内容部分，也是一个JSON对象，包含需要传递的数据。 JWT指定七个默认字段供选择。 sub: 主题 iss: jwt签发者 aud: 接收jwt的一方 iat: jwt的签发时间 exp: jwt的过期时间，这个过期时间必须要大于签发时间 nbf: 定义在什么时间之前，该jwt都是不可用的. jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击。 除以上默认字段外，我们还可以自定义私有字段，如下例： { \"name\": \"Helen\", \"admin\": true, \"avatar\": \"helen.jpg\" } 请注意，默认情况下JWT是未加密的，任何人都可以解读其内容，因此不要构建隐私信息字段，存放保密信息，以防止信息泄露。 JSON对象也使用Base64 URL算法转换为字符串保存。 3. 签名哈希签名哈希部分是对上面两部分数据签名，通过指定的算法生成哈希，以确保数据不会被篡改。 首先，需要指定一个密码（secret）。该密码仅仅为保存在服务器中，并且不能向用户公开。然后，使用标头中指定的签名算法（默认情况下为HMAC SHA256）根据以下公式生成 HMACSHA256(base64UrlEncode(header) + \".\" + base64UrlEncode(claims), secret) ==&gt; 签名hash 在计算出签名哈希后，JWT头，有效载荷和签名哈希的三个部分组合成一个字符串，每个部分用”.”分隔，就构成整个JWT对象。 4. Base64URL算法如前所述，JWT头和有效载荷序列化的算法都用到了Base64URL。该算法和常见Base64算法类似，稍有差别。 作为令牌的JWT可以放在URL中（例如api.example/?token=xxx）。 Base64中用的三个字符是”+”，”/“和”=”，由于在URL中有特殊含义，因此Base64URL中对他们做了替换：”=”去掉，”+”用”-“替换，”/“用”_”替换，这就是Base64URL算法。 注意：base64编码，并不是加密，只是把明文信息变成了不可见的字符串。但是其实只要用一些工具就可以把base64编码解成明文，所以不要在JWT中放入涉及私密的信息。 三、JWT测试","categories":[{"name":"项目-尚融宝","slug":"项目-尚融宝","permalink":"https://mykkto.github.io/categories/%E9%A1%B9%E7%9B%AE-%E5%B0%9A%E8%9E%8D%E5%AE%9D/"}],"tags":[{"name":"sentinel","slug":"sentinel","permalink":"https://mykkto.github.io/tags/sentinel/"},{"name":"redis","slug":"redis","permalink":"https://mykkto.github.io/tags/redis/"},{"name":"gatway","slug":"gatway","permalink":"https://mykkto.github.io/tags/gatway/"},{"name":"数据字典","slug":"数据字典","permalink":"https://mykkto.github.io/tags/%E6%95%B0%E6%8D%AE%E5%AD%97%E5%85%B8/"}],"author":"mykk"},{"title":"项目-尚融宝-01-金融背景及其后端搭建","slug":"08-项目/01尚融宝/01_金融项目说明和搭建","date":"2022-04-26T15:11:33.000Z","updated":"2022-05-22T15:01:03.825Z","comments":true,"path":"posts/a6407b24.html","link":"","permalink":"https://mykkto.github.io/posts/a6407b24.html","excerpt":"","text":"〇、主目录总纲Ⅰ、项目概念一、项目简介1、项目说明尚融宝是一个网络借贷信息中介服务平台，为个人投资者、个人融资用户和小微企业提供专业的线上信贷及出借撮合服务。 行业案例：人人贷 https://www.renrendai.com/、拍拍贷 https://www.paipaidai.com/ 2、项目架构图 3、业务流程图 二、开发环境和技术栈1、技术栈-后端 SpringBoot 2.3.4.RELEASE SpringCloud Hoxton.SR8：微服务基础设施 - 服务注册、服务发现、服务熔断、微服务网关、配置中心等 SpringCloud Alibaba 2.2.2.RELEASE MyBatis Plus：持久层框架和代码生成器 Lombok：简化实体类开发 Swagger2：Api接口文档生成工具 Logback：日志系统 alibaba-easyexcel：Excel读写 Spring Data Redis：Spring项目中访问Redis缓存 HTTPClient: 基于Http协议的客户端，用来实现远程调用 Spring Task：定时任务 2、技术栈-前端 Node.js： JavaScript 运行环境 ES6：JavaScript的模块化版本 axios：一个发送Ajax请求的工具 Vue.js：web 界面的渐进式框架 Element-UI：前端组件库 模块化开发：解决javascript变量全局空间污染的问题 NPM：模块资源管理器 vue-element-admin：基于Vue.js的后台管理系统UI集成方案 NuxtJS：基于Vue.js构建的服务器端渲染应用的轻量级框架 3、中间件 MySQL 5.7：关系型数据库 Redis 5.0：缓存技术 RabbitMQ 3.8：消息中间件 4、第三方接口 阿里云短信：短信网关 阿里云OSS：分布式文件存储 资金托管平台API对接：汇付宝 5、开发环境 jdk 1.8 maven 3.6 ideaIU-2020.2.3： 插件：lombok、MyBatisX 三、金融知识普及1、信用贷款平台的类别1、银行系 优势： 第一，资金雄厚，流动性充足； 第二，项目源质地优良，大多来自于银行原有中小型客户； 第三，风险控制能力强。如恒丰银行、招商银行等旗下都有信用贷款平台。 劣势：收益率偏低，预期年化收益率处于5.5%-8.6%之间，略高于银行其他理财产品，对投资人吸引力有限。 2、国资系 优势： 拥有国有背景股东的隐性背书，兑付能力有保障，业务模式较为规范，从业人员金融专业素养较高。 劣势： 缺乏互联网基因；项目标的较大，起投门槛较高；且产品种类有限，多为企业信用贷； 较为谨慎，层层审核的机制严重影响了平台运营效率；收益率不具有吸引力。 3、民营系民营系平台数量最多，起步最早，但鱼龙混杂，不胜枚举。 优势： 普惠金融，手续便捷；门槛极低，投资起点低最低起投门槛甚至50元； 强大的互联网思维，产品创新能力高，市场化程度高；收益率高，投资收益率具有吸引力。 劣势： 风险偏高，资本实力及风控能力偏弱，跑路及倒闭的高发区。 2、业务流程 1、投资人希望在平台上找到合适的投资项目，获取利润回报的用户 2、借款人需要资金周转的用户 3、资金池风险 资金池：一个大池子放钱，一边存进来（入水管），一边贷出去（出水管）。不管是张三的钱、李四的钱、还是王五的钱，只要进到池子里，就都叫池子的钱了。银行就是典型的资金池。 资金池风险： 第一种情况：投资入水管流量过大，池子里全是水。这种情况，平台亏钱，干不长。原因很简单，池子里的钱是有成本的，只进不出，没有利差，拿什么钱付投资人的利息，时间长了，就只能用投资人的本金还投资人的利息，借新还旧，庞氏骗局。这个过程就直接背离了平台信息中介的身份，而成了与银行类似的金融机构。 第二种情况：突然来了这么多钱，怎么办？只能把放贷出水管的流量调大。放贷的这条出水管上有两个阀门，一个叫找项目，一个叫做风控。遇到这种情况，经常就是两个阀门一块儿放，钱是贷出去了，但由于放松了对风险的把控，能不能再流回来，就不好说了，危险。 第三种情况：提款的出水管流量变大。比如，一个黑天鹅事件，一个负面新闻，一个平台垮了，都可能诱发这种情况，这就是挤兑。比如说某租宝事件后，不只这一家平台，很多其他平台的用户，也在疯狂的提现，有可能一直提到关门为止。 第四种情况最极端：平台把池子里的钱都提出来，走人。这个就不用解释了，就是 跑路。 以上四种情况就是资金池最主要的几个风险——经营不善，风险失控，挤兑和跑路。银监会发布的《网络借贷信息中介机构业务活动管理暂行办法》让资金存管成为网贷平台的硬性要求，同时降低了平台建立资金池、挪用用户资金的风险。 4、资金托管平台 第三方存管模式：“第三方存管”的全称是“客户交易结算资金第三方存管”。这里的第三方存管机构，目前是指具备第三方存管资格的商业银行。银行的流入资金成本低，风控体系较完善，资金池子足够大，而且是国家背书，不会跑路。 说明：由于我们是教学使用，无法申请到正式的资金托管平台的支持，所以我们根据资金托管平台API接口文档，自行开发模拟一套API接口来满足业务需要，业务过程与实际开发基本一致。 Ⅱ、后端架构搭建一、接口工程创建1、创建父工程 BackEndCode1、创建 maven 项目Group：com.kk Artifact：BackEndCode 2、删除src目录3、配置SpringBoot版本&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.3.4.RELEASE&lt;/version&gt; &lt;/parent&gt; 4、配置pom依赖版本号&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud-alibaba.version&gt;2.2.2.RELEASE&lt;/spring-cloud-alibaba.version&gt; &lt;spring-cloud.version&gt;Hoxton.SR8&lt;/spring-cloud.version&gt; &lt;mybatis-plus.version&gt;3.4.1&lt;/mybatis-plus.version&gt; &lt;velocity.version&gt;2.0&lt;/velocity.version&gt; &lt;swagger.version&gt;2.9.2&lt;/swagger.version&gt; &lt;swagger-bootstrap-ui.version&gt;1.9.2&lt;/swagger-bootstrap-ui.version&gt; &lt;commons-lang3.version&gt;3.9&lt;/commons-lang3.version&gt; &lt;commons-fileupload.version&gt;1.3.1&lt;/commons-fileupload.version&gt; &lt;commons-io.version&gt;2.6&lt;/commons-io.version&gt; &lt;alibaba.easyexcel.version&gt;2.1.1&lt;/alibaba.easyexcel.version&gt; &lt;apache.xmlbeans.version&gt;3.1.0&lt;/apache.xmlbeans.version&gt; &lt;fastjson.version&gt;1.2.28&lt;/fastjson.version&gt; &lt;gson.version&gt;2.8.2&lt;/gson.version&gt; &lt;json.version&gt;20170516&lt;/json.version&gt; &lt;aliyun-java-sdk-core.version&gt;4.3.3&lt;/aliyun-java-sdk-core.version&gt; &lt;aliyun-sdk-oss.version&gt;3.10.2&lt;/aliyun-sdk-oss.version&gt; &lt;jodatime.version&gt;2.10.1&lt;/jodatime.version&gt; &lt;jwt.version&gt;0.7.0&lt;/jwt.version&gt; &lt;httpclient.version&gt;4.5.1&lt;/httpclient.version&gt; &lt;/properties&gt; 5、配置pom依赖&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--Spring Cloud--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--Spring Cloud Alibaba--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-alibaba.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--mybatis-plus--&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;${mybatis-plus.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--mybatis-plus 代码生成器--&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;version&gt;${mybatis-plus.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Mybatis Plus 代码生成器模板引擎, --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-engine-core&lt;/artifactId&gt; &lt;version&gt;${velocity.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--swagger--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;${swagger.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--swagger ui--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;${swagger.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--swagger-bootstrap-ui--&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt; &lt;version&gt;${swagger-bootstrap-ui.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--commons-lang3--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;${commons-lang3.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--文件上传--&gt; &lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;${commons-fileupload.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--commons-io--&gt; &lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;${commons-io.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--excel解析--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;easyexcel&lt;/artifactId&gt; &lt;version&gt;${alibaba.easyexcel.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--excel解析依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.xmlbeans&lt;/groupId&gt; &lt;artifactId&gt;xmlbeans&lt;/artifactId&gt; &lt;version&gt;${apache.xmlbeans.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--json--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;${fastjson.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.json&lt;/groupId&gt; &lt;artifactId&gt;json&lt;/artifactId&gt; &lt;version&gt;${json.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;version&gt;${gson.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--阿里云SDK远程调用--&gt; &lt;dependency&gt; &lt;groupId&gt;com.aliyun&lt;/groupId&gt; &lt;artifactId&gt;aliyun-java-sdk-core&lt;/artifactId&gt; &lt;version&gt;${aliyun-java-sdk-core.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--阿里云文件管理--&gt; &lt;dependency&gt; &lt;groupId&gt;com.aliyun.oss&lt;/groupId&gt; &lt;artifactId&gt;aliyun-sdk-oss&lt;/artifactId&gt; &lt;version&gt;${aliyun-sdk-oss.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--日期时间工具--&gt; &lt;dependency&gt; &lt;groupId&gt;joda-time&lt;/groupId&gt; &lt;artifactId&gt;joda-time&lt;/artifactId&gt; &lt;version&gt;${jodatime.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--jwt工具--&gt; &lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;${jwt.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--httpclient--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;${httpclient.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 2、创建模块kk-common1、创建Maven模块在 父工程 下创建普通maven模块 Group：com.kk Artifact：kk-common 2、配置pom&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--lombok用来简化实体类：需要安装lombok插件--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 3、创建模块service-base1、创建Maven模块在 父工程 下创建普通maven模块 Group：com.kk Artifact：service-base 2、配置pom注意：依赖kk-common &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;service-base&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--swagger--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--swagger ui--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 4、创建模块service-core1、创建Maven模块在 父工程 下创建普通maven模块 Group：com.kk Artifact：service-core 2、配置pom注意：依赖kk-common &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;service-base&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mybatis-plus--&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mybatis-plus 代码生成器--&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Mybatis Plus 代码生成器模板引擎, --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-engine-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 5、代码生成器1、创建数据库创建数据库srb_core 并执行sql脚本初始化数据结构和数据 2、创建代码生成器在test目录中创建测试用例，并执行 package com.kk.srb.core; import com.baomidou.mybatisplus.annotation.DbType; import com.baomidou.mybatisplus.annotation.IdType; import com.baomidou.mybatisplus.generator.AutoGenerator; import com.baomidou.mybatisplus.generator.config.DataSourceConfig; import com.baomidou.mybatisplus.generator.config.GlobalConfig; import com.baomidou.mybatisplus.generator.config.PackageConfig; import com.baomidou.mybatisplus.generator.config.StrategyConfig; import com.baomidou.mybatisplus.generator.config.rules.NamingStrategy; import org.junit.Test; public class CodeGenerator { @Test public void genCode() { // 1、创建代码生成器 AutoGenerator mpg = new AutoGenerator ( ); // 2、全局配置 GlobalConfig gc = new GlobalConfig ( ); String projectPath = System.getProperty (\"user.dir\"); gc.setOutputDir (projectPath + \"/src/main/java\"); gc.setAuthor (\"mykk\"); gc.setOpen (false); //生成后是否打开资源管理器 gc.setServiceName (\"%sService\"); //去掉Service接口的首字母I gc.setIdType (IdType.AUTO); //主键策略 gc.setSwagger2 (true);//开启Swagger2模式 mpg.setGlobalConfig (gc); // 3、数据源配置 DataSourceConfig dsc = new DataSourceConfig ( ); dsc.setUrl (\"jdbc:mysql://121.4.120.62:3306/srb_core?serverTimezone=GMT%2B8&amp;characterEncoding=utf-8\"); dsc.setDriverName (\"com.mysql.cj.jdbc.Driver\"); dsc.setUsername (\"root\"); dsc.setPassword (\"root\"); dsc.setDbType (DbType.MYSQL); mpg.setDataSource (dsc); // 4、包配置 PackageConfig pc = new PackageConfig ( ); pc.setParent (\"com.kk.srb.core\"); pc.setEntity (\"pojo.entity\"); //此对象与数据库表结构一一对应，通过 DAO 层向上传输数据源对象。 mpg.setPackageInfo (pc); // 5、策略配置 StrategyConfig strategy = new StrategyConfig ( ); strategy.setNaming (NamingStrategy.underline_to_camel);//数据库表映射到实体的命名策略 strategy.setColumnNaming (NamingStrategy.underline_to_camel);//数据库表字段映射到实体的命名策略 strategy.setEntityLombokModel (true); // lombok strategy.setLogicDeleteFieldName (\"is_deleted\");//逻辑删除字段名 strategy.setEntityBooleanColumnRemoveIsPrefix (true);//去掉布尔值的is_前缀（确保tinyint(1)） strategy.setRestControllerStyle (true); //restful api风格控制器 mpg.setStrategy (strategy); // 6、执行 mpg.execute ( ); } } 6、启动应用程序1、创建application.ymlserver: port: 8110 # 服务端口 spring: profiles: active: dev # 环境设置 application: name: service-core # 服务名 datasource: # mysql数据库连接 type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://121.4.120.62:3306/srb_core?serverTimezone=GMT%2B8&amp;characterEncoding=utf-8 username: root password: root mybatis-plus: #mybatis configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl mapper-locations: classpath:com/kk/srb/core/mapper/xml/*.xml 2、创建SpringBoot配置文件在service-core中创建config包，创建MybatisPlusConfig类 package com.kk.srb.core.config; import com.baomidou.mybatisplus.annotation.DbType; import com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor; import com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor; import org.mybatis.spring.annotation.MapperScan; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.transaction.annotation.EnableTransactionManagement; @Configuration @MapperScan(\"com.kk.srb.core.mapper\") @EnableTransactionManagement //事务处理 public class MybatisPlusConfig { @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() { MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor ( ); interceptor.addInnerInterceptor (new PaginationInnerInterceptor (DbType.MYSQL));//分页 return interceptor; } } 3、创建SpringBoot启动类注意：扫描com.kk.srb package com.kk.srb.core; import org.mybatis.spring.annotation.MapperScan; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication @MapperScan({\"com.kk.srb\"}) public class ServiceCoreApplication { public static void main(String[] args) { SpringApplication.run (ServiceCoreApplication.class, args); } } 4、运行启动类查看控制台8110端口是否成功启动 7、整体代码结构图 二、积分等级CRUD1、积分等级列表接口1、编写积分等级管理接口在controller中添加admin包，添加AdminIntegralGradeController类 package com.kk.srb.core.controller.admin; import com.kk.srb.core.pojo.entity.IntegralGrade; import com.kk.srb.core.service.IntegralGradeService; import org.springframework.web.bind.annotation.CrossOrigin; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; import java.util.List; @CrossOrigin//允许可访问的域列表 @RestController @RequestMapping(\"/admin/core/integralGrade\") public class AdminIntegralGradeController { @Resource private IntegralGradeService integralGradeService; @GetMapping(\"/list\") public List&lt;IntegralGrade&gt; listAll() { return integralGradeService.list ( ); } } 2、测试重启服务，访问： http://localhost:8110/admin/core/integralGrade/list 查看结果json数据 2、逻辑删除接口1、添加删除方法AdminIntegralGradeController添加removeById方法 @DeleteMapping(\"/remove/{id}\") public boolean removeById(@PathVariable Long id){ return integralGradeService.removeById(id); } 2、使用postman测试删除 3、配置Swagger21、Swagger2配置文件在service-base中创建Swagger2Config package com.kk.srb.core.config; import com.google.common.base.Predicates; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import springfox.documentation.builders.ApiInfoBuilder; import springfox.documentation.builders.PathSelectors; import springfox.documentation.service.ApiInfo; import springfox.documentation.service.Contact; import springfox.documentation.spi.DocumentationType; import springfox.documentation.spring.web.plugins.Docket; import springfox.documentation.swagger2.annotations.EnableSwagger2; @Configuration @EnableSwagger2 public class Swagger2Config { @Bean public Docket adminApiConfig() { return new Docket (DocumentationType.SWAGGER_2) .groupName (\"adminApi\") .apiInfo (adminApiInfo ( )) .select ( ) //只显示admin路径下的页面 .paths (Predicates.and (PathSelectors.regex (\"/admin/.*\"))) .build ( ); } private ApiInfo adminApiInfo() { return new ApiInfoBuilder ( ) .title (\"尚融宝后台管理系统-API文档\") .description (\"本文档描述了尚融宝后台管理系统接口\") .version (\"1.0\") .contact (new Contact (\"Helen\", \"http://mykkto.cn\", \"763856958@qq.com\")) .build ( ); } } 2、查看Swagger文档重启服务器查看接口文档：http://localhost:8110/swagger-ui.html 3、常见注解实体类注解：entity的实体类中可以添加一些自定义设置，例如： @ApiModelProperty(value = \"创建时间\", example = \"2019-01-01 8:00:00\") private LocalDateTime createTime; @ApiModelProperty(value = \"更新时间\", example = \"2019-01-01 8:00:00\") private LocalDateTime updateTime; controller注解： 定义在类上 @Api(tags = \"积分等级管理\") 定义在方法上 @ApiOperation(\"积分等级列表\") @ApiOperation(value = \"根据id删除积分等级\", notes = \"逻辑删除\") 定义在参数上 @ApiParam(value = \"数据id\", required = true, example = \"100\") 三、统一返回结果1、数据格式的定义项目中我们会将响应封装成json返回，一般我们会将所有接口的数据格式统一， 使前端对数据的操作更一致、轻松。 一般情况下，统一返回数据格式没有固定的格式，只要能描述清楚返回的数据状态以及要返回的具体数据就可以。但是一般会包含状态码、返回消息、数据这几部分内容 例如，我们的系统要求返回的基本数据格式如下： 成功： { \"code\": 0, \"message\": \"成功\", \"data\": 数据 } 失败： { \"code\": -1, \"message\": \"失败\", \"data\": null } 因此，我们定义统一结果 { \"code\": 数字, //业务响应码 \"message\": 字符串, //返回消息 \"data\": 对象 //返回数据 } 2、创建枚举在kk-common中创建result包，创建枚举 ResponseEnum package com.kk.common.result; import lombok.AllArgsConstructor; import lombok.Getter; import lombok.ToString; @Getter @AllArgsConstructor @ToString public enum ResponseEnum { SUCCESS (0, \"成功\"), ERROR (-1, \"服务器内部错误\"); // 响应状态码 private Integer code; // 响应信息 private String message; } 3、定义同统一结果类package com.kk.common.result; import lombok.Data; import java.util.HashMap; import java.util.Map; @Data public class R { private Integer code; private String message; private Map&lt;String, Object&gt; data = new HashMap ( ); /** * 构造器私有 */ private R() { } /** * 返回成功 */ public static R ok() { R r = new R ( ); r.setCode (ResponseEnum.SUCCESS.getCode ( )); r.setMessage (ResponseEnum.SUCCESS.getMessage ( )); return r; } /** * 返回失败 */ public static R error() { R r = new R ( ); r.setCode (ResponseEnum.ERROR.getCode ( )); r.setMessage (ResponseEnum.ERROR.getMessage ( )); return r; } /** * 设置特定结果 */ public static R setResult(ResponseEnum responseEnum) { R r = new R ( ); r.setCode (responseEnum.getCode ( )); r.setMessage (responseEnum.getMessage ( )); return r; } public R message(String message) { this.setMessage (message); return this; } public R code(Integer code) { this.setCode (code); return this; } public R data(String key, Object value) { this.data.put (key, value); return this; } public R data(Map&lt;String, Object&gt; map) { this.setData (map); return this; } } 4、使用统一返回结果1、修改listAll@GetMapping(\"/list\") @ApiOperation(\"积分等级列表\") public List&lt;IntegralGrade&gt; listAll() { return integralGradeService.list ( ); } 2、修改removeById@ApiOperation(value = \"根据id删除积分等级\", notes = \"逻辑删除\") @DeleteMapping(\"/remove/{id}\") public R removeById( @ApiParam(value = \"数据id\", required = true, example = \"1\") @PathVariable Long id) { boolean result = integralGradeService.removeById (id); if (result) { //return R.setResult(ResponseEnum.UPLOAD_ERROR); return R.ok ( ).message (\"删除成功\"); } else { return R.error ( ).message (\"删除失败\"); } } 3、新增数据@ApiOperation(\"新增积分等级\") @PostMapping(\"/save\") public R save( @ApiParam(value = \"积分等级对象\", required = true) @RequestBody IntegralGrade integralGrade) { boolean result = integralGradeService.save (integralGrade); if (result) { return R.ok ( ).message (\"保存成功\"); } else { return R.error ( ).message (\"保存失败\"); } } 4、根据id查询@ApiOperation(\"根据id获取积分等级\") @GetMapping(\"/get/{id}\") public R getById( @ApiParam(value = \"数据id\", required = true, example = \"1\") @PathVariable Long id ) { IntegralGrade integralGrade = integralGradeService.getById (id); if (integralGrade != null) { return R.ok ( ).data (\"record\", integralGrade); } else { return R.error ( ).message (\"数据不存在\"); } } 5、根据id修改@ApiOperation(\"更新积分等级\") @PutMapping(\"/update\") public R updateById( @ApiParam(value = \"积分等级对象\", required = true) @RequestBody IntegralGrade integralGrade) { boolean result = integralGradeService.updateById (integralGrade); if (result) { return R.ok ( ).message (\"修改成功\"); } else { return R.error ( ).message (\"修改失败\"); } } 四、统一异常处理1、项目中的异常1、制造异常屏蔽 IntegralGrade 中的 @TableField注解 @ApiModelProperty(value = \"逻辑删除(1:已删除，0:未删除)\") //@TableField(\"is_deleted\") @TableLogic private Boolean deleted; 2、Swagger中测试测试列表查询功能，查看结果，发生错误，显示响应失败 2、统一异常处理目标：我们想让异常结果也显示为统一的返回结果对象，并且统一处理系统的异常信息，那么需要进行统一异常处理。 1、创建统一异常处理器kk-common中创建exception包，创建统一异常处理器类UnifiedExceptionHandler package com.kk.common.exception; import com.kk.common.result.R; import lombok.extern.slf4j.Slf4j; import org.springframework.stereotype.Component; import org.springframework.web.bind.annotation.ExceptionHandler; import org.springframework.web.bind.annotation.RestControllerAdvice; @Slf4j @Component //Spring容易自动管理 @RestControllerAdvice //在controller层添加通知。如果使用@ControllerAdvice，则方法上需要添加@ResponseBody public class UnifiedExceptionHandler { /** * 未定义异常 */ @ExceptionHandler(value = Exception.class) //当controller中抛出Exception，则捕获 public R handleException(Exception e) { log.error (e.getMessage ( ), e); return R.error ( ); } } 2、service-core添加扫描添加 “com.kk.common” @SpringBootApplication //@MapperScan({\"com.kk.srb\"})// 需要指定指定路径 @ComponentScan({\"com.kk.srb\",\"com.kk.common\"}) public class ServiceCoreApplication { 3、测试返回统一错误结果 3、处理特定异常如果我们不想显示统一的“服务器内部错误”，需要个性化的显示异常信息，那么需要针对特定的异常做处理 1、添加依赖在kk-common中添加jdbc依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; 2、添加异常处理方法在 UnifiedExceptionHandler 中添加 /** * 特定异常 */ @ExceptionHandler(BadSqlGrammarException.class) public R handleBadSqlGrammarException(BadSqlGrammarException e){ log.error(e.getMessage(), e); return R.setResult(ResponseEnum.BAD_SQL_GRAMMAR_ERROR); } 完整枚举 package com.kk.common.result; import lombok.AllArgsConstructor; import lombok.Getter; import lombok.ToString; @Getter @AllArgsConstructor @ToString public enum ResponseEnum { SUCCESS (0, \"成功\"), ERROR (-1, \"服务器内部错误\"), //-1xx 服务器错误 BAD_SQL_GRAMMAR_ERROR (-101, \"sql语法错误\"), SERVLET_ERROR (-102, \"servlet请求异常\"), //-2xx 参数校验 UPLOAD_ERROR (-103, \"文件上传错误\"), EXPORT_DATA_ERROR (104, \"数据导出失败\"), //-2xx 参数校验 BORROW_AMOUNT_NULL_ERROR (-201, \"借款额度不能为空\"), MOBILE_NULL_ERROR (-202, \"手机号码不能为空\"), MOBILE_ERROR (-203, \"手机号码不正确\"), PASSWORD_NULL_ERROR (204, \"密码不能为空\"), CODE_NULL_ERROR (205, \"验证码不能为空\"), CODE_ERROR (206, \"验证码错误\"), MOBILE_EXIST_ERROR (207, \"手机号已被注册\"), LOGIN_MOBILE_ERROR (208, \"用户不存在\"), LOGIN_PASSWORD_ERROR (209, \"密码错误\"), LOGIN_LOKED_ERROR (210, \"用户被锁定\"), LOGIN_AUTH_ERROR (-211, \"未登录\"), USER_BIND_IDCARD_EXIST_ERROR (-301, \"身份证号码已绑定\"), USER_NO_BIND_ERROR (302, \"用户未绑定\"), USER_NO_AMOUNT_ERROR (303, \"用户信息未审核\"), USER_AMOUNT_LESS_ERROR (304, \"您的借款额度不足\"), LEND_INVEST_ERROR (305, \"当前状态无法投标\"), LEND_FULL_SCALE_ERROR (306, \"已满标，无法投标\"), NOT_SUFFICIENT_FUNDS_ERROR (307, \"余额不足，请充值\"), PAY_UNIFIEDORDER_ERROR (401, \"统一下单错误\"), ALIYUN_SMS_LIMIT_CONTROL_ERROR (-502, \"短信发送过于频繁\"),//业务限流 ALIYUN_SMS_ERROR (-503, \"短信发送失败\"),//其他失败 WEIXIN_CALLBACK_PARAM_ERROR (-601, \"回调参数不正确\"), WEIXIN_FETCH_ACCESSTOKEN_ERROR (-602, \"获取access_token失败\"), WEIXIN_FETCH_USERINFO_ERROR (-603, \"获取用户信息失败\"); // 响应状态码 private Integer code; // 响应信息 private String message; } 3、恢复制造的异常@TableField(value = \"is_deleted\") 4、自定义异常目标：使用一个或较少的异常类，可以捕获和显示所有的异常信息。 方案：因此，我们可以创建一个自定义异常类（必须是运行时异常），在程序中抛出这个自定义异常对象，并在统一异常处理器中捕获自定义异常对象 1、创建自定义异常类完整查看github源码 package com.kk.common.exception; import lombok.Data; import lombok.NoArgsConstructor; @Data @NoArgsConstructor public class BusinessException extends RuntimeException { //状态码 private Integer code; //错误消息 private String message; } 2、添加异常处理方法UnifiedExceptionHandler类中添加 /** * 自定义异常 */ @ExceptionHandler(BusinessException.class) public R handleBusinessException(BusinessException e){ log.error(e.getMessage(), e); return R.error().message(e.getMessage()).code(e.getCode()); } 3、修改Controller在AdminIntegralGradeController的方法中添加异常处理，业务中需要的位置抛出BusinessException自定义异常。 @ApiOperation(\"新增积分等级\") @PostMapping(\"/save\") public R save( @ApiParam(value = \"积分等级对象\", required = true) @RequestBody IntegralGrade integralGrade){ //如果借款额度为空就手动抛出一个自定义的异常！ if(integralGrade.getBorrowAmount() == null){ //BORROW_AMOUNT_NULL_ERROR(-201, \"借款额度不能为空\"), throw new BusinessException(ResponseEnum.BORROW_AMOUNT_NULL_ERROR); } boolean result = integrationService.save(integralGrade); if (result) { return R.ok().message(\"保存成功\"); } else { return R.error().message(\"保存失败\"); } } 4、测试 5、异常处理优化目标：以优雅的 Assert(断言) 方式来校验业务的异常情况，消除 if else 1、什么是断言用断言的方式封装异常的抛出 package com.kk.srb.core; import org.junit.Test; import org.springframework.util.Assert; public class AssertTests { //if else的用法 @Test public void test1() { Object o = null; if (o == null) { throw new IllegalArgumentException (\"用户不存在.\"); } } //断言的用法：更为简洁 @Test public void test2() { // 另一种写法 Object o = null; Assert.notNull (o, \"用户不存在.\"); } } 2、自定义断言引入自定义断言，类路径：com.kk.common.exception.Assert @Slf4j public class Assert { /** * 断言对象不为空 * obj 为空则抛异常 * * @param obj * @param responseEnum */ public static void notNull(Object obj, ResponseEnum responseEnum) { if (obj == null) { log.info (\"obj is null.....................\"); throw new BusinessException (responseEnum); } } ........... } 完整的源代码：Assert.java 3、修改controller在controller中用断言替换if else Assert.notNull(integralGrade.getBorrowAmount(), ResponseEnum.BORROW_AMOUNT_NULL_ERROR); 6、Controller上层异常1、异常分类对异常按阶段进行分类，大体可以分成：进入Controller前的异常 和 业务层异常，具体可以参考下图： 2、处理Controller上层异常UnifiedExceptionHandler中添加 /** * Controller上一层相关异常 */ @ExceptionHandler({ NoHandlerFoundException.class, HttpRequestMethodNotSupportedException.class, HttpMediaTypeNotSupportedException.class, MissingPathVariableException.class, MissingServletRequestParameterException.class, TypeMismatchException.class, HttpMessageNotReadableException.class, HttpMessageNotWritableException.class, MethodArgumentNotValidException.class, HttpMediaTypeNotAcceptableException.class, ServletRequestBindingException.class, ConversionNotSupportedException.class, MissingServletRequestPartException.class, AsyncRequestTimeoutException.class }) public R handleServletException(Exception e) { log.error(e.getMessage(), e); //SERVLET_ERROR(-102, \"servlet请求异常\"), return R.error().message(ResponseEnum.SERVLET_ERROR.getMessage()).code(ResponseEnum.SERVLET_ERROR.getCode()); } 3、测试在save测试用例中输入非法的json参数，则得到下面的结果。我们可以在控制台日志中查看具体的错误原因。前端只需要返回相对简单友好的提示即可。 五、统一日志处理1、Logback日志1.什么是日志通过日志查看程序的运行过程，运行信息，异常信息等 2.日志级别日志记录器（Logger）的行为是分等级的。如下表所示： 分为：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF 默认情况下，spring boot从控制台打印出来的日志级别只有INFO及以上级别，可以配置日志级别 # 设置日志级别 logging: level: root: ERROR 这种方式能将ERROR级别以及以上级别的日志输出到控制台上，其他级别将不会输出 3.创建日志文件spring boot内部使用Logback作为日志实现的框架。 先删除前面在application.yml中的日志级别配置 resources 中创建 logback-spring.xml （默认日志文件的名字） &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;configuration&gt; &lt;/configuration&gt; 4、创建测试日志输出将以下日志输出到任意controller的方法中即可，例如list方法中 前提：类上记得加 @Slf4j，注入 log.info @GetMapping(\"/list\") @ApiOperation(\"积分等级列表\") public R listAll() { log.info (\"hi i'm helen\"); log.warn (\"warning!!!\"); log.error (\"it's a error\"); List&lt;IntegralGrade&gt; list = integralGradeService.list ( ); return R.ok ( ).data (\"list\", list); } 2、基本配置说明1.configuration日志配置的根节点 &lt;configuration&gt;&lt;/configuration&gt; 2.contextName是 的子节点。 每个logger都关联到logger上下文，默认上下文名称为“default”。但可以使用设置成其他名字，用于区分不同的应用程序。 &lt;contextName&gt;kkSrb&lt;/contextName&gt; 3.property是 的子节点，用来定义变量。 有两个属性，name和value：name的值是变量的名称，value是变量的值。 通过 定义的值会被插入到logger上下文中。定义变量后，可以使“${}”来使用变量。 &lt;!-- 日志的输出目录 --&gt; &lt;property name=\"log.path\" value=\"D:/project/finance/srb_log/core\" /&gt; &lt;!--控制台日志格式：彩色日志--&gt; &lt;!-- magenta:洋红 --&gt; &lt;!-- boldMagenta:粗红--&gt; &lt;!-- cyan:青色 --&gt; &lt;!-- white:白色 --&gt; &lt;!-- magenta:洋红 --&gt; &lt;property name=\"CONSOLE_LOG_PATTERN\" value=\"%yellow(%date{yyyy-MM-dd HH:mm:ss}) %highlight([%-5level]) %green(%logger) %msg%n\"/&gt; &lt;!--文件日志格式--&gt; &lt;property name=\"FILE_LOG_PATTERN\" value=\"%date{yyyy-MM-dd HH:mm:ss} [%-5level] %thread %file:%line %logger %msg%n\" /&gt; &lt;!--编码--&gt; &lt;property name=\"ENCODING\" value=\"UTF-8\" /&gt; 4、appender 是的子节点，是负责写日志的组件 有两个必要属性name和class：name指定appender名称，class指定appender的全限定名 对日志进行格式化 定义日志的具体输出格式 编码方式 4.1控制台日志配置 &lt;!-- 控制台日志 --&gt; &lt;appender name=\"CONSOLE\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder&gt; &lt;pattern&gt;${CONSOLE_LOG_PATTERN}&lt;/pattern&gt; &lt;charset&gt;${ENCODING}&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; 4.2文件日志配置 表示日志文件的位置，如果上级目录不存在会自动创建，没有默认值。 默认 true，日志被追加到文件结尾，如果是 false，服务重启后清空现存文件。 &lt;!-- 文件日志 --&gt; &lt;appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"&gt; &lt;file&gt;${log.path}/log.log&lt;/file&gt; &lt;append&gt;true&lt;/append&gt; &lt;encoder&gt; &lt;pattern&gt;${FILE_LOG_PATTERN}&lt;/pattern&gt; &lt;charset&gt;${ENCODING}&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; 5、logger可以是 的子节点，用来设置某一个包或具体某一个类的日志打印级别、指定 name： 用来指定受此logger约束的某一个包或者具体的某一个类 level： 用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF。默认继承上级的级别 可以包含零个或多个元素，标识这个appender将会添加到这个logger &lt;!-- 日志记录器 --&gt; &lt;logger name=\"com.kk\" level=\"INFO\"&gt; &lt;appender-ref ref=\"CONSOLE\" /&gt; &lt;appender-ref ref=\"FILE\" /&gt; &lt;/logger&gt; 6、测试测试日志记录的控制台输出、文件输出、以及日志级别 3、多环境配置springProfile在一个基于Spring boot开发的项目里，常常需要有多套环境的配置：开发，测试以及产品。 使用springProfile 可以分别配置开发（dev），测试（test）以及生产（prod）等不同的环境 &lt;!-- 开发环境和测试环境 --&gt; &lt;springProfile name=\"dev,test\"&gt; &lt;logger name=\"com.kk\" level=\"INFO\"&gt; &lt;appender-ref ref=\"CONSOLE\" /&gt; &lt;/logger&gt; &lt;/springProfile&gt; &lt;!-- 生产环境 --&gt; &lt;springProfile name=\"prod\"&gt; &lt;logger name=\"com.kk\" level=\"ERROR\"&gt; &lt;appender-ref ref=\"CONSOLE\" /&gt; &lt;appender-ref ref=\"FILE\" /&gt; &lt;/logger&gt; &lt;/springProfile&gt; 注意：需要注释原始配置 &lt;!-- 日志记录器 --&gt; &lt;!--&lt;logger name=\"com.kk\" level=\"INFO\"&gt;--&gt; &lt;!--&lt;appender-ref ref=\"CONSOLE\"/&gt;--&gt; &lt;!--&lt;appender-ref ref=\"FILE\"/&gt;--&gt; &lt;!--&lt;/logger&gt;--&gt; 4、滚动日志 ★问题：生产环境下，如果系统长时间运行，那么日志文件会变得越来越大，系统读取和写入日志的时间会越来越慢，严重的情况会耗尽系统内存，导致系统宕机。 解决方案：可以设置滚动日志。 1.设置时间滚动策略RollingFileAppender是 Appender的另一个实现，表示滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将旧日志备份到其他文件 是 的子节点，用来定义滚动策略。 TimeBasedRollingPolicy： 最常用的滚动策略，根据时间来制定滚动策略。 ： 包含文件名及转换符， “%d”可以包含指定的时间格式，如：%d{yyyy-MM-dd}。如果直接使用 %d，默认格式是 yyyy-MM-dd。 ： 可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件。假设设置每个月滚动，且是6，则只保存最近6个月的文件，删除之前的旧文件。注意，删除旧文件是，那些为了归档而创建的目录也会被删除。 &lt;appender name=\"ROLLING_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 要区别于其他的appender中的文件名字 --&gt; &lt;file&gt;${log.path}/log-rolling.log&lt;/file&gt; &lt;encoder&gt; &lt;pattern&gt;${FILE_LOG_PATTERN}&lt;/pattern&gt; &lt;charset&gt;${ENCODING}&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 设置滚动日志记录的滚动策略 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- 日志归档路径以及格式 --&gt; &lt;fileNamePattern&gt;${log.path}/info/log-rolling-%d{yyyy-MM-dd}.log&lt;/fileNamePattern&gt; &lt;!--归档日志文件保留的最大数量--&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; 2.设置触发滚动时机放在的子节点的位置里面，基于实践策略的触发滚动策略 设置触发滚动条件：单个文件大于100M时生成新的文件 注意：修改日志文件名 此时 ${log.path}/info/log-rolling-%d{yyyy-MM-dd}.%i.log &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;1KB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; 5、完整的日志配置文件&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;configuration&gt; &lt;contextName&gt;kkSrb&lt;/contextName&gt; &lt;!-- 日志的输出目录 --&gt; &lt;property name=\"log.path\" value=\"D:/project/test/srb_log/core\"/&gt; &lt;!--控制台日志格式：彩色日志--&gt; &lt;!-- magenta:洋红 --&gt; &lt;!-- boldMagenta:粗红--&gt; &lt;!-- cyan:青色 --&gt; &lt;!-- white:白色 --&gt; &lt;!-- magenta:洋红 --&gt; &lt;property name=\"CONSOLE_LOG_PATTERN\" value=\"%yellow(%date{yyyy-MM-dd HH:mm:ss}) %highlight([%-5level]) %green(%logger) %msg%n\"/&gt; &lt;!--文件日志格式--&gt; &lt;property name=\"FILE_LOG_PATTERN\" value=\"%date{yyyy-MM-dd HH:mm:ss} [%-5level] %thread %file:%line %logger %msg%n\"/&gt; &lt;!--编码--&gt; &lt;property name=\"ENCODING\" value=\"UTF-8\"/&gt; &lt;!-- 控制台日志 --&gt; &lt;appender name=\"CONSOLE\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder&gt; &lt;pattern&gt;${CONSOLE_LOG_PATTERN}&lt;/pattern&gt; &lt;charset&gt;${ENCODING}&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 文件日志 --&gt; &lt;appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"&gt; &lt;file&gt;${log.path}/log.log&lt;/file&gt; &lt;append&gt;true&lt;/append&gt; &lt;encoder&gt; &lt;pattern&gt;${FILE_LOG_PATTERN}&lt;/pattern&gt; &lt;charset&gt;${ENCODING}&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name=\"ROLLING_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 要区别于其他的appender中的文件名字 --&gt; &lt;file&gt;${log.path}/log-rolling.log&lt;/file&gt; &lt;encoder&gt; &lt;pattern&gt;${FILE_LOG_PATTERN}&lt;/pattern&gt; &lt;charset&gt;${ENCODING}&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 设置滚动日志记录的滚动策略 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- 日志归档路径以及格式 --&gt; &lt;fileNamePattern&gt;${log.path}/info/log-rolling-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;!--归档日志文件保留的最大数量--&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;1KB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;!-- &lt;logger name=\"com.kk\" level=\"INFO\"&gt;--&gt; &lt;!-- &lt;appender-ref ref=\"CONSOLE\" /&gt;--&gt; &lt;!-- &lt;appender-ref ref=\"FILE\" /&gt;--&gt; &lt;!-- &lt;/logger&gt;--&gt; &lt;!-- 开发环境和测试环境 --&gt; &lt;springProfile name=\"dev,test\"&gt; &lt;logger name=\"com.kk\" level=\"INFO\"&gt; &lt;appender-ref ref=\"CONSOLE\"/&gt; &lt;/logger&gt; &lt;/springProfile&gt; &lt;!-- 生产环境 --&gt; &lt;springProfile name=\"prod\"&gt; &lt;logger name=\"com.kk\" level=\"ERROR\"&gt; &lt;appender-ref ref=\"CONSOLE\"/&gt; &lt;appender-ref ref=\"ROLLING_FILE\"/&gt; &lt;/logger&gt; &lt;/springProfile&gt; &lt;/configuration&gt; Ⅲ、前端架构搭建一、搭建前端平台1、vue-element-adminvue-element-admin是基于element-ui 的一套后台管理系统集成方案。 GitHub地址：https://github.com/PanJiaChen/vue-element-admin 项目在线预览：https://panjiachen.gitee.io/vue-element-admin 2、vue-admin-template1、简介vueAdmin-template是基于vue-element-admin的一套后台管理系统基础模板（最少精简版），可作为模板进行二次开发。 GitHub地址：https://github.com/PanJiaChen/vue-admin-template 根据用户角色来动态生成侧边栏的分支：https://github.com/PanJiaChen/vue-admin-template/tree/permission-control 2、安装和运行# clone 项目 git clone https...... # 重命名,删掉自带的 .git文件夹 # 进入目录 cd FrontEndCode # 安装依赖 npm install # 启动。执行后，浏览器自动弹出并访问http://localhost:9528/ npm run dev 3、前端配置1、禁用ESLint语法检查vue.config.js 第30行处禁用ESLint语法检查 lintOnSave: false, 2、添加prettier格式化配置在vue项目根目录下新建一个文件.prettierrc { \"semi\": false, \"singleQuote\": true, \"htmlWhitespaceSensitivity\": \"ignore\" } 3、修改页面标题src/settings.js 第3行处修改页面标题 4、国际化设置src/main.js 第7行处修改语言 import locale from 'element-ui/lib/locale/lang/zh-CN' // lang i18n 测试平台语言的修改 5、下拉菜单修改 6、登录页修改src/views/login/index.vue 修改页面标题、登录按钮等 二、系统路由配置1、组件定义1、创建vue组件在src/views文件夹下创建以下文件夹和文件 2、list.vuecore/integral-grade/list.vue 注意，最底下保留一行，不然vscode报错 &lt;template&gt; &lt;div class=\"app-container\"&gt;积分等级列表&lt;/div&gt; &lt;/template&gt; 3、form.vuecore/integral-grade/orm.vue &lt;template&gt; &lt;div class=\"app-container\"&gt; 积分等级表单 &lt;/div&gt; &lt;/template&gt; 2、路由定义修改 src/router/index.js 文件，重新定义constantRoutes，拷贝到 dashboard路由节点 下面 注意：每个路由的name不能相同 { path: '/core/integral-grade', component: Layout, redirect: '/core/integral-grade/list', name: 'coreIntegralGrade', meta: { title: '积分等级管理', icon: 'el-icon-s-marketing' }, alwaysShow: true, children: [ { path: 'list', name: 'coreIntegralGradeList', component: () =&gt; import('@/views/core/integral-grade/list'), meta: { title: '积分等级列表' } }, { path: 'create', name: 'coreIntegralGradeCreate', component: () =&gt; import('@/views/core/integral-grade/form'), meta: { title: '新增积分等级' } }, { path: 'edit/:id', name: 'coreIntegralGradeEdit', component: () =&gt; import('@/views/core/integral-grade/form'), meta: { title: '编辑积分等级' }, hidden: true } ] }, 三、前端开发流程1、全栈开发流程1、前端调用流程下图是开发过程中涉及到和几个核心的模块，我们已经完成了路由的配置和页面组件的创建，接下来我们需要进一步完善页面组件的模板 &lt;template&gt;部分，以及脚本&lt;script&gt;等部分的开发，然后创建前后端对接需要的api模块，最后通过api模块向后端接口发起调用。 2、nginx反向代理配置目前，应用程序的前后端基本架构如下：srb-admin是前端程序，直接调用后端的srb-core微服务 为了能够让前端程序能够同时对接多个后端服务，我们可以使用多种解决方案，例如nginx反向代理、微服务网关等。这里我们先使用nginx作为前后端中间的反向代理层，架构如下 nginx的配置 server { listen 80; server_name localhost; location ~ /core/ { proxy_pass http://localhost:8110; } location ~ /sms/ { proxy_pass http://localhost:8120; } location ~ /oss/ { proxy_pass http://localhost:8130; } } nginx的命令 start nginx #启动 nginx -s stop #停止 nginx -s reload #重新加载配置 前端的配置： .env.development # base api：连接到nginx VUE_APP_BASE_API = 'http://localhost' 3、mock-serverVUE_APP_BASE_API 的 修改会影响到平台模拟登录功能的mock数据，因此需要修改mock-server的地址 修改 mock/mock-server.js 文件 第37行 url: new RegExp(`/dev-api${url}`), 修改 src/api/user.js中的接口调用，为每一个远程调用添加配置 baseURL: '/dev-api', 2、前端组件开发1、定义api模块创建文件 src/api/core/integral-grade.js // @ 符号在vue.config.js 中配置， 表示 'src' 路径的别名 import request from '@/utils/request' export default { list() { return request({ url: '/admin/core/integralGrade/list', method: 'get' }) } } 2、定义页面组件脚本src/views/core/integral-grade/list.vue &lt;script&gt; import integralGradeApi from '@/api/core/integral-grade' export default { // 定义数据模型 data() { return { list: [] // 数据列表 } }, // 页面渲染成功后获取数据 created() { this.fetchData() }, // 定义方法 methods: { fetchData() { // 调用api integralGradeApi.list().then(response =&gt; { this.list = response.data.list }) } } } &lt;/script&gt; 3、定义页面组件模板src/views/core/integral-grade/list.vue &lt;template&gt; &lt;div class=\"app-container\"&gt; &lt;!-- 表格 --&gt; &lt;el-table :data=\"list\" border stripe&gt; &lt;el-table-column type=\"index\" width=\"50\" /&gt; &lt;el-table-column prop=\"borrowAmount\" label=\"借款额度\" /&gt; &lt;el-table-column prop=\"integralStart\" label=\"积分区间开始\" /&gt; &lt;el-table-column prop=\"integralEnd\" label=\"积分区间结束\" /&gt; &lt;/el-table&gt; &lt;/div&gt; &lt;/template&gt; 4、axios响应拦截器修改src/utils/request.js 中 将第49行的 if (res.code !== 20000) { 修改成 if (res.code !== 0 &amp;&amp; res.code !== 20000) { 因为我们的后端接口统一结果判断0为成功的响应结果，而mock数据判断20000位正确的结果 四、完善积分模块1、删除数据1.定义api src/api/core/integral-grade.js removeById(id) { return request({ url: `/admin/core/integralGrade/remove/${id}`, method: 'delete' }) } 2.页面组件模板src/views/core/integral-grade/list.vue，在table组件中添加删除列 &lt;el-table-column label=\"操作\" width=\"200\" align=\"center\"&gt; &lt;template slot-scope=\"scope\"&gt; &lt;el-button type=\"danger\" size=\"mini\" icon=\"el-icon-delete\" @click=\"removeById(scope.row.id)\" &gt; 删除 &lt;/el-button&gt; &lt;/template&gt; &lt;/el-table-column&gt; 3.删除数据脚本// 根据id删除数据 removeById(id) { // debugger console.log('id', id) this.$confirm('此操作将永久删除该记录, 是否继续?', '提示', { confirmButtonText: '确定', cancelButtonText: '取消', type: 'warning' }) .then(() =&gt; { return integralGradeApi.removeById(id) }) .then(response =&gt; { this.$message({ message: response.message, type: 'success' }) this.fetchData() }) .catch(error =&gt; { console.log('catch的error', error) if (error === 'cancel') { this.$message({ type: 'info', message: '已取消删除' }) } }) } 2、新增数据1.定义api src/api/core/integral-grade.js save(integralGrade) { return request({ url: '/admin/core/integralGrade/save', method: 'post', data: integralGrade }) } 2.定义页面datasrc/views/core/integral-grade/form.vue，完善data定义 &lt;script&gt; export default { data() { return { integralGrade: {}, // 初始化数据 saveBtnDisabled: false // 保存按钮是否禁用，防止表单重复提交 } } } &lt;/script&gt; 3.页面组件模板src/views/core/integral-grade/form.vue，完善template &lt;template&gt; &lt;div class=\"app-container\"&gt; &lt;!-- 输入表单 --&gt; &lt;el-form label-width=\"120px\"&gt; &lt;el-form-item label=\"借款额度\"&gt; &lt;el-input-number v-model=\"integralGrade.borrowAmount\" :min=\"0\" /&gt; &lt;/el-form-item&gt; &lt;el-form-item label=\"积分区间开始\"&gt; &lt;el-input-number v-model=\"integralGrade.integralStart\" :min=\"0\" /&gt; &lt;/el-form-item&gt; &lt;el-form-item label=\"积分区间结束\"&gt; &lt;el-input-number v-model=\"integralGrade.integralEnd\" :min=\"0\" /&gt; &lt;/el-form-item&gt; &lt;el-form-item&gt; &lt;el-button :disabled=\"saveBtnDisabled\" type=\"primary\" @click=\"saveOrUpdate()\"&gt; 保存 &lt;/el-button&gt; &lt;/el-form-item&gt; &lt;/el-form&gt; &lt;/div&gt; &lt;/template&gt; 4.新增数据脚本src/views/core/integral-grade/form.vue，引入api import integralGradeApi from '@/api/core/integral-grade' 定义保存方法 methods: { saveOrUpdate() { // 禁用保存按钮 this.saveBtnDisabled = true this.saveData() }, // 新增数据 saveData() { // debugger integralGradeApi.save(this.integralGrade).then(response =&gt; { this.$message({ type: 'success', message: response.message }) this.$router.push('/core/integral-grade/list') }) } } 3、回显数据1.列表页编辑按钮src/views/core/integral-grade/list.vue，表格“操作”列中增加“修改”按钮 &lt;router-link :to=\"'/core/integral-grade/edit/' + scope.row.id\" style=\"margin-right:5px;\" &gt; &lt;el-button type=\"primary\" size=\"mini\" icon=\"el-icon-edit\"&gt; 修改 &lt;/el-button&gt; &lt;/router-link&gt; 2.定义apisrc/api/core/integral-grade.js getById(id) { return request({ url: `/admin/core/integralGrade/get/${id}`, method: 'get' }) } 3.获取数据脚本src/views/core/integral-grade/form.vue，methods中定义回显方法 // 根据id查询记录 fetchDataById(id) { integralGradeApi.getById(id).then(response =&gt; { this.integralGrade = response.data.record }) } 页面渲染成功后获取数据 因为已在路由中定义如下内容：path: ‘edit/:id’/，因此可以使用 this.$route.params.id 获取路由中的id //页面渲染成功 created() { if (this.$route.params.id) { this.fetchDataById(this.$route.params.id) } }, 4、更新数据1.定义apisrc/api/core/integral-grade.js updateById(integralGrade) { return request({ url: '/admin/core/integralGrade/update', method: 'put', data: integralGrade }) } 2.更新数据脚本src/views/core/integral-grade/form.vue，methods中定义updateData // 根据id更新记录 updateData() { // 数据的获取 integralGradeApi.updateById(this.integralGrade).then(response =&gt; { this.$message({ type: 'success', message: response.message }) this.$router.push('/core/integral-grade/list') }) } 完善saveOrUpdate方法 saveOrUpdate() { // 禁用保存按钮 this.saveBtnDisabled = true if (!this.integralGrade.id) { this.saveData() } else { this.updateData() } }, 参考地址 ↓1、Springboot 启动注解扫描：https://blog.csdn.net/m0_50932526/article/details/122936434 2、异常：org.apache.ibatis.binding.BindingException: Invalid bound statement (not fou 需要指定扫描包路径为具体路径，之前是 @MapperScan({“com.kk.srb”}),现在是**@MapperScan({“com.kk.srb.core.mapper”})** https://www.freesion.com/article/7476436940/ 3、vue项目 出现 Failed to compile. 编译错误，可能是指定的路径和文件不匹配 4、 &lt; 标签开头如果不是成对存在，需用 \\ 转义","categories":[{"name":"项目-尚融宝","slug":"项目-尚融宝","permalink":"https://mykkto.github.io/categories/%E9%A1%B9%E7%9B%AE-%E5%B0%9A%E8%9E%8D%E5%AE%9D/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://mykkto.github.io/tags/nginx/"},{"name":"springboot","slug":"springboot","permalink":"https://mykkto.github.io/tags/springboot/"},{"name":"vue","slug":"vue","permalink":"https://mykkto.github.io/tags/vue/"}],"author":"mykk"},{"title":"项目-尚融宝-00-项目目录总纲","slug":"08-项目/01尚融宝/00_主篇","date":"2022-04-26T14:17:15.000Z","updated":"2022-04-26T14:15:45.875Z","comments":true,"path":"posts/73b5f9d8.html","link":"","permalink":"https://mykkto.github.io/posts/73b5f9d8.html","excerpt":"","text":"一、前言1、废话最近入职了外包，技术远古，寻思着，做个金融项目练练手，不至于被外包弱后的技术带偏，想着利用下班时间做点事情，一方面是不想技术被停留在节点上，一方面想着能有所提升和巩固。为什么选择金融相关项目，做了一些调研，银行和金融相对含金量搞点，虽然这个项目也比较普通，但是做练习入手还行，后面也会在此基础上做一些自己的扩展。 2、食用说明把整个项目切分为多个篇章，避免一篇下来比较多也乱，参考以下目录，会把项目的源码放到 gitHub上 ，在 上面会做说明。 3、4、5、二、项目分片目录0、GitHub仓库1、金融背景及其后端搭建2、3、4、5、三、注意事项和基本操作参考地址 ↓环环主讲项目：https://www.bilibili.com/video/BV1VV411n7nR?spm_id_from=333.337.search-card.all.click 老齐解说外包：https://www.bilibili.com/video/BV1vP4y1x7T2?spm_id_from=333.880.my_history.page.click","categories":[{"name":"项目-尚融宝","slug":"项目-尚融宝","permalink":"https://mykkto.github.io/categories/%E9%A1%B9%E7%9B%AE-%E5%B0%9A%E8%9E%8D%E5%AE%9D/"}],"tags":[{"name":"合集","slug":"合集","permalink":"https://mykkto.github.io/tags/%E5%90%88%E9%9B%86/"},{"name":"金融","slug":"金融","permalink":"https://mykkto.github.io/tags/%E9%87%91%E8%9E%8D/"},{"name":"项目","slug":"项目","permalink":"https://mykkto.github.io/tags/%E9%A1%B9%E7%9B%AE/"}],"author":"mykk"},{"title":"JVM-01-字节码","slug":"07-senior/03jvm/01_jvm_Byte","date":"2022-04-16T13:00:12.000Z","updated":"2022-05-22T15:01:03.835Z","comments":true,"path":"posts/6ae84987.html","link":"","permalink":"https://mykkto.github.io/posts/6ae84987.html","excerpt":"","text":"一、JVM概述1、Java的生态1、Oracle JDK与Open JDK 关系Oracle与OpenJDK之间的主要区别： Oracle JDK版本将每三年发布一次LTS版本，而OpenJDK版本每三个月发布一次。 Oracle JDK将更多地关注稳定性，它重视更多的企业级用户，而OpenJDK经常发布以支持其他性能，这可能会导致不稳定。 Oracle JDK支持长期发布的更改，而Open JDK仅支持计划和完成下一个发行版。 Oracle JDK根据二进制代码许可协议获得许可，而OpenJDK根据GPL v2许可获得许可。 使用Oracle平台时会产生一些许可影响。如Oracle 宣布的那样，在没有商业许可的情况下，在2019年1月之后发布的Oracle Java SE 8的公开更新将无法用于商业，商业或生产用途。但是，OpenJDK是完全开源的，可以自由使用。 Oracle JDK的构建过程基于OpenJDK，因此OpenJDK与Oracle JDK之间没有技术差异。 顶级公司正在使用Oracle JDK，例如Android Studio，Minecraft和IntelliJ IDEA开发工具，其中Open JDK不太受欢迎。 Oracle JDK具有Flight Recorder，Java Mission Control和Application Class-Data Sharing功能，Open JDK具有Font Renderer功能，这是OpenJDK与Oracle JDK之间的显着差异。 Oracle JDK具有良好的GC选项和更好的渲染器，而OpenJDK具有更少的GC选项，并且由于其包含自己的渲染器的分布，因此具有较慢的图形渲染器选项。 在响应性和JVM性能方面，Oracle JDK与OpenJDK相比提供了更好的性能。 与OpenJDK相比，Oracle JDK的开源社区较少，OpenJDK社区用户的表现优于Oracle JDK发布的功能，以提高性能。 如果使用Oracle JDK会产生许可影响，而OpenJDK没有这样的问题，并且可以以任何方式使用，以满足完全开源和免费使用。 Oracle JDK在运行JDK时不会产生任何问题，而OpenJDK在为某些用户运行JDK时会产生一些问题。 根据使用方的使用和许可协议，现有应用程序可以从Oracle JDK迁移到Open JDK，反之亦然。 Oracle JDK将从其10.0.X版本将收费，用户必须付费或必须依赖OpenJDK才能使用其免费版本。 Oracle JDK不会为即将发布的版本提供长期支持，用户每次都必须通过更新到最新版本获得支持来获取最新版本。 Oracle JDK以前的1.0版以前的版本是由Sun开发的，后来被Oracle收购并为其他版本维护，而OpenJDK最初只基于Java SDK或JDK版本7。 Oracle JDK发布时大多数功能都是开源的，其中一些功能免于开源，并且根据Sun的许可授权，而OpenJDK发布了所有功能，如开源和免费。 Oracle JDK完全由Oracle公司开发，而Open JDK项目由IBM，Apple，SAP AG，Redhat等顶级公司加入和合作。 2、JDK与JVM是什么关系 1、如何理解Java是跨平台的语言 当Java源代码成功编译成字节码后，如果想在不同的平台上面运行，则无须再次编译这个优势不再那么吸引人了。Python、PHP、Perl、Ruby、Lisp等有强大的解释器。跨平台似乎已经快成为一门语言必选的特性。 2、如何理解JVM跨语言的平台 Java虚拟机根本不关心运行在其内部的程序到底是使用何种编程语言编写的，它只关心“字节码”文件。 Java不是最强大的语言，但是JVM是最强大的虚拟机。 3、Java发展的几个重大事件2000年，JDK 1.3发布，Java HotSpot Virtual Machine正式发布，成为Java的默认虚拟机。2002年，JDK 1.4发布，古老的Classic虚拟机退出历史舞台。2003年年底，Java平台的Scala正式发布，同年Groovy也加入了 Java阵营。2006年，JDK 6发布。同年，Java开源并建立了 OpenJDK。顺理成章，Hotspot虚拟机也成为了 OpenJDK中的默认虚拟机。2007年，Java平台迎来了新伙伴Clojure。2008 年，Oracle 收购了 BEA,得到了 JRockit 虚拟机。2009年，Twitter宣布把后台大部分程序从Ruby迁移到Scala，这是Java平台的又一次大规模应用。2010年，Oracle收购了Sun，获得Java商标和最具价值的HotSpot虚拟机。此时，Oracle拥有市场占用率最高的两款虚拟机HotSpot和JRockit，并计划在未来对它们进行整合：HotRockit. JCP组织管理：Java语言2011年，JDK7发布。在JDK 1.7u4中，正式启用了新的垃圾回收器G1。2017年，JDK9发布。将G1设置为默认GC，替代CMS (被标记为Deprecated)同年，IBM的J9开源，形成了现在的Open J9社区2018年，Android的Java侵权案判决，Google赔偿Oracle计88亿美元同年，JDK11发布，LTS版本的JDK,发布革命性的ZGC,调整JDK授权许可2019年，JDK12发布，加入RedHat领导开发的Shenandoah GC 2、JVM的架构1、JVM架构图 这个架构可以分成三层看： 最上层：javac编译器将编译好的字节码class文件，通过java 类装载器执行机制，把对象或class文件存放在 jvm划分内存区域。中间层：称为Runtime Data Area，主要是在Java代码运行时用于存放数据的，从左至右为方法区(永久代、元数据区)、堆(共享,GC回收对象区域)、栈、程序计数器、寄存器、本地方法栈(私有)。最下层：解释器、JIT(just in time)编译器和 GC（Garbage Collection，垃圾回收器） 2、JVM脉络 二、字节码文件概述1、字节码文件跨平台Class文件结构不仅仅是Java虚拟机的执行入口，更是Java生态圈的基础和核心。 1、class文件里是什么字节码文件里是什么？ 源代码经过编译器编译之后便会生成一个字节码文件，字节码是一种二进制的类文件，它的内容是JVM的指令，而不像C、C++经由编译器直接生成机器码。 随着Java平台的不断发展，在将来，Class文件的内容也一定会做进一步的扩充，但是其基本的格式和结构不会做重大调整。 2、☆ class文件的编译器1、从位置上理解 2、前端编译器的种类Java源代码的编译结果是字节码，那么肯定需要有一种编译器能够将Java源码编译为字节码，承担这个重要责任的就是配置在path环境变量中的javac编译器。javac是一种能够将Java源码编译为字节码的前端编译器。 HotSpot VM并没有强制要求前端编译器只能使用javac来编译字节码，其实只要编译结果符合JVM规范都可以被JVM所识别即可。在Java的前端编译器领域，除了javac之外，还有一种被大家经常用到的前端编译器，那就是内置在Eclipse中的ECJ (Eclipse Compiler for Java)编译器。和Javac的全量式编译不同，ECJ是一种增量式编译器。 默认情况下，IntelliJ IDEA 使用 javac 编译器。(还可以自己设置为AspectJ编译器 ajc) 3、前端编译器的任务前端编译器的主要任务就是负责将符合Java语法规范的Java代码转换为符合JVM规范的字节码文件。 3、前端编译器的局限性前端编译器并不会直接涉及编译优化等方面的技术，而是将这些具体优化细节移交给HotSpot的JIT编译器负责。 复习：AOT(静态提前编译器，Ahead Of Time Compiler) jdk9引入了AOT编译器(静态提前编译器，Ahead Of Time Compiler) Java 9 引入了实验性 AOT 编译工具jaotc。它借助了 Graal 编译器，将所输入的 Java 类文件转换为机器码，并存放至生成的动态共享库之中。 所谓 AOT 编译，是与即时编译相对立的一个概念。我们知道，即时编译指的是在程序的运行过程中，将字节码转换为可在硬件上直接运行的机器码，并部署至托管环境中的过程。而 AOT 编译指的则是，在程序运行之前，便将字节码转换为机器码的过程。.java -&gt; .class -&gt; .so 最大好处：Java虚拟机加载已经预编译成二进制库，可以直接执行。不必等待即时编译器的预热，减少Java应用给人带来“第一次运行慢”的不良体验。 缺点：破坏了java“一次编译，到处运行”，必须为每个不同硬件、OS编译对应的发行包。降低了Java链接过程的动态性，加载的代码在编译期就必须全部已知。 还需要继续优化中，最初只支持Linux x64 java base 2、Class对象对应类型 （1）class：外部类，成员(成员内部类，静态内部类)，局部内部类，匿名内部类（2）interface：接口（3）[]：数组（4）enum：枚举（5）annotation：注解@interface（6）primitive type：基本数据类型（7）void @Test public void test(){ Class c1 = Object.class; Class c2 = Comparable.class; Class c3 = String[].class; Class c4 = int[][].class; Class c5 = ElementType.class; Class c6 = Override.class; Class c7 = int.class; Class c8 = void.class; Class c9 = Class.class; int[] a = new int[10]; int[] b = new int[100]; Class c10 = a.getClass(); Class c11 = b.getClass(); // 只要元素类型与维度一样，就是同一个Class System.out.println(c10 == c11); } 3、字节码指令1、什么是字节码指令Java虚拟机的指令由一个字节长度的、代表着某种特定操作含义的操作码（opcode）以及跟随其后的零至多个代表此操作所需参数的操作数（operand）所构成。虚拟机中许多指令并不包含操作数，只有一个操作码。 2、☆ 面试题i++和++i有什么区别 public class ByteCodeInterview { //面试题： i++和++i有什么区别？ @Test public void test1(){ int i = 10; i++; //++i; System.out.println(i); } @Test public void test2(){ int i = 10; i = i++; System.out.println(i); } @Test public void test3(){ int i = 2; i *= i++; System.out.println(i); } @Test public void test4(){ int k = 10; k = k + (k++) + (++k); System.out.println(k); } //包装类对象的缓存问题 @Test public void test5(){ // Integer x = 5; // int y = 5; Integer i1 = 10; Integer i2 = 10; System.out.println(i1 == i2); Integer i3 = 128; Integer i4 = 128; System.out.println(i3 == i4); Boolean b1 = true; Boolean b2 = true; System.out.println(b1 == b2); } @Test public void test6(){ String str = new String(\"hello\") + new String(\"world\"); String str1 = \"helloworld\"; System.out.println(str == str1); } } class Father { int x = 10; public Father() { this.print(); x = 20; } public void print() { System.out.println(\"Father.x = \" + x); } } class Son extends Father { int x = 30; public Son() { this.print(); x = 40; } public void print() { System.out.println(\"Son.x = \" + x); } } public class SonTest { public static void main(String[] args) { Father f = new Son(); System.out.println(f.x); } } 4、如何解读class文件方式一：一个一个二进制的看。这里用到的是Notepad++,需要安装一个HEX-Editor插件，或者使用Binary Viewer 方式二：使用javap指令：jdk自带的反解析工具方式三：使用IDEA插件：jclasslib 或jclasslib bytecode viewer客户端工具。（可视化更好） 三、Class文件结构细节1、概述1、class文件结构概述Class文件的结构并不是一成不变的，随着Java虚拟机的不断发展，总是不可避免地会对Class文件结构做出一些调整，但是其基本结构和框架是非常稳定的。Class文件的总体结构如下： 魔数 Class文件版本 常量池 访问标识(或标志) 类索引，父类索引，接口索引集合 字段表集合 方法表集合 属性表集合 2、结构图表 这是一张Java字节码总的结构表，我们按照上面的顺序逐一进行解读就可以了。 2、魔数Magic Number（魔数）：class文件的标志 每个 Class 文件开头的4个字节的无符号整数称为魔数（Magic Number） 它的唯一作用是确定这个文件是否为一个能被虚拟机接受的有效合法的Class文件。即：魔数是Class文件的标识符。 魔数值固定为0xCAFEBABE。不会改变。 如果一个Class文件不以0xCAFEBABE开头，虚拟机在进行文件校验的时候就会直接抛出以下错误： Error: A JNI error has occurred, please check your installation and try againException in thread “main” java.lang.ClassFormatError: Incompatible magic value 1885430635 in class file StringTest 使用魔数而不是扩展名来进行识别主要是基于安全方面的考虑，因为文件扩展名可以随意地改动。 3、高版本执行低版本Class不同版本的Java编译器编译的Class文件对应的版本是不一样的。目前，高版本的Java虚拟机可以执行由低版本编译器生成的Class文件,但是低版本的Java虚拟机不能执行由高版本编译器生成的Class文件。否则JVM会抛出java.lang.UnsupportedClassVersionError异常。 （向下兼容） 在实际应用中，由于开发环境和生产环境的不同，可能会导致该问题的发生。因此，需要我们在开发时，特别注意开发编译的JDK版本和生产环境中的JDK版本是否一致。 class文件版本号 紧接着魔数的 4 个字节存储的是 Class 文件的版本号。同样也是4个字节。第5个和第6个字节所代表的含义就是编译的副版本号minor_version，而第7个和第8个字节就是编译的主版本号major_version。 它们共同构成了class文件的格式版本号。譬如某个 Class 文件的主版本号为 M，副版本号为 m，那么这个Class 文件的格式版本号就确定为 M.m。 版本号和Java编译器的对应关系如下表： Java 的版本号是从45开始的，JDK 1.1之后的每个JDK大版本发布主版本号向上加1。 虚拟机JDK版本为1.k （k &gt;= 2）时，对应的class文件格式版本号的范围为45.0 - 44+k.0 （含两端）。 4、☆ 常量池常量池：class文件的基石？作用是？ 1、为什么需要常量池计数器constant_pool_count （常量池计数器） 由于常量池的数量不固定，时长时短，所以需要放置两个字节来表示常量池容量计数值。 常量池容量计数值（u2类型）：从1开始，表示常量池中有多少项常量。即constant_pool_count=1表示常量池中有0个常量项。 Demo的值为： 其值为0x0016,掐指一算，也就是22。需要注意的是，这实际上只有21项常量。索引为范围是1-21。为什么呢？通常我们写代码时都是从0开始的，但是这里的常量池却是从1开始，因为它把第0项常量空出来了。这是为了满足后面某些指向常量池的索引值的数据在特定情况下需要表达“不引用任何一个常量池项目”的含义，这种情况可用索引值0来表示。 int[] arr = new int[10]; arr[0]; arr[1]; ar[10 - 1]; #### 2、常量池表 **constant_pool []（常量池）** - constant_pool是一种表结构，以 1 ~ constant_pool_count - 1为索引。表明了后面有多少个常量项。 - 常量池主要存放两大类常量：`字面量（Literal）`和`符号引用（Symbolic References）` - 它包含了class文件结构及其子结构中引用的所有字符串常量、类或接口名、字段名和其他常量。常量池中的每一项都具备相同的特征。第1个字节作为类型标记，用于确定该项的格式，这个字节称为tag byte （标记字节、标签字节）。 ![](https://fastly.jsdelivr.net/gh/mykkTo/image@main/blog/2022/jvm/20220417163310.png) ##### 1、字面量和符号引用 1、字面量和符号引用 在对这些常量解读前，我们需要搞清楚几个概念。 常量池主要存放两大类常量：字面量（Literal）和符号引用（Symbolic References）。如下表： ![](https://fastly.jsdelivr.net/gh/mykkTo/image@main/blog/2022/jvm/20220417164111.png) ```java String str = \"mykk\"; final int NUM = 10; 2、全限定名com/kk/test/Demo这个就是类的全限定名，仅仅是把包名的”.”替换成”/“，为了使连续的多个全限定名之间不产生混淆，在使用时最后一般会加入一个“;”表示全限定名结束。 3、简单名称简单名称是指没有类型和参数修饰的方法或者字段名称，上面例子中的类的add()方法和num字段的简单名称分别是add和num。 4、描述符描述符的作用是用来描述字段的数据类型、方法的参数列表（包括数量、类型以及顺序）和返回值。根据描述符规则，基本数据类型（byte、char、double、float、int、long、short、boolean）以及代表无返回值的void类型都用一个大写字符来表示，而对象类型则用字符L加对象的全限定名来表示，详见下表: （数据类型：基本数据类型 、 引用数据类型） 用描述符来描述方法时，按照先参数列表，后返回值的顺序描述，参数列表按照参数的严格顺序放在一组小括号“()”之内。如：方法java.lang.String toString()的描述符为() Ljava/lang/String;，方法int abc(int[] x, int y)的描述符为([II) I。 2、谈谈你对符号引用、直接引用的理解？这里说明下符号引用和直接引用的区别与关联：符号引用：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。符号引用与虚拟机实现的内存布局无关，引用的目标并不一定已经加载到了内存中。直接引用：直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是与虚拟机实现的内存布局相关的，同一个符号引用在不同虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那说明引用的目标必定已经存在于内存之中了。 3、常量类型和结构常量池中每一项常量都是一个表，JDK1.7之后共有14种不同的表结构数据。如下表格所示： 这14种表（或者常量项结构）的共同点是：表开始的第一位是一个u1类型的标志位（tag），代表当前这个常量项使用的是哪种表结构，即哪种常量类型。 在常量池列表中，CONSTANT_Utf8_info常量项是一种使用改进过的UTF-8编码格式来存储诸如文字字符串、类或者接口的全限定名、字段或者方法的简单名称以及描述符等常量字符串信息。 这14种常量项结构还有一个特点是，其中13个常量项占用的字节固定，只有CONSTANT_Utf8_info占用字节不固定，其大小由length决定。为什么呢？因为从常量池存放的内容可知，其存放的是字面量和符号引用，最终这些内容都会是一个字符串，这些字符串的大小是在编写程序时才确定，比如你定义一个类，类名可以取长取短，所以在没编译前，大小不固定，编译后，通过utf-8编码，就可以知道其长度。 3、访问标识访问标识(access_flag、访问标志、访问标记) 在常量池后，紧跟着访问标记。该标记使用两个字节表示，用于识别一些类或者接口层次的访问信息，包括：这个 Class 是类还是接口；是否定义为 public 类型；是否定义为 abstract 类型；如果是类的话，是否被声明为 final 等。各种访问标记如下所示： 类的访问权限通常为 ACC_ 开头的常量。 每一种类型的表示都是通过设置访问标记的32位中的特定位来实现的。比如，若是public final的类，则该标记为ACC_PUBLIC | ACC_FINAL。 使用ACC_SUPER可以让类更准确地定位到父类的方法super.method(),现代编译器都会设置并且使用这个标记。 4、类索引、父类索引、接口索引集合 在访问标记后，会指定该类的类别、父类类别以及实现的接口，格式如下： 这三项数据来确定这个类的继承关系。 类索引用于确定这个类的全限定名 父类索引用于确定这个类的父类的全限定名。由于 Java语言不允许多重继承，所以父类索引只有一个，除了java.lang.Object 之外，所有的Java类都有父类，因此除了java.lang.Object 外，所有Java类的父类索引都不为 0。 接口索引集合就用来描述这个类实现了哪些接口，这些被实现的接口将按 implements 语句（如果这个类本身是一个接口，则应当是 extends 语句）后的接口顺序从左到右排列在接口索引集合中。 this_class（类索引） 字节无符号整数，指向常量池的索引。它提供了类的全限定名,如com/kk/java1/Demo。this_class的值必须是对常量池表中某项的一个有效索引值。常量池在这个索引处的成员必须为CONSTANT_Class_info类型结构体，该结构体表示这个class文件所定义的类或接口。 super_class （父类索引） 2字节无符号整数，指向常量池的索引。它提供了当前类的父类的全限定名。如果我们没有继承任何类，其默认继承的是java/lang/Object类。同时，由于Java不支持多继承，所以其父类只有一个。 superclass指向的父类不能是final。 interfaces 指向常量池索引集合，它提供了一个符号引用到所有已实现的接口 由于一个类可以实现多个接口，因此需要以数组形式保存多个接口的索引，表示接口的每个索引也是一个指向常量池的CONSTANT_Class (当然这里就必须是接口，而不是类)。 interfaces_count (接口计数器) interfaces_count项的值表示当前类或接口的直接超接口数量。 interfaces [](接口索引集合) interfaces []中每个成员的值必须是对常量池表中某项的有效索引值，它的长度为 interfaces_count。 每个成员 interfaces[i]必须为 CONSTANT_Class_info结构，其中 0 &lt;= i &lt; interfaces_count。在 interfaces[]中，各成员所表示的接口顺序和对应的源代码中给定的接口顺序（从左至右）一样，即 interfaces[0]对应的是源代码中最左边的接口。 5、字段表集合1、字段计数器 fields_count的值表示当前class文件fields表的成员个数。使用两个字节来表示。 fields表中每个成员都是一个field_info结构，用于表示该类或接口所声明的所有类字段或者实例字段，不包括方法内部声明的变量，也不包括从父类或父接口继承的那些字段 2、字段表，fields [] fields表中的每个成员都必须是一个fields_info结构的数据项，用于表示当前类或接口中某个字段的完整描述。 一个字段的信息包括如下这些信息。这些信息中，各个修饰符都是布尔值，要么有，要么没有。 作用域（public、private、protected修饰符） 是实例变量还是类变量（static修饰符） 可变性（final） 并发可见性（volatile修饰符，是否强制从主内存读写） 可否序列化（transient修饰符） 字段数据类型（基本数据类型、对象、数组） 字段名称 字段表结构 6、方法表集合1、方法计数器 methods_count的值表示当前class文件methods表的成员个数。使用两个字节来表示。 methods 表中每个成员都是一个method_info结构。 2、方法表 methods表中的每个成员都必须是一个method_info结构，用于表示当前类或接口中某个方法的完整描述。如果某个method_info结构的access_flags项既没有设置 ACC_NATIVE 标志也没有设置ACC_ABSTRACT标志，那么该结构中也应包含实现这个方法所用的Java虚拟机指令。 method_info结构可以表示类和接口中定义的所有方法，包括实例方法、类方法、实例初始化方法和类或接口初始化方法 方法表的结构实际跟字段表是一样的，方法表结构如下： 7、属性表集合1、属性计数器attributes_count的值表示当前class文件属性表的成员个数。属性表中每一项都是一个attribute_info结构。 2、属性表 ConstantValue 属性 ConstantValue 属性表示一个常量字段的值。位于 field_info结构的属性表中。 ConstantValue_attribute { u2 attribute_name_index; u4 attribute_length; u2 constantvalue_index;//字段值在常量池中的索引，常量池在该索引处的项给出该属性表示的常量值。（例如，值是long型的，在常量池中便是CONSTANT_Long） } - Deprecated 属性 - Deprecated 属性是在 JDK 1.1 为了支持注释中的关键词@deprecated 而引入的。 ```java Deprecated_attribute { u2 attribute_name_index; u4 attribute_length; } Code 属性 Code属性就是存放方法体里面的代码。但是，并非所有方法表都有Code属性。像接口或者抽象方法，他们没有具体的方法体，因此也就不会有Code属性了。Code属性表的结构,如下图： 可以看到：Code属性表的前两项跟属性表是一致的，即Code属性表遵循属性表的结构，后面那些则是他自定义的结构。 InnerClasses 属性 为了方便说明特别定义一个表示类或接口的 Class 格式为 C。如果 C 的常量池中包含某个CONSTANT_Class_info 成员，且这个成员所表示的类或接口不属于任何一个包，那么 C 的ClassFile 结构的属性表中就必须含有对应的 InnerClasses 属性。InnerClasses 属性是在 JDK 1.1 中为了支持内部类和内部接口而引入的,位于 ClassFile结构的属性表。 LineNumberTable 属性 LineNumberTable 属性是可选变长属性，位于 Code结构的属性表。 LineNumberTable属性是用来描述Java源码行号与字节码行号之间的对应关系。这个属性可以用来在调试的时候定位代码执行的行数。 start_pc,即字节码行号;line_number，即Java源代码行号。 在 Code 属性的属性表中,LineNumberTable 属性可以按照任意顺序出现，此外，多个 LineNumberTable属性可以共同表示一个行号在源文件中表示的内容，即 LineNumberTable 属性不需要与源文件的行一一对应。 LocalVariableTable 属性 LocalVariableTable 是可选变长属性，位于 Code属性的属性表中。它被调试器用于确定方法在执行过程中局部变量的信息。在 Code 属性的属性表中，LocalVariableTable 属性可以按照任意顺序出现。 Code 属性中的每个局部变量最多只能有一个 LocalVariableTable 属性。 start pc + length表示这个变量在字节码中的生命周期起始和结束的偏移位置（this生命周期从头0到结尾） index就是这个变量在局部变量表中的槽位（槽位可复用） name就是变量名称 Descriptor表示局部变量类型描述 Signature 属性 Signature 属性是可选的定长属性，位于 ClassFile， field_info或 method_info结构的属性表中。在 Java 语言中，任何类、 接口、 初始化方法或成员的泛型签名如果包含了类型变量（ Type Variables） 或参数化类型（ Parameterized Types），则 Signature 属性会为它记录泛型签名信息。 SourceFile属性 其他属性 Java虚拟机中预定义的属性有20多个，这里就不一一介绍了，通过上面几个属性的介绍，只要领会其精髓，其他属性的解读也是易如反掌。 5、四、javaporacle官方的反解析工具：javap 1、解析字节码的作用通过反编译生成的字节码文件，我们可以深入的了解java代码的工作机制。但是，自己分析类文件结构太麻烦了！除了使用第三方的jclasslib工具之外，oracle官方也提供了工具：javap。 javap是jdk自带的反解析工具。它的作用就是根据class字节码文件，反解析出当前类对应的code区（字节码指令）、局部变量表、异常表和代码行偏移量映射表、常量池等信息。 通过局部变量表，我们可以查看局部变量的作用域范围、所在槽位等信息，甚至可以看到槽位复用等信息。 2、javac -g操作解析字节码文件得到的信息中，有些信息（如局部变量表、指令和代码行偏移量映射表、常量池中方法的参数名称等等）需要在使用javac编译成class文件时，指定参数才能输出。 比如，你直接javac xx.java，就不会在生成对应的局部变量表等信息，如果你使用javac -g xx.java就可以生成所有相关信息了。如果你使用的eclipse或IDEA，则默认情况下，eclipse、IDEA在编译时会帮你生成局部变量表、指令和代码行偏移量映射表等信息的。 3、javap的用法javap的用法格式：javap 其中，classes就是你要反编译的class文件。 在命令行中直接输入javap或javap -help可以看到javap的options有如下选项： -help –help -? 输出此用法消息 -version 版本信息，其实是当前javap所在jdk的版本信息，不是class在哪个jdk下生成的。 -public 仅显示公共类和成员 -protected 显示受保护的/公共类和成员 -p -private 显示所有类和成员 -package 显示程序包/受保护的/公共类 和成员 (默认) -sysinfo 显示正在处理的类的系统信息 (路径, 大小, 日期, MD5 散列,源文件名) -constants 显示静态最终常量 -s 输出内部类型签名 -l 输出行号和本地变量表 -c 对代码进行反汇编 -v -verbose 输出附加信息（包括行号、本地变量表，反汇编等详细信息） -classpath 指定查找用户类文件的位置 -cp 指定查找用户类文件的位置 -bootclasspath 覆盖引导类文件的位置 一般常用的是-v -l -c三个选项。 javap -l 会输出行号和本地变量表信息。javap -c 会对当前class字节码进行反编译生成汇编代码。javap -v classxx 除了包含-c内容外，还会输出行号、局部变量表信息、常量池等信息。 4、使用举例package com.kk.test; public class JavapTest { private int num; boolean flag; protected char gender; public String info; public static final int COUNTS = 1; static{ String url = \"www.mykkto.com\"; } { info = \"java\"; } public JavapTest(){ } private JavapTest(boolean flag){ this.flag = flag; } private void methodPrivate(){ } int getNum(int i){ return num + i; } protected char showGender(){ return gender; } public void showInfo(){ int i = 10; System.out.println(info + i); } } 希望输出的信息比较完整的话，使用如下操作： javac JavapTest.java javap -v -p JavapTest.class J:\\0 大厂素材\\jvm\\00Test&gt;javac JavapTest.java J:\\0 大厂素材\\jvm\\00Test&gt;javap -v -p JavapTest.class Classfile /J:/0 大厂素材/jvm/00Test/JavapTest.class Last modified 2022-4-17; size 1141 bytes MD5 checksum 16833cad2e0187d03ccf1baecaa23808 Compiled from \"JavapTest.java\" public class com.kk.test.JavapTest minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPER Constant pool: #1 = Methodref #16.#42 // java/lang/Object.\"&lt;init&gt;\":()V #2 = String #43 // java #3 = Fieldref #15.#44 // com/kk/test/JavapTest.info:Ljava/lang/String; #4 = Fieldref #15.#45 // com/kk/test/JavapTest.flag:Z #5 = Fieldref #15.#46 // com/kk/test/JavapTest.num:I #6 = Fieldref #15.#47 // com/kk/test/JavapTest.gender:C #7 = Fieldref #48.#49 // java/lang/System.out:Ljava/io/PrintStream; #8 = Class #50 // java/lang/StringBuilder #9 = Methodref #8.#42 // java/lang/StringBuilder.\"&lt;init&gt;\":()V #10 = Methodref #8.#51 // java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; #11 = Methodref #8.#52 // java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder; #12 = Methodref #8.#53 // java/lang/StringBuilder.toString:()Ljava/lang/String; #13 = Methodref #54.#55 // java/io/PrintStream.println:(Ljava/lang/String;)V #14 = String #56 // www.mykkto.com #15 = Class #57 // com/kk/test/JavapTest #16 = Class #58 // java/lang/Object #17 = Utf8 num #18 = Utf8 I #19 = Utf8 flag #20 = Utf8 Z #21 = Utf8 gender #22 = Utf8 C #23 = Utf8 info #24 = Utf8 Ljava/lang/String; #25 = Utf8 COUNTS #26 = Utf8 ConstantValue #27 = Integer 1 #28 = Utf8 &lt;init&gt; #29 = Utf8 ()V #30 = Utf8 Code #31 = Utf8 LineNumberTable #32 = Utf8 (Z)V #33 = Utf8 methodPrivate #34 = Utf8 getNum #35 = Utf8 (I)I #36 = Utf8 showGender #37 = Utf8 ()C #38 = Utf8 showInfo #39 = Utf8 &lt;clinit&gt; #40 = Utf8 SourceFile #41 = Utf8 JavapTest.java #42 = NameAndType #28:#29 // \"&lt;init&gt;\":()V #43 = Utf8 java #44 = NameAndType #23:#24 // info:Ljava/lang/String; #45 = NameAndType #19:#20 // flag:Z #46 = NameAndType #17:#18 // num:I #47 = NameAndType #21:#22 // gender:C #48 = Class #59 // java/lang/System #49 = NameAndType #60:#61 // out:Ljava/io/PrintStream; #50 = Utf8 java/lang/StringBuilder #51 = NameAndType #62:#63 // append:(Ljava/lang/String;)Ljava/lang/StringBuilder; #52 = NameAndType #62:#64 // append:(I)Ljava/lang/StringBuilder; #53 = NameAndType #65:#66 // toString:()Ljava/lang/String; #54 = Class #67 // java/io/PrintStream #55 = NameAndType #68:#69 // println:(Ljava/lang/String;)V #56 = Utf8 www.mykkto.com #57 = Utf8 com/kk/test/JavapTest #58 = Utf8 java/lang/Object #59 = Utf8 java/lang/System #60 = Utf8 out #61 = Utf8 Ljava/io/PrintStream; #62 = Utf8 append #63 = Utf8 (Ljava/lang/String;)Ljava/lang/StringBuilder; #64 = Utf8 (I)Ljava/lang/StringBuilder; #65 = Utf8 toString #66 = Utf8 ()Ljava/lang/String; #67 = Utf8 java/io/PrintStream #68 = Utf8 println #69 = Utf8 (Ljava/lang/String;)V { private int num; descriptor: I flags: ACC_PRIVATE boolean flag; descriptor: Z flags: protected char gender; descriptor: C flags: ACC_PROTECTED public java.lang.String info; descriptor: Ljava/lang/String; flags: ACC_PUBLIC public static final int COUNTS; descriptor: I flags: ACC_PUBLIC, ACC_STATIC, ACC_FINAL ConstantValue: int 1 public com.kk.test.JavapTest(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: aload_0 5: ldc #2 // String java 7: putfield #3 // Field info:Ljava/lang/String; 10: return LineNumberTable: line 16: 0 line 14: 4 line 18: 10 private com.kk.test.JavapTest(boolean); descriptor: (Z)V flags: ACC_PRIVATE Code: stack=2, locals=2, args_size=2 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: aload_0 5: ldc #2 // String java 7: putfield #3 // Field info:Ljava/lang/String; 10: aload_0 11: iload_1 12: putfield #4 // Field flag:Z 15: return LineNumberTable: line 19: 0 line 14: 4 line 20: 10 line 21: 15 private void methodPrivate(); descriptor: ()V flags: ACC_PRIVATE Code: stack=0, locals=1, args_size=1 0: return LineNumberTable: line 24: 0 int getNum(int); descriptor: (I)I flags: Code: stack=2, locals=2, args_size=2 0: aload_0 1: getfield #5 // Field num:I 4: iload_1 5: iadd 6: ireturn LineNumberTable: line 26: 0 protected char showGender(); descriptor: ()C flags: ACC_PROTECTED Code: stack=1, locals=1, args_size=1 0: aload_0 1: getfield #6 // Field gender:C 4: ireturn LineNumberTable: line 29: 0 public void showInfo(); descriptor: ()V flags: ACC_PUBLIC Code: stack=3, locals=2, args_size=1 0: bipush 10 2: istore_1 3: getstatic #7 // Field java/lang/System.out:Ljava/io/PrintStream; 6: new #8 // class java/lang/StringBuilder 9: dup 10: invokespecial #9 // Method java/lang/StringBuilder.\"&lt;init&gt;\":()V 13: aload_0 14: getfield #3 // Field info:Ljava/lang/String; 17: invokevirtual #10 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 20: iload_1 21: invokevirtual #11 // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder; 24: invokevirtual #12 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 27: invokevirtual #13 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 30: return LineNumberTable: line 32: 0 line 33: 3 line 34: 30 static {}; descriptor: ()V flags: ACC_STATIC Code: stack=1, locals=1, args_size=0 0: ldc #14 // String www.mykkto.com 2: astore_0 3: return LineNumberTable: line 11: 0 line 12: 3 } SourceFile: \"JavapTest.java\" J:\\0 大厂素材\\jvm\\00Test&gt; 5、总结1、通过javap命令可以查看一个java类反汇编得到的Class文件版本号、常量池、访问标识、变量表、指令代码行号表等等信息。不显示类索引、父类索引、接口索引集合、()、()等结构 2、通过对前面例子代码反汇编文件的简单分析，可以发现，一个方法的执行通常会涉及下面几块内存的操作：（1）java栈中：局部变量表、操作数栈。（2）java堆。通过对象的地址引用去操作。（3）常量池。（4）其他如帧数据区、方法区的剩余部分等情况，测试中没有显示出来，这里说明一下。 3、平常，我们比较关注的是java类中每个方法的反汇编中的指令操作过程，这些指令都是顺序执行的，可以参考官方文档查看每个指令的含义，很简单：https://docs.oracle.com/javase/specs/jvms/se7/html/jvms-6.html 五、字节码指令集与解析概述Java字节码对于虚拟机，就好像汇编语言对于计算机，属于基本执行指令。 Java 虚拟机的指令由一个字节长度的、代表着某种特定操作含义的数字（称为操作码，Opcode）以及跟随其后的零至多个代表此操作所需参数（称为操作数，Operands）而构成。由于 Java 虚拟机采用面向操作数栈而不是寄存器的结构，所以大多数的指令都不包含操作数，只有一个操作码。 由于限制了 Java 虚拟机操作码的长度为一个字节（即 0～255），这意味着指令集的操作码总数不可能超过 256 条。 官方文档：https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-6.html 熟悉虚拟机的指令对于动态字节码生成、反编译Class文件、Class文件修补都有着非常重要的价值。因此，阅读字节码作为了解 Java 虚拟机的基础技能，需要熟练掌握常见指令。 1、字节码与数据类型在Java虚拟机的指令集中，大多数的指令都包含了其操作所对应的数据类型信息。例如，iload指令用于从局部变量表中加载int型的数据到操作数栈中，而fload指令加载的则是float类型的数据。 对于大部分与数据类型相关的字节码指令，它们的操作码助记符中都有特殊的字符来表明专门为哪种数据类型服务： i代表对int类型的数据操作 l代表long类型的数据操作 s代表short类型的数据操作 b代表byte类型的数据操作 c代表char类型的数据操作 f代表float类型的数据操作 d代表double类型的数据操作 也有一些指令的助记符中没有明确地指明操作类型的字母，如arraylength指令，它没有代表数据类型的特殊字符，但操作数永远只能是一个数组类型的对象。 还有另外一些指令，如无条件跳转指令goto则是与数据类型无关的。 大部分的指令都没有支持整数类型byte、char和short，甚至没有任何指令支持boolean类型。编译器会在编译期或运行期将byte和short类型的数据带符号扩展（Sign-Extend）为相应的int类型数据，将boolean和char类型数据零位扩展（Zero-Extend）为相应的int类型数据。与之类似，在处理boolean、byte、short和char类型的数组时，也会转换为使用对应的int类型的字节码指令来处理。因此，大多数对于boolean、byte、short和char类型数据的操作，实际上都是使用相应的int类型作为运算类型。 byte b1 = 12; short s1 = 10; int i = b1 + s1; 2、指令分类由于完全介绍和学习这些指令需要花费大量时间。为了让大家能够更快地熟悉和了解这些基本指令，这里将JVM中的字节码指令集按用途大致分成 9 类。 加载与存储指令 算术指令 类型转换指令 对象的创建与访问指令 方法调用与返回指令 操作数栈管理指令 控制转移指令 异常处理指令 同步控制指令 (说在前面)在做值相关操作时： 一个指令，可以从局部变量表、常量池、堆中对象、方法调用、系统调用中等取得数据，这些数据（可能是值，可能是对象的引用）被压入操作数栈。 一个指令，也可以从操作数栈中取出一到多个值（pop多次），完成赋值、加减乘除、方法传参、系统调用等等操作。 六、★ 字节码指令1、加载与存储指令2、算术指令3、类型转换指令4、对象的创建与访问指令5、方法调用与返回指令6、操作数栈管理指令7、控制转移指令8、异常处理指令9、同步控制指令","categories":[{"name":"高阶篇","slug":"高阶篇","permalink":"https://mykkto.github.io/categories/%E9%AB%98%E9%98%B6%E7%AF%87/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://mykkto.github.io/tags/jvm/"},{"name":"字节码","slug":"字节码","permalink":"https://mykkto.github.io/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"}],"author":"mykk"},{"title":"历来面基题【长期】","slug":"05-面试题/00面基/01_Always_Interview","date":"2022-04-09T03:06:12.000Z","updated":"2022-06-27T11:04:02.623Z","comments":true,"path":"posts/c1193e28.html","link":"","permalink":"https://mykkto.github.io/posts/c1193e28.html","excerpt":"","text":"一、前言1、说明初稿没想好怎么定义，把最近遇到的面试题大概梳理下（可能比较潦草，暂时没花时间排版） 二、题目一些题目会贴出问题方案，部分暂时没有归纳，不过在此站都能搜索得到，提下 本站采用全文搜索，可以方便的检索到问题以及方案。 数据库三范式（收集需求和怎么设计数据库的） Spring、SpringBoot、SpringCloud区别，展开 Spring特性用法，事务，jdbc模板之类 SpringBoot零配置……可以的话自定义配置聊下 SpringCloud分两部分说（netfix,alibaba），每个组件用法说下，可以的话原理展开下 Seata ID(1)+组件(3)扩展说明，用法及区别 这边ID用到的雪花算法，懂的话可以展开，如果会写的话，说出实现算法的原理最佳，以及雪花的缺陷（时钟问题），解决方案 三个组件原理本站也有写 数据库优化，索引失效哪些情况 数据库，物化视图 物化视图与普通的视图相比的区别是物化视图是建立的副本，它类似于一张表，需要占用存储空间。而对一个物化视图查询的执行效率与查询一个表是一样的。 其实就是存在物理内存的副本表，但是性能和视图一样 最近项目描述及其展开说明（这个不用多说了吧） 同步集合用过哪些，说明，以及分布式锁说明 这边之前想展开AQS说明但是讲了很多了口干舌燥的，水也不够喝了 一方面对底层也是大概了解，FIFO内的Node深入API的话未必答的全面 分布锁可以分为三个实现展开（lua、redission、zookeeper），lua又分为单体和集群都可以展开说明 lua 集群实现分布式锁，可以聊下redlock，redission底层就是….. redission 底层自旋的看门口狗(watchdog)机制可以说下 es用过说下，倒排索引机制原理说下 多线程扩展聊了CAS 基本介绍下CAS，优缺点，缺点方案解决 几种原子类说明，跟volatile可见性比较 可以的话原子类原理展开，LongAdder快的原因 Synchronized用过吗 可以的话说明下用法，然后展开下锁升级（无锁-偏锁-轻锁-重锁） 可以提下JUC中的读写锁（ReentrantReadWriteLock），大概说下读写四种情况以及锁降级 自述完读写锁，可以提下更高效的邮戳锁（StampedLock），优缺点说下，特点说下（名字就可以看出是不重入锁） redis击穿、穿透、雪崩 说下是什么，解决方案 布隆过滤器实现原理 参考文档 ↓物化视图：https://baijiahao.baidu.com/s?id=1709212821591222829&amp;wfr=spider&amp;for=pc","categories":[{"name":"面试题","slug":"面试题","permalink":"https://mykkto.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"原理","slug":"原理","permalink":"https://mykkto.github.io/tags/%E5%8E%9F%E7%90%86/"},{"name":"java","slug":"java","permalink":"https://mykkto.github.io/tags/java/"},{"name":"分布式","slug":"分布式","permalink":"https://mykkto.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"数据库","slug":"数据库","permalink":"https://mykkto.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"author":"mykk"},{"title":"ShardingSphere分库分表【暂更】","slug":"03-java分布式/05jdbc/01_ShardingSphere","date":"2022-04-09T01:01:02.000Z","updated":"2022-05-22T15:01:03.835Z","comments":true,"path":"posts/97bfaea3.html","link":"","permalink":"https://mykkto.github.io/posts/97bfaea3.html","excerpt":"","text":"一、概述1、学英语博主是个二流子，英语不会但又格外喜欢 ShardingSphere(塞腚-菲儿)【分片-球】、Proxy(普拉克谁)【代理】 2、分库分表1、什么是分库分表分库分表就是为了解决由于数据量过大而导致数据库性能降低的问题，将原来独立的数据库拆分成若干数据库组成，将数据大表拆分成若干数据表组成，使得单一数据库、单一数据表的数据量变小，从而达到提升数据库性能的目的。 2、分库分表方式分库分表 分库分表包括分库和分表两个部分： 在生产中通常包括：垂直分库、水平分库、垂直分表、水平分表四种方式。 水平拆分：根据表中数据的逻辑关系，将表中的数据按照某种条件拆分到多台数据库上。 垂直拆分：把单一的表拆分成多个表，并分散到不同的数据库（主机）上 2.1 垂直分库 2.2 垂直分表 2.3 水平分表 2.4 水平分库 3、为什么要分库分表一般的机器（4核16G），单库的MySQL并发（QPS+TPS）超过了2k，系统基本就宕机了。最好是并发量控制在1k左右。 QPS：每秒并发量 TPS：每秒吞吐量 分库分表目的：解决高并发，和数据量大的问题。 4、分库分表的场景（1）在数据库设计时候考虑垂直分库和垂直分表 （2）随着数据库数据量增加，不要马上考虑做水平切分，首先考虑缓存处理，读写分离，使用索引等等方式，如果这些方式不能根本解决问题了， 再考虑做水平分库和水平分表 5、分库分表带来的问题• 事务一致性问题 • 跨节点关联查询的问题 ( Join )。 • 跨节点分页、分组、排序问题。 • 存在多数据源管理的问题 二、Sharding-JDBC快速入门官网http://shardingsphere.apache.org/index_zh.html 1、基本介绍Sharding-JDBC是当当网研发的开源分布式数据库中间件，从3.0 开始Sharding-JDBC 被包含在Sharding-Sphere中， 之后该项目进入进入Apache孵化器，4.版本之后的版本为Apache版本。 定位为轻量级 Java 框架，在 Java 的 JDBC 层提供的额外服务。 它使用客户端直连数据库，以 jar 包形式提供服务，无需额外部署和依赖，可理解为增强版的 JDBC 驱动，完全兼容 JDBC 和各种 ORM 框架。 Sharding-JDBC架构图： Sharding-Proxy架构图： Sharding-Jdbc混合架构： ShardingSphere-JDBC 采用无中心化架构，适用于 Java 开发的高性能的轻量级 OLTP（连接事务处理） 应用；ShardingSphere-Proxy 提供静态入口以及异构语言的支持，适用于 OLAP（连接数据分析） 应用以及对分片数据库进行管理和运维的场景。 Apache ShardingSphere 是多接入端共同组成的生态圈。 通过混合使用 ShardingSphere-JDBC 和 ShardingSphere-Proxy，并采用同一注册中心统一配置分片策略，能够灵活的搭建适用于各种场景的应用系统，使得架构师更加自由地调整适合与当前业务的最佳系统架构。 与jdbc性能对比 2、需求说明1、案例一：水平分表手动创建两张表，t_order_1和t_order_2，这两张表是订单表，拆分后的表，通过Sharding-Jdbc向课程表插入数据，按照一定的分片规则，主键为偶数的进入t_order_1，另一部分数据进入t_order_2，通过Sharding-Jdbc 查询数据，根据 SQL语句的内容从t_order_1或t_order_2查询数据。 2、案例二、水平分库在案例一的基础上，扩展出两个数据库，根据 user_id 偶数入库，sharding_jdbc1 奇数入库，sharding_jdbc2 3、案例三、垂直分库按照业余去区分库 3、项目搭建1、技术选型springboot2.2.1+MybatisPlus+Sharding-JDBC+Druid连接池 阿里镜像：比较快 https://start.aliyun.com/ 建表 两张结构一样 DROP TABLE IF EXISTS `course_1`; CREATE TABLE `course_1` ( `cid` bigint(20) NOT NULL COMMENT '课程id', `cname` VARCHAR(50) NOT NULL COMMENT '课程名', `user_id` bigint(20) NOT NULL COMMENT '课程老师', `cstatus` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '课程状态', PRIMARY KEY (`cid`) USING BTREE ) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic; DROP TABLE IF EXISTS `course_2`; CREATE TABLE `course_2` ( `cid` bigint(20) NOT NULL COMMENT '课程id', `cname` VARCHAR(50) NOT NULL COMMENT '课程名', `user_id` bigint(20) NOT NULL COMMENT '课程老师', `cstatus` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '课程状态', PRIMARY KEY (`cid`) USING BTREE ) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic; 2、建model 3、导pom&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.20&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;4.0.0-RC1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 4、基础业务代码1、entirypackage com.kk.shardingjdbc.entiry; import lombok.Data; @Data public class Course { private Long cid; private String cname; private Long userId; private String cstatus; } 2、mapperpackage com.kk.shardingjdbc.mapper; import com.baomidou.mybatisplus.core.mapper.BaseMapper; import org.springframework.stereotype.Repository; @Repository public interface CourseMapper extends BaseMapper&lt;CourseMapper&gt; { } 3、扫描配置package com.kk.shardingjdbc; import org.mybatis.spring.annotation.MapperScan; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication @MapperScan(\"com.kk.shardingjdbc.entiry.mapper\") public class ShardingjdbcApplication { public static void main(String[] args) { SpringApplication.run (ShardingjdbcApplication.class, args); } } 5、写 application.propertiesmysql 数据源 8.0的话驱动包路径要加 cj，com.mysql.cj.jdbc.Driver url要加**时区[?serverTimezone=GMT%2B8]**，jdbc:mysql://localhost:3306/sharding_jdbc1?serverTimezone=GMT%2B8 # sharding分片策略 # 配置数据源，给数据源起别名 spring.shardingsphere.datasource.names=s1 # 配置数据源具体内容，包含连接池，驱动，地址，用户名和密码 spring.shardingsphere.datasource.s1.type=com.alibaba.druid.pool.DruidDataSource spring.shardingsphere.datasource.s1.driver-class-name=com.mysql.jdbc.Driver spring.shardingsphere.datasource.s1.url=jdbc:mysql://localhost:3306/sharding_jdbc1 spring.shardingsphere.datasource.s1.username=root spring.shardingsphere.datasource.s1.password=a1b2c3 # 指定 course 表分布情况，配置表在哪个数据库里面，表名称都是什么 s1.course_1 , s1.course_2 #course 是表的前缀， {1,2}是表的后缀，表示有course1 和 course2 spring.shardingsphere.sharding.tables.course.actual-data-nodes=s1.course_$-&gt;{1..2} # 指定 以course为前缀的表里面主键 cid 。生成策略 SNOWFLAKE（雪花算法） spring.shardingsphere.sharding.tables.course.key-generator.column=cid spring.shardingsphere.sharding.tables.course.key-generator.type=SNOWFLAKE # 指定分片策略，约定 cid值为偶数添加到表 course_1, 奇数到 course_2 #course 是表的前缀 #第二行的取模后，+1 操作防止取模后为 0 spring.shardingsphere.sharding.tables.course.table-strategy.inline.sharding-column=cid spring.shardingsphere.sharding.tables.course.table-strategy.inline.algorithm-expression=course_$-&gt;{cid % 2 + 1} # 打开sql 输出日志 spring.shardingsphere.props.sql.show=true # 解决一个实体对应两个表问题 spring.main.allow-bean-definition-overriding=true 6、测试类package com.kk.shardingjdbc; import com.kk.shardingjdbc.entiry.Course; import com.kk.shardingjdbc.mapper.CourseMapper; import org.junit.jupiter.api.Test; import org.junit.runner.RunWith; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; @RunWith(SpringRunner.class) @SpringBootTest class ShardingjdbcApplicationTests { @Autowired private CourseMapper courseMapper; @Test public void addCourse() { for (int i = 0; i &lt; 10; i++) { Course course = new Course ( ); course.setCname (\"java\"+i); course.setUserId (100L); course.setCstatus (\"Normal\"+i); courseMapper.insert (course); } } @Test public void searchCourse() { QueryWrapper&lt;Course&gt; wrapper = new QueryWrapper&lt;&gt; ( ); wrapper.eq (\"cid\",721132131354411008L); Course course = courseMapper.selectOne (wrapper); System.out.println (course ); } } 4、案例二基于案例一扩展 1、当前库结构 2、application.properties# sharding分片策略 # 配置数据源，给数据源起别名 spring.shardingsphere.datasource.names=s1,s2 # 配置数据源具体内容，包含连接池，驱动，地址，用户名和密码 spring.shardingsphere.datasource.s1.type=com.alibaba.druid.pool.DruidDataSource spring.shardingsphere.datasource.s1.driver-class-name=com.mysql.cj.jdbc.Driver spring.shardingsphere.datasource.s1.url=jdbc:mysql://localhost:3306/sharding_jdbc1?serverTimezone=GMT%2B8 spring.shardingsphere.datasource.s1.username=root spring.shardingsphere.datasource.s1.password=a1b2c3 # 配置数据源具体内容，包含连接池，驱动，地址，用户名和密码 spring.shardingsphere.datasource.s2.type=com.alibaba.druid.pool.DruidDataSource spring.shardingsphere.datasource.s2.driver-class-name=com.mysql.cj.jdbc.Driver spring.shardingsphere.datasource.s2.url=jdbc:mysql://localhost:3306/sharding_jdbc2?serverTimezone=GMT%2B8 spring.shardingsphere.datasource.s2.username=root spring.shardingsphere.datasource.s2.password=a1b2c3 #--------------------------------------------------------------------------------------------------- # 指定 course 表分布情况，配置表在哪个数据库里面，表名称都是什么 s1.course_1 , s1.course_2 #course 是表的前缀， {1,2}是表的后缀，表示有course1 和 course2 #spring.shardingsphere.sharding.tables.course.actual-data-nodes=s1.course_$-&gt;{1..2} # 配置两个数据库 spring.shardingsphere.sharding.tables.course.actual-data-nodes=s$-&gt;{1..2}.course_$-&gt;{1..2} # 指定 以course为前缀的表里面主键 cid 。生成策略 SNOWFLAKE（雪花算法） spring.shardingsphere.sharding.tables.course.key-generator.column=cid spring.shardingsphere.sharding.tables.course.key-generator.type=SNOWFLAKE # 指定分片策略，约定 cid值为偶数添加到表 course_1, 奇数到 course_2 #course 是表的前缀 #第二行的取模后，+1 操作防止取模后为 0 spring.shardingsphere.sharding.tables.course.table-strategy.inline.sharding-column=cid spring.shardingsphere.sharding.tables.course.table-strategy.inline.algorithm-expression=course_$-&gt;{cid % 2 + 1} # 指定数据库分片策略 #约定user_id是偶数添加m1，是奇数添加m2 spring.shardingsphere.sharding.tables.course.database-strategy.inline.sharding-column=user_id spring.shardingsphere.sharding.tables.course.database-strategy.inline.algorithm-expression=s$-&gt;{user_id % 2 + 1} # 打开sql 输出日志 spring.shardingsphere.props.sql.show=true # 解决一个实体对应两个表问题 spring.main.allow-bean-definition-overriding=true 3、测试package com.kk.shardingjdbc; import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper; import com.kk.shardingjdbc.entiry.Course; import com.kk.shardingjdbc.mapper.CourseMapper; import org.junit.jupiter.api.Test; import org.junit.runner.RunWith; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; @RunWith(SpringRunner.class) @SpringBootTest class ShardingjdbcApplicationTests { @Autowired private CourseMapper courseMapper; //----------------以下是水平分库测试 @Test public void add() { for (int i = 0; i &lt; 20; i++) { Course course = new Course ( ); course.setUserId (0L + i); course.setCname (\"java\" + i); course.setCstatus (\"Normal\" + i); courseMapper.insert (course); } } @Test public void delete() { QueryWrapper&lt;Course&gt; wrapper = new QueryWrapper&lt;&gt; ( ); wrapper.isNotNull (\"cid\"); courseMapper.delete (wrapper); } //----------------以下是水平分表测试 @Test public void addCourse() { for (int i = 0; i &lt; 10; i++) { Course course = new Course ( ); course.setCname (\"java\" + i); course.setUserId (100L); course.setCstatus (\"Normal\" + i); courseMapper.insert (course); } } @Test public void searchCourse() { QueryWrapper&lt;Course&gt; wrapper = new QueryWrapper&lt;&gt; ( ); wrapper.eq (\"cid\", 721132131354411008L); Course course = courseMapper.selectOne (wrapper); System.out.println (course); } } 5、案例三1、建表2、三、Sharding-JDBC执行原理1、2、3、4、5、四、分库分表分类1、2、3、4、5、五、Mysql主从搭建路由：nacos高可用搭建 六、读写分离1、2、3、4、5、参考文档 ↓https://blog.csdn.net/unique_perfect/article/details/116134490 https://www.kuangstudy.com/zl/sharding#1369532356595126274","categories":[{"name":"中间件","slug":"中间件","permalink":"https://mykkto.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"ShardingSphere","slug":"ShardingSphere","permalink":"https://mykkto.github.io/tags/ShardingSphere/"},{"name":"分库分表","slug":"分库分表","permalink":"https://mykkto.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"},{"name":"jdbc","slug":"jdbc","permalink":"https://mykkto.github.io/tags/jdbc/"}],"author":"mykk"},{"title":"Redis_三剑(击穿、穿透、雪崩)【暂停】","slug":"03-java分布式/04redis/02_Redis_ThreeSwords","date":"2022-04-07T15:01:06.000Z","updated":"2022-04-09T01:59:00.924Z","comments":true,"path":"posts/32917ce1.html","link":"","permalink":"https://mykkto.github.io/posts/32917ce1.html","excerpt":"","text":"一、布隆过滤器1、2、3、4、5、二、击穿1、2、3、4、5、三、穿透1、2、3、4、5、四、雪崩1、2、3、4、5、","categories":[{"name":"缓存中间件","slug":"缓存中间件","permalink":"https://mykkto.github.io/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://mykkto.github.io/tags/redis/"},{"name":"击穿、击穿、穿透","slug":"击穿、击穿、穿透","permalink":"https://mykkto.github.io/tags/%E5%87%BB%E7%A9%BF%E3%80%81%E5%87%BB%E7%A9%BF%E3%80%81%E7%A9%BF%E9%80%8F/"},{"name":"BloomFilter","slug":"BloomFilter","permalink":"https://mykkto.github.io/tags/BloomFilter/"}],"author":"mykk"},{"title":"Redis_实现分布式锁【暂停】","slug":"03-java分布式/04redis/01_Redis_Lock","date":"2022-04-07T14:01:06.000Z","updated":"2022-04-09T01:58:58.008Z","comments":true,"path":"posts/aaae178b.html","link":"","permalink":"https://mykkto.github.io/posts/aaae178b.html","excerpt":"","text":"一、面试题 Redis除了拿来做缓存，你还见过基于Redis的什么用法？ Redis 做分布式锁的时候有需要注意的问题？ 如果是 Redis 是单点部署的，会带来什么问题？那你准备怎么解决单点问题呢？ 集群模式下，比如主从模式，有没有什么问题呢？ 你知道 Redis 是怎么解决集群模式也不靠谱的问题的吗？ 那你简单的介绍一下 Redlock 吧？你简历上写redisson，你谈谈 你觉得 Redlock 有什么问题呢？ Redis分布式锁如何续期？看门狗知道吗？ 二、1、2、3、4、5、三、1、2、3、4、5、","categories":[{"name":"缓存中间件","slug":"缓存中间件","permalink":"https://mykkto.github.io/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://mykkto.github.io/tags/redis/"},{"name":"分布式锁","slug":"分布式锁","permalink":"https://mykkto.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"},{"name":"redlock","slug":"redlock","permalink":"https://mykkto.github.io/tags/redlock/"}],"author":"mykk"},{"title":"Lua脚本语言基础","slug":"06-脚本语言/01lua/01_lua","date":"2022-04-03T15:17:13.000Z","updated":"2022-05-22T15:01:03.835Z","comments":true,"path":"posts/fafe363a.html","link":"","permalink":"https://mykkto.github.io/posts/fafe363a.html","excerpt":"","text":"一、概述1、概念Lua是一种轻量、小巧的脚本语言，用标准C语言编写并以源代码形式开发。设计的目的是为了嵌入到其他应用程序中，从而为应用程序提供灵活的扩展和定制功能。 2、特性跟其他语言进行比较，Lua有其自身的特点： （1）轻量级 Lua用标准C语言编写并以源代码形式开发，编译后仅仅一百余千字节，可以很方便的嵌入到其他程序中。 （2）可扩展 Lua提供非常丰富易于使用的扩展接口和机制，由宿主语言(通常是C或C++)提供功能，Lua可以使用它们，就像内置的功能一样。 （3）支持面向过程编程和函数式编程 3、应用场景Lua在不同的系统中得到大量应用，场景的应用场景如下: 游戏开发、独立应用脚本、web应用脚本、扩展和数据库插件、系统安全上。 二、安装1、官网在linux上安装Lua非常简单，只需要下载源码包并在终端解压、编译即可使用。 Lua的官网地址为:https://www.lua.org 2、下载并且解压1、下载wget https://www.lua.org/ftp/lua-5.4.1.tar.gz 2、安装依赖libreadline-dev依赖包，需要通过命令来进行安装 yum install -y readline-devel 3、解压tar zxvf lua-5.4.1.tar.gz 4、编译安装cd lua-5.4.1 make linux make install 5、验证lua -v 三、Lua的语法1、第一个程序1、进入控制台操作1、用 lua进入 2、编写输出语句，print(“xxxx”) 3、ctrl+D 退出控制台 2、lua 文件运行1、创建 test.lua 2、编写语句，保存 3、运行 3、lua直接运行 1、创建 test2.lua 2、编写语句的时候前缀加上声明，可以直接运行 #!/usr/local/bin/lua 3、文件赋权限，运行 chmod 755 test2.lua ./test2.lua 2、注释1、单行注释的语法为：--注释内容 2、多行注释的语法为:--[[ 注释内容 注释内容 --]] 3、取消多行如果想取消多行注释，只需要在第一个–之前在加一个-即可，如： ---[[ 注释内容 注释内容 --]] 3、标识符换句话说标识符就是我们的变量名，Lua定义变量名以一个字母 A 到 Z 或 a 到 z 或下划线 _ 开头后加上0个或多个字母，下划线，数字（0到9）。这块建议大家最好不要使用下划线加大写字母的标识符，因为Lua的保留字也是这样定义的，容易发生冲突。注意Lua是区分大小写字母的。 简单来说参考java规范就好 4、关键字下列是Lua的关键字，大家在定义常量、变量或其他用户自定义标识符都要避免使用以下这些关键字： and break do else elseif end false for function if in local nil not or repeat return then true until while goto 一般约定，以下划线开头连接一串大写字母的名字（比如 _VERSION）被保留用于 Lua 内部全局变量。这个也是上面我们不建议这么定义标识符的原因。 5、运算符Lua中支持的运算符有算术运算符、关系运算符、逻辑运算符、其他运算符。 算术运算符: + 加法 - 减法 * 乘法 / 除法 % 取余 ^ 乘幂 - 负号 例如: 10+20 --&gt;30 20-10 --&gt;10 10*20 --&gt;200 20/10 --&gt;2 3%2 --&gt;1 10^2 --&gt;100 -10 --&gt;-10 关系运算符 == 等于 ~= 不等于 &gt; 大于 &lt; 小于 &gt;= 大于等于 &lt;= 小于等于 例如: 10==10 --&gt;true 10~=10 --&gt;false 20&gt;10 --&gt;true 20&lt;10 --&gt;false 20&gt;=10 --&gt;true 20&lt;=10 --&gt;false 逻辑运算符 and 逻辑与 A and B &amp;&amp; or 逻辑或 A or B || not 逻辑非 取反，如果为true,则返回false ! 逻辑运算符可以作为if的判断条件，返回的结果如下: A = true B = true A and B --&gt;true A or B --&gt;true not A --&gt;false ------------------------------------------------------------------------------------------------ A = true B = false A and B --&gt;false A or B --&gt;true not A --&gt;false ------------------------------------------------------------------------------------------------ A = false B = true A and B --&gt;false A or B --&gt;true not A --&gt;true 其他运算符 .. 连接两个字符串 # 一元预算法，返回字符串或表的长度 例如: &gt; \"HELLO \"..\"WORLD\" --&gt;HELLO WORLD &gt; #\"HELLO\" --&gt;5 6、全局变量&amp;局部变量在Lua语言中，全局变量无须声明即可使用。在默认情况下，变量总是认为是全局的，如果未提前赋值，默认为nil: 要想声明一个局部变量，需要使用local来声明 7、Lua数据类型Lua有8个数据类型 nil(空，无效值) boolean(布尔，true/false) number(数值) string(字符串) function(函数) table（表） thread(线程) userdata（用户数据） 可以使用type函数测试给定变量或者的类型： print(type(nil)) --&gt;nil print(type(true)) --&gt; boolean print(type(1.1*1.1)) --&gt; number print(type(\"Hello world\")) --&gt; string print(type(type(X))) --&gt; string ，type函数返回的也是字符串类型 print(type(print)) --&gt; function print(type(type)) --&gt;function print(type{}) --&gt;table print(type(io.stdin)) --&gt;userdata nilnil是一种只有一个nil值的类型，它的作用可以用来与其他所有值进行区分，也可以当想要移除一个变量时，只需要将该变量名赋值为nil,垃圾回收就会会释放该变量所占用的内存。 booleanboolean类型具有两个值，true和false。boolean类型一般被用来做条件判断的真与假。在Lua语言中，只会将false和nil视为假，其他的都视为真，特别是在条件检测中0和空字符串都会认为是真，这个和我们熟悉的大多数语言不太一样。 number在Lua5.3版本开始，Lua语言为数值格式提供了两种选择:integer(整型)和float(双精度浮点型)[和其他语言不太一样，float不代表单精度类型]。 数值常量的表示方式: &gt;4 --&gt;4 &gt;0.4 --&gt;0.4 &gt;4.75e-3 --&gt;0.00475 &gt;4.75e3 --&gt;4750 不管是整型还是双精度浮点型，使用type()函数来取其类型，都会返回的是number &gt;type(3) --&gt;number &gt;type(3.3) --&gt;number 所以它们之间是可以相互转换的，同时，具有相同算术值的整型值和浮点型值在Lua语言中是相等的 stringLua语言中的字符串即可以表示单个字符，也可以表示一整本书籍。在Lua语言中，操作100K或者1M个字母组成的字符串的程序很常见。 可以使用单引号或双引号来声明字符串 &gt;a = \"hello\" &gt;b = 'world' &gt;print(a) --&gt;hello &gt;print(b) --&gt;world 如果声明的字符串比较长或者有多行，则可以使用如下方式进行声明 html = [[ &lt;html&gt; &lt;head&gt; &lt;title&gt;Lua-string&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;a href=\"http://www.lua.org\"&gt;Lua&lt;/a&gt; &lt;/body&gt; &lt;/html&gt; ]] table​ table是Lua语言中最主要和强大的数据结构。使用表， Lua 语言可以以一种简单、统一且高效的方式表示数组、集合、记录和其他很多数据结构。 Lua语言中的表本质上是一种辅助数组。这种数组比Java中的数组更加灵活，可以使用数值做索引，也可以使用字符串或其他任意类型的值作索引(除nil外)。 创建表的最简单方式: &gt; a = {} 创建数组: ​ 我们都知道数组就是相同数据类型的元素按照一定顺序排列的集合，那么使用table如何创建一个数组呢? &gt;arr = {\"TOM\",\"JERRY\",\"ROSE\"} ​ 要想获取数组中的值，我们可以通过如下内容来获取: print(arr[0]) nil print(arr[1]) TOM print(arr[2]) JERRY print(arr[3]) ROSE ​ 从上面的结果可以看出来，数组的下标默认是从1开始的。所以上述创建数组，也可以通过如下方式来创建 &gt;arr = {} &gt;arr[1] = \"TOM\" &gt;arr[2] = \"JERRY\" &gt;arr[3] = \"ROSE\" 上面我们说过了，表的索引即可以是数字，也可以是字符串等其他的内容，所以我们也可以将索引更改为字符串来创建 &gt;arr = {} &gt;arr[\"X\"] = 10 &gt;arr[\"Y\"] = 20 &gt;arr[\"Z\"] = 30 当然，如果想要获取这些数组中的值，可以使用下面的方式 方式一 &gt;print(arr[\"X\"]) &gt;print(arr[\"Y\"]) &gt;print(arr[\"Z\"]) 方式二 &gt;print(arr.X) &gt;print(arr.Y) &gt;print(arr.Z) 当前table的灵活不进于此，还有更灵活的声明方式 &gt;arr = {\"TOM\",X=10,\"JERRY\",Y=20,\"ROSE\",Z=30} 如何获取上面的值? TOM : arr[1] 10 : arr[\"X\"] | arr.X JERRY: arr[2] 20 : arr[\"Y\"] | arr.Y ROESE? function在 Lua语言中，函数（ Function ）是对语句和表达式进行抽象的主要方式。 定义函数的语法为: function functionName(params) end 函数被调用的时候，传入的参数个数与定义函数时使用的参数个数不一致的时候，Lua 语言会通过 抛弃多余参数和将不足的参数设为 nil 的方式来调整参数的个数。 function f(a,b) print(a,b) end f() --&gt; nil nil f(2) --&gt; 2 nil f(2,6) --&gt; 2 6 f(2.6.8) --&gt; 2 6 (8被丢弃) 可变长参数函数 function add(...) a,b,c=... print(a) print(b) print(c) end add(1,2,3) --&gt; 1 2 3 函数返回值可以有多个，这点和Java不太一样 function f(a,b) return a,b end x,y=f(11,22) --&gt; x=11,y=22 threadthread翻译过来是线程的意思，在Lua中，thread用来表示执行的独立线路，用来执行协同程序。 userdatauserdata是一种用户自定义数据，用于表示一种由应用程序或C/C++语言库所创建的类型。 8、Lua控制结构Lua 语言提供了一组精简且常用的控制结构，包括用于条件执行的证 以及用于循环的 while、 repeat 和 for。 所有的控制结构语法上都有一个显式的终结符： end 用于终结 if、 for 及 while 结构， until 用于终结 repeat 结构。 if then elseif elseif语句先测试其条件，并根据条件是否满足执行相应的 then 部分或 else 部分。 else 部分 是可选的。 function testif(a) if a&gt;0 then print(\"a是正数\") end end function testif(a) if a&gt;0 then print(\"a是正数\") else print(\"a是负数\") end end 如果要编写嵌套的 if 语句，可以使用 elseif。 它类似于在 else 后面紧跟一个if。根据传入的年龄返回不同的结果，如 age&lt;=18 青少年， age&gt;18 , age &lt;=45 青年 age&gt;45 , age&lt;=60 中年人 age&gt;60 老年人 function show(age) if age&lt;=18 then return \"青少年\" elseif age&gt;18 and age&lt;=45 then return \"青年\" elseif age&gt;45 and age&lt;=60 then return \"中年人\" elseif age&gt;60 then return \"老年人\" end end while循环顾名思义，当条件为真时 while 循环会重复执行其循环体。 Lua 语言先测试 while 语句 的条件，若条件为假则循环结束；否则， Lua 会执行循环体并不断地重复这个过程。 语法： while 条件 do 循环体 end 例子:实现数组的循环 function testWhile() local i = 1 while i&lt;=10 do print(i) i=i+1 end end repeat循环顾名思义， repeat-until语句会重复执行其循环体直到条件为真时结束。 由于条件测试在循环体之后执行，所以循环体至少会执行一次。 语法 repeat 循环体 until 条件 function testRepeat() local i = 10 repeat print(i) i=i-1 until i &lt; 1 end for循环数值型for循环 语法 for param=exp1,exp2,exp3 do 循环体 end param的值从exp1变化到exp2之前的每次循环会执行 循环体，并在每次循环结束后将步长(step)exp3增加到param上。exp3可选，如果不设置默认为1 人话：从输出1开始，每次 +10，小于100（1，11，21，…,91） for i = 1,100,10 do print(i) end 泛型for循环 泛型for循环通过一个迭代器函数来遍历所有值，类似于java中的foreach语句。 语法 for i,v in ipairs(x) do 循环体 end i是数组索引值，v是对应索引的数组元素值，ipairs是Lua提供的一个迭代器函数，用来迭代数组，x是要遍历的数组。 例如: arr = {\"TOME\",\"JERRY\",\"ROWS\",\"LUCY\"} for i,v in ipairs(arr) do print(i,v) end 上述实例输出的结果为 1 TOM 2 JERRY 3 ROWS 4 LUCY 但是如果将arr的值进行修改为 arr = {\"TOME\",\"JERRY\",\"ROWS\",x=\"JACK\",\"LUCY\"} 同样的代码在执行的时候，就只能看到和之前一样的结果，而其中的x为JACK就无法遍历出来，缺失了数据，如果解决呢? 我们可以将迭代器函数变成pairs,如 for i,v in pairs(arr) do print(i,v) end 上述实例就输出的结果为 1 TOM 2 JERRY 3 ROWS 4 LUCY x JACK 四、OpenResty1、基本操作1、是什么OpenResty是一个基于Nginx与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。所以本身OpenResty内部就已经集成了Nginx和Lua，所以我们使用起来会更加方便。 2、安装详情可见【OpenResty】 1、拉取docker pull openresty/openresty 2、挂载并启动说明下： 完全基于上面的nginx配置的三个部分，唯一修改的是 nginx.conf配置文件，这边挂载改成了 nginx2.conf，用于保留之前的（自己懒而已） 新增了，lua文件挂载 修改了容器内的挂载位置，因为 openresty容器位置不一样了(外部还是不变，容器内的位置变了) docker run -d -p 443:443 -p 80:80 --name openresty -v /root/nginx/www:/usr/local/openresty/nginx/html -v /root/nginx/conf/nginx2.conf:/usr/local/openresty/nginx/conf/nginx.conf -v /root/nginx/logs:/usr/local/openresty/nginx/logs -v /root/nginx/lls/:/usr/local/openresty/nginx/ssl -v /root/nginx/lua/:/usr/local/openresty/nginx/lua openresty/openresty 2、ngx_lua的使用使用Lua编写Nginx脚本的基本构建块是指令。指令用于指定何时运行用户Lua代码以及如何使用结果。下图显示了执行指令的顺序。 先来解释下*的作用 *：无 ， 即 xxx_by_lua ,指令后面跟的是 lua指令 *:_file，即 xxx_by_lua_file 指令后面跟的是 lua文件 *:_block,即 xxx_by_lua_block 在0.9.17版后替换init_by_lua_file init_by_lua*该指令在每次Nginx重新加载配置时执行，可以用来完成一些耗时模块的加载，或者初始化一些全局配置。 init_worker_by_lua*该指令用于启动一些定时任务，如心跳检查、定时拉取服务器配置等。 set_by_lua*该指令只要用来做变量赋值，这个指令一次只能返回一个值，并将结果赋值给Nginx中指定的变量。 rewrite_by_lua*该指令用于执行内部URL重写或者外部重定向，典型的如伪静态化URL重写，本阶段在rewrite处理阶段的最后默认执行。 access_by_lua*该指令用于访问控制。例如，如果只允许内网IP访问。 content_by_lua*该指令是应用最多的指令，大部分任务是在这个阶段完成的，其他的过程往往为这个阶段准备数据，正式处理基本都在本阶段。 header_filter_by_lua*该指令用于设置应答消息的头部信息。 body_filter_by_lua*该指令是对响应数据进行过滤，如截断、替换。 log_by_lua*该指令用于在log请求处理阶段，用Lua代码处理日志，但并不替换原有log处理。 balancer_by_lua*该指令主要的作用是用来实现上游服务器的负载均衡器算法 ssl_certificate_by_*该指令作用在Nginx和下游服务开始一个SSL握手操作时将允许本配置项的Lua代码。 需求:http://192.168.200.133?name=张三&amp;gender=1 Nginx接收到请求后，根据gender传入的值，如果gender传入的是1，则在页面上展示 张三先生,如果gender传入的是0，则在页面上展示张三女士,如果未传或者传入的不是1和2则在页面上展示张三。 实现代码 注意：加入配置文件的时候 #内容要去掉 location /getByGender { default_type 'text/html'; set_by_lua $name \" #获取请求url上的值 name，gender local uri_args = ngx.req.get_uri_args() gender = uri_args['gender'] name = uri_args['name'] if gender=='1' then return name..'先生' elseif gender=='0' then return name..'女士' else return name end \"; #解决乱码问题 charset utf-8; return 200 $name; } 3、ngx_lua操作Redis1、Api及其语句说明lua-resty-redis提供了访问Redis的详细API，包括创建对接、连接、操作、数据处理等。这些API基本上与Redis的操作一一对应。 （1）redis = require \"resty.redis\" （2）new 语法: redis,err = redis:new(),创建一个Redis对象。 （3）connect 语法:ok,err=redis:connect(host,port[,options_table]),设置连接Redis的连接信息。 ok:连接成功返回 1，连接失败返回nil err:返回对应的错误信息 （4）set_timeout 语法: redis:set_timeout(time) ，设置请求操作Redis的超时时间。 （5）close 语法: ok,err = redis:close(),关闭当前连接，成功返回1，失败返回nil和错误信息 （6）redis命令对应的方法 在lua-resty-redis中，所有的Redis命令都有自己的方法，方法名字和命令名字相同，只是全部为小写。 2、实现location /testRedis { default_type \"text/html\"; content_by_lua_block{ local redis = require \"resty.redis\" -- 引入Redis local redisObj = redis:new() --创建Redis对象 redisObj:set_timeout(1000) --设置超时数据为1s local ok,err = redisObj:connect(\"10.0.4.7\",6379) --设置redis连接信息，这边不要用127.0.0.1 if not ok then --判断是否连接成功 ngx.say(\"failed to connection redis\",err) return end ok,err = redisObj:set(\"username\",\"TOM\")--存入数据 if not ok then --判断是否存入成功 ngx.say(\"failed to set username\",err) return end local res,err = redisObj:get(\"username\") --从redis中获取数据 ngx.say(res) --将数据写会消息体中 redisObj:close() } } 4、ngx_lua操作Mysql1、查询1、准备driverClass=com.mysql.jdbc.Driver url=jdbc:mysql://10.0.4.7:3306/nginx_db username=root password=root 2、建库 create table users( id int primary key auto_increment, username varchar(30), birthday date, salary double ); insert into users(id,username,birthday,salary) values(null,\"TOM\",\"1988-11-11\",10000.0); insert into users(id,username,birthday,salary) values(null,\"JERRY\",\"1989-11-11\",20000.0); insert into users(id,username,birthday,salary) values(null,\"ROWS\",\"1990-11-11\",30000.0); insert into users(id,username,birthday,salary) values(null,\"LUCY\",\"1991-11-11\",40000.0); insert into users(id,username,birthday,salary) values(null,\"JACK\",\"1992-11-11\",50000.0); 3、Api详解（1）引入\"resty.mysql\"模块 local mysql = require \"resty.mysql\" （2）new 创建一个MySQL连接对象，遇到错误时，db为nil，err为错误描述信息 语法: db,err = mysql:new() （3）connect 尝试连接到一个MySQL服务器 语法:ok,err=db:connect(options),options是一个参数的Lua表结构，里面包含数据库连接的相关信息 host:服务器主机名或IP地址 port:服务器监听端口，默认为3306 user:登录的用户名 password:登录密码 database:使用的数据库名 （4）set_timeout 设置子请求的超时时间(ms)，包括connect方法 语法:db:set_timeout(time) （5）close 关闭当前MySQL连接并返回状态。如果成功，则返回1；如果出现任何错误，则将返回nil和错误描述。 语法:db:close() （6）send_query 异步向远程MySQL发送一个查询。如果成功则返回成功发送的字节数；如果错误，则返回nil和错误描述 语法:bytes,err=db:send_query(sql) （7）read_result 从MySQL服务器返回结果中读取一行数据。res返回一个描述OK包或结果集包的Lua表,语法: res, err, errcode, sqlstate = db:read_result() res, err, errcode, sqlstate = db:read_result(rows) :rows指定返回结果集的最大值，默认为4 如果是查询，则返回一个容纳多行的数组。每行是一个数据列的key-value对，如 { {id=1,username=\"TOM\",birthday=\"1988-11-11\",salary=10000.0}, {id=2,username=\"JERRY\",birthday=\"1989-11-11\",salary=20000.0} } 如果是增删改，则返回类上如下数据 { insert_id = 0, server_status=2, warning_count=1, affected_rows=2, message=nil } 返回值: res:操作的结果集 err:错误信息 errcode:MySQL的错误码，比如1064 sqlstate:返回由5个字符组成的标准SQL错误码，比如42000 4、实现location /mysqlSearch{ default_type 'text/html'; content_by_lua_block{ local mysql = require \"resty.mysql\" local db = mysql:new() local ok,err = db:connect{ host=\"10.0.4.7\", #不要用127.0.0.1 port=3306, user=\"root\", password=\"root\", database=\"lua_db\" } db:set_timeout(1000) db:send_query(\"select * from users where id =1\") local res,err,errcode,sqlstate = db:read_result() ngx.say(res[1].id..\",\"..res[1].username..\",\"..res[1].birthday..\",\"..res[1].salary) db:close() } } 5、🐤优化:location /mysqlSearch { default_type 'text/html'; content_by_lua_block{ local mysql = require \"resty.mysql\" local db = mysql:new() local ok,err = db:connect{ host=\"10.0.4.7\", port=3306, user=\"root\", password=\"root\", database=\"lua_db\" } db:set_timeout(1000) local uri_args = ngx.req.get_uri_args() local reqId = uri_args['id'] db:send_query(\"select * from users where id =\"..reqId) local res,err,errcode,sqlstate = db:read_result() ngx.say(res[1].id..\",\"..res[1].username..\",\"..res[1].birthday..\",\"..res[1].salary) db:close() } } 6、🛰lua-cjsonread_result()得到的结果res都是table类型，要想在页面上展示，就必须知道table的具体数据结构才能进行遍历获取。处理起来比较麻烦，接下来我们介绍一种简单方式cjson，使用它就可以将table类型的数据转换成json字符串，把json字符串展示在页面上即可。 步骤一：引入cjson local cjson = require \"cjson\" 步骤二：调用cjson的encode方法进行类型转换 cjson.encode(res) 优化代码： location /mysqlSearch { default_type 'text/html'; content_by_lua_block{ local mysql = require \"resty.mysql\" local db = mysql:new() local cjson = require \"cjson\" local ok,err = db:connect{ host=\"10.0.4.7\", port=3306, user=\"root\", password=\"root\", database=\"lua_db\" } db:set_timeout(1000) local uri_args = ngx.req.get_uri_args() local reqId = uri_args['id'] db:send_query(\"select * from users where id =\"..reqId) local res,err,errcode,sqlstate = db:read_result() ngx.say(cjson.encode(res)) for i,v in ipairs(res) do ngx.say(v.id..\",\"..v.username..\",\"..v.birthday..\",\"..v.salary) end db:close() } } 2、增删改location /mysql { default_type 'text/html'; content_by_lua_block{ local mysql = require \"resty.mysql\" local db = mysql:new() local cjson = require \"cjson\" local ok,err = db:connect{ host=\"10.0.4.7\", port=3306, user=\"root\", password=\"root\", database=\"lua_db\" } db:set_timeout(1000) local uri_args = ngx.req.get_uri_args() local reqId = uri_args['id'] local reqType = uri_args['reqType'] db:send_query(\"select * from users where id =\"..reqId) if reqType == 'search' then local res,err,errcode,sqlstate = db:read_result() ngx.say(cjson.encode(res)) for i,v in ipairs(res) do ngx.say(v.id..\",\"..v.username..\",\"..v.birthday..\",\"..v.salary) end elseif reqType == 'add' then local res,err,errcode,sqlstate = db:query(\"insert into users(id,username,birthday,salary) values(6,'zhangsan','2023-11-11',32222.0)\") elseif reqType == 'update' then local res,err,errcode,sqlstate = db:query(\"update users set username='lisi' where id = 6\") elseif reqType == 'delete' then local res,err,errcode,sqlstate = db:query(\"delete from users where id = 6\") end db:close() } } 5、Rdis缓存预热使用ngx_lua模块完成Redis缓存预热。 步骤: （1）先得有一张表(users) （2）浏览器输入如下地址 http://10.0.4.7?username=TOM （3）从表中查询出符合条件的记录，此时获取的结果为table类型 （4）使用cjson将table数据转换成json字符串 （5）将查询的结果数据存入Redis中 init_by_lua_block{ redis = require \"resty.redis\" mysql = require \"resty.mysql\" cjson = require \"cjson\" } location /redisPreheat{ default_type \"text/html\"; content_by_lua_block{ --获取请求的参数username local param = ngx.req.get_uri_args()[\"username\"] --建立mysql数据库的连接 local db = mysql:new() local ok,err = db:connect{ host=\"10.0.4.7\", port=3306, user=\"root\", password=\"root\", database=\"lua_db\" } if not ok then ngx.say(\"failed connect to mysql:\",err) return end --设置连接超时时间 db:set_timeout(1000) --查询数据 local sql = \"\"; if not param then sql=\"select * from users\" else sql=\"select * from users where username=\"..\"'\"..param..\"'\" end local res,err,errcode,sqlstate=db:query(sql) if not res then ngx.say(\"failed to query from mysql:\",err) return end --连接redis local rd = redis:new() ok,err = rd:connect(\"10.0.4.7\",6379) if not ok then ngx.say(\"failed to connect to redis:\",err) return end rd:set_timeout(1000) --循环遍历数据 for i,v in ipairs(res) do rd:set(\"user_\"..v.username,cjson.encode(v)) end ngx.say(\"success\") rd:close() db:close() } } 发现: + 英文字母有小图标 :c —&gt; ⏰🐤 关于撤回，vim","categories":[{"name":"计算机语言","slug":"计算机语言","permalink":"https://mykkto.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://mykkto.github.io/tags/nginx/"},{"name":"lua","slug":"lua","permalink":"https://mykkto.github.io/tags/lua/"},{"name":"openresty","slug":"openresty","permalink":"https://mykkto.github.io/tags/openresty/"}],"author":"mykk"},{"title":"SpringCloud-Alibaba-Seata 处理分布式事务","slug":"03-java分布式/01springcloud/16_SpringCloudAlibaba-Seata","date":"2022-03-25T12:11:33.000Z","updated":"2022-05-22T15:01:03.836Z","comments":true,"path":"posts/e1138fa5.html","link":"","permalink":"https://mykkto.github.io/posts/e1138fa5.html","excerpt":"","text":"一、分布式事务问题1、分布式前 单机单库没这个问题 从1：1 -&gt; 1：N -&gt; N：N 2、分布式之后单体应用被拆分成微服务应用，原来的三个模块被拆分成三个独立的应用，分别使用三个独立的数据源，业务操作需要调用三个服务来完成。此时每个服务内部的数据一致性由本地**事务来保证，但是全局**的数据一致性问题没法保证。 3、一句话一次业务操作需要跨多个数据源或需要跨多个系统进行远程调用，就会产生分布式事务问题 二、Seata简介1、是什么Seata是一款开源的分布式事务解决方案，致力于在微服务架构下提供高性能和简单易用的分布式事务服务。 2、能干嘛（★）1、ID(1)+组件(3)1、ID全局唯一的事务ID：Transaction ID XID 2、组件Transaction Coordinator (TC)【打工人】 事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚； Transaction Manager (TM)【老板】 控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议； Resource Manager (RM)【任务】 控制分支事务，负责分支注册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚 2、处理过程1、TM 向 TC 申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的 XID； 2、XID 在微服务调用链路的上下文中传播； 3、RM 向 TC 注册分支事务，将其纳入 XID 对应全局事务的管辖； 4、TM 向 TC 发起针对 XID 的全局提交或回滚决议； 5、TC 调度 XID 下管辖的全部分支事务完成提交或回滚请求。 3、怎么用1、本地单体架构上，本地使用spring：@Transactional 2、全局分布式上，全局使用Seata：@GlobalTransactional 三、Seata-Server安装1、官网1、地址http://seata.io/zh-cn/ 2、下载地址https://github.com/seata/seata/releases 选择 1.0.0 GA 稳定版 2、配置seata-server-1.0.0.zip 解压到指定目录并修改conf目录下的file.conf配置文件 1、file.conf（service模块）vgroup_mapping.my_test_tx_group = \"fsp_tx_group\" 2、file.conf（store模块）mode = \"db\" url = \"jdbc:mysql://127.0.0.1:3306/seata\" user = \"root\" password = \"你自己密码\" 3、导入建表sql-- -------------------------------- The script used when storeMode is 'db' -------------------------------- -- the table to store GlobalSession data CREATE TABLE IF NOT EXISTS `global_table` ( `xid` VARCHAR(128) NOT NULL, `transaction_id` BIGINT, `status` TINYINT NOT NULL, `application_id` VARCHAR(32), `transaction_service_group` VARCHAR(32), `transaction_name` VARCHAR(128), `timeout` INT, `begin_time` BIGINT, `application_data` VARCHAR(2000), `gmt_create` DATETIME, `gmt_modified` DATETIME, PRIMARY KEY (`xid`), KEY `idx_gmt_modified_status` (`gmt_modified`, `status`), KEY `idx_transaction_id` (`transaction_id`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8; -- the table to store BranchSession data CREATE TABLE IF NOT EXISTS `branch_table` ( `branch_id` BIGINT NOT NULL, `xid` VARCHAR(128) NOT NULL, `transaction_id` BIGINT, `resource_group_id` VARCHAR(32), `resource_id` VARCHAR(256), `branch_type` VARCHAR(8), `status` TINYINT, `client_id` VARCHAR(64), `application_data` VARCHAR(2000), `gmt_create` DATETIME(6), `gmt_modified` DATETIME(6), PRIMARY KEY (`branch_id`), KEY `idx_xid` (`xid`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8; -- the table to store lock data CREATE TABLE IF NOT EXISTS `lock_table` ( `row_key` VARCHAR(128) NOT NULL, `xid` VARCHAR(96), `transaction_id` BIGINT, `branch_id` BIGINT NOT NULL, `resource_id` VARCHAR(256), `table_name` VARCHAR(32), `pk` VARCHAR(36), `gmt_create` DATETIME, `gmt_modified` DATETIME, PRIMARY KEY (`row_key`), KEY `idx_branch_id` (`branch_id`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8; 4、启动1、启动cacos，seate 2、查看 nacos 控制台 四、订单/库存/账户业务数据库准备1、实战业务说明1、详细这里我们会创建三个服务，一个订单服务，一个库存服务，一个账户服务。 当用户下单时，会在订单服务中创建一个订单，然后通过远程调用库存服务来扣减下单商品的库存，再通过远程调用账户服务来扣减用户账户里面的余额，最后在订单服务中修改订单状态为已完成。 该操作跨越三个数据库，有两次远程调用，很明显会有分布式事务问题。 2、调用流程下订单—&gt;扣库存—&gt;减账户(余额) 2、建库建表0、建库CREATE DATABASE seata_order; CREATE DATABASE seata_storage; CREATE DATABASE seata_account; 1、订单seata_order：存储订单的数据库； 表语句： CREATE TABLE t_order ( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY, `user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id', `product_id` BIGINT(11) DEFAULT NULL COMMENT '产品id', `count` INT(11) DEFAULT NULL COMMENT '数量', `money` DECIMAL(11,0) DEFAULT NULL COMMENT '金额', `status` INT(1) DEFAULT NULL COMMENT '订单状态：0：创建中；1：已完结' ) ENGINE=INNODB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8; SELECT * FROM t_order; 2、库存seata_storage：存储库存的数据库； 表语句： CREATE TABLE t_storage ( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY, `product_id` BIGINT(11) DEFAULT NULL COMMENT '产品id', `total` INT(11) DEFAULT NULL COMMENT '总库存', `used` INT(11) DEFAULT NULL COMMENT '已用库存', `residue` INT(11) DEFAULT NULL COMMENT '剩余库存' ) ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; INSERT INTO seata_storage.t_storage(`id`, `product_id`, `total`, `used`, `residue`) VALUES ('1', '1', '100', '0', '100'); SELECT * FROM t_storage; 3、账户信息seata_account：存储账户信息的数据库。 表语句： CREATE TABLE t_account ( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'id', `user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id', `total` DECIMAL(10,0) DEFAULT NULL COMMENT '总额度', `used` DECIMAL(10,0) DEFAULT NULL COMMENT '已用余额', `residue` DECIMAL(10,0) DEFAULT '0' COMMENT '剩余可用额度' ) ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; INSERT INTO seata_account.t_account(`id`, `user_id`, `total`, `used`, `residue`) VALUES ('1', '1', '1000', '0', '1000'); SELECT * FROM t_account; 4、回滚日志表按照上述3库分别建对应的回滚日志表 -- the table to store seata xid data -- 0.7.0+ add context -- you must to init this sql for you business databese. the seata server not need it. -- 此脚本必须初始化在你当前的业务数据库中，用于AT 模式XID记录。与server端无关（注：业务数据库） -- 注意此处0.3.0+ 增加唯一索引 ux_undo_log DROP TABLE `undo_log`; CREATE TABLE `undo_log` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT, `branch_id` BIGINT(20) NOT NULL, `xid` VARCHAR(100) NOT NULL, `context` VARCHAR(128) NOT NULL, `rollback_info` LONGBLOB NOT NULL, `log_status` INT(11) NOT NULL, `log_created` DATETIME NOT NULL, `log_modified` DATETIME NOT NULL, `ext` VARCHAR(100) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`) ) ENGINE=INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; 5、效果 五、订单/库存/账户业务微服务准备1、业务需求下订单-&gt;减库存-&gt;扣余额-&gt;改(订单)状态 2、新建订单Order-Module1、modelseata-order-service2001 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;seata-order-service2001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--nacos--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--seata--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--feign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web-actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mysql-druid--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.37&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 2001 spring: application: name: seata-order-service cloud: alibaba: seata: #自定义事务组名称需要与seata-server中的对应 tx-service-group: fsp_tx_group nacos: discovery: server-addr: 106.52.23.202:8848 datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://106.52.23.202:3306/seata_order username: root password: root feign: hystrix: enabled: false logging: level: io: seata: info mybatis: mapperLocations: classpath:mapper/*.xml 4、file.confyml 同层目录下 需要修改的是 mysql url,username,password transport { # tcp udt unix-domain-socket type = \"TCP\" #NIO NATIVE server = \"NIO\" #enable heartbeat heartbeat = true #thread factory for netty thread-factory { boss-thread-prefix = \"NettyBoss\" worker-thread-prefix = \"NettyServerNIOWorker\" server-executor-thread-prefix = \"NettyServerBizHandler\" share-boss-worker = false client-selector-thread-prefix = \"NettyClientSelector\" client-selector-thread-size = 1 client-worker-thread-prefix = \"NettyClientWorkerThread\" # netty boss thread size,will not be used for UDT boss-thread-size = 1 #auto default pin or 8 worker-thread-size = 8 } shutdown { # when destroy server, wait seconds wait = 3 } serialization = \"seata\" compressor = \"none\" } service { vgroup_mapping.fsp_tx_group = \"default\" #修改自定义事务组名称 default.grouplist = \"127.0.0.1:8091\" enableDegrade = false disable = false max.commit.retry.timeout = \"-1\" max.rollback.retry.timeout = \"-1\" disableGlobalTransaction = false } client { async.commit.buffer.limit = 10000 lock { retry.internal = 10 retry.times = 30 } report.retry.count = 5 tm.commit.retry.count = 1 tm.rollback.retry.count = 1 } ## transaction log store store { ## store mode: file、db mode = \"db\" ## file store file { dir = \"sessionStore\" # branch session size , if exceeded first try compress lockkey, still exceeded throws exceptions max-branch-session-size = 16384 # globe session size , if exceeded throws exceptions max-global-session-size = 512 # file buffer size , if exceeded allocate new buffer file-write-buffer-cache-size = 16384 # when recover batch read size session.reload.read_size = 100 # async, sync flush-disk-mode = async } ## database store db { ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp) etc. datasource = \"dbcp\" ## mysql/oracle/h2/oceanbase etc. db-type = \"mysql\" driver-class-name = \"com.mysql.jdbc.Driver\" url = \"jdbc:mysql://106.52.23.202:3306/seata\" user = \"root\" password = \"root\" min-conn = 1 max-conn = 3 global.table = \"global_table\" branch.table = \"branch_table\" lock-table = \"lock_table\" query-limit = 100 } } lock { ## the lock store mode: local、remote mode = \"remote\" local { ## store locks in user's database } remote { ## store locks in the seata's server } } recovery { #schedule committing retry period in milliseconds committing-retry-period = 1000 #schedule asyn committing retry period in milliseconds asyn-committing-retry-period = 1000 #schedule rollbacking retry period in milliseconds rollbacking-retry-period = 1000 #schedule timeout retry period in milliseconds timeout-retry-period = 1000 } transaction { undo.data.validation = true undo.log.serialization = \"jackson\" undo.log.save.days = 7 #schedule delete expired undo_log in milliseconds undo.log.delete.period = 86400000 undo.log.table = \"undo_log\" } ## metrics settings metrics { enabled = false registry-type = \"compact\" # multi exporters use comma divided exporter-list = \"prometheus\" exporter-prometheus-port = 9898 } support { ## spring spring { # auto proxy the DataSource bean datasource.autoproxy = false } } 5、registry.confregistry { # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = \"nacos\" nacos { serverAddr = \"106.52.23.202:8848\" namespace = \"\" cluster = \"default\" } eureka { serviceUrl = \"http://localhost:8761/eureka\" application = \"default\" weight = \"1\" } redis { serverAddr = \"localhost:6379\" db = \"0\" } zk { cluster = \"default\" serverAddr = \"127.0.0.1:2181\" session.timeout = 6000 connect.timeout = 2000 } consul { cluster = \"default\" serverAddr = \"127.0.0.1:8500\" } etcd3 { cluster = \"default\" serverAddr = \"http://localhost:2379\" } sofa { serverAddr = \"127.0.0.1:9603\" application = \"default\" region = \"DEFAULT_ZONE\" datacenter = \"DefaultDataCenter\" cluster = \"default\" group = \"SEATA_GROUP\" addressWaitTime = \"3000\" } file { name = \"file.conf\" } } config { # file、nacos 、apollo、zk、consul、etcd3 type = \"file\" nacos { serverAddr = \"localhost\" namespace = \"\" } consul { serverAddr = \"127.0.0.1:8500\" } apollo { app.id = \"seata-server\" apollo.meta = \"http://192.168.1.204:8801\" } zk { serverAddr = \"127.0.0.1:2181\" session.timeout = 6000 connect.timeout = 2000 } etcd3 { serverAddr = \"http://localhost:2379\" } file { name = \"file.conf\" } } 6、业务类1、domainpackage com.kk.springcloud.domain; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @Data @AllArgsConstructor @NoArgsConstructor public class CommonResult&lt;T&gt; { private Integer code; private String message; private T data; public CommonResult(Integer code, String message) { this (code, message, null); } } package com.kk.springcloud.domain; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; import java.math.BigDecimal; @Data @AllArgsConstructor @NoArgsConstructor public class Order { private Long id; private Long userId; private Long productId; private Integer count; private BigDecimal money; /** * 订单状态：0：创建中；1：已完结 */ private Integer status; } 2、daopackage com.kk.springcloud.dao; import com.kk.springcloud.domain.Order; import org.apache.ibatis.annotations.Mapper; import org.apache.ibatis.annotations.Param; @Mapper public interface OrderDao { /** * 创建订单 */ void create(Order order); /** * 修改订单金额 */ void update(@Param(\"userId\") Long userId, @Param(\"status\") Integer status); } OrderMapper.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt; &lt;mapper namespace=\"com.kk.springcloud.dao.OrderDao\"&gt; &lt;resultMap id=\"BaseResultMap\" type=\"com.kk.springcloud.domain.Order\"&gt; &lt;id column=\"id\" property=\"id\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"user_id\" property=\"userId\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"product_id\" property=\"productId\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"count\" property=\"count\" jdbcType=\"INTEGER\"/&gt; &lt;result column=\"money\" property=\"money\" jdbcType=\"DECIMAL\"/&gt; &lt;result column=\"status\" property=\"status\" jdbcType=\"INTEGER\"/&gt; &lt;/resultMap&gt; &lt;insert id=\"create\"&gt; INSERT INTO `t_order` (`id`, `user_id`, `product_id`, `count`, `money`, `status`) VALUES (NULL, #{userId}, #{productId}, #{count}, #{money}, 0); &lt;/insert&gt; &lt;update id=\"update\"&gt; UPDATE `t_order` SET status = 1 WHERE user_id = #{userId} AND status = #{status}; &lt;/update&gt; &lt;/mapper&gt; 3、serivce OrderService OrderServiceImpl package com.kk.springcloud.service; import com.kk.springcloud.domain.Order; public interface OrderService { /** * 创建订单 */ void create(Order order); } package com.kk.springcloud.service; import com.kk.springcloud.dao.OrderDao; import com.kk.springcloud.domain.Order; import io.seata.spring.annotation.GlobalTransactional; import lombok.extern.slf4j.Slf4j; import org.springframework.stereotype.Service; import javax.annotation.Resource; @Service @Slf4j public class OrderServiceImpl implements OrderService { @Resource private OrderDao orderDao; @Resource private StorageService storageService; @Resource private AccountService accountService; /** * 创建订单-&gt;调用库存服务扣减库存-&gt;调用账户服务扣减账户余额-&gt;修改订单状态 * 简单说： * 下订单-&gt;减库存-&gt;减余额-&gt;改状态 * rollbackFor = Exception.class ,任何异常都回滚 */ @Override @GlobalTransactional(name = \"fsp-create-order\", rollbackFor = Exception.class) public void create(Order order) { log.info (\"===开始下单===\"); //本应用创建订单 orderDao.create (order); //远程调用库存服务扣减库存 log.info (\"-------&gt;order-service中扣减库存开始\"); storageService.decrease (order.getProductId ( ), order.getCount ( )); log.info (\"-------&gt;order-service中扣减库存结束\"); //远程调用账户服务扣减余额 log.info (\"-------&gt;order-service中扣减余额开始\"); accountService.decrease (order.getUserId ( ), order.getMoney ( )); log.info (\"-------&gt;order-service中扣减余额结束\"); //修改订单状态为已完成 log.info (\"-------&gt;order-service中修改订单状态开始\"); orderDao.update (order.getUserId ( ), 0); log.info (\"-------&gt;order-service中修改订单状态结束\"); log.info (\"-------&gt;下单结束\"); } } AccountService package com.kk.springcloud.service; import com.kk.springcloud.domain.CommonResult; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestParam; import java.math.BigDecimal; @FeignClient(value = \"seata-account-service\") public interface AccountService { /** * 扣减账户余额 */ //@RequestMapping(value = \"/account/decrease\", method = RequestMethod.POST, produces = \"application/json; charset=UTF-8\") @PostMapping(\"/account/decrease\") CommonResult decrease(@RequestParam(\"userId\") Long userId, @RequestParam(\"money\") BigDecimal money); } StorageService package com.kk.springcloud.service; import com.kk.springcloud.domain.CommonResult; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestParam; @FeignClient(value = \"seata-storage-service\") public interface StorageService { /** * 扣减库存 */ @PostMapping(value = \"/storage/decrease\") CommonResult decrease(@RequestParam(\"productId\") Long productId, @RequestParam(\"count\") Integer count); } 4、controllerpackage com.kk.springcloud.controller; import com.kk.springcloud.domain.CommonResult; import com.kk.springcloud.domain.Order; import com.kk.springcloud.service.OrderService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class OrderController { @Autowired private OrderService orderService; /** * 创建订单 */ @GetMapping(\"/order/create\") public CommonResult create(Order order) { orderService.create(order); return new CommonResult(200, \"订单创建成功!\"); } } 7、Config配置 MybatisConfig package com.kk.springcloud.config; import org.mybatis.spring.annotation.MapperScan; import org.springframework.context.annotation.Configuration; @Configuration @MapperScan({\"com.kk.springcloud.dao\"}) public class MyBatisConfig { } DataSourceProxyConfig package com.kk.springcloud.config; import com.alibaba.druid.pool.DruidDataSource; import io.seata.rm.datasource.DataSourceProxy; import org.apache.ibatis.session.SqlSessionFactory; import org.mybatis.spring.SqlSessionFactoryBean; import org.mybatis.spring.transaction.SpringManagedTransactionFactory; import org.springframework.beans.factory.annotation.Value; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.core.io.support.PathMatchingResourcePatternResolver; import javax.sql.DataSource; /* * @Description: 使用Seata对数据源进行代理 * @Author: 阿K * @CreateDate: 2022/3/27 13:31 * @Param: * @Return: **/ @Configuration public class DataSourceProxyConfig { @Value(\"${mybatis.mapperLocations}\") private String mapperLocations; @Bean @ConfigurationProperties(prefix = \"spring.datasource\") public DataSource druidDataSource() { return new DruidDataSource ( ); } @Bean public DataSourceProxy dataSourceProxy(DataSource dataSource) { return new DataSourceProxy (dataSource); } @Bean public SqlSessionFactory sqlSessionFactoryBean(DataSourceProxy dataSourceProxy) throws Exception { SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean ( ); sqlSessionFactoryBean.setDataSource (dataSourceProxy); sqlSessionFactoryBean.setMapperLocations (new PathMatchingResourcePatternResolver ( ).getResources (mapperLocations)); sqlSessionFactoryBean.setTransactionFactory (new SpringManagedTransactionFactory ( )); return sqlSessionFactoryBean.getObject ( ); } } 8、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; import org.springframework.cloud.openfeign.EnableFeignClients; @EnableDiscoveryClient @EnableFeignClients @SpringBootApplication(exclude = DataSourceAutoConfiguration.class)//取消数据源的自动创建 public class SeataOrderMainApp2001 { public static void main(String[] args) { SpringApplication.run (SeataOrderMainApp2001.class, args); } } 3、新建库存Storage-Module1、modelseata-storage-service2002 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;seata-order-service2001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--nacos--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--seata--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--feign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web-actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mysql-druid--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.37&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 2002 spring: application: name: seata-storage-service cloud: alibaba: seata: tx-service-group: fsp_tx_group nacos: discovery: server-addr: 106.52.23.202:8848 datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://106.52.23.202:3306/seata_storage username: root password: root logging: level: io: seata: info mybatis: mapperLocations: classpath:mapper/*.xml 4、file.confvgroup_mapping.fsp_tx_group = \"default\" transport { # tcp udt unix-domain-socket type = \"TCP\" #NIO NATIVE server = \"NIO\" #enable heartbeat heartbeat = true #thread factory for netty thread-factory { boss-thread-prefix = \"NettyBoss\" worker-thread-prefix = \"NettyServerNIOWorker\" server-executor-thread-prefix = \"NettyServerBizHandler\" share-boss-worker = false client-selector-thread-prefix = \"NettyClientSelector\" client-selector-thread-size = 1 client-worker-thread-prefix = \"NettyClientWorkerThread\" # netty boss thread size,will not be used for UDT boss-thread-size = 1 #auto default pin or 8 worker-thread-size = 8 } shutdown { # when destroy server, wait seconds wait = 3 } serialization = \"seata\" compressor = \"none\" } service { #vgroup-&gt;rgroup vgroup_mapping.fsp_tx_group = \"default\" #only support single node default.grouplist = \"127.0.0.1:8091\" #degrade current not support enableDegrade = false #disable disable = false #unit ms,s,m,h,d represents milliseconds, seconds, minutes, hours, days, default permanent max.commit.retry.timeout = \"-1\" max.rollback.retry.timeout = \"-1\" disableGlobalTransaction = false } client { async.commit.buffer.limit = 10000 lock { retry.internal = 10 retry.times = 30 } report.retry.count = 5 tm.commit.retry.count = 1 tm.rollback.retry.count = 1 } transaction { undo.data.validation = true undo.log.serialization = \"jackson\" undo.log.save.days = 7 #schedule delete expired undo_log in milliseconds undo.log.delete.period = 86400000 undo.log.table = \"undo_log\" } support { ## spring spring { # auto proxy the DataSource bean datasource.autoproxy = false } } 5、registry.confregistry { # file 、nacos 、eureka、redis、zk type = \"nacos\" nacos { serverAddr = \"106.52.23.202:8848\" namespace = \"\" cluster = \"default\" } eureka { serviceUrl = \"http://localhost:8761/eureka\" application = \"default\" weight = \"1\" } redis { serverAddr = \"localhost:6381\" db = \"0\" } zk { cluster = \"default\" serverAddr = \"127.0.0.1:2181\" session.timeout = 6000 connect.timeout = 2000 } file { name = \"file.conf\" } } config { # file、nacos 、apollo、zk type = \"file\" nacos { serverAddr = \"localhost\" namespace = \"\" cluster = \"default\" } apollo { app.id = \"fescar-server\" apollo.meta = \"http://192.168.1.204:8801\" } zk { serverAddr = \"127.0.0.1:2181\" session.timeout = 6000 connect.timeout = 2000 } file { name = \"file.conf\" } } 6、业务类1、domainpackage com.kk.springcloud.domain; import lombok.Data; @Data public class Storage { private Long id; /** * 产品id */ private Long productId; /** * 总库存 */ private Integer total; /** * 已用库存 */ private Integer used; /** * 剩余库存 */ private Integer residue; } 2、daopackage com.kk.springcloud.dao; import org.apache.ibatis.annotations.Mapper; import org.apache.ibatis.annotations.Param; @Mapper public interface StorageDao { /** * 扣减库存 */ void decrease(@Param(\"productId\") Long productId, @Param(\"count\") Integer count); } &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt; &lt;mapper namespace=\"com.kk.springcloud.dao.StorageDao\"&gt; &lt;resultMap id=\"BaseResultMap\" type=\"com.kk.springcloud.domain.Storage\"&gt; &lt;id column=\"id\" property=\"id\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"product_id\" property=\"productId\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"total\" property=\"total\" jdbcType=\"INTEGER\"/&gt; &lt;result column=\"used\" property=\"used\" jdbcType=\"INTEGER\"/&gt; &lt;result column=\"residue\" property=\"residue\" jdbcType=\"INTEGER\"/&gt; &lt;/resultMap&gt; &lt;update id=\"decrease\"&gt; UPDATE t_storage SET used = used + #{count}, residue = residue - #{count} WHERE product_id = #{productId} &lt;/update&gt; &lt;/mapper&gt; 3、serivcepackage com.kk.springcloud.service; public interface StorageService { /** * 扣减库存 */ void decrease(Long productId, Integer count); } package com.kk.springcloud.service; import com.kk.springcloud.dao.StorageDao; import lombok.extern.slf4j.Slf4j; import org.springframework.stereotype.Service; import javax.annotation.Resource; @Service @Slf4j public class StorageServiceImpl implements StorageService { @Resource private StorageDao storageDao; /** * 扣减库存 */ @Override public void decrease(Long productId, Integer count) { log.info (\"-------&gt;storage-service中扣减库存开始\"); storageDao.decrease (productId, count); log.info (\"-------&gt;storage-service中扣减库存结束\"); } } 4、controllerpackage com.kk.springcloud.controller; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.service.StorageService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class StorageController { @Autowired private StorageService storageService; /** * 扣减库存 */ @RequestMapping(\"/storage/decrease\") public CommonResult decrease(Long productId, Integer count) { storageService.decrease (productId, count); return new CommonResult (200, \"扣减库存成功！\"); } } 7、Config配置 MybatisConfig package com.kk.springcloud.config; import org.mybatis.spring.annotation.MapperScan; import org.springframework.context.annotation.Configuration; @Configuration @MapperScan({\"com.kk.springcloud.dao\"}) public class MyBatisConfig { } DataSourceProxyConfig package com.kk.springcloud.config; import com.alibaba.druid.pool.DruidDataSource; import io.seata.rm.datasource.DataSourceProxy; import org.apache.ibatis.session.SqlSessionFactory; import org.mybatis.spring.SqlSessionFactoryBean; import org.mybatis.spring.transaction.SpringManagedTransactionFactory; import org.springframework.beans.factory.annotation.Value; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.core.io.support.PathMatchingResourcePatternResolver; import javax.sql.DataSource; /* * @Description: 使用Seata对数据源进行代理 * @Author: 阿K * @CreateDate: 2022/3/27 13:31 * @Param: * @Return: **/ @Configuration public class DataSourceProxyConfig { @Value(\"${mybatis.mapperLocations}\") private String mapperLocations; @Bean @ConfigurationProperties(prefix = \"spring.datasource\") public DataSource druidDataSource() { return new DruidDataSource ( ); } @Bean public DataSourceProxy dataSourceProxy(DataSource dataSource) { return new DataSourceProxy (dataSource); } @Bean public SqlSessionFactory sqlSessionFactoryBean(DataSourceProxy dataSourceProxy) throws Exception { SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean ( ); sqlSessionFactoryBean.setDataSource (dataSourceProxy); sqlSessionFactoryBean.setMapperLocations (new PathMatchingResourcePatternResolver ( ).getResources (mapperLocations)); sqlSessionFactoryBean.setTransactionFactory (new SpringManagedTransactionFactory ( )); return sqlSessionFactoryBean.getObject ( ); } } 8、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; import org.springframework.cloud.openfeign.EnableFeignClients; @SpringBootApplication(exclude = DataSourceAutoConfiguration.class) @EnableDiscoveryClient @EnableFeignClients public class SeataStorageServiceApplication2002 { public static void main(String[] args) { SpringApplication.run (SeataStorageServiceApplication2002.class, args); } } 4、新建账户Account-Module1、modelseata-account-service2003 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;seata-account-service2003&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--nacos--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--seata--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--feign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.37&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 2003 spring: application: name: seata-account-service cloud: alibaba: seata: tx-service-group: fsp_tx_group nacos: discovery: server-addr: 106.52.23.202:8848 datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://106.52.23.202:3306/seata_account username: root password: root feign: hystrix: enabled: false logging: level: io: seata: info mybatis: mapperLocations: classpath:mapper/*.xml 4、file.conftransport { # tcp udt unix-domain-socket type = \"TCP\" #NIO NATIVE server = \"NIO\" #enable heartbeat heartbeat = true #thread factory for netty thread-factory { boss-thread-prefix = \"NettyBoss\" worker-thread-prefix = \"NettyServerNIOWorker\" server-executor-thread-prefix = \"NettyServerBizHandler\" share-boss-worker = false client-selector-thread-prefix = \"NettyClientSelector\" client-selector-thread-size = 1 client-worker-thread-prefix = \"NettyClientWorkerThread\" # netty boss thread size,will not be used for UDT boss-thread-size = 1 #auto default pin or 8 worker-thread-size = 8 } shutdown { # when destroy server, wait seconds wait = 3 } serialization = \"seata\" compressor = \"none\" } service { vgroup_mapping.fsp_tx_group = \"default\" #修改自定义事务组名称 default.grouplist = \"127.0.0.1:8091\" enableDegrade = false disable = false max.commit.retry.timeout = \"-1\" max.rollback.retry.timeout = \"-1\" disableGlobalTransaction = false } client { async.commit.buffer.limit = 10000 lock { retry.internal = 10 retry.times = 30 } report.retry.count = 5 tm.commit.retry.count = 1 tm.rollback.retry.count = 1 } ## transaction log store store { ## store mode: file、db mode = \"db\" ## file store file { dir = \"sessionStore\" # branch session size , if exceeded first try compress lockkey, still exceeded throws exceptions max-branch-session-size = 16384 # globe session size , if exceeded throws exceptions max-global-session-size = 512 # file buffer size , if exceeded allocate new buffer file-write-buffer-cache-size = 16384 # when recover batch read size session.reload.read_size = 100 # async, sync flush-disk-mode = async } ## database store db { ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp) etc. datasource = \"dbcp\" ## mysql/oracle/h2/oceanbase etc. db-type = \"mysql\" driver-class-name = \"com.mysql.jdbc.Driver\" url = \"jdbc:mysql://106.52.23.202:3306/seata\" user = \"root\" password = \"root\" min-conn = 1 max-conn = 3 global.table = \"global_table\" branch.table = \"branch_table\" lock-table = \"lock_table\" query-limit = 100 } } lock { ## the lock store mode: local、remote mode = \"remote\" local { ## store locks in user's database } remote { ## store locks in the seata's server } } recovery { #schedule committing retry period in milliseconds committing-retry-period = 1000 #schedule asyn committing retry period in milliseconds asyn-committing-retry-period = 1000 #schedule rollbacking retry period in milliseconds rollbacking-retry-period = 1000 #schedule timeout retry period in milliseconds timeout-retry-period = 1000 } transaction { undo.data.validation = true undo.log.serialization = \"jackson\" undo.log.save.days = 7 #schedule delete expired undo_log in milliseconds undo.log.delete.period = 86400000 undo.log.table = \"undo_log\" } ## metrics settings metrics { enabled = false registry-type = \"compact\" # multi exporters use comma divided exporter-list = \"prometheus\" exporter-prometheus-port = 9898 } support { ## spring spring { # auto proxy the DataSource bean datasource.autoproxy = false } } 5、registry.confregistry { # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = \"nacos\" nacos { serverAddr = \"106.52.23.202:8848\" namespace = \"\" cluster = \"default\" } eureka { serviceUrl = \"http://localhost:8761/eureka\" application = \"default\" weight = \"1\" } redis { serverAddr = \"localhost:6379\" db = \"0\" } zk { cluster = \"default\" serverAddr = \"127.0.0.1:2181\" session.timeout = 6000 connect.timeout = 2000 } consul { cluster = \"default\" serverAddr = \"127.0.0.1:8500\" } etcd3 { cluster = \"default\" serverAddr = \"http://localhost:2379\" } sofa { serverAddr = \"127.0.0.1:9603\" application = \"default\" region = \"DEFAULT_ZONE\" datacenter = \"DefaultDataCenter\" cluster = \"default\" group = \"SEATA_GROUP\" addressWaitTime = \"3000\" } file { name = \"file.conf\" } } config { # file、nacos 、apollo、zk、consul、etcd3 type = \"file\" nacos { serverAddr = \"localhost\" namespace = \"\" } consul { serverAddr = \"127.0.0.1:8500\" } apollo { app.id = \"seata-server\" apollo.meta = \"http://192.168.1.204:8801\" } zk { serverAddr = \"127.0.0.1:2181\" session.timeout = 6000 connect.timeout = 2000 } etcd3 { serverAddr = \"http://localhost:2379\" } file { name = \"file.conf\" } } 6、业务类1、domainpackage com.kk.springclpid.domain; import lombok.Data; import java.math.BigDecimal; @Data public class Account { private Long id; /** * 用户id */ private Long userId; /** * 总额度 */ private BigDecimal total; /** * 已用额度 */ private BigDecimal used; /** * 剩余额度 */ private BigDecimal residue; } 2、daopackage com.kk.springcloud.dao; import org.apache.ibatis.annotations.Mapper; import org.apache.ibatis.annotations.Param; import java.math.BigDecimal; @Mapper public interface AccountDao { /** * 扣减账户余额 */ void decrease(@Param(\"userId\") Long userId, @Param(\"money\") BigDecimal money); } &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt; &lt;mapper namespace=\"com.kk.springcloud.dao.AccountDao\"&gt; &lt;resultMap id=\"BaseResultMap\" type=\"com.kk.springcloud.domain.Account\"&gt; &lt;id column=\"id\" property=\"id\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"user_id\" property=\"userId\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"total\" property=\"total\" jdbcType=\"DECIMAL\"/&gt; &lt;result column=\"used\" property=\"used\" jdbcType=\"DECIMAL\"/&gt; &lt;result column=\"residue\" property=\"residue\" jdbcType=\"DECIMAL\"/&gt; &lt;/resultMap&gt; &lt;update id=\"decrease\"&gt; UPDATE t_account SET residue = residue - #{money},used = used + #{money} WHERE user_id = #{userId}; &lt;/update&gt; &lt;/mapper&gt; 3、serivcepackage com.kk.springcloud.service; import org.springframework.web.bind.annotation.RequestParam; import java.math.BigDecimal; public interface AccountService { /** * 扣减账户余额 * * @param userId 用户id * @param money 金额 */ void decrease(@RequestParam(\"userId\") Long userId, @RequestParam(\"money\") BigDecimal money); } package com.kk.springcloud.service; import com.kk.springcloud.dao.AccountDao; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.stereotype.Service; import javax.annotation.Resource; import java.math.BigDecimal; import java.util.concurrent.TimeUnit; @Service public class AccountServiceImpl implements AccountService { private static final Logger LOGGER = LoggerFactory.getLogger (AccountServiceImpl.class); @Resource AccountDao accountDao; /** * 扣减账户余额 */ @Override public void decrease(Long userId, BigDecimal money) { LOGGER.info (\"-------&gt;account-service中扣减账户余额开始\"); //模拟超时异常，全局事务回滚 //暂停几秒钟线程 try { TimeUnit.SECONDS.sleep (30); } catch (InterruptedException e) { e.printStackTrace ( ); } accountDao.decrease (userId, money); LOGGER.info (\"-------&gt;account-service中扣减账户余额结束\"); } } 4、controllerpackage com.kk.springcloud.controller; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.service.AccountService; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; import java.math.BigDecimal; @RestController public class AccountController { @Resource AccountService accountService; /** * 扣减账户余额 */ @RequestMapping(\"/account/decrease\") public CommonResult decrease(@RequestParam(\"userId\") Long userId, @RequestParam(\"money\") BigDecimal money) { accountService.decrease (userId, money); return new CommonResult (200, \"扣减账户余额成功！\"); } } 7、Config配置 MybatisConfig package com.kk.springcloud.config; import org.mybatis.spring.annotation.MapperScan; import org.springframework.context.annotation.Configuration; @Configuration @MapperScan({\"com.kk.springcloud.dao\"}) public class MyBatisConfig { } DataSourceProxyConfig package com.kk.springcloud.config; import com.alibaba.druid.pool.DruidDataSource; import io.seata.rm.datasource.DataSourceProxy; import org.apache.ibatis.session.SqlSessionFactory; import org.mybatis.spring.SqlSessionFactoryBean; import org.mybatis.spring.transaction.SpringManagedTransactionFactory; import org.springframework.beans.factory.annotation.Value; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.core.io.support.PathMatchingResourcePatternResolver; import javax.sql.DataSource; /* * @Description: 使用Seata对数据源进行代理 * @Author: 阿K * @CreateDate: 2022/3/27 13:31 * @Param: * @Return: **/ @Configuration public class DataSourceProxyConfig { @Value(\"${mybatis.mapperLocations}\") private String mapperLocations; @Bean @ConfigurationProperties(prefix = \"spring.datasource\") public DataSource druidDataSource() { return new DruidDataSource ( ); } @Bean public DataSourceProxy dataSourceProxy(DataSource dataSource) { return new DataSourceProxy (dataSource); } @Bean public SqlSessionFactory sqlSessionFactoryBean(DataSourceProxy dataSourceProxy) throws Exception { SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean ( ); sqlSessionFactoryBean.setDataSource (dataSourceProxy); sqlSessionFactoryBean.setMapperLocations (new PathMatchingResourcePatternResolver ( ).getResources (mapperLocations)); sqlSessionFactoryBean.setTransactionFactory (new SpringManagedTransactionFactory ( )); return sqlSessionFactoryBean.getObject ( ); } } 8、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; import org.springframework.cloud.openfeign.EnableFeignClients; @SpringBootApplication(exclude = DataSourceAutoConfiguration.class) @EnableDiscoveryClient @EnableFeignClients public class SeataAccountMainApp2003 { public static void main(String[] args) { SpringApplication.run (SeataAccountMainApp2003.class, args); } } 六、Test1、初始情况 2、正常下单1、请求http://localhost:2001/order/create?userId=1&amp;productId=1&amp;count=10&amp;money=100 2、数据库情况 3、无注解超时异常，没加@GlobalTransactional 1、AccountServiceImpl添加超时 2、数据库情况 3、故障情况 当库存和账户金额扣减后，订单状态并没有设置为已经完成，没有从零改为1 而且由于feign的重试机制，账户余额还有可能被多次扣减 4、有注解超时异常，添加@GlobalTransactional 1、AccountServiceImpl添加超时 2、OrderServiceImpl@GlobalTransactional @GlobalTransactional(name = \"fsp-create-order\",rollbackFor = Exception.class) public void create(Order order) { 。。。。。。 } 3、结果 下单后数据库数据并没有任何改变 记录都添加不进来 七、一部分补充1、再看TC/TM/RM三大组件分布式事务的执行流程 1、TM 开启分布式事务（TM 向 TC 注册全局事务记录）； 2、按业务场景，编排数据库、服务等事务内资源（RM 向 TC 汇报资源准备状态 ）； 3、TM 结束分布式事务，事务一阶段结束（TM 通知 TC 提交/回滚分布式事务）； 4、TC 汇总事务信息，决定分布式事务是提交还是回滚； 5、TC 通知所有 RM 提交/回滚 资源，事务二阶段结束。 2、AT模式如何做到对业务的无侵入1、是什么 2、一阶段加载在一阶段，Seata 会拦截“业务 SQL”，1 解析 SQL 语义，找到“业务 SQL”要更新的业务数据，在业务数据被更新前，将其保存成“before image”，2 执行“业务 SQL”更新业务数据，在业务数据更新之后，3 其保存成“after image”，最后生成行锁。以上操作全部在一个数据库事务内完成，这样保证了一阶段操作的原子性。 3、二阶段提交二阶段如是顺利提交的话，因为“业务 SQL”在一阶段已经提交至数据库，所以Seata框架只需将一阶段保存的快照数据和行锁删掉，完成数据清理即可。 3、二阶段回滚二阶段回滚：二阶段如果是回滚的话，Seata 就需要回滚一阶段已经执行的“业务 SQL”，还原业务数据。回滚方式便是用“before image”还原业务数据；但在还原前要首先要校验脏写，对比“数据库当前业务数据”和 “after image”，如果两份数据完全一致就说明没有脏写，可以还原业务数据，如果不一致就说明有脏写，出现脏写就需要转人工处理。 3、补充 参考文档 ↓docker 安装问题：https://www.cnblogs.com/youngyajun/p/14002547.html docker 网络问题：https://blog.csdn.net/tilyp/article/details/103371360 docker 运行问题：https://www.manongdao.com/article-2421258.html","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud-alibaba","slug":"springcloud-alibaba","permalink":"https://mykkto.github.io/tags/springcloud-alibaba/"},{"name":"seata","slug":"seata","permalink":"https://mykkto.github.io/tags/seata/"},{"name":"分布式事务","slug":"分布式事务","permalink":"https://mykkto.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"}],"author":"mykk"},{"title":"云主机部署并同步更新二级域名","slug":"00-blog/01_blogSynGithub","date":"2022-03-20T08:17:13.000Z","updated":"2022-05-22T15:01:03.891Z","comments":true,"path":"posts/829b453d.html","link":"","permalink":"https://mykkto.github.io/posts/829b453d.html","excerpt":"","text":"一、本地拉取配置1、创建并启动1、拉取docker pull nginx 2、启动docker run --name nginx-test -p 80:80 -d nginx – name 容器命名 -v 映射目录 -d 设置容器后台运行 -p 本机端口映射 将容器的80端口映射到本机的80端口 2、映射到本地1、创建首先在本机创建nginx的一些文件存储目录 mkdir -p /root/nginx/www /root/nginx/logs /root/nginx/conf www: nginx存储网站网页的目录 logs: nginx日志目录 conf: nginx配置文件目录 2、映射（1）先查看容器 docker ps -a （2）映射 docker cp 481e121fb29f:/etc/nginx/nginx.conf /root/nginx/conf 3、启动容器需要说明下，ngxin-test 容器是为了获得容器的配置文件，最终使用的是 nginx-web 目前已经启动 nginx-test 80端口，若是 nginx-web指定的也是 80，就需要关闭 nginx-test了 docker stop nginx-test 1、新容器映射创建新nginx容器nginx-web,并将www,logs,conf目录映射到本地 docker run -d -p 80:80 --name nginx-web -v /root/nginx/www:/usr/share/nginx/html -v /root/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v /root/nginx/logs:/var/log/nginx nginx 2、启动docker start nginx-web 二、下载git1、下载yum install git 2、配置github 代理git config --global url.\"https://ghproxy.com/https://github.com\".insteadOf \"https://github.com\" 3、拉取git clone https://github.com/mykkTo/mykkTo.github.io.git 4、剪切文件mv /root/nginx/www/mykkTo.github.io/* /root/nginx/www 三、定时任务1、编写shell脚本#!/bin/bash #删除原始静态页面数据以及拉取的文件夹 rm -rf /root/nginx/www/* rm -rf /root/nginx/mykkTo.github.iopwd #拉取，剪切到80映射下 cd /root/nginx/ git clone https://github.com/mykkTo/mykkTo.github.io.git mv /root/nginx/mykkTo.github.io/* /root/nginx/www #复制令牌用户百度站长验证使用 cp /root/nginx/baidu_verify_code-Os7hLX61vV.html /root/nginx/www/baidu_verify_code-Os7hLX61vV.html #替换文本，用于百度站长seo映射 sed 's/github.io/cn/g' /root/nginx/www/baidu_urls.txt&gt;/root/nginx/www/baidu_urls1.txt sed 's/https/http/g' /root/nginx/www/baidu_urls1.txt&gt;/root/nginx/www/baidu_urls2.txt echo \"============成功=========\" 2、创建定时任务crontab -e 补充： linux 黑洞，防止资源占用 /dev/null 2&gt;&amp;1 #后缀加上 /root/nginx/synblog.sh /dev/null 2&gt;&amp;1 启动： 这边设置没一个小时更新一次（需要注意centos7.6写法启动） service crond start 四、SSL证书1、是什么数据加密：开启 HTTPS 绿色加密通道，网站数据的加密传输，防止网站核心数据被窃取或篡改。 简单来说，就是把 http 访问的变成 https，并且浏览器显示安全，不在是不安全了 2、获取证书1、下载 2、上传到服务器并解压 3、重挂载1、删掉之前的容器docker rm -f nginx-web 2、重新挂载1、新增了 443端口映射，目录挂载 2、容器外，在nginx底下，创建新目录 mkdir lls 3、创建容器 多加了两个配置 docker run -d -p 443:443 -p 80:80 --name nginx-web -v /root/nginx/www:/usr/share/nginx/html -v /root/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v /root/nginx/logs:/var/log/nginx -v /root/nginx/lls/:/etc/nginx/ssl nginx 4、修改配置nginx.conf user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { limit_req_zone $binary_remote_addr zone=mylimit:10m rate=2r/s; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; server{ listen 443 ssl; #对应的域名，把mykkto.cn改成你们自己的域名就可以了 server_name mykkto.cn; #证书的两个配置文件 ssl_certificate /etc/nginx/ssl/7526194_www.mykkto.cn.pem; ssl_certificate_key /etc/nginx/ssl/7526194_www.mykkto.cn.key; #以下都是一些加密规则 ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; #这是我的主页访问地址，因为使用的是静态的html网页，所以直接使用location就可以完成了。 location / { #文件夹（这个其实挂载的就是外部的www目录下的静态资源） root //usr/share/nginx/html; #主页文件 index index.html; } } server { listen 80; #这边空格隔开，配置了两个，因为加了www也要配置 server_name mykkto.cn www.mykkto.cn; rewrite ^/(.*)$ https://mykkto.cn:443/$1 permanent; # location / { # limit_req zone=mylimit; #} } } 5、重启并测试1、重启docker restart nginx-web 2、测试1、访问，www.mykkto.cnm，自动跳转 2、访问，mykkto.cn，自动跳转 五、IP黑名单限制1、前言1、用到什么技术栈首先，基本架构是 docker+nginx+lua+mysql这是最初的想法，但是作者用了docker搭建的nginx，lua模块集成不是很方便，所以替换成了，OpenResty。 2、什么是 OpenResty简单来说就是 lua + nginx，当然还有更多功能，自己百度吧 3、遇到的问题简单描述下，上面用到的 nginx.conf写法，前缀 user nginx; 会导致无法运行，因为openresty没有这个用户，可以自己新建，我采用的是改写配置。 2、搭建 OpenResty1、拉取docker pull openresty/openresty 2、挂载并启动说明下： 完全基于上面的nginx配置的三个部分，唯一修改的是 nginx.conf配置文件，这边挂载改成了 nginx2.conf，用于保留之前的（自己懒而已） 新增了，lua文件挂载 修改了容器内的挂载位置，因为 openresty容器位置不一样了(外部还是不变，容器内的位置变了) docker run -d -p 443:443 -p 80:80 --name openresty -v /root/nginx/www:/usr/local/openresty/nginx/html -v /root/nginx/conf/nginx2.conf:/usr/local/openresty/nginx/conf/nginx.conf -v /root/nginx/logs:/usr/local/openresty/nginx/logs -v /root/nginx/lls/:/usr/local/openresty/nginx/ssl -v /root/nginx/lua/:/usr/local/openresty/nginx/lua openresty/openresty 3、配置文件修改1、初始化这是自带的，可以自己 DIY # nginx.conf -- docker-openresty # # This file is installed to: # `/usr/local/openresty/nginx/conf/nginx.conf` # and is the file loaded by nginx at startup, # unless the user specifies otherwise. # # It tracks the upstream OpenResty's `nginx.conf`, but removes the `server` # section and adds this directive: # `include /etc/nginx/conf.d/*.conf;` # # The `docker-openresty` file `nginx.vh.default.conf` is copied to # `/etc/nginx/conf.d/default.conf`. It contains the `server section # of the upstream `nginx.conf`. # # See https://github.com/openresty/docker-openresty/blob/master/README.md#nginx-config-files # #user nobody; #worker_processes 1; # Enables the use of JIT for regular expressions to speed-up their processing. pcre_jit on; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; # Enables or disables the use of underscores in client request header fields. # When the use of underscores is disabled, request header fields whose names contain underscores are marked as invalid and become subject to the ignore_invalid_headers directive. # underscores_in_headers off; #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #access_log logs/access.log main; # Log in JSON Format # log_format nginxlog_json escape=json '{ \"timestamp\": \"$time_iso8601\", ' # '\"remote_addr\": \"$remote_addr\", ' # '\"body_bytes_sent\": $body_bytes_sent, ' # '\"request_time\": $request_time, ' # '\"response_status\": $status, ' # '\"request\": \"$request\", ' # '\"request_method\": \"$request_method\", ' # '\"host\": \"$host\",' # '\"upstream_addr\": \"$upstream_addr\",' # '\"http_x_forwarded_for\": \"$http_x_forwarded_for\",' # '\"http_referrer\": \"$http_referer\", ' # '\"http_user_agent\": \"$http_user_agent\", ' # '\"http_version\": \"$server_protocol\", ' # '\"nginx_access\": true }'; # access_log /dev/stdout nginxlog_json; # See Move default writable paths to a dedicated directory (#119) # https://github.com/openresty/docker-openresty/issues/119 client_body_temp_path /var/run/openresty/nginx-client-body; proxy_temp_path /var/run/openresty/nginx-proxy; fastcgi_temp_path /var/run/openresty/nginx-fastcgi; uwsgi_temp_path /var/run/openresty/nginx-uwsgi; scgi_temp_path /var/run/openresty/nginx-scgi; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; # Don't reveal OpenResty version to clients. # server_tokens off; } 2、引入之前的配置在初始的基础上加上，两个之前写好的 server 块，以及lua脚本用于测试 # nginx.conf -- docker-openresty # # This file is installed to: # `/usr/local/openresty/nginx/conf/nginx.conf` # and is the file loaded by nginx at startup, # unless the user specifies otherwise. # # It tracks the upstream OpenResty's `nginx.conf`, but removes the `server` # section and adds this directive: # `include /etc/nginx/conf.d/*.conf;` # # The `docker-openresty` file `nginx.vh.default.conf` is copied to # `/etc/nginx/conf.d/default.conf`. It contains the `server section # of the upstream `nginx.conf`. # # See https://github.com/openresty/docker-openresty/blob/master/README.md#nginx-config-files # #user nobody; #worker_processes 1; # Enables the use of JIT for regular expressions to speed-up their processing. pcre_jit on; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; # Enables or disables the use of underscores in client request header fields. # When the use of underscores is disabled, request header fields whose names contain underscores are marked as invalid and become subject to the ignore_invalid_headers directive. # underscores_in_headers off; #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #access_log logs/access.log main; # Log in JSON Format # log_format nginxlog_json escape=json '{ \"timestamp\": \"$time_iso8601\", ' # '\"remote_addr\": \"$remote_addr\", ' # '\"body_bytes_sent\": $body_bytes_sent, ' # '\"request_time\": $request_time, ' # '\"response_status\": $status, ' # '\"request\": \"$request\", ' # '\"request_method\": \"$request_method\", ' # '\"host\": \"$host\",' # '\"upstream_addr\": \"$upstream_addr\",' # '\"http_x_forwarded_for\": \"$http_x_forwarded_for\",' # '\"http_referrer\": \"$http_referer\", ' # '\"http_user_agent\": \"$http_user_agent\", ' # '\"http_version\": \"$server_protocol\", ' # '\"nginx_access\": true }'; # access_log /dev/stdout nginxlog_json; # See Move default writable paths to a dedicated directory (#119) # https://github.com/openresty/docker-openresty/issues/119 client_body_temp_path /var/run/openresty/nginx-client-body; proxy_temp_path /var/run/openresty/nginx-proxy; fastcgi_temp_path /var/run/openresty/nginx-fastcgi; uwsgi_temp_path /var/run/openresty/nginx-uwsgi; scgi_temp_path /var/run/openresty/nginx-scgi; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; server{ listen 443 ssl; #对应的域名，把mykkto.cn改成你们自己的域名就可以了 server_name mykkto.cn; #证书的两个配置文件 ssl_certificate /usr/local/openresty/nginx/ssl/7526194_www.mykkto.cn.pem; ssl_certificate_key /usr/local/openresty/nginx/ssl/7526194_www.mykkto.cn.key; #以下都是一些加密规则 ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; #这是我的主页访问地址，因为使用的是静态的html网页，所以直接使用location就可以完成了。 location / { #文件夹（这个其实挂载的就是外部的www目录下的静态资源） root /usr/local/openresty/nginx/html; #主页文件 index index.html; } #lua脚本用于测试 location /lua { default_type 'text/html'; content_by_lua 'ngx.say(\"&lt;h1&gt; hello,openrestry&lt;/h1&gt;\")'; } } server { listen 80; #这边空格隔开，配置了两个，因为加了www也要配置 server_name mykkto.cn www.mykkto.cn; rewrite ^/(.*)$ https://mykkto.cn:443/$1 permanent; # location / { # limit_req zone=mylimit; #} } # Don't reveal OpenResty version to clients. # server_tokens off; } 3、测试lua脚本 六、限流1、配置http { limit_req_zone $binary_remote_addr zone=one:10m rate=5r/s; server { location /search/ { limit_req zone=one burst=5 nodelay; } } limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; 第一个参数：$binary_remote_addr 表示通过remote_addr这个标识来做限制，“binary_”的目的是缩写内存占用量，是限制同一客户端ip地址。 第二个参数：zone=one:10m表示生成一个大小为10M，名字为one的内存区域，用来存储访问的频次信息。 第三个参数：rate=5r/s表示允许相同标识的客户端的访问频次，这里限制的是每秒 5 次，还可以有比如30r/m的。 limit_req zone=one burst=5 nodelay; 第一个参数：zone=one 设置使用哪个配置区域来做限制，与上面limit_req_zone 里的name对应。 第二个参数：burst=5，重点说明一下这个配置，burst爆发的意思，这个配置的意思是设置一个大小为5的缓冲区当有大量请求（爆发）过来时，超过了访问频次限制的请求可以先放到这个缓冲区内。 第三个参数：nodelay，如果设置，超过访问频次而且缓冲区也满了的时候就会直接返回503，如果没有设置，则所有请求会等待排队。 2、网站配置源码#user nobody; #worker_processes 1; # Enables the use of JIT for regular expressions to speed-up their processing. pcre_jit on; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; server_tokens off; #引入lib包 lua_package_path \"/usr/local/openresty/lualib/?.lua;;\"; #开辟一块内存区域 lua_shared_dict ip_blacklist 4m; # Enables or disables the use of underscores in client request header fields. # When the use of underscores is disabled, request header fields whose names contain underscores are marked as invalid and become subject to the ignore_invalid_headers directive. # underscores_in_headers off; #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #access_log logs/access.log main; # Log in JSON Format # log_format nginxlog_json escape=json '{ \"timestamp\": \"$time_iso8601\", ' # '\"remote_addr\": \"$remote_addr\", ' # '\"body_bytes_sent\": $body_bytes_sent, ' # '\"request_time\": $request_time, ' # '\"response_status\": $status, ' # '\"request\": \"$request\", ' # '\"request_method\": \"$request_method\", ' # '\"host\": \"$host\",' # '\"upstream_addr\": \"$upstream_addr\",' # '\"http_x_forwarded_for\": \"$http_x_forwarded_for\",' # '\"http_referrer\": \"$http_referer\", ' # '\"http_user_agent\": \"$http_user_agent\", ' # '\"http_version\": \"$server_protocol\", ' # '\"nginx_access\": true }'; # access_log /dev/stdout nginxlog_json; # See Move default writable paths to a dedicated directory (#119) # https://github.com/openresty/docker-openresty/issues/119 client_body_temp_path /var/run/openresty/nginx-client-body; proxy_temp_path /var/run/openresty/nginx-proxy; fastcgi_temp_path /var/run/openresty/nginx-fastcgi; uwsgi_temp_path /var/run/openresty/nginx-uwsgi; scgi_temp_path /var/run/openresty/nginx-scgi; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; #限流设置 limit_req_zone $binary_remote_addr zone=one:30m rate=10r/s; server{ listen 443 ssl; #对应的域名，把mykkto.cn改成你们自己的域名就可以了 server_name mykkto.cn; #证书的两个配置文件 ssl_certificate /usr/local/openresty/nginx/ssl/7526194_www.mykkto.cn.pem; ssl_certificate_key /usr/local/openresty/nginx/ssl/7526194_www.mykkto.cn.key; #以下都是一些加密规则 ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; #这是我的主页访问地址，因为使用的是静态的html网页，所以直接使用location就可以完成了。 set $real_ip $remote_addr; if ( $http_x_forwarded_for ~ \"^(\\d+\\.\\d+\\.\\d+\\.\\d+)\" ) { set $real_ip $1; } # 管理信息，访问该URL可以查看nginx中的IP黑名单信息 location /get-ipblacklist-info { access_by_lua_file /usr/local/openresty/nginx/lua/get_ipblacklist_info.lua; } # 同步URL，通过定时任务调用该URL,实现IP黑名单从mysql到nginx的定时刷新 location /sync-ipblacklist { access_by_lua_file /usr/local/openresty/nginx/lua/sync_ipblacklist.lua; } location / { #限流 limit_req zone=one burst=10 nodelay; # 所有IP进来都要校验 access_by_lua_file /usr/local/openresty/nginx/lua/check_realip.lua; # proxy_read_timeout 60s; # proxy_set_header Host $http_host; # proxy_set_header X-Real_IP $remote_addr; # proxy_set_header X-Forwarded-for $remote_addr; # proxy_http_version 1.1; #文件夹（这个其实挂载的就是外部的www目录下的静态资源） root /usr/local/openresty/nginx/html; #主页文件 index index.html; } } server { listen 80; #这边空格隔开，配置了两个，因为加了www也要配置 server_name mykkto.cn www.mykkto.cn; rewrite ^/(.*)$ https://mykkto.cn:443/$1 permanent; # location / { # limit_req zone=mylimit; #} } # Don't reveal OpenResty version to clients. # server_tokens off; } 3、测试QPS：3000压测 5次 压测的IP为 A，通过，同网段的机器访问（手机模拟），503异常，结论被限流成功 切换网段B ，非压测IP 不限流，测试成功 参考 ↓—— 【一到三】参考———– https://www.cnblogs.com/zltech/p/13517231.html https://www.cnblogs.com/thepoy/p/14848080.html https://www.cnblogs.com/jianqingwang/p/6726589.html —— 【一到三】参考———– SSL证书参考&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; https://www.cnblogs.com/zeussbook/p/11231820.html https://www.cnblogs.com/yuyeblog/p/13582127.html https://www.cnblogs.com/makalochen/p/14241052.html#%E5%A4%9A%E7%9B%AE%E5%BD%95%E6%8C%82%E8%BD%BD IP黑名单参考&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; https://www.jb51.net/article/168907.htm https://blog.csdn.net/weixin_33971205/article/details/89861486 https://www.csdn.net/tags/MtTaIgzsNDYzNDUtYmxvZwO0O0OO0O0O.html 限流&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; https://www.cnblogs.com/biglittleant/p/8979915.html","categories":[{"name":"博客","slug":"博客","permalink":"https://mykkto.github.io/categories/%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"blog","slug":"blog","permalink":"https://mykkto.github.io/tags/blog/"},{"name":"部署","slug":"部署","permalink":"https://mykkto.github.io/tags/%E9%83%A8%E7%BD%B2/"},{"name":"小姿势","slug":"小姿势","permalink":"https://mykkto.github.io/tags/%E5%B0%8F%E5%A7%BF%E5%8A%BF/"}],"author":"mykk"},{"title":"SpringCloud-Alibaba-Sentinel 实现熔断与限流","slug":"03-java分布式/01springcloud/15_SpringCloudAlibaba-Sentinel","date":"2022-03-13T07:17:13.000Z","updated":"2022-05-22T15:01:03.836Z","comments":true,"path":"posts/32724da3.html","link":"","permalink":"https://mykkto.github.io/posts/32724da3.html","excerpt":"","text":"一、概述1、官网https://github.com/alibaba/Sentinel https://github.com/alibaba/Sentinel/wiki/%E4%BB%8B%E7%BB%8D 2、是什么一句话解释，就是类似于 Hystrix 3、去哪下https://github.com/alibaba/Sentinel/releases 4、能干嘛 服务使用中的各种问题 服务雪崩 服务降级 服务熔断 服务限流 二、安装控制台1、sentinel组件由两部分构成 后台 前台8080 2、安装步骤1、拉取镜像docker pull bladex/sentinel-dashboard:1.7.0 2、启动并创建容器docker run --name sentinel -d -p 8858:8858 bladex/sentinel-dashboard:1.7.0 3、访问ip:8858 登录账号密码均为sentinel 三、初始化工程1、启动准备工作启动 sentinel （8858），nacos（8848） 2、model1、建modelcloudalibaba-sentinel-service8401 2、pom&lt;!--SpringCloud ailibaba nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--SpringCloud ailibaba sentinel-datasource-nacos 后续做持久化用到--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--SpringCloud ailibaba sentinel --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloudalibaba-sentinel-service8401&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--SpringCloud ailibaba nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--SpringCloud ailibaba sentinel-datasource-nacos 后续做持久化用到--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--SpringCloud ailibaba sentinel --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- SpringBoot整合Web组件+actuator --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--日常通用jar包配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.6.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: #Nacos服务注册中心地址 server-addr: 101.34.180.133:8848 sentinel: transport: #配置Sentinel dashboard地址 # dashboard: 101.34.180.133:8858 # dashboard: 106.52.23.202:8080 # 项目和 sentinel 不在同一台机器无法查看实时监控 dashboard: localhost:8080 #默认8719端口，假如被占用会自动从8719开始依次+1扫描,直至找到未被占用的端口 port: 8719 # 本地机器ip(docker容器必须加上) # client-ip: 169.254.135.77 management: endpoints: web: exposure: include: '*' 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @SpringBootApplication @EnableDiscoveryClient public class SpringCloudSentinelMain8401 { public static void main(String[] args) { SpringApplication.run (SpringCloudSentinelMain8401.class,args); } } 5、业务类package com.kk.springcloud.controller; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class FlowLimitController { @GetMapping(\"/testA\") public String testA() { return \"------testA\"; } @GetMapping(\"/testB\") public String testB() { return \"------testB\"; } } 3、操作 sentinel控制台1、刚进来空空如也，啥都没有 2、懒加载说明 Sentinel采用的懒加载说明 需要执行一次 http://localhost:8401/testA http://localhost:8401/testB 这边需要注意一点：如果你的实时监控没有数据，可能是因为 sentinel 和项目不再同一个 机器或者 sentinel访问不到 项目就监控不到了 四、流控制规则1、基本介绍 2、流控模式1、直接(默认)表示：1秒钟内查询1次就是OK，若超过次数1，就直接-快速失败，报默认错误 1、配置内容 2、测试效果访问：http://localhost:8401/testA 3、结论思考直接调用默认报错信息，技术方面OK， 但是否应该有我们自己的后续处理，类似有个fallback的兜底方法 2、关联1、是什么 当关联的资源达到阈值时，就限流自己 当与A关联的资源B达到阀值后，就限流A自己 B惹事，A挂了 2、配置A当关联资源 /testB 的 qps 阀值超过1时，就限流 /testA 的Rest访问地址，当关联资源到阈值后限制配置好的资源名 3、postman模拟并发密集访问testB创建一个集合并发测试文件夹 将测试的url放进文件夹 4、测试启动并发对 /testB run，再次过程中访问 /testB 发现出错 3、链路 多个请求调用了同一个微服务 2X（流控模式总结） 直接：对当前资源限流 关联：高优先级资源触发阈值，对低优先级资源限流。 链路：阈值统计时，只统计从指定资源进入当前资源的请求，是对请求来源的限流 3、流控效果1、快速失败达到峰值，直接失败，抛出异常（Blocked by Sentinel (flow limiting)） 源码（修改扩展位置）：com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 2、WarmUp（预热）1、公式阈值除以coldFactor(默认值为3),经过预热时长后才会达到阈值 2、官网 默认coldFactor为3，即请求 QPS 从 threshold / 3 开始，经预热时长逐渐升至设定的 QPS 阈值。 限流，冷启动 https://github.com/alibaba/Sentinel/wiki/%E9%99%90%E6%B5%81---%E5%86%B7%E5%90%AF%E5%8A%A8 3、源码com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 4、WarmUp配置 默认 coldFactor 为 3，即请求QPS从(threshold / 3) 开始，经多少预热时长才逐渐升至设定的 QPS 阈值。 案例，阀值为10+预热时长设置5秒。系统初始化的阀值为10 / 3 约等于3,即阀值刚开始为3；然后过了5秒后阀值才慢慢升高恢复到10 5、点击测试多次点击http://localhost:8401/testB 刚开始不行，后续慢慢OK 6、应用场景如：秒杀系统在开启的瞬间，会有很多流量上来，很有可能把系统打死，预热方式就是把为了保护系统，可慢慢的把流量放进来，慢慢的把阀值增长到设置的阀值。 3、排队等待1、说明匀速排队，阈值必须设置为QPS 2、官网https://github.com/alibaba/Sentinel/wiki/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6 3、源码com.alibaba.csp.sentinel.slots.block.flow.controller.RateLimiterController 4、配置 匀速排队，让请求以均匀的速度通过，阀值类型必须设成QPS，否则无效。 设置含义： /testB 每秒1次请求，超过的话就排队等待，等待的超时时间为20000毫秒。 5、测试 五、降级规则1、官网https://github.com/alibaba/Sentinel/wiki/%E7%86%94%E6%96%AD%E9%99%8D%E7%BA%A7 2、基本介绍1、说明 Sentinel 熔断降级会在调用链路中某个资源出现不稳定状态时（例如调用超时或异常比例升高），对这个资源的调用进行限制，让请求快速失败，避免影响到其它的资源而导致级联错误。 当资源被降级后，在接下来的降级时间窗口之内，对该资源的调用都自动熔断（默认行为是抛出 DegradeException） 2、hystrix比较Sentinel的断路器是没有半开状态的 半开的状态系统自动去检测是否请求有异常，没有异常就关闭断路器恢复使用，有异常则继续打开断路器不可用。具体可以参考Hystrix 以下是hystrix断路器结构图 3、降级策略实战1、RT 1、代码@GetMapping(\"/testD\") public String testD() { //暂停几秒钟线程 try { TimeUnit.SECONDS.sleep (1); } catch (InterruptedException e) { e.printStackTrace ( ); } log.info (\"testD 测试RT\"); return \"------testD\"; } 2、配置 3、jmeter压测 4、结果 2、异常比例1、是什么 2、代码@GetMapping(\"/testD\") public String testD() { log.info (\"testD 测试异常比例\"); int age = 10 / 0; return \"------testD\"; } 3、配置 4、jmeter 5、结论 3、异常数1、是什么 2、需知异常数是按照分钟统计的 3、代码@GetMapping(\"/testE\") public String testE() { log.info (\"testE 测试异常比例\"); int age = 10 / 0; return \"------testE 测试异常比例\"; } 4、配置 5、jmeter 六、热点key限流1、基本介绍1、是什么何为热点 热点即经常访问的数据，很多时候我们希望统计或者限制某个热点数据中访问频次最高的TopN数据，并对其访问进行限流或者其它操作 2、官网https://github.com/alibaba/Sentinel/wiki/%E7%83%AD%E7%82%B9%E5%8F%82%E6%95%B0%E9%99%90%E6%B5%81 3、兜底方法sentinel系统默认的提示：Blocked by Sentinel (flow limiting) 可以指定，自定义兜底方法 从HystrixCommand 到@SentinelResource 2、案例1、代码@GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"dealHandler_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false) String p1, @RequestParam(value = \"p2\", required = false) String p2) { return \"------testHotKey\"; } public String dealHandler_testHotKey(String p1, String p2, BlockException exception) { return \"-----dealHandler_testHotKey\"; } 2、配置说明 限流模式只支持QPS模式，固定写死了。（这才叫热点）@SentinelResource注解的方法参数索引，0代表第一个参数，1代表第二个参数，以此类推单机阀值以及统计窗口时长表示在此窗口时间超过阀值就限流。上面的抓图就是第一个参数有值的话，1秒的QPS为1，超过就限流，限流后调用 dealHandler_testHotKey支持方法。 3、配置 @SentinelResource(value = \"testHotKey\",blockHandler = \"dealHandler_testHotKey\") 方法testHotKey里面第一个参数只要QPS超过每秒1次，马上降级处理 4、测试http://localhost:8401/testHotKey?p1=abc http://localhost:8401/testHotKey?p1=abc&amp;p2=33 http://localhost:8401/testHotKey?p2=33 3、参数高级选项1、作用上述案例，第一个参数p1，当QPS超过1秒1次点击后马上被限流 若是我们有一个需求，p1特例为5 ，QPS 阈值为 200就可以通过 这个实现 2、配置 3、测试http://localhost:8401/testHotKey?p1=5 http://localhost:8401/testHotKey?p1=3 4、结论当p1等于5的时候，阈值变为 200 当p1不等于5的时候，阈值为平常的 1 热点参数的注意点，参数必须是基本类型或者String 七、@SentinelResource1、按资源名称限流+后续处理1、代码1、代码 package com.kk.springcloud.controller; import com.alibaba.csp.sentinel.annotation.SentinelResource; import com.alibaba.csp.sentinel.slots.block.BlockException; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class RateLimitController { @GetMapping(\"/byResource\") @SentinelResource(value = \"byResource\",blockHandler = \"handleException\") public CommonResult byResource() { return new CommonResult (200,\"按资源名称限流测试OK\",new Payment (2020L,\"serial001\")); } public CommonResult handleException(BlockException exception) { return new CommonResult(444,exception.getClass().getCanonicalName()+\"\\t 服务不可用\"); } } 2、pom &lt;dependency&gt; &lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; 2、配置流控规则1、步骤 2、图形配置和代码关系 3、配置说明表示1秒钟内查询次数大于1，就跑到我们自定义的处流，限流 3、测试1秒钟点击1下，OK 超过上述，疯狂点击，返回了自己定义的限流处理信息，限流发生 2、按照Url地址限流+后续处理1、作用通过访问的URL来限流，会返回Sentinel自带默认的限流处理信息 2、代码@GetMapping(\"/rateLimit/byUrl\") @SentinelResource(value = \"byUrl\") public CommonResult byUrl() { return new CommonResult (200, \"按url限流测试OK\", new Payment (2020L, \"serial002\")); } 3、访问（1次）为了刷新实时配置，线上就没必要这个操作了 http://localhost:8401//rateLimit/byUrl 4、配置 5、访问（狂点） 3、兜底方案面临的问题1 系统默认的，没有体现我们自己的业务要求。 2 依照现有条件，我们自定义的处理方法又和业务代码耦合在一块，不直观。 3 每个业务方法都添加一个兜底的，那代码膨胀加剧。 4 全局统一的处理方法没有体现 4、用户自定义限流处理逻辑1、自定义限流处理类创建CustomerBlockHandler类用于自定义限流处理逻辑 package com.kk.springcloud.handler; import com.alibaba.csp.sentinel.slots.block.BlockException; import com.kk.springcloud.entities.CommonResult; public class CustomerBlockHandler { public static CommonResult handleException(BlockException exception) { return new CommonResult (2020, \"自定义的限流处理信息......CustomerBlockHandler\"); } } 2、使用/** * 自定义通用的限流处理逻辑， blockHandlerClass = CustomerBlockHandler.class blockHandler = handleException 上述配置：找CustomerBlockHandler类里的handleException2方法进行兜底处理 */ /** * 自定义通用的限流处理逻辑 */ @GetMapping(\"/rateLimit/customerBlockHandler\") @SentinelResource(value = \"customerBlockHandler\", blockHandlerClass = CustomerBlockHandler.class, blockHandler = \"handleException\") public CommonResult customerBlockHandler() { return new CommonResult (200, \"按客户自定义限流处理逻辑\"); } 3、配置 4、配置说明 5、测试 5、更多注解属性说明 八、服务熔断功能1、整合sentinel整合ribbon+openFeign+fallback 2、Ribbon1、生产者1、建modelcloudalibaba-provider-payment9003 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloudalibaba-provider-payment9003&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--SpringCloud ailibaba nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- SpringBoot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--日常通用jar包配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 9003 spring: application: name: nacos-payment-provider cloud: nacos: discovery: server-addr: localhost:8848 #配置Nacos地址 management: endpoints: web: exposure: include: '*' 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @EnableDiscoveryClient @SpringBootApplication public class PaymentMain9003 { public static void main(String[] args) { SpringApplication.run (PaymentMain9003.class,args); } } 5、业务类package com.kk.springcloud.controller; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import java.util.HashMap; @RestController public class PaymentController { @Value(\"${server.port}\") private String serverPort; public static HashMap&lt;Long, Payment&gt; hashMap = new HashMap&lt;&gt; ( ); static { hashMap.put (1L, new Payment (1L, \"28a8c1e3bc2742d8848569891fb42181\")); hashMap.put (2L, new Payment (2L, \"bba8c1e3bc2742d8848569891ac32182\")); hashMap.put (3L, new Payment (3L, \"6ua8c1e3bc2742d8848569891xt92183\")); } @GetMapping(value = \"/paymentSQL/{id}\") public CommonResult&lt;Payment&gt; paymentSQL(@PathVariable(\"id\") Long id) { Payment payment = hashMap.get (id); CommonResult&lt;Payment&gt; result = new CommonResult (200, \"from mysql,serverPort: \" + serverPort, payment); return result; } } 6、启动同一个服务，启动9003，9004 -Dserver.port=9004 7、测试http://localhost:9003/paymentSQL/1 http://localhost:9004/paymentSQL/1 2、消费者1、model新建cloudalibaba-consumer-nacos-order84 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloudalibaba-consumer-nacos-order84&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--SpringCloud ailibaba nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--SpringCloud ailibaba sentinel --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- SpringBoot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--日常通用jar包配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 84 spring: application: name: nacos-order-consumer cloud: nacos: discovery: server-addr: localhost:8848 sentinel: transport: #配置Sentinel dashboard地址 dashboard: localhost:8080 #默认8719端口，假如被占用会自动从8719开始依次+1扫描,直至找到未被占用的端口 port: 8719 #消费者将要去访问的微服务名称(注册成功进nacos的微服务提供者) service-url: nacos-user-service: http://nacos-payment-provider 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @EnableDiscoveryClient @SpringBootApplication public class OrderNacosMain84 { public static void main(String[] args) { SpringApplication.run (OrderNacosMain84.class,args); } } 5、配置类1、rabbion 负载配置 package com.kk.springcloud.config; import org.springframework.cloud.client.loadbalancer.LoadBalanced; import org.springframework.context.annotation.Bean; import org.springframework.stereotype.Component; import org.springframework.web.client.RestTemplate; @Component public class ApplicationContextConfig { @Bean @LoadBalanced public RestTemplate getRestTemplate() { return new RestTemplate ( ); } } 6、业务类1、只配置fallback（本例sentinel无配置） 2、只配置blockHandler package com.kk.springcloud.controller; import com.alibaba.csp.sentinel.annotation.SentinelResource; import com.alibaba.csp.sentinel.slots.block.BlockException; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import lombok.extern.slf4j.Slf4j; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import javax.annotation.Resource; @RestController @Slf4j public class CircleBreakerController { public static final String SERVICE_URL = \"http://nacos-payment-provider\"; @Resource private RestTemplate restTemplate; @RequestMapping(\"/consumer/fallback/{id}\") @SentinelResource(value = \"fallback\", blockHandler = \"blockHandler\") //blockHandler负责在sentinel里面配置的降级限流 public CommonResult&lt;Payment&gt; fallback(@PathVariable Long id) { CommonResult&lt;Payment&gt; result = restTemplate.getForObject (SERVICE_URL + \"/paymentSQL/\" + id, CommonResult.class, id); if (id == 4) { throw new IllegalArgumentException (\"非法参数异常....\"); } else if (result.getData ( ) == null) { throw new NullPointerException (\"NullPointerException,该ID没有对应记录\"); } return result; } // 兜底 public CommonResult handlerFallback(@PathVariable Long id, Throwable e) { Payment payment = new Payment (id, \"null\"); return new CommonResult&lt;&gt; (444, \"兜底异常handlerFallback,exception内容 \" + e.getMessage ( ), payment); } // 降级 public CommonResult blockHandler(@PathVariable Long id, BlockException blockException) { Payment payment = new Payment (id, \"null\"); return new CommonResult&lt;&gt; (445, \"blockHandler-sentinel限流,无此流水: blockException \" + blockException.getMessage ( ), payment); } } 3、fallback和blockHandler都配置 package com.kk.springcloud.controller; import com.alibaba.csp.sentinel.annotation.SentinelResource; import com.alibaba.csp.sentinel.slots.block.BlockException; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import lombok.extern.slf4j.Slf4j; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import javax.annotation.Resource; @RestController @Slf4j public class CircleBreakerController { public static final String SERVICE_URL = \"http://nacos-payment-provider\"; @Resource private RestTemplate restTemplate; @RequestMapping(\"/consumer/fallback/{id}\") @SentinelResource(value = \"fallback\", fallback = \"handlerFallback\", blockHandler = \"blockHandler\") public CommonResult&lt;Payment&gt; fallback(@PathVariable Long id) { CommonResult&lt;Payment&gt; result = restTemplate.getForObject (SERVICE_URL + \"/paymentSQL/\" + id, CommonResult.class, id); if (id == 4) { throw new IllegalArgumentException (\"非法参数异常....\"); } else if (result.getData ( ) == null) { throw new NullPointerException (\"NullPointerException,该ID没有对应记录\"); } return result; } // 兜底 public CommonResult handlerFallback(@PathVariable Long id, Throwable e) { Payment payment = new Payment (id, \"null\"); return new CommonResult&lt;&gt; (444, \"fallback,无此流水,exception \" + e.getMessage ( ), payment); } // 降级 public CommonResult blockHandler(@PathVariable Long id, BlockException blockException) { Payment payment = new Payment (id, \"null\"); return new CommonResult&lt;&gt; (445, \"blockHandler-sentinel限流,无此流水: blockException \" + blockException.getMessage ( ), payment); } } 降级优先于限流：若 blockHandler 和 fallback 都进行了配置，则被限流降级而抛出 BlockException 时只会进入 blockHandler 处理逻辑。 4、属性忽略 直接抛到前台对用户体验不好，细节注意 3、Feign1、model修改84模块 2、pom&lt;!--SpringCloud openfeign --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; 3、yml# 激活Sentinel对Feign的支持 feign: sentinel: enabled: true 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; import org.springframework.cloud.openfeign.EnableFeignClients; @EnableDiscoveryClient @SpringBootApplication @EnableFeignClients public class OrderNacosMain84 { public static void main(String[] args) { SpringApplication.run (OrderNacosMain84.class,args); } } 5、业务类1、远程调服务接口package com.kk.springcloud.serivice; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; /** * @auther mykk * @create 2022年3月24日 21:45:49 * 使用 fallback 方式是无法获取异常信息的， * 如果想要获取异常信息，可以使用 fallbackFactory参数 */ @FeignClient(value = \"nacos-payment-provider\", fallback = PaymentFallbackService.class)//调用中关闭9003服务提供者 public interface PaymentService { @GetMapping(value = \"/paymentSQL/{id}\") CommonResult&lt;Payment&gt; paymentSQL(@PathVariable(\"id\") Long id); } 2、兜底实现package com.kk.springcloud.serivice; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import org.springframework.stereotype.Component; @Component public class PaymentFallbackService implements PaymentService { @Override public CommonResult&lt;Payment&gt; paymentSQL(Long id) { return new CommonResult&lt;&gt; (444, \"服务降级返回,没有该流水信息\", new Payment (id, \"errorSerial......\")); } } 3、Controller//==================OpenFeign @Resource private PaymentService paymentService; @GetMapping(value = \"/consumer/openfeign/{id}\") public CommonResult&lt;Payment&gt; paymentSQL(@PathVariable(\"id\") Long id) { if (id == 4) { throw new RuntimeException (\"没有该id\"); } return paymentService.paymentSQL (id); } 6、测试测试84调用9003，此时故意关闭9003/9004微服务提供者，看84消费侧自动降级，不会被耗死 4、熔断框架比较 九、持久化规则1、是什么一旦我们重启应用，sentinel规则将消失，生产环境需要将配置规则进行持久化 2、怎么玩将限流配置规则持久化进Nacos保存，只要刷新8401某个rest地址，sentinel控制台的流控规则就能看到，只要Nacos里面的配置不删除，针对8401上sentinel上的流控规则持续有效 3、实战1、model修改cloudalibaba-sentinel-service8401 2、pom &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloudalibaba-sentinel-service8401&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--SpringCloud ailibaba sentinel-datasource-nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--SpringCloud ailibaba nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--SpringCloud ailibaba sentinel-datasource-nacos 后续做持久化用到--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--SpringCloud ailibaba sentinel --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- SpringBoot整合Web组件+actuator --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--日常通用jar包配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.6.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、yml server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: #Nacos服务注册中心地址 server-addr: 101.34.180.133:8848 sentinel: transport: #配置Sentinel dashboard地址 # dashboard: 101.34.180.133:8858 # dashboard: 106.52.23.202:8080 # 项目和 sentinel 不在同一台机器无法查看实时监控 dashboard: localhost:8080 #默认8719端口，假如被占用会自动从8719开始依次+1扫描,直至找到未被占用的端口 port: 8719 datasource: ds1: nacos: server-addr: 101.34.180.133:8848 dataId: cloudalibaba-sentinel-service groupId: DEFAULT_GROUP data-type: json rule-type: flow # 本地机器ip(docker容器必须加上) # client-ip: 169.254.135.77 feign: sentinel: enabled: true # 激活Sentinel对Feign的支持 management: endpoints: web: exposure: include: '*' 4、添加Nacos业务规则配置[ { \"resource\": \"/rateLimit/byUrl\", \"limitApp\": \"default\", \"grade\": 1, \"count\": 1, \"strategy\": 0, \"controlBehavior\": 0, \"clusterMode\": false } ] 5、启动启动8401后刷新sentinel发现业务规则有了 6、测试（访问）快速访问测试接口 http://localhost:8401/rateLimit/byUrl 十二、参考文档 ↓https://www.cnblogs.com/linjiqin/p/15369091.html https://www.jianshu.com/p/373eb512ec48 https://m.imooc.com/article/details?article_id=289384 https://www.cnblogs.com/yunqing/p/11406225.html","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud-alibaba","slug":"springcloud-alibaba","permalink":"https://mykkto.github.io/tags/springcloud-alibaba/"},{"name":"熔断器","slug":"熔断器","permalink":"https://mykkto.github.io/tags/%E7%86%94%E6%96%AD%E5%99%A8/"},{"name":"sentinel","slug":"sentinel","permalink":"https://mykkto.github.io/tags/sentinel/"},{"name":"限流","slug":"限流","permalink":"https://mykkto.github.io/tags/%E9%99%90%E6%B5%81/"}],"author":"mykk"},{"title":"Nacos 高可用集群（docker-compose）","slug":"03-java分布式/02容器/01_docker(nacos)","date":"2022-03-12T03:17:13.000Z","updated":"2022-05-22T15:01:03.835Z","comments":true,"path":"posts/d9c3bea0.html","link":"","permalink":"https://mykkto.github.io/posts/d9c3bea0.html","excerpt":"","text":"一、架构1、前言本来这部分是要在 Spring-nacos 手册中 ，但是后面搭建遇到很多坑找了很多资料，就单独整理后写出这篇。 2、架构图 一个ngxin 负载 三个 nacos节点，mysql 主从两个节点 二、搭建 mysql 主从1、拉取和创建# 1、拉取 [root@VM_0_17_centos ~]docker pull mysql:5.7.13 # 2、启动 [root@VM_0_17_centos ~]docker run --name master -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root -d mysql:5.7.13 # 参数说明 --name 为容器指定名称，这里是master -p 将容器的指定端口映射到主机的指定端口，这里是将容器的3306端口映射到主机的3306端口 -e 设置环境变量，这里是指定root账号的密码为root -d 后台运行容器，并返回容器ID mysql:5.7.13 指定运行的mysql版 # 3、查看是否启动,以有容器 [root@VM_0_17_centos ~]# docker ps -a 2、开放端口firewall-cmd --zone=public --add-port=3306/tcp --permanent firewall-cmd --reload # 说明 --permanent 永久开启，避免下次开机需要再次手动开启端口 3、创建[主容器]的复制账号使用Navicat友好的图像化界面执行SQL GRANT REPLICATION SLAVE ON *.* to 'backup'@'%' identified by 'backup'; show grants for 'backup'@'%'; 4、修改MySQL[主容器]配置环境1、创建配置文件目录，目录结构如下：/usr/local/mysql/master/usr/local/mysql/slave1/usr/local/mysql/slave2 [root@VM_0_17_centos ~]# mkdir -p /usr/local/mysql/master /usr/local/mysql/slave1 /usr/local/mysql/slave2 2、拷贝一份MySQL配置文件[root@VM_0_17_centos local]# docker cp master:/etc/mysql/my.cnf /usr/local/mysql/master/my.cnf 3、进到master目录下，已存在拷贝的my.cnf[root@VM_0_17_centos master]# ll total 4 -rw-r--r-- 1 root root 1801 May 10 10:27 my.cnf 4、修改my.cnf，在 [mysqld] 节点最后加上后保存log-bin=mysql-bin server-id=1 log-bin=mysql-bin 使用binary logging，mysql-bin是log文件名的前缀 server-id=1 唯一服务器ID，非0整数，不能和其他服务器的server-id重复 5、将修改后的文件覆盖Docker中MySQL中的配置文件docker cp /usr/local/mysql/master/my.cnf master:/etc/mysql/my.cnf 6、重启 mysql 的docker , 让配置生效[root@VM_0_17_centos master]# docker restart master 5、运行MySQL [从]容器1、首先运行从容器[root@VM_0_17_centos ~]# docker run --name slave1 -p 3307:3306 -e MYSQL_ROOT_PASSWORD=root -d mysql:5.7.13 2、与主容器相似，拷贝配置文件至slave1目录修改后覆盖回Docker中log-bin=mysql-bin server-id=2 3、别忘记，重启slave1容器，使配置生效[root@VM_0_17_centos master]# docker slave1 master 6、配置主从复制1、使用Navicat连接 [slave1]后新建查询，执行以下SQLCHANGE MASTER TO MASTER_HOST='连接Navicat的ip', MASTER_PORT=3306, MASTER_USER='backup', MASTER_PASSWORD='backup'; START SLAVE; MASTER_HOST 填Navicat连接配置中的ip应该就可以 MASTER_PORT 主容器的端口 MASTER_USER 同步账号的用户名 MASTER_PASSWORD 同步账号的密码 2、检查是否配置成功show slave status; 7、检查主从 三、搭建 nacos 集群1、前言docker-compose配置的源码，已经上传到 github,可直接clone ： https://github.com/mykkTo/nacos-cluster-docker.git 2、配置文件说明1、Nacos共用的init.d/custom.properties，与官方保持一致，按需使用 2、docker-compose-nacos1.yml 以 1为例， 带个都大同小异 3、启动 nacos 集群1、将源代码配置修改后，分别上传到三台主机 101.34.180.133 对应 nacos-1 106.52.23.202 对应 nacos-2 119.45.122.161 对应 nacos-3 2、启动容器分别在各主机上进入各自对应的nacos目录中，启动容器，命令如下： 133服务器： $ cd nacos-cluster-docker/nacos-1 $ docker-compose -f docker-compose-nacos1.yml up -d 202服务器： $ cd nacos-cluster-docker/nacos-2 $ docker-compose -f docker-compose-nacos2.yml up -d 161服务器： $ cd nacos-cluster-docker/nacos-3 $ docker-compose -f docker-compose-nacos3.yml up -d 3、查看日志查看日志分别在对应的nacos-*目录下，执行 tail -f cluster-logs/nacos*/nacos.log 4、停止容器$ docker-compose -f docker-compose-nacos1.yml stop 5、访问Nacos UI界面 这里我们看到Nacos集群各节点已经正常了，LEADER与FOLLOWER已经选出，一切正常了 四、nginx 负载1、创建并启动1、拉取docker pull nginx 2、启动docker run --name nginx-test -p 80:80 -d nginx – name 容器命名 -v 映射目录 -d 设置容器后台运行 -p 本机端口映射 将容器的80端口映射到本机的80端口 2、映射到本地1、创建首先在本机创建nginx的一些文件存储目录 mkdir -p /root/nginx/www /root/nginx/logs /root/nginx/conf www: nginx存储网站网页的目录 logs: nginx日志目录 conf: nginx配置文件目录 2、映射（1）先查看容器 docker ps -a （2）映射 docker cp 481e121fb29f:/etc/nginx/nginx.conf /root/nginx/conf 3、启动容器需要说明下，ngxin-test 容器是为了获得容器的配置文件，最终使用的是 nginx-web 目前已经启动 nginx-test 80端口，若是 nginx-web指定的也是 80，就需要关闭 nginx-test了 docker stop nginx-test 1、新容器映射创建新nginx容器nginx-web,并将www,logs,conf目录映射到本地 docker run -d -p 80:80 --name nginx-web -v /root/nginx/www:/usr/share/nginx/html -v /root/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v /root/nginx/logs:/var/log/nginx nginx 2、启动docker start nginx-web 4、配置负载均衡1、进入 配置在 root 底下 2、配置源码user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { #gzip on; upstream nacos-cluster { server 101.34.180.133:8848; server 106.52.23.202:8848; server 119.45.122.161:8848; } server { listen 80; location /{ proxy_pass http://nacos-cluster; } } } 主要的是这块 说明下： 新手可能不太会nginx，listen 为 80 是因为你容器启动时候是 80，当访问 80的时候转到 以上三个 ip 负载轮训，还可以设置权重可以去看文档 3、重启docker restart nginx-web 五、Spring-boot连接1、yml配置 2、查看客户端 六、问题汇总1、关于 503异常信息：java.lang.IllegalStateException: failed to req API:/nacos/v1/ns/instance after all servers([101.34.180.133:8848]) tried: failed to req API:101.34.180.133:8848/nacos/v1/ns/instance. code:503 msg: server is DOWN now, please try again later! 个人见解：这个问题博主认为是集群节点少于3个出现的，因为服务器过期了一台剩下了 两台，所以报这个错误，三台没有这个问题。 七、参考文档 ↓https://www.cnblogs.com/hellxz/p/nacos-cluster-docker.html https://docs.docker.com/compose/install/ https://www.cnblogs.com/bigband/p/13515219.html https://my.oschina.net/u/3773384/blog/1810111 https://www.jianshu.com/p/658911a8cff3 https://www.yht7.com/news/92162 https://blog.csdn.net/weixin_40461281/article/details/92586378 https://www.cnblogs.com/ilinuxer/p/6916969.html https://blog.csdn.net/weixin_40461281/article/details/92586378","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud-alibaba","slug":"springcloud-alibaba","permalink":"https://mykkto.github.io/tags/springcloud-alibaba/"},{"name":"集群","slug":"集群","permalink":"https://mykkto.github.io/tags/%E9%9B%86%E7%BE%A4/"},{"name":"nacos","slug":"nacos","permalink":"https://mykkto.github.io/tags/nacos/"},{"name":"docker-compose","slug":"docker-compose","permalink":"https://mykkto.github.io/tags/docker-compose/"}],"author":"mykk"},{"title":"高阶面试题：JUC-AQS","slug":"05-面试题/01multithreading/01_Interview-JUC-AQS","date":"2022-03-09T13:32:10.000Z","updated":"2022-05-22T15:01:03.835Z","comments":true,"path":"posts/3fb37166.html","link":"","permalink":"https://mykkto.github.io/posts/3fb37166.html","excerpt":"","text":"一、是什么1、字面意思抽象的队列同步器 结构关系图： 2、技术解释 用来构建锁或者其它同步器组件的重量级基础框架及整个JUC体系的基石。 通过内置的FIFO1队列来完成资源获取线程的排队工作，并通过一个int类变量表示持有锁的状态 CLH：Craig、Landin and Hagersten 队列，是一个单向链表，AQS中的队列是CLH变体的虚拟双向队列FIFO 二、AQS=JUC（基石）AQS为什么是JUC内容中最重要的基石 1、AQS有关的锁 ReentrantLock CountDownLatch ReentrantReadWriteLock Semaphore ……………等等 2、进一步理解锁和同步器的关系 锁，面向锁的使用者： 定义了程序员和锁交互的使用层API，隐藏了实现细节，你调用即可。 同步器，面向锁的实现者 比如Java并发大神DougLee，提出统一规范并简化了锁的实现，屏蔽了同步状态管理、阻塞线程排队和通知、唤醒机制等。 三、能干嘛1、加锁会导致阻塞有阻塞就需要排队，实现排队必然需要队列 2、说明解释抢到资源的线程直接使用处理业务，抢不到资源的必然涉及一种排队等候机制。抢占资源失败的线程继续去等待(类似银行业务办理窗口都满了，暂时没有受理窗口的顾客只能去候客区排队等候)，但等候线程仍然保留获取锁的可能且获取锁流程仍在继续(候客区的顾客也在等着叫号，轮到了再去受理窗口办理业务)。 既然说到了排队等候机制，那么就一定会有某种队列形成，这样的队列是什么数据结构呢？ 如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中，这个队列就是AQS的抽象表现。它将请求共享资源的线程封装成队列的结点（Node），通过CAS、自旋以及LockSupport.park()的方式，维护state变量的状态，使并发达到同步的效果。 LockSupport.park()：阻塞当前线程的执行，且都不会释放当前线程占有的锁资源； 四、AQS 解读1、AQS概述1、官网解释 2、阻塞-&gt;队列有阻塞就需要排队，实现排队必然需要队列 AQS使用一个volatile的int类型的成员变量来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作将每条要去抢占资源的线程封装成一个Node节点来实现锁的分配，通过CAS完成对State值的修改。 2、AQS内部体系架构 1、AQS自身1、AQS的int变量 ★1、AQS的同步状态State成员变量 2、银行办理业务的受理窗口状态（通俗理解） 零就是没人（自由状态），可以办理 大于等于1，有人占用窗口，等着去 2、AQS的CLH队列1、CLH队列(三个大牛的名字组成)，为一个双向队列 2、银行候客区的等待顾客（通俗理解） 3、小总结 有阻塞就需要排队，实现排队必然需要队列 state变量+CLH双端队列 2、内部类Node内部类Node(Node类在AQS类内部) 1、Node的int变量 ★1、Node的等待状态waitState成员变量 2、说明 等候区其它顾客(其它线程)的等待状态 队列中每个排队的个体就是一个 Node 2、Node此类详解1、内部结构 2、属性说明 3、AQS同步队列的基本结构 CLH：Craig、Landin and Hagersten 队列，是个单向链表，AQS中的队列是CLH变体的虚拟双向队列（FIFO） FIFO：队列中用到了哨兵节点（傀儡节点）既，头节点（好处就是不用去判空，因为有头节点） 五、从ReentrantLock开始解读AQS1、说明Lock接口的实现类，基本都是通过【聚合】了一个【队列同步器】的子类完成线程访问控制的 1、可以看出内部子类 Sync，继承了 AQS 2、看下类 UML图，Sync 底下又有两个子类（分别为公平和非公平） 2、公平锁和非公平锁1、先从创建入手 2、追溯1、默认构造方法，默认不传参构造 2、带参传入，此时判断是非公平还是公平 3、很明显这是两个类，分别继承与Sync，上面有提到 3、看源码1、看差异1、可以明显看出公平锁与非公平锁的lock()方法唯一的区别就在于公平锁在获取同步状态时多了一个限制条件 hasQueuedPredecessors() hasQueuedPredecessors是公平锁加锁时判断等待队列中是否存在有效节点的方法 2、对比公平锁：公平锁讲究先来先到，线程在获取锁时，如果这个锁的等待队列中已经有线程在等待，那么当前线程就会进入等待队列中； 非公平锁：不管是否有等待队列，如果可以获取锁，则立刻占有锁对象。也就是说队列的第一个排队线程在unpark()，之后还是需要竞争锁（存在线程竞争的情况下） 3、必调 lock()在创建完公平/非公平锁，调用lock方法进行加锁，最终都会调用 acquire 方法 3、源码Api解读1、lock() 2、acquire() 三个走向 1、tryAcquire() -&gt; tryAcquire () 由于子类 FairSync 实现 2、调用 addWaiter() -&gt; enq() 入队操作 3、acquireQueued() -&gt; cancelAcquire() 参考文档https://www.cnblogs.com/tong-yuan/p/11768904.html https://baijiahao.baidu.com/s?id=1718317852417206951&amp;wfr=spider&amp;for=pc https://blog.csdn.net/hengyunabc/article/details/28126139 哨兵节点解读：https://www.cnblogs.com/litexy/p/9749544.html","categories":[{"name":"面试题","slug":"面试题","permalink":"https://mykkto.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"AQS","slug":"AQS","permalink":"https://mykkto.github.io/tags/AQS/"},{"name":"多线程","slug":"多线程","permalink":"https://mykkto.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"JUC","slug":"JUC","permalink":"https://mykkto.github.io/tags/JUC/"}],"author":"mykk"},{"title":"Oracle11g(docker版)","slug":"04-基础/04oracle/01_oracle11g-docker","date":"2022-02-28T04:49:31.000Z","updated":"2022-05-22T15:01:03.835Z","comments":true,"path":"posts/42dbeac3.html","link":"","permalink":"https://mykkto.github.io/posts/42dbeac3.html","excerpt":"","text":"一、Docker安装和配置1、镜像拉取（第三方）docker pull registry.cn-hangzhou.aliyuncs.com/helowin/oracle_11g 2、下载完后，查看docker images 3、创建容器docker run -d -p 1521:1521 --name oracle11g registry.cn-hangzhou.aliyuncs.com/helowin/oracle_11g 4、启动容器，操作1、启动docker start oracle11g 2、进入容器docker exec -it oracle11g bash 3、切换root用户su root 密码：helowin 注意：现在还不能退出，继续操作 5、编辑profile文件配置ORACLE环境变量在docker中查找并编辑profile文件 vi /etc/profile export ORACLE_HOME=/home/oracle/app/oracle/product/11.2.0/dbhome_2 export ORACLE_SID=helowin export PATH=$ORACLE_HOME/bin:$PATH 在最后上加： 保存并退出 ：wq 6、oracle的配置1. 创建软连接ln -s $ORACLE_HOME/bin/sqlplus /usr/bin 2.切换到oracle 用户这里还要说一下，一定要写中间的 - 必须要，否则软连接无效 su - oracle 7、oracle数据库的操作1. 登录sqlplus并修改sys、system用户密码sqlplus /nolog conn /as sysdba 2. 修改和创建用户alter user system identified by system; alter user sys identified by sys; 也可以创建用户 create user test identified by test; 并给用户赋予权限 grant connect,resource,dba to test; 3. scott用户的开启--解锁scott用户（安装时若使用默认情况没有解锁和设置密码进行下列操作，要超级管理员操作） alter user scott account unlock; --解锁scott用户的密码【此句也可以用来重置密码】 alter user scott identified by tiger; 二、客户端连接1、navicat连接打开navicat后（navicat12不用配置oci.dll文件了） 2、pl/sql 连接101.xx.xxx.133:1521/helowinXDB密码：tiger 三、其他功能1、scott赋予最高权限分两条运行 CONN / AS SYSDBA; GRANT DBA TO SCOTT; 参考https://www.cnblogs.com/laoluoits/p/13942119.html https://www.cnblogs.com/flyingsand/p/9463460.html","categories":[{"name":"数据库","slug":"数据库","permalink":"https://mykkto.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"oracle","slug":"oracle","permalink":"https://mykkto.github.io/tags/oracle/"},{"name":"docker","slug":"docker","permalink":"https://mykkto.github.io/tags/docker/"},{"name":"安装","slug":"安装","permalink":"https://mykkto.github.io/tags/%E5%AE%89%E8%A3%85/"}],"author":"mykk"},{"title":"项目-尚融宝-03-金融项目核心业务实现","slug":"08-项目/01尚融宝/03_金融项目核心业务实现","date":"2022-02-25T11:17:13.000Z","updated":"2022-05-10T13:15:49.365Z","comments":true,"path":"posts/f6bd040d.html","link":"","permalink":"https://mykkto.github.io/posts/f6bd040d.html","excerpt":"","text":"〇、主目录总纲Ⅰ、一、1、1.2.3.4.5.2、1.2.3.4.5.3、1.2.3.4.5.4、1.2.3.4.5.5、1.2.3.4.5.二、三、四、五、Ⅱ、1、2、3、4、5、Ⅲ、1、2、3、4、5、","categories":[{"name":"项目-尚融宝","slug":"项目-尚融宝","permalink":"https://mykkto.github.io/categories/%E9%A1%B9%E7%9B%AE-%E5%B0%9A%E8%9E%8D%E5%AE%9D/"}],"tags":[{"name":"springcloud-alibaba","slug":"springcloud-alibaba","permalink":"https://mykkto.github.io/tags/springcloud-alibaba/"},{"name":"熔断器","slug":"熔断器","permalink":"https://mykkto.github.io/tags/%E7%86%94%E6%96%AD%E5%99%A8/"},{"name":"sentinel","slug":"sentinel","permalink":"https://mykkto.github.io/tags/sentinel/"},{"name":"限流","slug":"限流","permalink":"https://mykkto.github.io/tags/%E9%99%90%E6%B5%81/"}],"author":"mykk"},{"title":"SpringCloud-Alibaba-Nacos 服务注册+配置中心","slug":"03-java分布式/01springcloud/14_SpringCloudAlibaba-Nacos","date":"2022-02-23T13:12:31.000Z","updated":"2022-05-22T15:01:03.851Z","comments":true,"path":"posts/af0a257d.html","link":"","permalink":"https://mykkto.github.io/posts/af0a257d.html","excerpt":"","text":"友情链接-早期Nacos文章一、Nacos简介1、是什么项目文档：https://github.com/alibaba/Nacos 使用文档：https://nacos.io/zh-cn/index.html 一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 Nacos = Eureka+Config +Bus 2、能干嘛 替代Eureka做服务注册中心 替代Config做服务配置中心 3、注册中心比较 二、安装（docker）1、pull镜像推荐稳定版版本(官方推荐1.3.1),如果不指定版本的话则就是latest版本(对应nacos的1.4版本) docker pull nacos/nacos-server:1.3.1 2、运行并创建容器docker run --name nacosName -e MODE=standalone -d -v /mnt/logs/nacos:/home/logs/nacos -p 8848:8848 nacos/nacos-server:1.1.4 -d 后台运行 -p 外部访问端口:内部被映射端口 Docker相对于虚拟机 外部访问端口就是 外网访问的端口 内部被映射端口就是 该镜像在docker里面的端口 –name 容器的名称 镜像名称：版本号 nacos/nacos-server:1.3.1 （运行该镜像） -e 环境变量设置 -e MODE=standalone -v 映射到centos上的某个目录:配置某个容器的目录 -v /mnt/logs/nacos:/home/logs/nacos 3、查看启动日志 #查看已经启动的容器 获取容器ID docker ps #查看指定容器的输出日志 docker logs --since 10m nacos的容器id #查看指定容器的输出日志 4、访问http://lhttp://localhost:8848/nacos 登录账号 登录密码 nacos nacos 三、Nacos（注册中心）1、基于Nacos生产者1、建modelcloudalibaba-provider-payment9001 2、pom1、父pom &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; 2、本模块pom &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloudalibaba-provider-payment9001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--SpringCloud ailibaba nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- SpringBoot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--日常通用jar包配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 9001 spring: application: name: nacos-payment-provider cloud: nacos: discovery: server-addr: 101.34.180.133:8848 #配置Nacos地址 management: endpoints: web: exposure: include: '*' 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @EnableDiscoveryClient @SpringBootApplication public class PaymentMain9001 { public static void main(String[] args) { SpringApplication.run (PaymentMain9001.class, args); } } 5、业务类package com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; @RestController public class PaymentController { @Value(\"${server.port}\") private String serverPort; @GetMapping(value = \"/payment/nacos/{id}\") public String getPayment(@PathVariable(\"id\") Integer id) { return \"nacos registry, serverPort: \" + serverPort + \"\\t id\" + id; } } 6、测试1、访问：http://localhost:9001/payment/nacos/1 2、nacos客户端 7、映射出一模一样的9002，测试负载1、复制配置 2、编写配置 -DServer.port=9002 3、查看是否成功启动 2、基于Nacos消费者1、建modelcloudalibaba-consumer-nacos-order83 2、pom为什么nacos支持负载均衡 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloudalibaba-consumer-nacos-order83&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--SpringCloud ailibaba nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- SpringBoot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--日常通用jar包配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 83 spring: application: name: nacos-order-consumer cloud: nacos: discovery: server-addr: 101.34.180.133:8848 #配置Nacos地址 #消费者将要去访问的微服务名称(注册成功进nacos的微服务提供者) service-url: nacos-user-service: http://nacos-payment-provider 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @EnableDiscoveryClient @SpringBootApplication public class OrderNacosMain83 { public static void main(String[] args) { SpringApplication.run(OrderNacosMain83.class,args); } } 5、业务类ApplicationContextBean： package com.kk.springcloud.config; import org.springframework.cloud.client.loadbalancer.LoadBalanced; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.web.client.RestTemplate; @Configuration public class ApplicationContextBean { @Bean @LoadBalanced public RestTemplate getRestTempe() { return new RestTemplate ( ); } } OrderNacosController： package com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import javax.annotation.Resource; @RestController public class OrderNacosController { @Resource private RestTemplate restTemplate; @Value(\"${service-url.nacos-user-service}\") private String serverURL; @GetMapping(\"/consumer/payment/nacos/{id}\") public String paymentInfo(@PathVariable(\"id\") Long id) { return restTemplate.getForObject (serverURL + \"/payment/nacos/\" + id, String.class); } } 6、测试1、客户端注册 2、访问：http://localhost:83/consumer/payment/nacos/13 1,2,1,2,1,2 切换效果存在 3、服务注册中心对比1、nacos全景图 2、Nacos和CAP 3、Nacos 支持AP和CP模式的切换C是所有节点在同一时间看到的数据是一致的；而A的定义是所有的请求都会收到响应。 何时选择使用何种模式？一般来说，如果不需要存储服务级别的信息且服务实例是通过nacos-client注册，并能够保持心跳上报，那么就可以选择AP模式。当前主流的服务如 Spring cloud 和 Dubbo 服务，都适用于AP模式，AP模式为了服务的可能性而减弱了一致性，因此AP模式下只支持注册临时实例。 如果需要在服务级别编辑或者存储配置信息，那么 CP 是必须，K8S服务和DNS服务则适用于CP模式。CP模式下则支持注册持久化实例，此时则是以 Raft 协议为集群运行模式，该模式下注册实例之前必须先注册服务，如果服务不存在，则会返回错误。 curl -X PUT ‘$NACOS_SERVER:8848/nacos/v1/ns/operator/switches?entry=serverMode&amp;value=CP’ 四、Nacos（配置中心）1、建model1、建modelcloudalibaba-config-nacos-client3377 2、pom&lt;!--nacos-config--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloudalibaba-config-nacos-client3377&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--nacos-config--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--nacos-discovery--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web + actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--一般基础配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、yml1、why配置两个springboot中配置文件的加载是存在优先级顺序的，bootstrap优先级高于application 2、bootstrap.ymlfile-extension: yaml #指定yaml格式的配置 # nacos配置 server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 #Nacos服务注册中心地址 config: server-addr: localhost:8848 #Nacos作为配置中心地址 file-extension: yaml #指定yaml格式的配置 3、application.ymlspring: profiles: active: dev # 表示开发环境 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @EnableDiscoveryClient @SpringBootApplication public class NacosConfigClientMain3377 { public static void main(String[] args) { SpringApplication.run (NacosConfigClientMain3377.class, args); } } 5、业务类@RefreshScope package com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Value; import org.springframework.cloud.context.config.annotation.RefreshScope; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController @RefreshScope //在控制器类加入@RefreshScope注解使当前类下的配置支持Nacos的动态刷新功能。 public class ConfigClientController { @Value(\"${config.info}\") private String configInfo; @GetMapping(\"/config/info\") public String getConfigInfo() { return configInfo; } } 2、配置中心基础1、规则${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} 2、新增配置文件 nacos-config-client-dev.yaml config: info: nacos to info 3、对应配置说明 prefix 默认为 spring.application.name 的值 spring.profile.active 即为当前环境对应的 profile，可以通过配置项 spring.profile.active 来配置。 file-exetension 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置 4、历史配置（回滚）Nacos会记录配置文件的历史版本默认保留30天，此外还有一键回滚功能，回滚操作将会触发配置更新 nacos-config-client-dev.yaml DEFAULT_GROUP 3、测试 启动 3377 访问：http://localhost:3377/config/info 测试自带刷新功能 修改下Nacos中的yaml配置文件，再次调用查看配置的接口，就会发现配置已经刷新 4、配置中心分类1、Nacos的图形化管理界面1、配置管理 2、名称空间 3、三种方案加载配置1、DataID方案（1）说明 指定spring.profile.active和配置文件的DataID来使不同环境下读取不同的配置 （2）新建两个配置 （3）配置是什么就加载什么 2、Group方案（1）说明 通过Group实现环境区分 （2）新建组 （3）控制台上的效果 （4）Springboot上的配置 在config下增加一条group的配置即可。可配置为DEV_GROUP或TEST_GROUP 3、Namespace方案（1）新建dev/test的Namespace （2）回到服务管理-服务列表查看 （3）按照域名配置填写 （4）yml配置文件 application.yml bootstrap.yml 五、★ Nacos（集群和持久化）1、基本说明1、架构图 2、官方信息 2、Nacos持久化配置解释1、Nacos默认自带的是嵌入式数据库derby2、derby切换到mysql 步骤（1）进入容器，找到对应的配置文件 （2）在数据库执行以上 sql schema.sql CREATE DATABASE nacos_config; USE nacos_config; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_info */ /******************************************/ CREATE TABLE `config_info` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT 'id', `data_id` VARCHAR(255) NOT NULL COMMENT 'data_id', `group_id` VARCHAR(255) DEFAULT NULL, `content` LONGTEXT NOT NULL COMMENT 'content', `md5` VARCHAR(32) DEFAULT NULL COMMENT 'md5', `gmt_create` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '创建时间', `gmt_modified` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '修改时间', `src_user` TEXT COMMENT 'source user', `src_ip` VARCHAR(20) DEFAULT NULL COMMENT 'source ip', `app_name` VARCHAR(128) DEFAULT NULL, `tenant_id` VARCHAR(128) DEFAULT '' COMMENT '租户字段', `c_desc` VARCHAR(256) DEFAULT NULL, `c_use` VARCHAR(64) DEFAULT NULL, `effect` VARCHAR(64) DEFAULT NULL, `type` VARCHAR(64) DEFAULT NULL, `c_schema` TEXT, PRIMARY KEY (`id`), UNIQUE KEY `uk_configinfo_datagrouptenant` (`data_id`,`group_id`,`tenant_id`) ) ENGINE=INNODB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_info'; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_info_aggr */ /******************************************/ CREATE TABLE `config_info_aggr` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT 'id', `data_id` VARCHAR(255) NOT NULL COMMENT 'data_id', `group_id` VARCHAR(255) NOT NULL COMMENT 'group_id', `datum_id` VARCHAR(255) NOT NULL COMMENT 'datum_id', `content` LONGTEXT NOT NULL COMMENT '内容', `gmt_modified` DATETIME NOT NULL COMMENT '修改时间', `app_name` VARCHAR(128) DEFAULT NULL, `tenant_id` VARCHAR(128) DEFAULT '' COMMENT '租户字段', PRIMARY KEY (`id`), UNIQUE KEY `uk_configinfoaggr_datagrouptenantdatum` (`data_id`,`group_id`,`tenant_id`,`datum_id`) ) ENGINE=INNODB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='增加租户字段'; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_info_beta */ /******************************************/ CREATE TABLE `config_info_beta` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT 'id', `data_id` VARCHAR(255) NOT NULL COMMENT 'data_id', `group_id` VARCHAR(128) NOT NULL COMMENT 'group_id', `app_name` VARCHAR(128) DEFAULT NULL COMMENT 'app_name', `content` LONGTEXT NOT NULL COMMENT 'content', `beta_ips` VARCHAR(1024) DEFAULT NULL COMMENT 'betaIps', `md5` VARCHAR(32) DEFAULT NULL COMMENT 'md5', `gmt_create` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '创建时间', `gmt_modified` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '修改时间', `src_user` TEXT COMMENT 'source user', `src_ip` VARCHAR(20) DEFAULT NULL COMMENT 'source ip', `tenant_id` VARCHAR(128) DEFAULT '' COMMENT '租户字段', PRIMARY KEY (`id`), UNIQUE KEY `uk_configinfobeta_datagrouptenant` (`data_id`,`group_id`,`tenant_id`) ) ENGINE=INNODB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_info_beta'; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_info_tag */ /******************************************/ CREATE TABLE `config_info_tag` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT 'id', `data_id` VARCHAR(255) NOT NULL COMMENT 'data_id', `group_id` VARCHAR(128) NOT NULL COMMENT 'group_id', `tenant_id` VARCHAR(128) DEFAULT '' COMMENT 'tenant_id', `tag_id` VARCHAR(128) NOT NULL COMMENT 'tag_id', `app_name` VARCHAR(128) DEFAULT NULL COMMENT 'app_name', `content` LONGTEXT NOT NULL COMMENT 'content', `md5` VARCHAR(32) DEFAULT NULL COMMENT 'md5', `gmt_create` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '创建时间', `gmt_modified` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '修改时间', `src_user` TEXT COMMENT 'source user', `src_ip` VARCHAR(20) DEFAULT NULL COMMENT 'source ip', PRIMARY KEY (`id`), UNIQUE KEY `uk_configinfotag_datagrouptenanttag` (`data_id`,`group_id`,`tenant_id`,`tag_id`) ) ENGINE=INNODB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_info_tag'; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_tags_relation */ /******************************************/ CREATE TABLE `config_tags_relation` ( `id` BIGINT(20) NOT NULL COMMENT 'id', `tag_name` VARCHAR(128) NOT NULL COMMENT 'tag_name', `tag_type` VARCHAR(64) DEFAULT NULL COMMENT 'tag_type', `data_id` VARCHAR(255) NOT NULL COMMENT 'data_id', `group_id` VARCHAR(128) NOT NULL COMMENT 'group_id', `tenant_id` VARCHAR(128) DEFAULT '' COMMENT 'tenant_id', `nid` BIGINT(20) NOT NULL AUTO_INCREMENT, PRIMARY KEY (`nid`), UNIQUE KEY `uk_configtagrelation_configidtag` (`id`,`tag_name`,`tag_type`), KEY `idx_tenant_id` (`tenant_id`) ) ENGINE=INNODB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_tag_relation'; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = group_capacity */ /******************************************/ CREATE TABLE `group_capacity` ( `id` BIGINT(20) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '主键ID', `group_id` VARCHAR(128) NOT NULL DEFAULT '' COMMENT 'Group ID，空字符表示整个集群', `quota` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '配额，0表示使用默认值', `usage` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '使用量', `max_size` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '单个配置大小上限，单位为字节，0表示使用默认值', `max_aggr_count` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '聚合子配置最大个数，，0表示使用默认值', `max_aggr_size` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值', `max_history_count` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '最大变更历史数量', `gmt_create` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '创建时间', `gmt_modified` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '修改时间', PRIMARY KEY (`id`), UNIQUE KEY `uk_group_id` (`group_id`) ) ENGINE=INNODB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='集群、各Group容量信息表'; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = his_config_info */ /******************************************/ CREATE TABLE `his_config_info` ( `id` BIGINT(64) UNSIGNED NOT NULL, `nid` BIGINT(20) UNSIGNED NOT NULL AUTO_INCREMENT, `data_id` VARCHAR(255) NOT NULL, `group_id` VARCHAR(128) NOT NULL, `app_name` VARCHAR(128) DEFAULT NULL COMMENT 'app_name', `content` LONGTEXT NOT NULL, `md5` VARCHAR(32) DEFAULT NULL, `gmt_create` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00', `gmt_modified` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00', `src_user` TEXT, `src_ip` VARCHAR(20) DEFAULT NULL, `op_type` CHAR(10) DEFAULT NULL, `tenant_id` VARCHAR(128) DEFAULT '' COMMENT '租户字段', PRIMARY KEY (`nid`), KEY `idx_gmt_create` (`gmt_create`), KEY `idx_gmt_modified` (`gmt_modified`), KEY `idx_did` (`data_id`) ) ENGINE=INNODB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='多租户改造'; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = tenant_capacity */ /******************************************/ CREATE TABLE `tenant_capacity` ( `id` BIGINT(20) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '主键ID', `tenant_id` VARCHAR(128) NOT NULL DEFAULT '' COMMENT 'Tenant ID', `quota` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '配额，0表示使用默认值', `usage` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '使用量', `max_size` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '单个配置大小上限，单位为字节，0表示使用默认值', `max_aggr_count` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '聚合子配置最大个数', `max_aggr_size` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值', `max_history_count` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '最大变更历史数量', `gmt_create` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '创建时间', `gmt_modified` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '修改时间', PRIMARY KEY (`id`), UNIQUE KEY `uk_tenant_id` (`tenant_id`) ) ENGINE=INNODB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='租户容量信息表'; CREATE TABLE `tenant_info` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT 'id', `kp` VARCHAR(128) NOT NULL COMMENT 'kp', `tenant_id` VARCHAR(128) DEFAULT '' COMMENT 'tenant_id', `tenant_name` VARCHAR(128) DEFAULT '' COMMENT 'tenant_name', `tenant_desc` VARCHAR(256) DEFAULT NULL COMMENT 'tenant_desc', `create_source` VARCHAR(32) DEFAULT NULL COMMENT 'create_source', `gmt_create` BIGINT(20) NOT NULL COMMENT '创建时间', `gmt_modified` BIGINT(20) NOT NULL COMMENT '修改时间', PRIMARY KEY (`id`), UNIQUE KEY `uk_tenant_info_kptenantid` (`kp`,`tenant_id`), KEY `idx_tenant_id` (`tenant_id`) ) ENGINE=INNODB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='tenant_info'; CREATE TABLE users ( username VARCHAR(50) NOT NULL PRIMARY KEY, PASSWORD VARCHAR(500) NOT NULL, enabled BOOLEAN NOT NULL ); CREATE TABLE roles ( username VARCHAR(50) NOT NULL, role VARCHAR(50) NOT NULL ); INSERT INTO users (username, PASSWORD, enabled) VALUES ('nacos', '$2a$10$EuWPZHzz32dJN7jexM34MOeYirDdFAZm2kuWj7VEOJhhZkDrxfvUu', TRUE); INSERT INTO roles (username, role) VALUES ('nacos', 'ROLE_ADMIN'); （3）在 application.properties修改配置 以上 五个配置均要修改 （4）改完之后重启 （5）重新登录客户端，发现以前的数据没有了，说明切换成功 3、高可用集群搭建1、架构图 最终落地：Nacos 高可用集群（docker-compose）参考文章https://www.jianshu.com/p/d2c81d647323 https://blog.csdn.net/wwwwwww31311/article/details/113066637 https://www.cnblogs.com/hellxz/p/nacos-cluster-docker.html","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud-alibaba","slug":"springcloud-alibaba","permalink":"https://mykkto.github.io/tags/springcloud-alibaba/"},{"name":"nacos","slug":"nacos","permalink":"https://mykkto.github.io/tags/nacos/"},{"name":"服务注册与发现","slug":"服务注册与发现","permalink":"https://mykkto.github.io/tags/%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0/"},{"name":"配置中心","slug":"配置中心","permalink":"https://mykkto.github.io/tags/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"}],"author":"mykk"},{"title":"SpringCloud-Sleuth分布式请求链路跟踪","slug":"03-java分布式/01springcloud/13_SpringCloud-Sleuth","date":"2022-02-21T18:22:22.000Z","updated":"2022-05-22T15:01:03.851Z","comments":true,"path":"posts/35c50dd0.html","link":"","permalink":"https://mykkto.github.io/posts/35c50dd0.html","excerpt":"","text":"1、概述1、为什么出现​ 在微服务框架中，一个由客户端发起的请求在后端系统中会经过多个不同的的服务节点调用来协同产生最后的请求结果，每一个前段请求都会形成一条复杂的分布式服务调用链路，链路中的任何一环出现高延时或错误都会引起整个请求最后的失败。 2、是什么1、官网https://github.com/spring-cloud/spring-cloud-sleuth 2、说明Spring Cloud Sleuth提供了一套完整的服务跟踪的解决方案 在分布式系统中提供追踪解决方案并且兼容支持了zipkin 2、搭建链路监控步骤1、zipkin1、下载 SpringCloud从F版起已不需要自己构建Zipkin Server了，只需调用jar包即可 https://repo1.maven.org/maven2/io/zipkin/java/zipkin-server/ zipkin-server-2.12.9-exec.jar 2、运行 jarjava -jar zipkin-server-2.12.9-exec.jar 3、运行控制台 3、服务生产者1、建modelcloud-provider-sleuth8001 2、pom&lt;!--包含了sleuth+zipkin--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-provider-sleuth8001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--包含了sleuth+zipkin--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--eureka-client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;!--mysql-connector-java--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--jdbc--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、yml server: port: 8001 spring: application: name: cloud-payment-service zipkin: base-url: http://106.52.23.202:9411 sleuth: sampler: #采样率值介于 0 到 1 之间，1 则表示全部采集 probability: 1 datasource: type: com.alibaba.druid.pool.DruidDataSource # 当前数据源操作类型 driver-class-name: org.gjt.mm.mysql.Driver # mysql驱动包 url: jdbc:mysql://101.34.180.133:3306/spring_cloud?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: a1b2c3 eureka: client: #表示是否将自己注册进EurekaServer默认为true。 register-with-eureka: true #是否从EurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetchRegistry: true service-url: #defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka # 集群版 defaultZone: http://localhost:7001/eureka # 单机版 instance: instance-id: payment8001 #访问路径可以显示IP地址 prefer-ip-address: true #Eureka客户端向服务端发送心跳的时间间隔，单位为秒(默认是30秒) lease-renewal-interval-in-seconds: 1 #Eureka服务端在收到最后一次心跳后等待时间上限，单位为秒(默认是90秒)，超时将剔除服务 lease-expiration-duration-in-seconds: 2 mybatis: mapperLocations: classpath:mapper/*.xml type-aliases-package: com.kk.springcloud.entities # 所有Entity别名类所在包 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication @EnableEurekaClient public class SleuthZipkinMain8001 { public static void main(String[] args) { SpringApplication.run (SleuthZipkinMain8001.class,args); } } 5、业务类package com.kk.springcloud.controller; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class PromentController { @GetMapping(\"/payment/zipkin\") public String paymentZipkin() { return \"hi ,i'am paymentzipkin server fall back，welcome to kk demo ，O(∩_∩)O哈哈~\"; } } 4、服务消费者1、建modelcloud-consumer-order81 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-consumer-sleuth80&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--包含了sleuth+zipkin--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 81 spring: application: name: cloud-order-service zipkin: base-url: http://106.52.23.202:9411 sleuth: sampler: probability: 1 eureka: client: #表示是否将自己注册进EurekaServer默认为true。 register-with-eureka: true #是否从EurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetchRegistry: true service-url: #defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ defaultZone: http://eureka7001.com:7001/eureka 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; import org.springframework.context.annotation.Bean; import org.springframework.web.client.RestTemplate; @SpringBootApplication @EnableEurekaClient public class ConsumerSleuthMain81 { public static void main(String[] args) { SpringApplication.run (ConsumerSleuthMain80.class,args); } @Bean public RestTemplate restTemplate() { return new RestTemplate(); } } 5、业务类package com.kk.springcloud.controller; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import javax.annotation.Resource; @RestController public class ConsumerController { public static final String PAYMENT_URL = \"http://CLOUD-PAYMENT-SERVICE\"; @Resource private RestTemplate restTemplate; // ====================&gt; zipkin+sleuth @GetMapping(\"/consumer/payment/zipkin\") public String paymentZipkin() { String result = restTemplate.getForObject (PAYMENT_URL + \"/payment/zipkin/\", String.class); return result; } } 5、测试1、访问 http://localhost:81/consumer/payment/zipkin 2、打开 zipkin客户端 http://106.52.23.202:9411/","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"服务跟踪","slug":"服务跟踪","permalink":"https://mykkto.github.io/tags/%E6%9C%8D%E5%8A%A1%E8%B7%9F%E8%B8%AA/"},{"name":"sleuth","slug":"sleuth","permalink":"https://mykkto.github.io/tags/sleuth/"}],"author":"mykk"},{"title":"SpringCloud-Stream消息驱动","slug":"03-java分布式/01springcloud/12_SpringCloud-Stream","date":"2022-02-19T14:52:16.000Z","updated":"2022-05-22T15:01:03.851Z","comments":true,"path":"posts/e867710e.html","link":"","permalink":"https://mykkto.github.io/posts/e867710e.html","excerpt":"","text":"友情链接rabitMQ安装（docker） 1、消息驱动概述1、是什么屏蔽底层消息中间件的差异,降低切换成本，统一消息的编程模型 官网：https://m.wang1314.com/doc/webapp/topic/20971999.html 2、设计思想1、标准MQ Message：生产者/消费者之间靠消息媒介传递信息内容 MessageChannel（消息通道）：消息必须走特定的通道 消息通道里的消息如何被消费呢，谁负责收发处理 消息通道MessageChannel的子接口SubscribableChannel，由MessageHandler消息处理器所订阅 2、为什么用Cloud Stream1、概念比方说我们用到了RabbitMQ和Kafka，由于这两个消息中间件的架构上的不同，像RabbitMQ有exchange，kafka有Topic和Partitions分区， 这些中间件的差异性导致我们实际项目开发给我们造成了一定的困扰，我们如果用了两个消息队列的其中一种，后面的业务需求，我想往另外一种消息队列进行迁移，这时候无疑就是一个灾难性的，一大堆东西都要重新推倒重新做，因为它跟我们的系统耦合了，这时候springcloud Stream给我们提供了一种解耦合的方式。 2、Stream中的消息通信方式遵循了发布-订阅模式Topic主题进行广播： 在RabbitMQ就是Exchange 在Kakfa中就是Topic 3、Spring Cloud Stream标准流程套路 Binder： 很方便的连接中间件，屏蔽差异 Channel： 通道，是队列Queue的一种抽象，在消息通讯系统中就是实现存储和转发的媒介，通过Channel对队列进行配置 Source和Sink： 简单的可理解为参照对象是Spring Cloud Stream自身，从Stream发布消息就是输出，接受消息就是输入 4、编码API和常用注解 2、案例说明工程中新建三个子模块 cloud-stream-rabbitmq-provider8801， 作为生产者进行发消息模块 cloud-stream-rabbitmq-consumer8802，作为消息接收模块 cloud-stream-rabbitmq-consumer8803 作为消息接收模块 3、消息驱动之生产者1、新建Modulecloud-stream-rabbitmq-provider8801 2、pom&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-stream-rabbitmq-provider8801&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--基础配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlbindings: # 服务的整合处理 output: # 这个名字是一个通道的名称 destination: studyExchange # 表示要使用的Exchange名称定义 content-type: application/json # 设置消息类型，本次为json，文本则设置“text/plain” binder: defaultRabbit # 设置要绑定的消息服务的具体设置 server: port: 8801 spring: application: name: cloud-stream-provider cloud: stream: binders: # 在此处配置要绑定的rabbitmq的服务信息； defaultRabbit: # 表示定义的名称，用于于binding整合 type: rabbit # 消息组件类型 environment: # 设置rabbitmq的相关的环境配置 spring: rabbitmq: host: 101.34.180.133 port: 5672 username: guest password: guest bindings: # 服务的整合处理 output: # 这个名字是一个通道的名称 destination: studyExchange # 表示要使用的Exchange名称定义 content-type: application/json # 设置消息类型，本次为json，文本则设置“text/plain” binder: defaultRabbit # 设置要绑定的消息服务的具体设置 eureka: client: # 客户端进行Eureka注册的配置 service-url: defaultZone: http://localhost:7001/eureka instance: lease-renewal-interval-in-seconds: 2 # 设置心跳的时间间隔（默认是30秒） lease-expiration-duration-in-seconds: 5 # 如果现在超过了5秒的间隔（默认是90秒） instance-id: send-8801.com # 在信息列表时显示主机名称 prefer-ip-address: true # 访问的路径变为IP地址 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class StreamMQMain8801 { public static void main(String[] args) { SpringApplication.run (StreamMQMain8801.class, args); } } 5、业务类1、接口package com.kk.springcloud.service; public interface IMessageProvider { String send(); } 2、接口实现package com.kk.springcloud.service.impl; import com.kk.springcloud.service.IMessageProvider; import org.springframework.cloud.stream.annotation.EnableBinding; import org.springframework.cloud.stream.messaging.Source; import org.springframework.messaging.MessageChannel; import org.springframework.integration.support.MessageBuilder; import javax.annotation.Resource; import java.util.UUID; @EnableBinding(Source.class) // 可以理解为是一个消息的发送管道的定义 public class MessageProviderImpl implements IMessageProvider { @Resource private MessageChannel output; // 消息的发送管道 @Override public String send() { String serial = UUID.randomUUID ( ).toString ( ); this.output.send (MessageBuilder.withPayload (serial).build ( )); // 创建并发送消息 System.out.println (\"***serial: \" + serial); return serial; } } 3、controllerpackage com.kk.springcloud.controller; import com.kk.springcloud.service.IMessageProvider; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; @RestController public class SendMessageController { @Resource private IMessageProvider messageProvider; @GetMapping(value = \"/sendMessage\") public String sendMessage() { return messageProvider.send ( ); } } 6、测试 启动eureka，以及rabbitMq，以及8801 访问：http://localhost:8801/sendMessage 4、消息驱动之消费者1、新建Modulecloud-stream-rabbitmq-consumer8802 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-stream-rabbitmq-consumer8802&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--基础配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 8802 spring: application: name: cloud-stream-consumer cloud: stream: binders: # 在此处配置要绑定的rabbitmq的服务信息； defaultRabbit: # 表示定义的名称，用于于binding整合 type: rabbit # 消息组件类型 environment: # 设置rabbitmq的相关的环境配置 spring: rabbitmq: host: 101.34.180.133 port: 5672 username: guest password: guest bindings: # 服务的整合处理 input: # 这个名字是一个通道的名称 destination: studyExchange # 表示要使用的Exchange名称定义 content-type: application/json # 设置消息类型，本次为对象json，如果是文本则设置“text/plain” binder: defaultRabbit # 设置要绑定的消息服务的具体设置 eureka: client: # 客户端进行Eureka注册的配置 service-url: defaultZone: http://localhost:7001/eureka instance: lease-renewal-interval-in-seconds: 2 # 设置心跳的时间间隔（默认是30秒） lease-expiration-duration-in-seconds: 5 # 如果现在超过了5秒的间隔（默认是90秒） instance-id: receive-8802.com # 在信息列表时显示主机名称 prefer-ip-address: true # 访问的路径变为IP地址 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class StreamMQMain8802 { public static void main(String[] args) { SpringApplication.run (StreamMQMain8802.class, args); } } 5、业务类package com.kk.springcloud.service; import org.springframework.beans.factory.annotation.Value; import org.springframework.cloud.stream.annotation.EnableBinding; import org.springframework.cloud.stream.annotation.StreamListener; import org.springframework.cloud.stream.messaging.Sink; import org.springframework.messaging.Message; import org.springframework.stereotype.Component; @Component @EnableBinding(Sink.class) public class ReceiveMessageListener { @Value(\"${server.port}\") private String serverPort; @StreamListener(Sink.INPUT) public void input(Message&lt;String&gt; message) { System.out.println (\"消费者1号，-------&gt;接收到的消息：\" + message.getPayload ( ) + \"\\t port: \" + serverPort); } } 6、测试url：http://localhost:8801/sendMessage 5、分组消费与持久化1、依照8802，clone出来一份运行8803 cloud-stream-rabbitmq-consumer8803 @SpringBootApplication public class StreamMQMain8803 { public static void main(String[] args) { SpringApplication.run (StreamMQMain8803.class, args); } } - ```java @Component @EnableBinding(Sink.class) public class ReceiveMessageListener { @Value(\"${server.port}\") private String serverPort; @StreamListener(Sink.INPUT) public void input(Message&lt;String&gt; message) { System.out.println (\"消费者2号，-------&gt;接收到的消息：\" + message.getPayload ( ) + \"\\t port: \" + serverPort); } } 2、启动 3、运行后有两个问题 有重复消费问题 消息持久化问题 4、重复消费问题目前是8802/8803同时都收到了，存在重复消费问题 如何解决：分组和持久化属性group比如在如下场景中，订单系统我们做集群部署，都会从RabbitMQ中获取订单信息，那如果一个订单同时被两个服务获取到，那么就会造成数据错误，我们得避免这种情况。这时我们就可以使用Stream中的消息分组来解决 注意在Stream中处于同一个group中的多个消费者是竞争关系，就能够保证消息只会被其中一个应用消费一次。不同组是可以全面消费的(重复消费)， 同一组内会发生竞争关系，只有其中一个可以消费。 5、分组1、原理微服务应用放置于同一个group中，就能够保证消息只会被其中一个应用消费一次。不同的组是可以消费的，同一个组内会发生竞争关系，只有其中一个可以消费。 2、划分组(不同组) 8802/8803都变成不同组，group两个不同组（kkA,kkB） 8802修改YML group: kkA 8803修改YML group: kkB 3、结论(不同组)不同组的还是重复消费 4、划分组(不同组)两边都配置为：kkA 5、结论(不同组)同一个组的多个微服务实例，每次只会有一个拿到。（解决重复消费问题） 6、持久化目前两个消费者8802/8803都是归类于 kkA分组 1、下面要做的是将 8802分组配置注释 2、关闭8002/8003服务 3、8801先发送4条消息到rabbitmq 4、启动8802（无分组），没有任何打印 5、启动8803（有分组），接收离线数据","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"消息驱动","slug":"消息驱动","permalink":"https://mykkto.github.io/tags/%E6%B6%88%E6%81%AF%E9%A9%B1%E5%8A%A8/"},{"name":"stream","slug":"stream","permalink":"https://mykkto.github.io/tags/stream/"}],"author":"mykk"},{"title":"SpringCloud-Bus分布式节点链接","slug":"03-java分布式/01springcloud/11_SpringCloud-Bus","date":"2022-02-06T03:49:12.000Z","updated":"2022-05-22T15:01:03.851Z","comments":true,"path":"posts/699f8954.html","link":"","permalink":"https://mykkto.github.io/posts/699f8954.html","excerpt":"","text":"1、概述1、是什么Bus支持两种消息代理：RabbitMQ 和 Kafka Spring Cloud Bus 配合 Spring Cloud Config 使用可以实现配置的动态刷新。 Spring Cloud Bus是用来将分布式系统的节点与轻量级消息系统链接起来的框架，它整合了Java的事件处理机制和消息中间件的功能。 Spring Clud Bus目前支持RabbitMQ和Kafka。 2、能干嘛Spring Cloud Bus能管理和传播分布式系统间的消息，就像一个分布式执行器，可用于广播状态更改、事件推送等，也可以当作微服务间的通信通道。 3、为何被称为总线什么是总线在微服务架构的系统中，通常会使用轻量级的消息代理来构建一个共用的消息主题，并让系统中所有微服务实例都连接上来。由于该主题中产生的消息会被所有实例监听和消费，所以称它为消息总线。在总线上的各个实例，都可以方便地广播一些需要让其他连接在该主题上的实例都知道的消息。 基本原理ConfigClient实例都监听MQ中同一个topic(默认是springCloudBus)。当一个服务刷新数据的时候，它会把这个信息放入到Topic中，这样其它监听同一Topic的服务就能得到通知，然后去更新自身的配置。 2、RabbitMQ环境配置1、安装安装docker：https://www.jianshu.com/p/f554c85b25c1 1、拉取docker pull rabbitmq:3.7.7-management 2、创建容器并启动docker run -d --hostname localhost --name myrabbit -p 15672:15672 -p 5672:5672 rabbitmq:3.7.7-management -d 后台运行容器； –name 指定容器名； -p 指定服务运行的端口（5672：应用访问端口；15672：控制台Web端口号）； -v 映射目录或文件； –hostname 主机名（RabbitMQ的一个重要注意事项是它根据所谓的 “节点名称” 存储数据，默认为主机名）； -e 指定环境变量； 默认的用户名：guest； 默认用户名的密码：guest） 3、访问http://localhost:15672/ （换成自己服务器的IP） 3、SpringCloud Bus 动态刷新全局广播1、演示广播效果，增加复杂度以3355为模板再制作一个3366 1、建modelcloud-config-client-3366 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-config-client-3366-2&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、bootstrap.ymlserver: port: 3366 spring: application: name: config-client cloud: #Config客户端配置 config: label: master #分支名称 name: config #配置文件名称 profile: dev #读取后缀名称 上述3个综合：master分支上config-dev.yml的配置文件被读取http://config-3344.com:3344/master/config-dev.yml uri: http://localhost:3344 #配置中心地址 eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; @SpringBootApplication @EnableEurekaClient public class ConfigClientMain3366 { public static void main(String[] args) { SpringApplication.run (ConfigClientMain3366.class,args); } } 5、业务类package com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Value; import org.springframework.cloud.context.config.annotation.RefreshScope; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController @RefreshScope public class ConfigClientController { @Value(\"${server.port}\") private String serverPort; @Value(\"${mytest.info}\") private String configInfo; @GetMapping(\"/configInfo\") public String configInfo() { return \"serverPort: \" + serverPort + \"\\t\\n\\n configInfo: \" + configInfo; } } 2、给cloud-config-center-3344配置中心服务端添加消息总线支持1、pom&lt;!--添加消息总线RabbitMQ支持--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt; &lt;/dependency&gt; 2、yml##rabbitmq相关配置,暴露bus刷新配置的端点 management: endpoints: #暴露bus刷新配置的端点 web: exposure: include: 'bus-refresh' 3、给cloud-config-client-3355客户端添加消息总线支持1、pom&lt;!--添加消息总线RabbitMQ支持--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt; &lt;/dependency&gt; 2、bootstrap.yml#rabbitmq相关配置 15672是Web管理界面的端口；5672是MQ访问的端口 rabbitmq: host: localhost port: 5672 username: guest password: guest server: port: 3355 spring: application: name: config-client cloud: #Config客户端配置 config: label: master #分支名称 name: config #配置文件名称 profile: dev #读取后缀名称 上述3个综合：master分支上config-dev.yml的配置文件被读取http://config-3344.com:3344/master/config-dev.yml uri: http://localhost:3344 #配置中心地址 #rabbitmq相关配置 15672是Web管理界面的端口；5672是MQ访问的端口 rabbitmq: host: 106.xx.xx.xx port: 5672 username: guest password: guest eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ # 暴露监控端点 management: endpoints: web: exposure: include: \"*\" 4、给cloud-config-client-3366客户端添加消息总线支持同上5、测试1、修改Github上配置文件增加版本号 2、发送 post 请求curl -X POST \"http://localhost:3344/actuator/bus-refresh 3、配置中心http://config-3344.com:3344/config-dev.yml 同步更新了配置信息 4、客户端http://localhost:3355/configInfo 发现并没有更新，运行指定 定点试试：curl -X POST \"http://localhost:3355/actuator/bus-refresh 运行后发现就更新了，很奇怪哦 5、结论一次修改，广播通知，处处生效（目前只有服务端是这样的，客户端只能手动，问题原因未知） 4、SpringCloud Bus 动态刷新定点(局部)通知1、概念指定具体某一个实例生效而不是全部 2、公式http://localhost:配置中心的端口号/actuator/bus-refresh/{destination} /bus/refresh请求不再发送到具体的服务实例上，而是发给config server并通过destination参数类指定需要更新配置的服务或实例 3、案例只刷新 3355 curl -X POST \"http://localhost:3344/actuator/bus-refresh/config-client:3355\" 参考：https://blog.csdn.net/haoweng4800/article/details/102946846 https://www.cnblogs.com/huanshilang/p/12585877.html https://www.jianshu.com/p/efac7bd8941f","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"bus","slug":"bus","permalink":"https://mykkto.github.io/tags/bus/"},{"name":"节点链接","slug":"节点链接","permalink":"https://mykkto.github.io/tags/%E8%8A%82%E7%82%B9%E9%93%BE%E6%8E%A5/"}],"author":"mykk"},{"title":"SpringCloud-Config分布式配置","slug":"03-java分布式/01springcloud/10_SpringCloud-Config","date":"2022-02-04T01:33:12.000Z","updated":"2022-05-22T15:01:03.851Z","comments":true,"path":"posts/fc38d8b7.html","link":"","permalink":"https://mykkto.github.io/posts/fc38d8b7.html","excerpt":"","text":"1、概述1、官网https://docs.spring.io/spring-cloud-config/docs/2.2.8.RELEASE/reference/html/ 2、分布式系统面临的—配置问题 微服务意味着要将单体应用中的业务拆分成一个个子服务，每个服务的粒度相对较小，因此系统中会出现大量的服务。由于每个服务都需要必要的配置信息才能运行，所以一套集中式的、动态的配置管理设施是必不可少的。 ​ SpringCloud提供了ConfigServer来解决这个问题，我们每一个微服务自己带着一个application.yml，上百个配置文件的管理。 3、是什么 SpringCloud Config为微服务架构中的微服务提供集中化的外部配置支持，配置服务器为各个不同微服务应用的所有环境提供了一个中心化的外部配置。 4、怎么玩SpringCloud Config分为服务端和客户端两部分。 服务端也称为分布式配置中心，它是一个独立的微服务应用，用来连接配置服务器并为客户端提供获取配置信息，加密/解密信息等访问接口 客户端则是通过指定的配置中心来管理应用资源，以及与业务相关的配置内容，并在启动的时候从配置中心获取和加载配置信息配置服务器默认采用git来存储配置信息，这样就有助于对环境配置进行版本管理，并且可以通过git客户端工具来方便的管理和访问配置内容。 5、能干嘛 集中管理配置文件 不同环境不同配置，动态化的配置更新，分环境部署比如dev/test/prod/beta/release 运行期间动态调整配置，不再需要在每个服务部署的机器上编写配置文件，服务会向配置中心统一拉取配置自己的信息 当配置发生变动时，服务不需要重启即可感知到配置的变化并应用新的配置 将配置信息以REST接口的形式暴露，post、curl访问刷新均可…… 6、与GitHub整合配置由于SpringCloud Config默认使用Git来存储配置文件(也有其它方式,比如支持SVN和本地文件)，但最推荐的还是Git，而且使用的是http/https访问的形式 2、Config服务端配置1、创建github仓库1、新建仓库用你自己的账号在GitHub/gitee 上新建一个名为springcloud-config的新Repository 2、获得刚新建的git地址https://gitee.com/TK_LIMR/spring-cloud-config.git 3、本地硬盘目录上新建git仓库并clonegit clone https://gitee.com/TK_LIMR/spring-cloud-config.git 4、编辑application.yml环境# 不同的开发环境，不同的微服务名字 spring: profiles: active: - dev --- spring: profiles: dev #开发环境 application: name: microservicecloud-config-kk-dev config: info: version1 --- spring: profiles: test #测试环境 application: name: microservicecloud-config-kk-test # 请保存为UTF-8格式 5、上传到gitee上（1）git add . （2）git commit -m \"init yml\" （3）git push origin master 2、项目搭建1、建model新建Module模块cloud-config-center-3344 2、pom&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-config-center-3344&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 3344 spring: application: name: cloud-config-center #注册进Eureka服务器的微服务名 cloud: config: server: git: uri: https://gitee.com/TK_LIMR/spring-cloud-config.git #GitHub上面的git仓库名字 ####权限登录(这里填写自己的) force-pull: true username: xxxxxxxx@163.com password: xxxxxxxx ####搜索目录 search-paths: - springcloud-config ####读取分支 label: master #服务注册到eureka地址 eureka: client: service-url: defaultZone: http://localhost:7001/eureka 4、主启动@EnableConfigServer package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.config.server.EnableConfigServer; @SpringBootApplication @EnableConfigServer public class ConfigCenterMain3344 { public static void main(String[] args) { SpringApplication.run (ConfigCenterMain3344.class,args); } } 5、本地hosts配置127.0.0.1 config-3344.com 6、启动测试生产：http://config-3344.com:3344/master/config-prod.yml 开发：http://config-3344.com:3344/master/config-dev.yml 测试：http://config-3344.com:3344/master/config-test.yml 3、配置读取规则1、官网 2、/{label}/{application}-{profile}.yml参数说明：/分支/服务名/环境 1、master分支http://config-3344.com:3344/master/config-dev.yml http://config-3344.com:3344/master/config-test.yml http://config-3344.com:3344/master/config-prod.yml 2、dev分支http://config-3344.com:3344/dev/config-dev.yml http://config-3344.com:3344/dev/config-test.yml http://config-3344.com:3344/dev/config-prod.yml 3、/{application}-{profile}.yml参数说明：/服务名/环境 http://config-3344.com:3344/config-dev.yml http://config-3344.com:3344/config-test.yml http://config-3344.com:3344/config-prod.yml http://config-3344.com:3344/config-xxxx.yml(不存在的配置) 4、/{application}/{profile}[/{label}]参数说明：/服务名/环境/分支 http://config-3344.com:3344/config/dev/master http://config-3344.com:3344/config/test/master http://config-3344.com:3344/config/test/dev 5、参数说明/{label}-{name}-{profiles}.yml label：分支(branch)name ：服务名profiles：环境(dev/test/prod) 3、Config客户端配置1、建model和测试1、建model新建cloud-config-client-3355 2、pom&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-config-client-3355&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、bootstrap.ymlapplicaiton.yml 是用户级的资源配置项bootstrap.yml 是系统级的，优先级更加高 server: port: 3355 spring: application: name: config-client cloud: #Config客户端配置 config: label: master #分支名称 name: config #配置文件名称 profile: dev #读取后缀名称 上述3个综合：master分支上config-dev.yml的配置文件被读取http://config-3344.com:3344/master/config-dev.yml uri: http://localhost:3344 #配置中心地址 eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; @SpringBootApplication @EnableEurekaClient public class ConfigClientMain3355 { public static void main(String[] args) { SpringApplication.run (ConfigClientMain3355.class,args); } } 5、业务类package com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class ConfigClientController { @Value(\"${config.info}\") private String configInfo; @GetMapping(\"/configInfo\") public String getConfigInfo() { return configInfo; } } 6、测试1、启动Config配置中心3344微服务并自测 http://config-3344.com:3344/master/config-prod.yml http://config-3344.com:3344/master/config-dev.yml 2、启动3355作为Client准备访问 http://localhost:3355/configInfo 2、动态刷新问题 Linux运维修改GitHub上的配置文件内容做调整 刷新3344，发现ConfigServer配置中心立刻响应 刷新3355，发现ConfigClient客户端没有任何响应 3355没有变化除非自己重启或者重新加载 难到每次运维修改配置文件，客户端都需要重启？？噩梦 4、Config客户端之动态刷新操作3355模块 1、POM引入actuator监控&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; 2、修改YML，暴露监控端口# 暴露监控端点 management: endpoints: web: exposure: include: \"*\" 3、业务类Controller修改@RefreshScope package com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Value; import org.springframework.cloud.context.config.annotation.RefreshScope; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController @RefreshScope public class ConfigClientController { @Value(\"${spring.application.name}\") private String configInfo; @GetMapping(\"/configInfo\") public String getConfigInfo() { return configInfo; } } 4、此时修改github—&gt; 3344 —-&gt;33551、添加一个版本号为1 2、此时看下3344（config服务端），没有重启的状态下 没有更新！ 3、此时看下3355（config客户端），没有重启的状态下 没有更新！ 4、总结：是不会更新的 5、解决：需要运维人员运行解决 必须是POST请求 curl -X POST \"http://localhost:3355/actuator/refresh\" 5、还存在的问题 每个微服务都要执行一次post请求，手动刷新？ 写循环代码解决（shell脚本） 可否广播，一次通知，处处生效？ 鸡肋所在 可以使用阿里的nacos 替换解决 整合SpringCloud-Bus解决","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"配置中心","slug":"配置中心","permalink":"https://mykkto.github.io/tags/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"},{"name":"config","slug":"config","permalink":"https://mykkto.github.io/tags/config/"}],"author":"mykk"},{"title":"SpringCloud-Gaywayl路由网关","slug":"03-java分布式/01springcloud/09_SpringCloud-GateWay","date":"2022-02-02T01:22:13.000Z","updated":"2022-05-22T15:01:03.851Z","comments":true,"path":"posts/d633875f.html","link":"","permalink":"https://mykkto.github.io/posts/d633875f.html","excerpt":"","text":"一、概述简介1、官网1、上一代zuul 1.Xhttps://github.com/Netflix/zuul/wiki 2、Gatewayhttps://cloud.spring.io/spring-cloud-static/spring-cloud-gateway/2.2.1.RELEASE/reference/html/ 2、是什么1、概述Gateway是在Spring生态系统之上构建的API网关服务，基于Spring 5，Spring Boot 2和 Project Reactor等技术。Gateway旨在提供一种简单而有效的方式来对API进行路由，以及提供一些强大的过滤器功能， 例如：熔断、限流、重试等 2、一句话SpringCloud Gateway 使用的Webflux中的reactor-netty响应式编程组件，底层使用了Netty通讯框架。 3、能干嘛 反向代理 鉴权 流量控制 熔断 日志监控 …… 4、网关在微服务的位置 5、GateWay优于Zuul的地方1、我们为什么选择Gateway？1、neflix不太靠谱，zuul2.0一直跳票，迟迟不发布2、SpringCloud Gateway具有如下特性 基于Spring Framework 5, Project Reactor 和 Spring Boot 2.0 进行构建； 动态路由：能够匹配任何请求属性； 可以对路由指定 Predicate（断言）和 Filter（过滤器）； 集成Hystrix的断路器功能； 集成 Spring Cloud 服务发现功能； 易于编写的 Predicate（断言）和 Filter（过滤器）； 请求限流功能； 支持路径重写。 3、SpringCloud Gateway 与 Zuul的区别 Zuul 1.x，是一个基于 阻塞 I/ O 的 API Gateway Zuul 1.x 基于Servlet 2. 5使用阻塞架构它不支持任何长连接(如 WebSocket) Zuul 的设计模式和Nginx较像，每次 I/ O 操作都是从工作线程中选择一个执行，请求线程被阻塞到工作线程完成，但是差别是Nginx 用C++ 实现，Zuul 用 Java 实现，而 JVM 本身会有第一次加载较慢的情况，使得Zuul 的性能相对较差。 Zuul 2.x理念更先进，想基于Netty非阻塞和支持长连接，但SpringCloud目前还没有整合。 Zuul 2.x的性能较 Zuul 1.x 有较大提升。在性能方面，根据官方提供的基准测试， Spring Cloud Gateway 的 RPS（每秒请求数）是Zuul 的 1. 6 倍。 Spring Cloud Gateway 建立 在 Spring Framework 5、 Project Reactor 和 Spring Boot 2 之上， 使用非阻塞 API。 Spring Cloud Gateway 还 支持 WebSocket， 并且与Spring紧密集成拥有更好的开发体验 2、Zuul1.x模型Springcloud中所集成的Zuul版本，采用的是Tomcat容器，使用的是传统的Servlet IO处理模型。 Servlet的生命周期?servlet由servlet container进行生命周期管理。 container启动时构造servlet对象并调用servlet init()进行初始化； container运行时接受请求，并为每个请求分配一个线程（一般从线程池中获取空闲线程）然后调用service()。 container关闭时调用servlet destory()销毁servlet； 3、GateWay模型WebFlux是什么 https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html#webflux-new-framework 传统的Web框架，比如说：struts2，springmvc等都是基于Servlet API与Servlet容器基础之上运行的。但是在Servlet3.1之后有了异步非阻塞的支持。而WebFlux是一个典型非阻塞异步的框架，它的核心是基于Reactor的相关API实现的。相对于传统的web框架来说，它可以运行在诸如Netty，Undertow及支持Servlet3.1的容器上。非阻塞式+函数式编程（Spring5必须让你使用java8） 二、三大核心概念1、Route(路由)路由是构建网关的基本模块，它由ID，目标URI，一系列的断言和过滤器组成，如果断言为true则匹配该路由 2、Predicate(断言)参考的是Java8的java.util.function.Predicate开发人员可以匹配HTTP请求中的所有内容(例如请求头或请求参数)，如果请求与断言相匹配则进行路由 3、Filter(过滤)指的是Spring框架中GatewayFilter的实例，使用过滤器，可以在请求被路由前或者之后对请求进行修改。 4、总体web请求，通过一些匹配条件，定位到真正的服务节点。并在这个转发过程的前后，进行一些精细化控制。predicate就是我们的匹配条件；而filter，就可以理解为一个无所不能的拦截器。有了这两个元素，再加上目标uri，就可以实现一个具体的路由了 三、Gateway工作流程1、官网客户端向 Spring Cloud Gateway 发出请求。然后在 Gateway Handler Mapping 中找到与请求相匹配的路由，将其发送到 Gateway Web Handler。 Handler 再通过指定的过滤器链来将请求发送到我们实际的服务执行业务逻辑，然后返回。过滤器之间用虚线分开是因为过滤器可能会在发送代理请求之前（“pre”）或之后（“post”）执行业务逻辑。 Filter在“pre”类型的过滤器可以做参数校验、权限校验、流量监控、日志输出、协议转换等，在“post”类型的过滤器中可以做响应内容、响应头的修改，日志的输出，流量监控等有着非常重要的作用。 2、核心逻辑路由转发+执行过滤器链 四、入门案例1、模块创建步骤1、建modelcloud-gateway-gateway9527 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-gateway-gateway9527&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--gateway--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--eureka-client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--一般基础配置类--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 9527 spring: application: name: cloud-gateway eureka: instance: hostname: cloud-gateway-service client: #服务提供者provider注册进eureka服务列表内 service-url: register-with-eureka: true fetch-registry: true defaultZone: http://eureka7001.com:7001/eureka 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; @SpringBootApplication @EnableEurekaClient public class GatewayMain9527 { public static void main(String[] args) { SpringApplication.run (GatewayMain9527.class,args); } } 2、网关映射配置1、yml配置spring: application: name: cloud-gateway cloud: gateway: routes: - id: payment_routh #payment_route #路由的ID，没有固定规则但要求唯一，建议配合服务名 uri: http://localhost:8001 #匹配后提供服务的路由地址 predicates: - Path=/payment/get/** # 断言，路径相匹配的进行路由 - id: payment_routh2 #payment_route #路由的ID，没有固定规则但要求唯一，建议配合服务名 uri: http://localhost:8001 #匹配后提供服务的路由地址 predicates: - Path=/payment/lb/** # 断言，路径相匹配的进行路由 2、配置说明 4、测试1、启动 eureka集群，启动8001/8002，启动网关9527 添加网关前uri：http://localhost:8001/payment/get/1 添加网关后uri：http://localhost:9527/payment/get/1 3、YML配置说明Gateway网关路由有两种配置方式： 1、方式一：在配置文件yml中配置既上面案例的方式 1、方式二：代码中注入RouteLocator的Beanpackage com.kk.springcloud.config; import org.springframework.cloud.gateway.route.RouteLocator; import org.springframework.cloud.gateway.route.builder.RouteLocatorBuilder; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class GatewayConfig { /** * 配置了一个id为route-name的路由规则， * 当访问地址 http://localhost:9527/kk时会自动转发到地址：http://news.baidu.com/ * * @param builder * @return */ @Bean public RouteLocator customRouteLocator(RouteLocatorBuilder builder) { RouteLocatorBuilder.Builder routes = builder.routes ( ); routes.route (\"path_route_mykk\", r -&gt; r.path (\"/kk\").uri (\"http://www.baidu.com/\")).build ( ); return routes.build ( ); } @Bean public RouteLocator customRouteLocator2(RouteLocatorBuilder builder) { RouteLocatorBuilder.Builder routes = builder.routes ( ); routes.route (\"path_route_mykk2\", r -&gt; r.path (\"/kkz\").uri (\"http://www.weibo.com/kkz\")).build ( ); return routes.build ( ); } } 五、微服务名实现动态路由1、概述默认情况下Gateway会根据注册中心注册的服务列表，以注册中心上微服务名为路径创建动态路由进行转发，从而实现动态路由的功能 2、启动一个eureka7001 + 两个服务提供者8001/8002 4、yml1、需要注意的是uri的协议为lb，表示启用Gateway的负载均衡功能。 2、lb://serviceName是spring cloud gateway在微服务中自动为我们创建的负载均衡uri server: port: 9527 spring: application: name: cloud-gateway cloud: gateway: discovery: locator: enabled: true #开启从注册中心动态创建路由的功能，利用微服务名进行路由 routes: - id: payment_routh #payment_route #路由的ID，没有固定规则但要求唯一，建议配合服务名 # uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service #匹配后提供服务的路由地址 predicates: - Path=/payment/get/** # 断言，路径相匹配的进行路由 - id: payment_routh2 #payment_route #路由的ID，没有固定规则但要求唯一，建议配合服务名 # uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service #匹配后提供服务的路由地址 predicates: - Path=/payment/lb/** # 断言，路径相匹配的进行路由 eureka: instance: hostname: cloud-gateway-service client: #服务提供者provider注册进eureka服务列表内 service-url: register-with-eureka: true fetch-registry: true defaultZone: http://eureka7001.com:7001/eureka 5、测试url：http://localhost:9527/payment/lb 六、Predicate(断言)的使用1、启动看下日志 2、Route Predicate FactoriesSpring Cloud Gateway 创建 Route 对象时， 使用 RoutePredicateFactory 创建 Predicate 对象，Predicate 对象可以赋值给 Route。 Spring Cloud Gateway 包含许多内置的Route Predicate Factories。 所有这些谓词是都匹配HTTP请求的不同属性。多种谓词工厂可以组合，并通过逻辑 and 组合。 3、常用的Route Predicate1、After Route Predicate必须要在配置断言的时区的时间之后对应的uri请求才能生效 package com.kk.test; import java.time.ZonedDateTime; public class Test { public static void main(String[] args) { ZonedDateTime zbj = ZonedDateTime.now ( ); // 默认时区 System.out.println (zbj); // ZonedDateTime zny = ZonedDateTime.now(ZoneId.of(\"America/New_York\")); // 用指定时区获取当前时间 // System.out.println(zny); } } - After=2022-02-03T13:53:16.164+08:00[Asia/Shanghai] # 断言，路径相匹配的进行路由 spring: application: name: cloud-gateway cloud: gateway: discovery: locator: enabled: true #开启从注册中心动态创建路由的功能，利用微服务名进行路由 routes: - id: payment_routh #payment_route #路由的ID，没有固定规则但要求唯一，建议配合服务名 # uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service #匹配后提供服务的路由地址 predicates: - Path=/payment/get/** # 断言，路径相匹配的进行路由 - After=2022-02-03T13:53:16.164+08:00[Asia/Shanghai] # 断言，路径相匹配的进行路由 - id: payment_routh2 #payment_route #路由的ID，没有固定规则但要求唯一，建议配合服务名 # uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service #匹配后提供服务的路由地址 predicates: - Path=/payment/lb/** # 断言，路径相匹配的进行路由 2、Before Route Predicate必须要在配置断言的时区的时间之前对应的uri请求才能生效 - Before=2022-02-03T13:53:16.164+08:00[Asia/Shanghai] # 断言，路径相匹配的进行路由 3、Between Route Predicate必须要在配置断言的时区的时间范围内对应的uri请求才能生效 - Between=2022-02-03T13:53:16.164+08:00[Asia/Shanghai],2022-12-03T13:53:16.164+08:00[Asia/Shanghai] # 断言，路径相匹配的进行路由 4、Cookie Route Predicate必须显示的指定携带的cookie信息，才能访问对应的uri - Cookie=username,mykk # 断言，路径相匹配的进行路由 1、不带cookie的情况 curl http://localhost:9527/payment/get/1 2、携带cookie的情况 curl http://localhost:9527/payment/get/1 --cookie \"username=mykk\" 5、Header Route Predicate必须显示的指定携带的请求头Header 信息，才能访问对应的uri。 两个参数：一个是属性名称和一个正则表达式，这个属性值和正则表达式匹配则执行。 - Header=X-Request-Id, \\d+ # 请求头要有X-Request-Id属性并且值为整数的正则表达式 1、不带Header的情况 curl http://localhost:9527/payment/get/1 2、携带Header的情况 curl http://localhost:9527/payment/get/1 -H \"X-Request-Id:123\" 6、Host Route Predicate必须显示的携带指定规则的主机地址 Host信息 ，才能访问对应的uri。 - Host=**.mykk.com 访问测试 curl http://localhost:9527/payment/get/1 -H \"Host:www.mykk.com\" curl http://localhost:9527/payment/get/1 -H \"Host:news.mykk.com\" 7、Method Route Predicate必须显示的指定请求方式 ，才能访问对应的uri。 - Method=GET # 请求方式 8、Path Route Predicate路由到指定的路径 9、Query Route Predicate必须显示的携带指定规则的 请求参数 ，才能访问对应的uri。 说明：支持传入两个参数，一个是属性名，一个为属性值，属性值可以是正则表达式。 测试： url：curl http://localhost:9527/payment/get/1?username=111 七、Filter的使用1、概述路由过滤器可用于修改进入的HTTP请求和返回的HTTP响应，路由过滤器只能指定路由进行使用。 Spring Cloud Gateway 内置了多种路由过滤器，他们都由GatewayFilter的工厂类来产生 1、生命周期前置：pre 后置：post 2、种类单一：GatewayFilter https://cloud.spring.io/spring-cloud-static/spring-cloud-gateway/2.2.1.RELEASE/reference/html/#the-addrequestparameter-gatewayfilter-factory 31种之多 全局：GlobalFilter 2、常用的GatewayFilterAddRequestParameter filters: - AddRequestParameter=X-Request-Id,1024 #过滤器工厂会在匹配的请求头加上一对请求头，名称为X-Request-Id值为1024 server: port: 9527 spring: application: name: cloud-gateway cloud: gateway: discovery: locator: enabled: true #开启从注册中心动态创建路由的功能，利用微服务名进行路由 routes: - id: payment_routh #payment_route #路由的ID，没有固定规则但要求唯一，建议配合服务名 # uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service #匹配后提供服务的路由地址 filters: - AddRequestParameter=X-Request-Id,1024 #过滤器工厂会在匹配的请求头加上一对请求头，名称为X-Request-Id值为1024 predicates: - Path=/payment/get/** # 断言，路径相匹配的进行路由 - After=2022-02-03T13:53:16.164+08:00[Asia/Shanghai] # 断言，路径相匹配的进行路由 # - Cookie=username,mykk # - Header=X-Request-Id, \\d+ # 请求头要有X-Request-Id属性并且值为整数的正则表达式 # - Host=**.mykk.com # - Method=GET # 请求方式 - Query=username, \\d+ # 要有参数名username并且值还要是整数才能路由 - id: payment_routh2 #payment_route #路由的ID，没有固定规则但要求唯一，建议配合服务名 # uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service #匹配后提供服务的路由地址 predicates: - Path=/payment/lb/** # 断言，路径相匹配的进行路由 eureka: instance: hostname: cloud-gateway-service client: #服务提供者provider注册进eureka服务列表内 service-url: register-with-eureka: true fetch-registry: true defaultZone: http://eureka7001.com:7001/eureka 3、自定义过滤器自定义全局GlobalFilter 1、两个主要接口介绍implements GlobalFilter,Ordered 2、能干嘛 全局日志记录 统一网关鉴权 …… 3、代码package com.kk.springcloud.config.config; import org.springframework.cloud.gateway.filter.GatewayFilterChain; import org.springframework.cloud.gateway.filter.GlobalFilter; import org.springframework.core.Ordered; import org.springframework.http.HttpStatus; import org.springframework.stereotype.Component; import org.springframework.web.server.ServerWebExchange; import reactor.core.publisher.Mono; import java.util.Date; @Component public class MyLogGateWayFilter implements GlobalFilter, Ordered { @Override // 过滤逻辑 public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { System.out.println(\"time:\"+new Date ()+\"\\t 执行了自定义的全局过滤器: \"+\"MyLogGateWayFilter\"+\"hello\"); String uname = exchange.getRequest().getQueryParams().getFirst(\"uname\"); if (uname == null) { System.out.println(\"****用户名为null，无法登录\"); exchange.getResponse().setStatusCode(HttpStatus.NOT_ACCEPTABLE); return exchange.getResponse().setComplete(); } return chain.filter(exchange); } // 优先级，越少越大 @Override public int getOrder() { return 0; } } 测试：curl http://localhost:9527/payment/get/1?uname=11","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"路由网关","slug":"路由网关","permalink":"https://mykkto.github.io/tags/%E8%B7%AF%E7%94%B1%E7%BD%91%E5%85%B3/"},{"name":"alibaba","slug":"alibaba","permalink":"https://mykkto.github.io/tags/alibaba/"},{"name":"gateway","slug":"gateway","permalink":"https://mykkto.github.io/tags/gateway/"}],"author":"mykk"},{"title":"mysql开启远程连接","slug":"04-基础/03mysql/01_Mysql_smallPosture","date":"2022-01-27T14:27:39.000Z","updated":"2022-05-22T15:01:03.835Z","comments":true,"path":"posts/bf62bc57.html","link":"","permalink":"https://mykkto.github.io/posts/bf62bc57.html","excerpt":"","text":"1、前言最近快过年了，回去肯定是要敲代码，写博文的，近期在写SpringCloud全家桶，数据库一直是在本地，想着还有几台云机在云上运行着，于是连接了下，出现了如下问题： 之前还是好的，可能挺久没用的权限自己关闭了，安装是docker 可以参考之前博主的简书文章 ： https://www.jianshu.com/p/f554c85b25c1 版本顺便说下5.7.35 MySQL Community Server (GPL) 2、开启远程连接#开启远程连接 GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'a1b2c3' WITH GRANT OPTION; #root 用户名 #a1b2c3 密码 #刷新权限，立即生效 flush privileges; 3、修改密码#修改密码(5.7.35) set password = password ('a1b2c3'); #修改密码（高版本 8.0+） update mysql.user set authentication_string=password('a1b2c3') where user='a1b2c3'; #刷新权限，立即生效 flush privileges;","categories":[{"name":"数据库","slug":"数据库","permalink":"https://mykkto.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"小姿势","slug":"小姿势","permalink":"https://mykkto.github.io/tags/%E5%B0%8F%E5%A7%BF%E5%8A%BF/"},{"name":"linux","slug":"linux","permalink":"https://mykkto.github.io/tags/linux/"},{"name":"mysql","slug":"mysql","permalink":"https://mykkto.github.io/tags/mysql/"}],"author":"mykk"},{"title":"SpringCloud-Zuul路由网关","slug":"03-java分布式/01springcloud/08_SpringCloud_Zuul","date":"2022-01-25T13:38:21.000Z","updated":"2022-05-22T15:01:03.851Z","comments":true,"path":"posts/d633875f.html","link":"","permalink":"https://mykkto.github.io/posts/d633875f.html","excerpt":"","text":"1、概述1、官网https://cloud.spring.io/spring-cloud-static/spring-cloud-netflix/2.2.1.RELEASE/reference/html/#router-and-filter-zuul 2、是什么Zuul是一种提供动态路由、监视、弹性、安全性等功能的边缘服务。 Zuul是Netflix出品的一个基于JVM路由和服务端的负载均衡器。 API网关为微服务架构中的服务提供了统一的访问入口，客户端通过API网关访问相关服务。API网关的定义类似于设计模式中的门面模式，它相当于整个微服务架构中的门面，所有客户端的访问都通过它来进行路由及过滤。它实现了请求路由、负载均衡、校验过滤、服务容错、服务聚合等功能。 Zuul包含了如下最主要的功能：代理+路由+过滤三大功能 3、能干嘛1、路由2、过滤3、负载均衡4、灰度发布（金丝雀发布）起源是，矿井工人发现，金丝雀对瓦斯气体很敏感，矿工会在下井之前，先放一只金丝雀到井中，如果金丝雀不叫了，就代表瓦斯浓度高。 在灰度发布开始后，先启动一个新版本应用，但是并不直接将流量切过来，而是测试人员对新版本进行线上测试，启动的这个新版本应用，就是我们的金丝雀。如果没有问题，那么可以将少量的用户流量导入到新版本上，然后再对新版本做运行状态观察，收集各种运行时数据，如果此时对新旧版本做各种数据对比，就是所谓的A/B测试。新版本没什么问题，那么逐步扩大范围、流量，把所有用户都迁移到新版本上面来。 2、路由基本配置路由功能负责将外部请求转发到具体的服务实例上去，是实现统一访问入口的基础 1、建Modelcloud-zuul-gateway9527 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-zuul-gateway9527&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 9527 spring: application: name: cloud-zuul-gateway eureka: client: service-url: #defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka,http://eureka7003.com:7003/eureka defaultZone: http://eureka7001.com:7001/eureka instance: instance-id: gateway-9527.com prefer-ip-address: true 4、hosts修改(本地环境)因为是本地环境，服务器，域名等资源有限 添加配置项：C:\\Windows\\System32\\drivers\\etc 127.0.0.1 myzuul.com 5、主启动注意：@EnableZuulProxy package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.zuul.EnableZuulProxy; @SpringBootApplication @EnableZuulProxy public class ZuulMain9527 { public static void main(String[] args) { SpringApplication.run (ZuulMain9527.class,args); } } 6、启动顺序1、eureka集群 2、8006生产者 3、9527网关 7、测试1、不用路由http://localhost:8001/payment/consul controller @GetMapping(\"/payment/consul\") public String paymentInfo() { return \"springcloud with consul: \" + serverPort + \"\\t\\t\" + UUID.randomUUID ( ).toString ( ); } 2、路由（1）zuul映射配置+注册中心注册后对外暴露的服务名称+rest调用地址 （2）url： http://myzuul.com:9527/cloud-payment-service/payment/consul ![](C:\\Users\\my_kk\\Documents\\Tencent Files\\763856958\\FileRecv_posts\\03javafenbushi\\01springcloud\\20220201141019.png) 3、路由访问映射规则1、名称代理1、yml详解zuul: routes: # 路由映射配置 mypayment.path: /mypayment/** #IE地址栏输入的路径 mypayment.serviceId: cloud-payment-service # 指定服务端的名称 server: port: 9527 spring: application: name: cloud-zuul-gateway eureka: client: service-url: #defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka,http://eureka7003.com:7003/eureka defaultZone: http://eureka7001.com:7001/eureka instance: instance-id: gateway-9527.com prefer-ip-address: true zuul: routes: # 路由映射配置 mypayment.path: /mypayment/** #IE地址栏输入的路径 mypayment.serviceId: cloud-payment-service # 指定服务端的名称 2、测试1、路由访问：OKhttp://myzuul.com:9527/mypayment/payment/consul 2、原路径访问：OKhttp://myzuul.com:9527/cloud-payment-service/payment/consul 2、忽略原有真实服务名1、yml配置zuul: ignored-services: cloud-payment-service #忽略服务名 2、测试1、使用服务名访问（失败）：http://myzuul.com:9527/cloud-payment-service/payment/consul ![](C:\\Users\\my_kk\\Documents\\Tencent Files\\763856958\\FileRecv_posts\\03javafenbushi\\01springcloud\\20220201165024.png) 2、映射访问：依旧可以！ 五角星：批量忽略zuul: ignored-services: \"*\" 3、路由转发和负载均衡功能1、生产者：SMS短信模块(8008)1、建modelcloud-provider-sms8008 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-provider-sms8008&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 8008 ###服务名称(服务注册到eureka名称) spring: application: name: cloud-provider-sms eureka: client: #服务提供者provider注册进eureka服务列表内 service-url: register-with-eureka: true fetch-registry: true defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka,http://eureka7003.com:7003/eureka #defaultZone: http://127.0.0.1:7001/eureka,http://127.0.0.1:7002/eureka #defaultZone: http://eureka7001.com:7001/eureka # eureka集群加@老本版 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; @SpringBootApplication @EnableEurekaClient public class SMSMain8008 { public static void main(String[] args) { SpringApplication.run (SMSMain8008.class,args); } } 5、业务类package com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class SMSController { @Value(\"${server.port}\") private String serverPort; @GetMapping(\"/sms\") public String sms() { return \"sms provider service: \"+\"\\t\"+serverPort; } } 6、启动服务 2、网关：zuul（9527）1、ymlzuul: # ignored-services: cloud-payment-service #忽略服务名 routes: # 路由映射配置 mysms.path: /mysms/** # IE地址栏输入的路径 mysms.serviceId: cloud-provider-sms # 指定服务端的名称 server: port: 9527 spring: application: name: cloud-zuul-gateway eureka: client: service-url: #defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka,http://eureka7003.com:7003/eureka defaultZone: http://eureka7001.com:7001/eureka instance: instance-id: gateway-9527.com prefer-ip-address: true zuul: # ignored-services: cloud-payment-service #忽略服务名 routes: # 路由映射配置 mysms.path: /mysms/** # IE地址栏输入的路径 mysms.serviceId: cloud-provider-sms # 指定服务端的名称 mypayment.path: /mypayment/** # IE地址栏输入的路径 mypayment.serviceId: cloud-payment-service # 指定服务端的名称 2、说明由于Zuul自动集成了Ribbon和Hystrix，所以Zuul天生就有负载均衡和服务容错能力 3、测试负载效果url： 4、设置统一公共前缀yml配置zuul: prefix: /mykk server: port: 9527 spring: application: name: cloud-zuul-gateway eureka: client: service-url: #defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka,http://eureka7003.com:7003/eureka defaultZone: http://eureka7001.com:7001/eureka instance: instance-id: gateway-9527.com prefer-ip-address: true zuul: prefix: /mykk # ignored-services: cloud-payment-service #忽略服务名 routes: # 路由映射配置 mysms.path: /mysms/** # IE地址栏输入的路径 mysms.serviceId: cloud-provider-sms # 指定服务端的名称 mypayment.path: /mypayment/** # IE地址栏输入的路径 mypayment.serviceId: cloud-payment-service # 指定服务端的名称 测试url（1）http://myzuul.com:9527/mykk/mypayment/payment/consul （2）http://myzuul.com:9527/mykk/mysms/sms 4、查看路由信息1、POM&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; 2、yml# 开启查看路由的端点 management: endpoints: web: exposure: include: 'routes' 3、查看路由详细信息url：http://localhost:9527/actuator/routes 5、过滤器1、功能过滤功能负责对请求过程进行额外的处理，是请求校验过滤及服务聚合的基础。 2、过滤器的生命周期 3、ZuulFilter1、过滤类型 pre：在请求被路由到目标服务前执行，比如权限校验、打印日志等功能； routing：在请求被路由到目标服务时执行 post：在请求被路由到目标服务后执行，比如给目标服务的响应添加头信息，收集统计数据等功能； error：请求在其他阶段发生错误时执行。 2、过滤顺序数字小的先执行 3、过滤是否开启shouldFilter方法为true走 4、执行逻辑自己的业务逻辑 4、案例Case1、说明前置过滤器，用于在请求路由到目标服务前打印请求日志 2、自定义过滤器过滤器代码： package com.kk.springcloud.filter; import com.netflix.zuul.ZuulFilter; import com.netflix.zuul.context.RequestContext; import com.netflix.zuul.exception.ZuulException; import lombok.extern.slf4j.Slf4j; import org.springframework.stereotype.Component; import javax.servlet.http.HttpServletRequest; import java.util.Date; @Component @Slf4j public class PreLogFilter extends ZuulFilter { /** * 定义过滤器的类型 * pre:在请求被路由之前执行 * route:在路由请求的时候执行 * post:请求路由以后执行 * error:处理请求时发生错误的时候执行 * * @return 过滤器的类型 */ @Override public String filterType() { return \"pre\"; } /** * 过滤器执行的顺序，配置多个有顺序的过滤 * 执行顺序从小到大 * * @return 执行顺序 */ @Override public int filterOrder() { // 优先级为0，数字越大，优先级越低 return 1; } /** * 是否开启过滤器 * true:开启 * false:禁用 * * @return 是否开启过滤器 */ @Override public boolean shouldFilter() { // 是否开启 return true; } /** * 过滤器的业务实现 * * @return null 没有意义 * @throws ZuulException 异常信息 */ @Override public Object run() throws ZuulException { // 业务逻辑代码 RequestContext requestContext = RequestContext.getCurrentContext ( ); HttpServletRequest request = requestContext.getRequest ( ); String host = request.getRemoteHost ( ); String method = request.getMethod ( ); String uri = request.getRequestURI ( ); log.info(\"=====&gt; Remote host:{},method:{},uri:{}\", host, method, uri); System.out.println (\"********\" + new Date ( ).getTime ( )); return null; } } 3、测试(1)url：http://myzuul.com:9527/mykk/mysms/sms (2)在调用8008之前会打印日志 4、yml 配置开关★这里需要特别注意：开启这里之后，per配置失效，不清楚为什么，博主搞了很久尝试才发现是这个问题，建议使用硬编码，在java上配置开关zuul: prefix: /mykk # ignored-services: cloud-payment-service #忽略服务名 routes: # 路由映射配置 mysms.path: /mysms/** # IE地址栏输入的路径 mysms.serviceId: cloud-provider-sms # 指定服务端的名称 mypayment.path: /mypayment/** # IE地址栏输入的路径 mypayment.serviceId: cloud-payment-service # 指定服务端的名称 #yml配置开关 # PreLogFilter: # pre: # disable: true 参考文章链接1、限制IP过滤博文https://www.jianshu.com/p/20d77ca5cfbc","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"netflix","slug":"netflix","permalink":"https://mykkto.github.io/tags/netflix/"},{"name":"路由网关","slug":"路由网关","permalink":"https://mykkto.github.io/tags/%E8%B7%AF%E7%94%B1%E7%BD%91%E5%85%B3/"},{"name":"zuul","slug":"zuul","permalink":"https://mykkto.github.io/tags/zuul/"}],"author":"mykk"},{"title":"SpringCloud-Hystrix断路器","slug":"03-java分布式/01springcloud/07_SpringCloud_Hystrix","date":"2022-01-23T13:19:18.000Z","updated":"2022-05-22T15:01:03.890Z","comments":true,"path":"posts/b0ab6264.html","link":"","permalink":"https://mykkto.github.io/posts/b0ab6264.html","excerpt":"","text":"1、概述1、分布式系统面临的问题复杂分布式体系结构中的应用程序有数十个依赖关系，每个依赖关系在某些时候将不可避免地失败。 服务雪崩 多个微服务之间调用的时候，假设微服务A调用微服务B和微服务C，微服务B和微服务C又调用其它的微服务，这就是所谓的“扇出”。如果扇出的链路上某个微服务的调用响应时间过长或者不可用，对微服务A的调用就会占用越来越多的系统资源，进而引起系统崩溃，所谓的“雪崩效应”. 对于高流量的应用来说，单一的后端依赖可能会导致所有服务器上的所有资源都在几秒钟内饱和。比失败更糟糕的是，这些应用程序还可能导致服务之间的延迟增加，备份队列，线程和其他系统资源紧张，导致整个系统发生更多的级联故障。这些都表示需要对故障和延迟进行隔离和管理，以便单个依赖关系的失败，不能取消整个应用程序或系统。 所以，通常当你发现一个模块下的某个实例失败后，这时候这个模块依然还会接收流量，然后这个有问题的模块还调用了其他的模块，这样就会发生级联故障，或者叫雪崩。 2、是什么 Hystrix是一个用于处理分布式系统的延迟和容错的开源库，在分布式系统里，许多依赖不可避免的会调用失败，比如超时、异常等，Hystrix能够保证在一个依赖出问题的情况下，不会导致整体服务失败，避免级联故障，以提高分布式系统的弹性。 “断路器”本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控（类似熔断保险丝），向调用方返回一个符合预期的、可处理的备选响应（FallBack），而不是长时间的等待或者抛出调用方无法处理的异常，这样就保证了服务调用方的线程不会被长时间、不必要地占用，从而避免了故障在分布式系统中的蔓延，乃至雪崩。 3、能干嘛 服务降级 服务熔断 接近实时的监控 ……….. 4、官网文档https://github.com/Netflix/Hystrix/wiki/How-To-Use 5、Hystrix停更https://github.com/Netflix/Hystrix 被动修复bugs 不再接受合并请求 不再发布新版本 2、Hystrix重要概念1、服务降级1、操作服务器忙，请稍后再试，不让客户端等待并立刻返回一个友好提示，fallback 2、哪些情况会出发降级 程序运行异常 超时 服务熔断触发服务降级 线程池/信号量打满也会导致服务降级 2、服务熔断类比保险丝达到最大服务访问后，直接拒绝访问，拉闸限电，然后调用服务降级的方法并返回友好提示 就是保险丝：服务的降级-&gt;进而熔断-&gt;恢复调用链路 3、服务限流秒杀高并发等操作，严禁一窝蜂的过来拥挤，大家排队，一秒钟N个，有序进行 3、hystrix案例1、构建1、建model新建cloud-provider-hystrix-payment8001 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-provider-hystrix-payment8001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--hystrix--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--eureka client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 8001 spring: application: name: cloud-provider-hystrix-payment eureka: client: register-with-eureka: true fetch-registry: true service-url: #defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka defaultZone: http://eureka7001.com:7001/eureka 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; @SpringBootApplication @EnableEurekaClient //本服务启动后会自动注册进eureka服务中 public class PaymentHystrixMain8001 { public static void main(String[] args) { SpringApplication.run (PaymentHystrixMain8001.class,args); } } 5、业务类1、servicepackage com.kk.springcloud.service.imp; import com.kk.springcloud.service.PaymentHystrixServoce; import org.springframework.stereotype.Service; import java.util.concurrent.TimeUnit; @Service public class PaymentHystrixServoceImpl implements PaymentHystrixServoce { /** * 正常访问，一切OK * * @param id * @return */ public String paymentInfo_OK(Integer id) { return \"线程池:\" + Thread.currentThread ( ).getName ( ) + \"paymentInfo_OK,id: \" + id + \"\\t\" + \"O(∩_∩)O\"; } /** * 超时访问，演示降级 * * @param id * @return */ public String paymentInfo_TimeOut(Integer id) { try { TimeUnit.SECONDS.sleep (3); } catch (InterruptedException e) { e.printStackTrace ( ); } return \"线程池:\" + Thread.currentThread ( ).getName ( ) + \"paymentInfo_TimeOut,id: \" + id + \"\\t\" + \"O(∩_∩)O，耗费3秒\"; } } 2、controllerpackage com.kk.springcloud.controller; import com.kk.springcloud.service.imp.PaymentHystrixServoceImpl; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; @RestController @Slf4j public class PaymentHystrixController { @Autowired private PaymentHystrixServoceImpl paymentService; @Value(\"${server.port}\") private String serverPort; @GetMapping(\"/payment/hystrix/ok/{id}\") public String paymentInfo_OK(@PathVariable(\"id\") Integer id) { String result = paymentService.paymentInfo_OK(id); log.info(\"****result: \"+result); return result; } @GetMapping(\"/payment/hystrix/timeout/{id}\") public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id) throws InterruptedException { String result = paymentService.paymentInfo_TimeOut(id); log.info(\"****result: \"+result); return result; } } 6、测试1、启动顺序先启动eureka，再启动hystrix 8001 2、访问 success的方法： http://localhost:8001/payment/hystrix/ok/1 每次调用耗费3 秒钟 http://localhost:8001/payment/hystrix/timeout/1 2、高并发测试上述在非高并发情形下，还能勉强满足 1、Jmeter压测测试1、开启Jmeter，来20000个并发压死8001，20000个请求都去访问paymentInfo_TimeOut服务 2、再来一个访问从3秒到不止3秒 http://localhost:8001/payment/hystrix/timeout/1 从秒回到延迟一秒多 http://localhost:8001/payment/hystrix/ok/1 3、看演示结果两个都在自己转圈圈 为什么会被卡死：tomcat的默认的工作线程数被打满 了，没有多余的线程来分解压力和处理。 2、Jmeter压测结论上面还是服务提供者8001自己测试，假如此时外部的消费者80也来访问，那消费者只能干等，最终导致消费端80不满意，服务端8001直接被拖死 3、看热闹不嫌弃事大，80新建加入cloud-consumer-feign-hystrix-order80 1、POM&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-consumer-feign-hystrix-order80&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--hystrix--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--eureka client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--一般基础通用配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 2、YMLserver: port: 80 eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ 3、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.openfeign.EnableFeignClients; @SpringBootApplication @EnableFeignClients public class OrderHystrixMain80 { public static void main(String[] args) { SpringApplication.run (OrderHystrixMain80.class,args); } } 4、业务类 service package com.kk.springcloud.service; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.stereotype.Component; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; @Component @FeignClient(value = \"CLOUD-PROVIDER-HYSTRIX-PAYMENT\") public interface PaymentHystrixService { @GetMapping(\"/payment/hystrix/ok/{id}\") String paymentInfo_OK(@PathVariable(\"id\") Integer id); @GetMapping(\"/payment/hystrix/timeout/{id}\") String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id); } controller package com.kk.springcloud.controller; import com.kk.springcloud.service.PaymentHystrixService; import lombok.extern.slf4j.Slf4j; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; @RestController @Slf4j public class OrderHystirxController { @Resource private PaymentHystrixService paymentHystrixService; @GetMapping(\"/consumer/payment/hystrix/ok/{id}\") public String paymentInfo_OK(@PathVariable(\"id\") Integer id) { String result = paymentHystrixService.paymentInfo_OK (id); return result; } @GetMapping(\"/consumer/payment/hystrix/timeout/{id}\") public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id) { String result = paymentHystrixService.paymentInfo_TimeOut (id); return result; } } 5、测试 需要启动的服务 url http://localhost/consumer/payment/hystrix/ok/1 6、高并发测试 2W个线程压8001 消费端80微服务再去访问正常的Ok微服务8001地址，http://localhost/consumer/payment/hystrix/ok/1 消费者80，o(╥﹏╥)o 要么转圈圈等待（2W个并发） 要么消费端报超时错误（20W个并发，冲垮） 3、故障现象和导致原因 8001同一层次的其它接口服务被困死，因为tomcat线程池里面的工作线程已经被挤占完毕 80此时调用8001，客户端访问响应缓慢，转圈圈 4、上诉结论正因为有上述故障或不佳表现，才有我们的降级/容错/限流等技术诞生 5、如何解决？解决的要求1、超时导致服务器变慢(转圈)超时不再等待 2、出错(宕机或程序运行出错)出错要有兜底（降级） 3、解决 对方服务(8001)超时了，调用者(80)不能一直卡死等待，必须有服务降级 对方服务(8001)down机了，调用者(80)不能一直卡死等待，必须有服务降级 对方服务(8001)OK，调用者(80)自己出故障或有自我要求（自己的等待时间小于服务提供者），自己处理降级 3-1实战：服务降级1、降级配置注解@HystrixCommand 2、8001先从自身找问题设置自身调用超时时间的峰值，峰值内可以正常运行，超过了需要有兜底的方法处理，作服务降级fallback。 3、8001fallback1、业务类启用1、代码8001（8002）PaymentServiceImpl @HystrixCommand(fallbackMethod = \"paymentInfo_TimeOutHandler\", commandProperties = { @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"3000\") }) ----------------------- public String paymentInfo_TimeOutHandler(Integer id) { return \"/(ㄒoㄒ)/调用支付接口超时或异常：\\t\" + \"\\t当前线程池名字\" + Thread.currentThread ( ).getName ( ); } package com.kk.springcloud.service.imp; import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand; import com.netflix.hystrix.contrib.javanica.annotation.HystrixProperty; import org.springframework.stereotype.Service; import java.util.concurrent.TimeUnit; @Service public class PaymentHystrixServoceImpl { /** * 正常访问，一切OK * * @param id * @return */ public String paymentInfo_OK(Integer id) { return \"线程池:\" + Thread.currentThread ( ).getName ( ) + \"paymentInfo_OK,id: \" + id + \"\\t\" + \"O(∩_∩)O\"; } /** * 超时访问，演示降级 * * @param id * @return */ @HystrixCommand(fallbackMethod = \"paymentInfo_TimeOutHandler\", commandProperties = { @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"3000\") }) public String paymentInfo_TimeOut(Integer id) { int age = 10/0; try { TimeUnit.SECONDS.sleep (3); } catch (InterruptedException e) { e.printStackTrace ( ); } return \"线程池:\" + Thread.currentThread ( ).getName ( ) + \"paymentInfo_TimeOut,id: \" + id + \"\\t\" + \"O(∩_∩)O，耗费3秒\"; } public String paymentInfo_TimeOutHandler(Integer id) { return \"/(ㄒoㄒ)/调用支付接口超时或异常：\\t\" + \"\\t当前线程池名字\" + Thread.currentThread ( ).getName ( ); } } 2、@HystrixCommand报异常后如何处理一旦调用服务方法失败并抛出了错误信息后，会自动调用@HystrixCommand标注好的 fallbackMethod调用类中的指定方法 2、主启动类激活添加新注解@EnableCircuitBreaker 3、制造问题：测试降级效果 上图故意制造两个异常： 1 int age = 10/0; 计算异常 2 我们能接受3秒钟，它运行5秒钟，超时异常。 当前服务不可用了，做服务降级，兜底的方案都是 paymentInfo_TimeOutHandler 无论是延迟指定时间还是异常，都会到对应方法降级 4、80fallback1、说明80订单微服务，也可以更好的保护自己，自己也依样画葫芦进行客户端降级保护 2、注意点我们自己配置过的热部署方式对java代码的改动明显，但对@HystrixCommand内属性的修改建议重启微服务 3、ymlfeign: hystrix: enabled: true server: port: 80 eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ feign: hystrix: enabled: true 4、主启动@EnableHystrix package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.hystrix.EnableHystrix; import org.springframework.cloud.openfeign.EnableFeignClients; @SpringBootApplication @EnableFeignClients @EnableHystrix public class OrderHystrixMain80 { public static void main(String[] args) { SpringApplication.run (OrderHystrixMain80.class,args); } } 5、业务类 @HystrixCommand(fallbackMethod = \"paymentTimeOutFallbackMethod\", commandProperties = { @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"1500\") }) ------------------ public String paymentTimeOutFallbackMethod(@PathVariable(\"id\") Integer id) { return \"我是消费者80,对方支付系统繁忙请10秒钟后再试或者自己运行出错请检查自己,o(╥﹏╥)o\"; } package com.kk.springcloud.controller; import com.kk.springcloud.service.PaymentHystrixService; import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand; import com.netflix.hystrix.contrib.javanica.annotation.HystrixProperty; import lombok.extern.slf4j.Slf4j; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; @RestController @Slf4j public class OrderHystirxController { @Resource private PaymentHystrixService paymentHystrixService; @GetMapping(\"/consumer/payment/hystrix/ok/{id}\") @HystrixCommand(fallbackMethod = \"paymentTimeOutFallbackMethod\", commandProperties = { @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"1500\") }) public String paymentInfo_OK(@PathVariable(\"id\") Integer id) { String result = paymentHystrixService.paymentInfo_OK (id); return result; } public String paymentTimeOutFallbackMethod(@PathVariable(\"id\") Integer id) { return \"我是消费者80,对方支付系统繁忙请10秒钟后再试或者自己运行出错请检查自己,o(╥﹏╥)o\"; } @GetMapping(\"/consumer/payment/hystrix/timeout/{id}\") public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id) { String result = paymentHystrixService.paymentInfo_TimeOut (id); return result; } } 6、测试url：http://localhost//consumer/payment/hystrix/ok/1 5、目前问题 每个业务方法对应一个兜底的方法，代码膨胀 统一和自定义的分开 6、问题解决1、每个方法配置一个？？？膨胀（feign接口系列）@DefaultProperties(defaultFallback = \"\") 每个方法配置一个服务降级方法，技术上可以，实际上傻X 除了个别重要核心业务有专属，其它普通的可以通过@DefaultProperties(defaultFallback = “”) 统一跳转到统一处理结果页面 通用的和独享的各自分开，避免了代码膨胀，合理减少了代码量，O(∩_∩)O哈哈~ ----------------- @DefaultProperties(defaultFallback = \"payment_Global_FallbackMethod\") ----------------- @HystrixCommand //加了@DefaultProperties属性注解，并且没有写具体方法名字，就用统一全局的 ----------------- public String payment_Global_FallbackMethod() { return \"Global异常处理信息，请稍后再试，/(ㄒoㄒ)/~~\"; } package com.kk.springcloud.controller; import com.kk.springcloud.service.PaymentHystrixService; import com.netflix.hystrix.contrib.javanica.annotation.DefaultProperties; import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand; import com.netflix.hystrix.contrib.javanica.annotation.HystrixProperty; import lombok.extern.slf4j.Slf4j; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; @RestController @Slf4j @DefaultProperties(defaultFallback = \"payment_Global_FallbackMethod\") public class OrderHystirxController { @Resource private PaymentHystrixService paymentHystrixService; @GetMapping(\"/consumer/payment/hystrix/ok/{id}\") @HystrixCommand(fallbackMethod = \"paymentTimeOutFallbackMethod\", commandProperties = { @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"1500\") }) public String paymentInfo_OK(@PathVariable(\"id\") Integer id) { String result = paymentHystrixService.paymentInfo_OK (id); return result; } public String paymentTimeOutFallbackMethod(@PathVariable(\"id\") Integer id) { return \"我是消费者80,对方支付系统繁忙请10秒钟后再试或者自己运行出错请检查自己,o(╥﹏╥)o\"; } @GetMapping(\"/consumer/payment/hystrix/timeout/{id}\") @HystrixCommand //加了@DefaultProperties属性注解，并且没有写具体方法名字，就用统一全局的 public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id) { String result = paymentHystrixService.paymentInfo_TimeOut (id); return result; } public String payment_Global_FallbackMethod() { return \"Global异常处理信息，请稍后再试，/(ㄒoㄒ)/~~\"; } } 2、和业务逻辑混一起？？？混乱原因：服务降级，客户端去调用服务端，碰上服务端宕机或关闭 本次案例服务降级处理是在客户端80实现完成的，与服务端8001没有关系只需要为Feign客户端定义的接口添加一个服务降级处理的实现类即可实现解耦 未来我们要面对的异常 运行 超时 宕机 根据cloud-consumer-feign-hystrix-order80已经有的PaymentHystrixService接口，重新新建一个类(PaymentFallbackService)实现该接口，统一为接口里面的方法进行异常处理 service统一处理异常业务 package com.kk.springcloud.service.impl; import com.kk.springcloud.service.PaymentHystrixService; import org.springframework.stereotype.Component; @Component public class PaymentFallbackService implements PaymentHystrixService { // 如果下游的服务接口挂掉，则进入这个实现类 @Override public String paymentInfo_OK(Integer id) { return \"服务调用失败，提示来自：cloud-consumer-feign-order80\"; } @Override public String paymentInfo_TimeOut(Integer id) { return \"服务调用失败，提示来自：cloud-consumer-feign-order80\"; } } yml # 用于服务降级 在注解@FeignClient中添加fallbackFactory属性值 feign: hystrix: enabled: true #在Feign中开启Hystrix openFeign：调用下游的接口 fallback = PaymentFallbackService.class package com.kk.springcloud.service; import com.kk.springcloud.service.impl.PaymentFallbackService; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.stereotype.Component; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; @Component @FeignClient(value = \"CLOUD-PROVIDER-HYSTRIX-PAYMENT\",fallback = PaymentFallbackService.class) public interface PaymentHystrixService { @GetMapping(\"/payment/hystrix/ok/{id}\") String paymentInfo_OK(@PathVariable(\"id\") Integer id); @GetMapping(\"/payment/hystrix/timeout/{id}\") String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id); } 测试：http://localhost/consumer/payment/hystrix/ok/1 正常访问： 故意关闭微服务8001后访问： 3-2实战：服务熔断1、断路器一句话就是家里的保险丝 2、熔断是什么熔断机制概述：熔断机制是应对雪崩效应的一种微服务链路保护机制。当扇出链路的某个微服务出错不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回错误的响应信息。当检测到该节点微服务调用响应正常后，恢复调用链路。 在Spring Cloud框架里，熔断机制通过Hystrix实现。Hystrix会监控微服务间调用的状况，当失败的调用到一定阈值，缺省是5秒内20次调用失败，就会启动熔断机制。熔断机制的注解是@HystrixCommand。 3、实操修改cloud-provider-hystrix-payment8001 1、PaymentService//服务熔断 @HystrixCommand(fallbackMethod = \"paymentCircuitBreaker_fallback\", commandProperties = { @HystrixProperty(name = \"circuitBreaker.enabled\", value = \"true\"),//是否开启断路器 @HystrixProperty(name = \"circuitBreaker.requestVolumeThreshold\", value = \"10\"),//请求次数 @HystrixProperty(name = \"circuitBreaker.sleepWindowInMilliseconds\", value = \"10000\"),//时间范围 @HystrixProperty(name = \"circuitBreaker.errorThresholdPercentage\", value = \"60\"),//失败率达到多少后跳闸 }) public String paymentCircuitBreaker(@PathVariable(\"id\") Integer id) { if (id &lt; 0) { throw new RuntimeException (\"******id 不能负数\"); } String serialNumber = IdUtil.simpleUUID ( ); return Thread.currentThread ( ).getName ( ) + \"\\t\" + \"调用成功，流水号: \" + serialNumber; } public String paymentCircuitBreaker_fallback(@PathVariable(\"id\") Integer id) { return \"id 不能负数，请稍后再试，/(ㄒoㄒ)/~~ id: \" + id; } 2、PaymentController@GetMapping(\"/payment/circuit/{id}\") public String paymentCircuitBreaker(@PathVariable(\"id\") Integer id) { String result = paymentService.paymentCircuitBreaker (id); log.info (\"****result: \" + result); return result; } 4、测试正确：http://localhost:8001/payment/circuit/1 错误：http://localhost:8001/payment/circuit/-1 5、原理(小总结)1、熔断类型 熔断打开 请求不再进行调用当前服务，内部设置时钟一般为MTTR（平均故障处理时间)，当打开时长达到所设时钟则进入半熔断状态 熔断关闭 熔断关闭不会对服务进行熔断 熔断半开 部分请求根据规则调用当前服务，如果请求成功且符合规则则认为当前服务恢复正常，关闭熔断 2、官网断路器流程图1、断路器在什么情况下开始起作用涉及到断路器的三个重要参数：快照时间窗、请求总数阀值、错误百分比阀值。1：快照时间窗：断路器确定是否打开需要统计一些请求和错误数据，而统计的时间范围就是快照时间窗，默认为最近的10秒。 2：请求总数阀值：在快照时间窗内，必须满足请求总数阀值才有资格熔断。默认为20，意味着在10秒内，如果该hystrix命令的调用次数不足20次，即使所有的请求都超时或其他原因失败，断路器都不会打开。 3：错误百分比阀值：当请求总数在快照时间窗内超过了阀值，比如发生了30次调用，如果在这30次调用中，有15次发生了超时异常，也就是超过50%的错误百分比，在默认设定50%阀值情况下，这时候就会将断路器打开 2、断路器开启或者关闭的条件 当满足一定的阀值的时候（默认10秒内超过20个请求次数） 当失败率达到一定的时候（默认10秒内超过50%的请求失败） 到达以上阀值，断路器将会开启 当开启的时候，所有请求都不会进行转发 一段时间之后（默认是5秒），这个时候断路器是半开状态，会让其中一个请求进行转发。如果成功，断路器会关闭，若失败，继续开启。重复4和5 3、断路器打开之后1：再有请求调用的时候，将不会调用主逻辑，而是直接调用降级fallback。通过断路器，实现了自动地发现错误并将降级逻辑切换为主逻辑，减少响应延迟的效果。 2：原来的主逻辑要如何恢复呢？对于这一问题，hystrix也为我们实现了自动恢复功能。当断路器打开，对主逻辑进行熔断之后，hystrix会启动一个休眠时间窗，在这个时间窗内，降级逻辑是临时的成为主逻辑，当休眠时间窗到期，断路器将进入半开状态，释放一次请求到原来的主逻辑上，如果此次请求正常返回，那么断路器将继续闭合，主逻辑恢复，如果这次请求依然有问题，断路器继续进入打开状态，休眠时间窗重新计时。 4、★ All配置//========================All @HystrixCommand(fallbackMethod = \"str_fallbackMethod\", groupKey = \"strGroupCommand\", commandKey = \"strCommand\", threadPoolKey = \"strThreadPool\", commandProperties = { // 设置隔离策略，THREAD 表示线程池 SEMAPHORE：信号池隔离 @HystrixProperty(name = \"execution.isolation.strategy\", value = \"THREAD\"), // 当隔离策略选择信号池隔离的时候，用来设置信号池的大小（最大并发数） @HystrixProperty(name = \"execution.isolation.semaphore.maxConcurrentRequests\", value = \"10\"), // 配置命令执行的超时时间 @HystrixProperty(name = \"execution.isolation.thread.timeoutinMilliseconds\", value = \"10\"), // 是否启用超时时间 @HystrixProperty(name = \"execution.timeout.enabled\", value = \"true\"), // 执行超时的时候是否中断 @HystrixProperty(name = \"execution.isolation.thread.interruptOnTimeout\", value = \"true\"), // 执行被取消的时候是否中断 @HystrixProperty(name = \"execution.isolation.thread.interruptOnCancel\", value = \"true\"), // 允许回调方法执行的最大并发数 @HystrixProperty(name = \"fallback.isolation.semaphore.maxConcurrentRequests\", value = \"10\"), // 服务降级是否启用，是否执行回调函数 @HystrixProperty(name = \"fallback.enabled\", value = \"true\"), // 是否启用断路器 @HystrixProperty(name = \"circuitBreaker.enabled\", value = \"true\"), // 该属性用来设置在滚动时间窗中，断路器熔断的最小请求数。例如，默认该值为 20 的时候， // 如果滚动时间窗（默认10秒）内仅收到了19个请求， 即使这19个请求都失败了，断路器也不会打开。 @HystrixProperty(name = \"circuitBreaker.requestVolumeThreshold\", value = \"20\"), // 该属性用来设置在滚动时间窗中，表示在滚动时间窗中，在请求数量超过 // circuitBreaker.requestVolumeThreshold 的情况下，如果错误请求数的百分比超过50, // 就把断路器设置为 \"打开\" 状态，否则就设置为 \"关闭\" 状态。 @HystrixProperty(name = \"circuitBreaker.errorThresholdPercentage\", value = \"50\"), // 该属性用来设置当断路器打开之后的休眠时间窗。 休眠时间窗结束之后， // 会将断路器置为 \"半开\" 状态，尝试熔断的请求命令，如果依然失败就将断路器继续设置为 \"打开\" 状态， // 如果成功就设置为 \"关闭\" 状态。 @HystrixProperty(name = \"circuitBreaker.sleepWindowinMilliseconds\", value = \"5000\"), // 断路器强制打开 @HystrixProperty(name = \"circuitBreaker.forceOpen\", value = \"false\"), // 断路器强制关闭 @HystrixProperty(name = \"circuitBreaker.forceClosed\", value = \"false\"), // 滚动时间窗设置，该时间用于断路器判断健康度时需要收集信息的持续时间 @HystrixProperty(name = \"metrics.rollingStats.timeinMilliseconds\", value = \"10000\"), // 该属性用来设置滚动时间窗统计指标信息时划分\"桶\"的数量，断路器在收集指标信息的时候会根据 // 设置的时间窗长度拆分成多个 \"桶\" 来累计各度量值，每个\"桶\"记录了一段时间内的采集指标。 // 比如 10 秒内拆分成 10 个\"桶\"收集这样，所以 timeinMilliseconds 必须能被 numBuckets 整除。否则会抛异常 @HystrixProperty(name = \"metrics.rollingStats.numBuckets\", value = \"10\"), // 该属性用来设置对命令执行的延迟是否使用百分位数来跟踪和计算。如果设置为 false, 那么所有的概要统计都将返回 -1。 @HystrixProperty(name = \"metrics.rollingPercentile.enabled\", value = \"false\"), // 该属性用来设置百分位统计的滚动窗口的持续时间，单位为毫秒。 @HystrixProperty(name = \"metrics.rollingPercentile.timeInMilliseconds\", value = \"60000\"), // 该属性用来设置百分位统计滚动窗口中使用 “ 桶 ”的数量。 @HystrixProperty(name = \"metrics.rollingPercentile.numBuckets\", value = \"60000\"), // 该属性用来设置在执行过程中每个 “桶” 中保留的最大执行次数。如果在滚动时间窗内发生超过该设定值的执行次数， // 就从最初的位置开始重写。例如，将该值设置为100, 滚动窗口为10秒，若在10秒内一个 “桶 ”中发生了500次执行， // 那么该 “桶” 中只保留 最后的100次执行的统计。另外，增加该值的大小将会增加内存量的消耗，并增加排序百分位数所需的计算时间。 @HystrixProperty(name = \"metrics.rollingPercentile.bucketSize\", value = \"100\"), // 该属性用来设置采集影响断路器状态的健康快照（请求的成功、 错误百分比）的间隔等待时间。 @HystrixProperty(name = \"metrics.healthSnapshot.intervalinMilliseconds\", value = \"500\"), // 是否开启请求缓存 @HystrixProperty(name = \"requestCache.enabled\", value = \"true\"), // HystrixCommand的执行和事件是否打印日志到 HystrixRequestLog 中 @HystrixProperty(name = \"requestLog.enabled\", value = \"true\"), }, threadPoolProperties = { // 该参数用来设置执行命令线程池的核心线程数，该值也就是命令执行的最大并发量 @HystrixProperty(name = \"coreSize\", value = \"10\"), // 该参数用来设置线程池的最大队列大小。当设置为 -1 时，线程池将使用 SynchronousQueue 实现的队列， // 否则将使用 LinkedBlockingQueue 实现的队列。 @HystrixProperty(name = \"maxQueueSize\", value = \"-1\"), // 该参数用来为队列设置拒绝阈值。 通过该参数， 即使队列没有达到最大值也能拒绝请求。 // 该参数主要是对 LinkedBlockingQueue 队列的补充,因为 LinkedBlockingQueue // 队列不能动态修改它的对象大小，而通过该属性就可以调整拒绝请求的队列大小了。 @HystrixProperty(name = \"queueSizeRejectionThreshold\", value = \"5\"), } ) public String strConsumer() { return \"hello 2020\"; } public String str_fallbackMethod() { return \"*****fall back str_fallbackMethod\"; } 3-3实战：服务限流采用alibaba的Sentinel，后面扩展 4、hystrix工作流程 1 创建 HystrixCommand（用在依赖的服务返回单个操作结果的时候） 或 HystrixObserableCommand（用在依赖的服务返回多个操作结果的时候） 对象。2 命令执行。其中 HystrixComand 实现了下面前两种执行方式；而 HystrixObservableCommand 实现了后两种执行方式：execute()：同步执行，从依赖的服务返回一个单一的结果对象， 或是在发生错误的时候抛出异常。queue()：异步执行， 直接返回 一个Future对象， 其中包含了服务执行结束时要返回的单一结果对象。observe()：返回 Observable 对象，它代表了操作的多个结果，它是一个 Hot Obserable（不论 “事件源” 是否有 “订阅者”，都会在创建后对事件进行发布，所以对于 Hot Observable 的每一个 “订阅者” 都有可能是从 “事件源” 的中途开始的，并可能只是看到了整个操作的局部过程）。toObservable()： 同样会返回 Observable 对象，也代表了操作的多个结果，但它返回的是一个Cold Observable（没有 “订阅者” 的时候并不会发布事件，而是进行等待，直到有 “订阅者” 之后才发布事件，所以对于 Cold Observable 的订阅者，它可以保证从一开始看到整个操作的全部过程）。3 若当前命令的请求缓存功能是被启用的， 并且该命令缓存命中， 那么缓存的结果会立即以 Observable 对象的形式 返回。4 检查断路器是否为打开状态。如果断路器是打开的，那么Hystrix不会执行命令，而是转接到 fallback 处理逻辑（第 8 步）；如果断路器是关闭的，检查是否有可用资源来执行命令（第 5 步）。5 线程池/请求队列/信号量是否占满。如果命令依赖服务的专有线程池和请求队列，或者信号量（不使用线程池的时候）已经被占满， 那么 Hystrix 也不会执行命令， 而是转接到 fallback 处理逻辑（第8步）。6 Hystrix 会根据我们编写的方法来决定采取什么样的方式去请求依赖服务。HystrixCommand.run() ：返回一个单一的结果，或者抛出异常。HystrixObservableCommand.construct()： 返回一个Observable 对象来发射多个结果，或通过 onError 发送错误通知。7 Hystrix会将 “成功”、”失败”、”拒绝”、”超时” 等信息报告给断路器， 而断路器会维护一组计数器来统计这些数据。断路器会使用这些统计数据来决定是否要将断路器打开，来对某个依赖服务的请求进行 “熔断/短路”。8 当命令执行失败的时候， Hystrix 会进入 fallback 尝试回退处理， 我们通常也称该操作为 “服务降级”。而能够引起服务降级处理的情况有下面几种：第4步： 当前命令处于”熔断/短路”状态，断路器是打开的时候。第5步： 当前命令的线程池、 请求队列或 者信号量被占满的时候。第6步：HystrixObservableCommand.construct() 或 HystrixCommand.run() 抛出异常的时候。9 当Hystrix命令执行成功之后， 它会将处理结果直接返回或是以Observable 的形式返回。 tips：如果我们没有为命令实现降级逻辑或者在降级处理逻辑中抛出了异常， Hystrix 依然会返回一个 Observable 对象， 但是它不会发射任何结果数据， 而是通过 onError 方法通知命令立即中断请求，并通过onError()方法将引起命令失败的异常发送给调用者。 5、服务监控HystrixDashboard1、概述除了隔离依赖服务的调用以外，Hystrix还提供了准实时的调用监控（Hystrix Dashboard），Hystrix会持续地记录所有通过Hystrix发起的请求的执行信息，并以统计报表和图形的形式展示给用户，包括每秒执行多少请求多少成功，多少失败等。Netflix通过hystrix-metrics-event-stream项目实现了对以上指标的监控。Spring Cloud也提供了Hystrix Dashboard的整合，对监控内容转化成可视化界面。 2、仪表盘90011、建model新建cloud-consumer-hystrix-dashboard9001 2、POM&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt; &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-consumer-hystrix-dashboard9001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 9001 4、@EnableHystrixDashboardpackage com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.hystrix.dashboard.EnableHystrixDashboard; @SpringBootApplication @EnableHystrixDashboard public class HystrixDashboardMain9001 { public static void main(String[] args) { SpringApplication.run (HystrixDashboardMain9001.class,args); } } 5、所有Provider微服务提供类(8001/8002/8003)都需要监控依赖配置 &lt;!-- actuator监控信息完善 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; 6、进入面板http://localhost:9001/hystrix 3、断路器演示(服务监控hystrixDashboard)1、修改cloud-provider-hystrix-payment80011、注意新版本注意:新版本Hystrix需要在主启动类MainAppHystrix8001中指定监控路径 报错信息：Unable to connect to Command Metric Stream. /** *此配置是为了服务监控而配置，与服务容错本身无关，springcloud升级后的坑 *ServletRegistrationBean因为springboot的默认路径不是\"/hystrix.stream\"， *只要在自己的项目里配置上下面的servlet就可以了 */ @Bean public ServletRegistrationBean getServlet() { HystrixMetricsStreamServlet streamServlet = new HystrixMetricsStreamServlet(); ServletRegistrationBean registrationBean = new ServletRegistrationBean(streamServlet); registrationBean.setLoadOnStartup(1); registrationBean.addUrlMappings(\"/hystrix.stream\"); registrationBean.setName(\"HystrixMetricsStreamServlet\"); return registrationBean; } package com.kk.springcloud; import com.netflix.hystrix.contrib.metrics.eventstream.HystrixMetricsStreamServlet; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.boot.web.servlet.ServletRegistrationBean; import org.springframework.cloud.client.circuitbreaker.EnableCircuitBreaker; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; import org.springframework.context.annotation.Bean; @SpringBootApplication @EnableEurekaClient //本服务启动后会自动注册进eureka服务中 @EnableCircuitBreaker public class PaymentHystrixMain8001 { public static void main(String[] args) { SpringApplication.run (PaymentHystrixMain8001.class, args); } /** * 此配置是为了服务监控而配置，与服务容错本身无关，springcloud升级后的坑 * ServletRegistrationBean因为springboot的默认路径不是\"/hystrix.stream\"， * 只要在自己的项目里配置上下面的servlet就可以了 */ @Bean public ServletRegistrationBean getServlet() { HystrixMetricsStreamServlet streamServlet = new HystrixMetricsStreamServlet ( ); ServletRegistrationBean registrationBean = new ServletRegistrationBean (streamServlet); registrationBean.setLoadOnStartup (1); registrationBean.addUrlMappings (\"/hystrix.stream\"); registrationBean.setName (\"HystrixMetricsStreamServlet\"); return registrationBean; } } 2、监控测试1、9001监控8001http://localhost:8001/hystrix.stream 1：Delay：该参数用来控制服务器上轮询监控信息的延迟时间，默认为2000毫秒，可以通过配置该属性来降低客户端的网络和CPU消耗。 2：Title：该参数对应了头部标题Hystrix Stream之后的内容，默认会使用具体监控实例的URL，可以通过配置该信息来展示更合适的标题。 2、访问正确：http://localhost:8001/payment/circuit/1 错误：http://localhost:8001/payment/circuit/-1 3、★ 如何看仪表盘 4、搞懂一个才能看懂复杂的","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"netflix","slug":"netflix","permalink":"https://mykkto.github.io/tags/netflix/"},{"name":"断路器","slug":"断路器","permalink":"https://mykkto.github.io/tags/%E6%96%AD%E8%B7%AF%E5%99%A8/"},{"name":"Hystrix","slug":"Hystrix","permalink":"https://mykkto.github.io/tags/Hystrix/"}],"author":"mykk"},{"title":"SpringCloud-OpenFeign远程调用服务","slug":"03-java分布式/01springcloud/06_SpringCloud_OpenFeign","date":"2022-01-21T13:32:13.000Z","updated":"2022-05-22T15:01:03.890Z","comments":true,"path":"posts/a723ac51.html","link":"","permalink":"https://mykkto.github.io/posts/a723ac51.html","excerpt":"","text":"1、概述1、是什么https://github.com/spring-cloud/spring-cloud-openfeign Feign是一个声明式的Web服务客户端，让编写Web服务客户端变得非常容易，只需创建一个接口并在接口上添加注解即可 2、能干嘛1、 Feign能干什么Feign旨在使编写Java Http客户端变得更容易。前面在使用Ribbon+RestTemplate时，利用RestTemplate对http请求的封装处理，形成了一套模版化的调用方法。但是在实际开发中，由于对服务依赖的调用可能不止一处，往往一个接口会被多处调用，所以通常都会针对每个微服务自行封装一些客户端类来包装这些依赖服务的调用。所以，Feign在此基础上做了进一步封装，由他来帮助我们定义和实现依赖服务接口的定义。在Feign的实现下，我们只需创建一个接口并使用注解的方式来配置它(以前是Dao接口上面标注Mapper注解,现在是一个微服务接口上面标注一个Feign注解即可)，即可完成对服务提供方的接口绑定，简化了使用Spring cloud Ribbon时，自动封装服务调用客户端的开发量。 2、Feign集成了Ribbon利用Ribbon维护了Payment的服务列表信息，并且通过轮询实现了客户端的负载均衡。而与Ribbon不同的是，通过feign只需要定义服务绑定接口且以声明式的方法，优雅而简单的实现了服务调用 3、区别1、feignFeign是Spring Cloud组件中的一个轻量级RESTful的HTTP服务客户端Feign内置了Ribbon，用来做客户端负载均衡，去调用服务注册中心的服务。Feign的使用方式是：使用Feign的注解定义接口，调用这个接口，就可以调用服务注册中心的服务 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt; &lt;/dependency&gt; 2、openfeignOpenFeign是Spring Cloud 在Feign的基础上支持了SpringMVC的注解，如@RequesMapping等等。OpenFeign的@FeignClient可以解析SpringMVC的@RequestMapping注解下的接口，并通过动态代理的方式产生实现类，实现类中做负载均衡并调用其他服务 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; 2、OpenFeign使用步骤1、建model新建cloud-consumer-feign-order80 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-consumer-feign-order80&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--eureka client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--一般基础通用配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 80 eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.openfeign.EnableFeignClients; @SpringBootApplication @EnableFeignClients public class OrderFeignMain80 { public static void main(String[] args) { SpringApplication.run (OrderFeignMain80.class,args); } } 5、业务类1、新建PaymentFeignService接口并新增注解@FeignClientpackage com.kk.springcloud.service; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.stereotype.Component; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; @Component @FeignClient(value = \"CLOUD-PAYMENT-SERVICE\") public interface PaymentFeignService { @GetMapping(value = \"/payment/get/{id}\") CommonResult&lt;Payment&gt; getPaymentById(@PathVariable(\"id\") Long id); } 2、控制层Controllerpackage com.kk.springcloud.controller; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import com.kk.springcloud.service.PaymentFeignService; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; @RestController public class OrderFeignController { @Resource private PaymentFeignService paymentFeignService; @GetMapping(value = \"consumer/payment/get/{id}\") public CommonResult&lt;Payment&gt; getPaymentById(@PathVariable(\"id\") Long id){ return paymentFeignService.getPaymentById (id); } } 6、测试1、启动顺序 启动 7001/7002 eureka集群 启动 8001/8002 生产者集群 启动 OpenFeign:80 消费者 2、访问http://localhost/consumer/payment/get/1 3、Feign自带负载均衡配置项 7、小结 3、OpenFeign超时控制1、模拟超时超时设置，故意设置超时演示出错情况 1、服务提供方8001故意写暂停程序com.kk.springcloud.controller.PaymentController; @GetMapping(value = \"/payment/feign/timeout\") public String paymentFeignTimeOut() { System.out.println (\"*****paymentFeignTimeOut from port: \" + serverPort); //暂停几秒钟线程 try { TimeUnit.SECONDS.sleep (3); } catch (InterruptedException e) { e.printStackTrace ( ); } return serverPort; } 2、服务消费方80添加超时方法PaymentFeignServicecom.kk.springcloud.service.PaymentFeignService @GetMapping(value = \"/payment/feign/timeout\") String paymentFeignTimeOut(); 3、服务消费方80添加超时方法OrderFeignControllercom.kk.springcloud.controller.OrderFeignController @GetMapping(value = \"/consumer/payment/feign/timeout\") public String paymentFeignTimeOut() { return paymentFeignService.paymentFeignTimeOut ( ); } 4、测试url：http://localhost/consumer/payment/feign/timeout 5、小结OpenFeign默认等待1秒钟，超过后报错 2、是什么1、概述默认Feign客户端只等待一秒钟，但是服务端处理需要超过1秒钟，导致Feign客户端不想等待了，直接返回报错。为了避免这样的情况，有时候我们需要设置Feign客户端的超时控制。 2、默认支持Ribbon 3、超时时间配置#设置feign客户端超时时间(OpenFeign默认支持ribbon) ribbon: #指的是建立连接所用的时间，适用于网络状况正常的情况下,两端连接所用的时间 ReadTimeout: 5000 #指的是建立连接后从服务器读取到可用资源所用的时间 ConnectTimeout: 5000 4、OpenFeign日志打印功能1、是什么Feign 提供了日志打印功能，我们可以通过配置来调整日志级别，从而了解 Feign 中 Http 请求的细节。说白了就是对Feign接口的调用情况进行监控和输出 2、日志级别 NONE：默认的，不显示任何日志； BASIC：仅记录请求方法、URL、响应状态码及执行时间； HEADERS：除了 BASIC 中定义的信息之外，还有请求和响应的头信息； FULL：除了 HEADERS 中定义的信息之外，还有请求和响应的正文及元数据。 3、配置日志 beanpackage com.kk.springcloud.config; import feign.Logger; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class OpenFeignConfig { @Configuration public class FeignConfig { @Bean Logger.Level feignLoggerLevel() { return Logger.Level.FULL; } } } 4、yml中配置logging: level: # feign日志以什么级别监控哪个接口 com.kk.springcloud.service.PaymentFeignService: debug server: port: 80 eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ #设置feign客户端超时时间(OpenFeign默认支持ribbon) ribbon: #指的是建立连接所用的时间，适用于网络状况正常的情况下,两端连接所用的时间 ReadTimeout: 5000 #指的是建立连接后从服务器读取到可用资源所用的时间 ConnectTimeout: 5000 logging: level: # feign日志以什么级别监控哪个接口 com.kk.springcloud.service.PaymentFeignService: debug 5、后台启动查看","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"netflix","slug":"netflix","permalink":"https://mykkto.github.io/tags/netflix/"},{"name":"远程调用服务","slug":"远程调用服务","permalink":"https://mykkto.github.io/tags/%E8%BF%9C%E7%A8%8B%E8%B0%83%E7%94%A8%E6%9C%8D%E5%8A%A1/"},{"name":"openfeign","slug":"openfeign","permalink":"https://mykkto.github.io/tags/openfeign/"}],"author":"mykk"},{"title":"SpringCloud- Ribbon负载均衡服务","slug":"03-java分布式/01springcloud/05_SpringCloud_Ribbon","date":"2022-01-17T14:42:11.000Z","updated":"2022-05-22T15:01:03.890Z","comments":true,"path":"posts/9091e07b.html","link":"","permalink":"https://mykkto.github.io/posts/9091e07b.html","excerpt":"","text":"1、概述1、是什么 Spring Cloud Ribbon是基于Netflix Ribbon实现的一套客户端负载均衡的工具。 简单的说，Ribbon是Netflix发布的开源项目，主要功能是提供客户端的软件负载均衡算法和服务调用。Ribbon客户端组件提供一系列完善的配置项如连接超时，重试等。简单的说，就是在配置文件中列出Load Balancer（简称LB）后面所有的机器，Ribbon会自动的帮助你基于某种规则（如简单轮询，随机连接等）去连接这些机器。我们很容易使用Ribbon实现自定义的负载均衡算法。 2、官网资料1、文档https://github.com/Netflix/ribbon/wiki/Getting-Started 2、Ribbon目前也进入维护模式 未来替换方案： 3、能干吗1、LB（负载均衡）简单的说就是将用户的请求平摊的分配到多个服务上，从而达到系统的HA（高可用）。常见的负载均衡有软件Nginx，LVS，硬件 F5等。 总结：Ribbon = 负载均衡+RestTemplate调用 2、区别（ribbon VS nginx） Ribbon本地负载均衡，在调用微服务接口时候，会在注册中心上获取注册信息服务列表之后缓存到JVM本地，从而在本地实现RPC远程服务调用技术。 3、划分1、集中式LB 即在服务的消费方和提供方之间使用独立的LB设施(可以是硬件，如F5, 也可以是软件，如nginx), 由该设施负责把访问请求通过某种策略转发至服务的提供方； 2、进程内LB 将LB逻辑集成到消费方，消费方从服务注册中心获知有哪些地址可用，然后自己再从这些地址中选择出一个合适的服务器。 Ribbon就属于进程内LB，它只是一个类库，集成于消费方进程，消费方通过它来获取到服务提供方的地址。 2、Ribbon案例1、架构说明 Ribbon在工作时分成两步 第一步先选择 EurekaServer ,它优先选择在同一个区域内负载较少的server. 第二步再根据用户指定的策略，在从server取到的服务注册列表中选择一个地址。其中Ribbon提供了多种策略：比如轮询、随机和根据响应时间加权。 总结：Ribbon其实就是一个软负载均衡的客户端组件，他可以和其他所需请求的客户端结合使用，和eureka结合只是其中的一个实例。 2、POM1、坐标&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; 2、eureka-client 自带 ribbon证明如下： 可以看到spring-cloud-starter-netflix-eureka-client 确实引入了Ribbon 3、二说RestTemplate的使用1、官网https://docs.spring.io/spring-framework/docs/5.2.2.RELEASE/javadoc-api/org/springframework/web/client/RestTemplate.html 2、getForObject方法/getForEntity（读） 返回对象为响应体中数据转化成的对象，基本上可以理解为Json 返回对象为ResponseEntity对象，包含了响应中的一些重要信息，比如响应头、响应状态码、响应体等 3、postForObject/postForEntity(写)写一个单元测试用例，测试用例的内容是向指定的URL提交一个Post(帖子). @Test void testSimple() { // 请求地址 String url = \"http://jsonplaceholder.typicode.com/posts\"; // 要发送的数据对象 PostDTO postDTO = new PostDTO(); postDTO.setUserId(110); postDTO.setTitle(\"zimug 发布文章\"); postDTO.setBody(\"zimug 发布文章 测试内容\"); // 发送post请求，并输出结果 PostDTO result = restTemplate.postForObject(url, postDTO, PostDTO.class); System.out.println(result); } 上面的所有的postForObject请求传参方法，postForEntity都可以使用，使用方法上也几乎是一致的，只是在返回结果接收的时候略有差别。使用ResponseEntity&lt;T&gt; responseEntity来接收响应结果。用responseEntity.getBody()获取响应体。响应体内容同postForObject方法返回结果一致。剩下的这些响应信息就是postForEntity比postForObject多出来的内容 HttpStatus statusCode = responseEntity.getStatusCode(); 获取整体的响应状态信息 int statusCodeValue = responseEntity.getStatusCodeValue(); 获取响应码值 HttpHeaders headers = responseEntity.getHeaders(); 获取响应头等 @Test public void testEntityPoJo() { // 请求地址 String url = \"http://jsonplaceholder.typicode.com/posts\"; // 要发送的数据对象 PostDTO postDTO = new PostDTO(); postDTO.setUserId(110); postDTO.setTitle(\"zimug 发布文章\"); postDTO.setBody(\"zimug 发布文章 测试内容\"); // 发送post请求，并输出结果 ResponseEntity&lt;String&gt; responseEntity = restTemplate.postForEntity(url, postDTO, String.class); String body = responseEntity.getBody(); // 获取响应体 System.out.println(\"HTTP 响应body：\" + postDTO.toString()); //以下是postForEntity比postForObject多出来的内容 HttpStatus statusCode = responseEntity.getStatusCode(); // 获取响应码 int statusCodeValue = responseEntity.getStatusCodeValue(); // 获取响应码值 HttpHeaders headers = responseEntity.getHeaders(); // 获取响应头 System.out.println(\"HTTP 响应状态：\" + statusCode); System.out.println(\"HTTP 响应状态码：\" + statusCodeValue); System.out.println(\"HTTP Headers信息：\" + headers); } 4、GET请求方法&lt;T&gt; T getForObject(String url, Class&lt;T&gt; responseType, Object... uriVariables); &lt;T&gt; T getForObject(String url, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables); &lt;T&gt; T getForObject(URI url, Class&lt;T&gt; responseType); &lt;T&gt; ResponseEntity&lt;T&gt; getForEntity(String url, Class&lt;T&gt; responseType, Object... uriVariables); &lt;T&gt; ResponseEntity&lt;T&gt; getForEntity(String url, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables); &lt;T&gt; ResponseEntity&lt;T&gt; getForEntity(URI var1, Class&lt;T&gt; responseType); 5、POST请求方法 &lt;T&gt; T postForObject(String url, @Nullable Object request, Class&lt;T&gt; responseType, Object... uriVariables); &lt;T&gt; T postForObject(String url, @Nullable Object request, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables); &lt;T&gt; T postForObject(URI url, @Nullable Object request, Class&lt;T&gt; responseType); &lt;T&gt; ResponseEntity&lt;T&gt; postForEntity(String url, @Nullable Object request, Class&lt;T&gt; responseType, Object... uriVariables); &lt;T&gt; ResponseEntity&lt;T&gt; postForEntity(String url, @Nullable Object request, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables); &lt;T&gt; ResponseEntity&lt;T&gt; postForEntity(URI url, @Nullable Object request, Class&lt;T&gt; responseType); 3、Ribbon核心组件IRule1、IRule：根据特定算法中从服务列表中选取一个要访问的服务 轮询: com.netflix.loadbalancer.RoundRobinRule 随机: com.netflix.loadbalancer.RandomRule com.netflix.loadbalancer.RetryRule 先按照RoundRobinRule的策略获取服务，如果获取服务失败则在指定时间内会进行重试，获取可用的服务 WeightedResponseTimeRule 对RoundRobinRule的扩展，响应速度越快的实例选择权重越大，越容易被选择 BestAvailableRule 会先过滤掉由于多次访问故障而处于断路器跳闸状态的服务，然后选择一个并发量最小的服务 AvailabilityFilteringRule 先过滤掉故障实例，再选择并发较小的实例 ZoneAvoidanceRule 默认规则,复合判断server所在区域的性能和server的可用性选择服务器 2、案例修改cloud-consumer-order801、细节说明官方文档明确给出了警告：这个自定义配置类不能放在@ComponentScan所扫描的当前包下以及子包下，否则我们自定义的这个配置类就会被所有的Ribbon客户端所共享，达不到特殊化定制的目的了。 2、新建packagecom.kk.myrule 3、新建MySelfRule规则类package com.kk.myrule; import com.netflix.loadbalancer.IRule; import com.netflix.loadbalancer.RandomRule; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class MySelfRule { @Bean public IRule myRule() { return new RandomRule ( );//定义为随机 } } 4、主启动类添加@RibbonClient@RibbonClient(name = \"CLOUD-PAYMENT-SERVICE\",configuration=MySelfRule.class) 5、测试启动：（1）eureka（单个或者集群都行），（2）生产者8001（单个或者集群都行），（3）消费者80 http://localhost/consumer/payment/get/1 4、Ribbon负载均衡算法1、原理负载均衡算法：rest接口第几次请求数 % 服务器集群总数量 = 实际调用服务器位置下标 ，每次服务重启动后rest接口计数从1开始。 List instances = discoveryClient.getInstances(“CLOUD-PAYMENT-SERVICE”); 如： List [0] instances = 127.0.0.1:8002 List [1] instances = 127.0.0.1:8001 8001+ 8002 组合成为集群，它们共计2台机器，集群总数为2， 按照轮询算法原理： 当总请求数为1时： 1 % 2 =1 对应下标位置为1 ，则获得服务地址为127.0.0.1:8001当总请求数位2时： 2 % 2 =0 对应下标位置为0 ，则获得服务地址为127.0.0.1:8002当总请求数位3时： 3 % 2 =1 对应下标位置为1 ，则获得服务地址为127.0.0.1:8001当总请求数位4时： 4 % 2 =0 对应下标位置为0 ，则获得服务地址为127.0.0.1:8002如此类推…… 2、RoundRobinRule源码 这里不是死循环，而是自旋锁，compareAndSet（CAS操作，JUC中乐观锁的底层实现） 3、手写1、8001和8002分别加入 @Value(\"${server.port}\") private String serverPort; @GetMapping(value = \"/payment/lb\") public String getPaymentLB() { return serverPort; } 2、去掉注解@LoadBalanced 3、新建LoadBalancer接口package com.kk.springcloud.lb; import org.springframework.cloud.client.ServiceInstance; import java.util.List; public interface LoadBalancer { ServiceInstance instances(List&lt;ServiceInstance&gt; serviceInstances); } 4、新建MyLBpackage com.kk.springcloud.lb; import org.springframework.cloud.client.ServiceInstance; import org.springframework.stereotype.Component; import java.util.List; import java.util.concurrent.atomic.AtomicInteger; @Component public class MyLB implements LoadBalancer { private AtomicInteger atomicInteger = new AtomicInteger (0); @Override public ServiceInstance instances(List&lt;ServiceInstance&gt; serviceInstances) { int index = getAndIncrement ( ) % serviceInstances.size ( ); return serviceInstances.get (index); } public final int getAndIncrement() { int current; int next; do { current = this.atomicInteger.get ( ); next = current &gt;= 2147483647 ? 0 : current + 1; } while (!this.atomicInteger.compareAndSet (current, next)); System.out.println (\"*****next: \" + next); return next; } } 5、OrderController@Resource private LoadBalancer loadBalancer; @GetMapping(\"/consumer/payment/lb\") public String getPaymentLB() { List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances (\"CLOUD-PAYMENT-SERVICE\"); if (instances == null || instances.size ( ) &lt;= 0) { return null; } ServiceInstance serviceInstance = loadBalancer.instances (instances); URI uri = serviceInstance.getUri ( ); return restTemplate.getForObject (uri + \"/payment/lb\", String.class); } package com.kk.springcloud.controller; import com.kk.springcloud.lb.LoadBalancer; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import lombok.extern.slf4j.Slf4j; import org.springframework.cloud.client.ServiceInstance; import org.springframework.cloud.client.discovery.DiscoveryClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import javax.annotation.Resource; import java.net.URI; import java.util.List; @RestController @Slf4j public class OrderController { //public static final String PAYMENT_URL = \"http://localhost:8001\"; public static final String PAYMENT_URL = \"http://cloud-payment-service\"; //可以获取注册中心上的服务列表 @Resource private DiscoveryClient discoveryClient; @Resource private LoadBalancer loadBalancer; @GetMapping(\"/consumer/payment/lb\") public String getPaymentLB() { List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances (\"CLOUD-PAYMENT-SERVICE\"); if (instances == null || instances.size ( ) &lt;= 0) { return null; } ServiceInstance serviceInstance = loadBalancer.instances (instances); URI uri = serviceInstance.getUri ( ); return restTemplate.getForObject (uri + \"/payment/lb\", String.class); } @Resource private RestTemplate restTemplate; @GetMapping(\"/consumer/payment/create\") public CommonResult&lt;Payment&gt; create(Payment payment) { return restTemplate.postForObject (PAYMENT_URL + \"/payment/create\", payment, CommonResult.class); //写操作 } @GetMapping(\"/consumer/payment/get/{id}\") public CommonResult&lt;Payment&gt; getPayment(@PathVariable(\"id\") Long id) { return restTemplate.getForObject (PAYMENT_URL + \"/payment/get/\" + id, CommonResult.class); } } 6、测试http://localhost/consumer/payment/lb 注意：8001和8002别名配置都要配好否则自定义算法 获取的url会报错","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"netflix","slug":"netflix","permalink":"https://mykkto.github.io/tags/netflix/"},{"name":"负载均衡","slug":"负载均衡","permalink":"https://mykkto.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"ribbon","slug":"ribbon","permalink":"https://mykkto.github.io/tags/ribbon/"}],"author":"mykk"},{"title":"hexo + github 在百度和谷歌 SEO站点收录","slug":"00-blog/01_seo","date":"2022-01-16T14:41:15.000Z","updated":"2022-05-22T15:01:03.891Z","comments":true,"path":"posts/f1d997d.html","link":"","permalink":"https://mykkto.github.io/posts/f1d997d.html","excerpt":"","text":"1、百度 seo1、登陆百度站长管理https://ziyuan.baidu.com/linksubmit/url?sitename=http://site:abc.github.io 2、填写自己的blog地址 3、hexo设置校验C:\\Users\\Administrator\\Desktop\\myblog\\mykkTo.github.io\\themes\\matery\\layout\\_partial 4、成功 5、站点收录https://mykkto.github.io/baidu_urls.txt 2、谷歌 seo参考https://www.jianshu.com/p/9be9b4786f97","categories":[{"name":"博客","slug":"博客","permalink":"https://mykkto.github.io/categories/%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://mykkto.github.io/tags/hexo/"},{"name":"github","slug":"github","permalink":"https://mykkto.github.io/tags/github/"},{"name":"seo","slug":"seo","permalink":"https://mykkto.github.io/tags/seo/"},{"name":"百度","slug":"百度","permalink":"https://mykkto.github.io/tags/%E7%99%BE%E5%BA%A6/"},{"name":"谷歌","slug":"谷歌","permalink":"https://mykkto.github.io/tags/%E8%B0%B7%E6%AD%8C/"}],"author":"mykk"},{"title":"SpringCloud-Consul","slug":"03-java分布式/01springcloud/04_SpringCloud_Consul","date":"2022-01-16T13:42:11.000Z","updated":"2022-05-22T15:01:03.891Z","comments":true,"path":"posts/51c7125f.html","link":"","permalink":"https://mykkto.github.io/posts/51c7125f.html","excerpt":"","text":"1、Consul简介1、是什么 Consul 是一套开源的分布式服务发现和配置管理系统，由 HashiCorp 公司用 Go 语言开发。 提供了微服务系统中的服务治理、配置中心、控制总线等功能。这些功能中的每一个都可以根据需要单独使用，也可以一起使用以构建全方位的服务网格，总之Consul提供了一种完整的服务网格解决方案。 它具有很多优点。包括： 基于 raft 协议，比较简洁； 支持健康检查, 同时支持 HTTP 和 DNS 协议 支持跨数据中心的 WAN 集群 提供图形界面 跨平台，支持 Linux、Mac、Windows 2、能干嘛1、服务发现提供HTTP和DNS两种发现方式。 2、健康监测支持多种方式，HTTP、TCP、Docker、Shell脚本定制化监控 3、KV存储Key、Value的存储方式 4、多数据中心Consul支持多数据中心 5、可视化Web界面3、官网文档1、下载地址https://www.consul.io/downloads.html 2、学习文档https://www.springcloud.cc/spring-cloud-consul.html 2、安装并运行Consul1、官网安装https://www.consul.io/downloads 2、安装说明下载完成后只有一个consul.exe文件，硬盘路径下双击运行，查看版本号信息 3、使用开发模式启动（1）命令：consul agent -dev （2）通过以下地址可以访问Consul的首页：http://localhost:8500 （3）效果： 3、服务提供者1、建modelcloud-providerconsul-payment8006 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-providerconsul-payment8006&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--SpringCloud consul-server --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- SpringBoot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--日常通用jar包配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、yml###consul服务端口号 server: port: 8006 spring: application: name: consul-provider-payment ####consul注册中心地址 cloud: consul: host: localhost port: 8500 discovery: #hostname: 127.0.0.1 service-name: ${spring.application.name} 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class Payment8006 { public static void main(String[] args) { SpringApplication.run (Payment8006.class,args); } } 5、业务类package com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; import java.util.UUID; @RestController public class PaymentController { @Value(\"${server.port}\") private String serverPort; @GetMapping(\"/payment/consul\") public String paymentInfo() { return \"springcloud with consul: \" + serverPort + \"\\t\\t\" + UUID.randomUUID ( ).toString ( ); } } 5、测试1、访问http://localhost:8006/payment/consul 2、控制台 4、服务消费者1、建modelcloud-consumerconsul-order82 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-consumerconsul-order82&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--SpringCloud consul-server --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- SpringBoot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--日常通用jar包配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、yml###consul服务端口号 server: port: 82 spring: application: name: cloud-consumer-order ####consul注册中心地址 cloud: consul: host: localhost port: 8500 discovery: #hostname: 127.0.0.1 service-name: ${spring.application.name} 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @SpringBootApplication @EnableDiscoveryClient public class OrderConsulMain82 { public static void main(String[] args) { SpringApplication.run (OrderConsulMain82.class,args); } } 5、业务类1、Bean配置类package com.kk.springcloud.config; import org.springframework.cloud.client.loadbalancer.LoadBalanced; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.web.client.RestTemplate; @Configuration public class ApplicationContextBean { @Bean @LoadBalanced public RestTemplate getRestTemplate() { return new RestTemplate ( ); } } 2、Controllerpackage com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; @RestController public class OrderConsulController { public static final String INVOKE_URL = \"http://cloud-provider-payment\"; //consul-provider-payment @Autowired private RestTemplate restTemplate; @GetMapping(value = \"/consumer/payment/consul\") public String paymentInfo() { String result = restTemplate.getForObject (INVOKE_URL + \"/payment/consul\", String.class); System.out.println (\"消费者调用支付服务(consule)---&gt;result:\" + result); return result; } } 6、测试1、客户端 2、访问http://localhost/consumer/payment/consul 5、三个注册中心异同点1、CAPCAP理论关注粒度是数据，而不是整体系统设计的策略 C:Consistency（强一致性） A:Availability（可用性） P:Partition tolerance（分区容错性） 2、CAP图最多只能同时较好的满足两个。 CAP理论的核心是：一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求，因此，根据 CAP 原理将 NoSQL 数据库分成了满足 CA 原则、满足 CP 原则和满足 AP 原则三 大类：CA - 单点集群，满足一致性，可用性的系统，通常在可扩展性上不太强大。CP - 满足一致性，分区容忍必的系统，通常性能不是特别高。AP - 满足可用性，分区容忍性的系统，通常可能对一致性要求低一些。 3、AP-CP架构图1、AP(Eureka)AP架构 当网络分区出现后，为了保证可用性，系统B可以返回旧值，保证系统的可用性。结论：违背了一致性C的要求，只满足可用性和分区容错，即AP 2、CP(Zookeeper/Consul)CP架构 当网络分区出现后，为了保证一致性，就必须拒接请求，否则无法保证一致性结论：违背了可用性A的要求，只满足一致性和分区容错，即CP","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"服务注册与发现","slug":"服务注册与发现","permalink":"https://mykkto.github.io/tags/%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0/"},{"name":"Consul","slug":"Consul","permalink":"https://mykkto.github.io/tags/Consul/"}],"author":"mykk"},{"title":"Springcloud-Zookeeper(快速入门)","slug":"03-java分布式/01springcloud/03_SpringCloud-Zookeeper","date":"2022-01-15T15:01:12.000Z","updated":"2022-05-22T15:01:03.891Z","comments":true,"path":"posts/c0125b8a.html","link":"","permalink":"https://mykkto.github.io/posts/c0125b8a.html","excerpt":"","text":"安装参考【后面写】https://blog.csdn.net/zhou_fan_xi/article/details/103275955 安装完，windown访问测试 telnet 106.52.23.202 2181 1、注册中心Zookeeper基本概述 zookeeper是一个分布式协调工具，可以实现注册中心功能 关闭Linux服务器防火墙后才能启动zookeeper服务器 zookeeper服务器取代Eureka服务器，zk作为服务注册中心 2、服务提供者1、建model新建cloud-provider-payment8004 2、写pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-provider-payment8004&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!-- SpringBoot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- SpringBoot整合zookeeper客户端 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zookeeper-discovery&lt;/artifactId&gt; &lt;!--先排除自带的zookeeper3.5.3--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!--添加zookeeper3.4.9版本--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.9&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、改yml#8004表示注册到zookeeper服务器的支付服务提供者端口号 server: port: 8004 #服务别名----注册zookeeper到注册中心名称 spring: application: name: cloud-provider-payment cloud: zookeeper: connect-string: 106.52.23.202:2181 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @SpringBootApplication @EnableDiscoveryClient//该注解用于向使用consul或者zookeeper作为注册中心时注册服务 public class PaymentMain8004 { public static void main(String[] args) { SpringApplication.run (PaymentMain8004.class,args); } } 5、业务类package com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import java.util.UUID; @RestController public class PaymentController { @Value(\"${server.port}\") private String serverPort; @RequestMapping(value = \"/payment/zk\") public String paymentzk() { return \"springcloud with zookeeper: \" + serverPort + \"\\t\" + UUID.randomUUID ( ).toString ( ); } } 6、启动8004注册进zookeeper1、liunx启动 zookeeper#查看执行路径 [root@VM-0-13-centos bin]# pwd /root/zookeeper-3.4.9/bin #启动 [root@VM-0-13-centos bin]# ./zkServer.sh start #停止 [root@VM-0-13-centos bin]# ./zkServer.sh stop #重启 [root@VM-0-13-centos bin]# ./zkServer.sh restart 7、测试1、访问服务http://localhost:8004/payment/zk 2、查看服务端被是否被注册#进入 zookeeper客户端 [root@VM-0-13-centos bin]# ./zkCli.sh WatchedEvent state:SyncConnected type:None path:null #查看序列 [zk: localhost:2181(CONNECTED) 0] ls /services/cloud-provider-payment [a6293666-45c1-490e-adb8-bee63f121983] #查看详细信息 [zk: localhost:2181(CONNECTED) 1] ls /services/cloud-provider-payment/a6293666-45c1-490e-adb8-bee63f121983 [] [zk: localhost:2181(CONNECTED) 2] get /services/cloud-provider-payment/a6293666-45c1-490e-adb8-bee63f121983 {\"name\":\"cloud-provider-payment\",\"id\":\"a6293666-45c1-490e-adb8-bee63f121983\",\"address\":\"FYYX-2020GVNPLA\",\"port\":8004,\"sslPort\":null,\"payload\":{\"@class\":\"org.springframework.cloud.zookeeper.discovery.ZookeeperInstance\",\"id\":\"application-1\",\"name\":\"cloud-provider-payment\",\"metadata\":{}},\"registrationTimeUTC\":1642423897607,\"serviceType\":\"DYNAMIC\",\"uriSpec\":{\"parts\":[{\"value\":\"scheme\",\"variable\":true},{\"value\":\"://\",\"variable\":false},{\"value\":\"address\",\"variable\":true},{\"value\":\":\",\"variable\":false},{\"value\":\"port\",\"variable\":true}]}} 8、思考服务节点是临时节点还是持久节点？？ （1）当我关闭 8004节点后，zookeeper 依旧会持续发心跳，当有接收到反馈则还有序列号，没有则返回空[] （2）然后再次启动，则返回一个新的序列，由此说明这是一个临时节点 3、服务消费者1、建model新建cloud-consumerzk-order81 2、写pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-consumerzk-order81&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!-- SpringBoot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- SpringBoot整合zookeeper客户端 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zookeeper-discovery&lt;/artifactId&gt; &lt;!--先排除自带的zookeeper--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!--添加zookeeper3.4.9版本--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.9&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、改yml#81表示注册到zookeeper服务器的支付服务提供者端口号 server: port: 81 #服务别名----注册zookeeper到注册中心名称 spring: application: name: cloud-consumer-order cloud: zookeeper: connect-string: 106.52.23.202:2181 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @SpringBootApplication @EnableDiscoveryClient public class OrderZK81 { public static void main(String[] args) { SpringApplication.run (OrderZK81.class,args); } } 5、业务类1、配置Beanpackage com.kk.springcloud.config; import org.springframework.cloud.client.loadbalancer.LoadBalanced; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.web.client.RestTemplate; @Configuration public class ApplicationContextBean { @Bean @LoadBalanced// 给予 RestTemplate 负载均衡的能力 public RestTemplate getRestTemplate() { return new RestTemplate ( ); } } 2、Controllerpackage com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; @RestController public class OrderZKController81 { public static final String INVOKE_URL = \"http://cloud-provider-payment\"; @Autowired private RestTemplate restTemplate; @RequestMapping(value = \"/consumer/payment/zk\") public String paymentInfo() { String result = restTemplate.getForObject (INVOKE_URL + \"/payment/zk\", String.class); System.out.println (\"消费者调用支付服务(zookeeper)---&gt;result:\" + result); return result; } } 6、测试1、zookeeper[zk: localhost:2181(CONNECTED) 21] ls /services [cloud-provider-payment, cloud-consumer-order] 2、访问http://localhost:81/consumer/payment/zk","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"服务注册与发现","slug":"服务注册与发现","permalink":"https://mykkto.github.io/tags/%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://mykkto.github.io/tags/Zookeeper/"}],"author":"mykk"},{"title":"SpringCloud-Eureka","slug":"03-java分布式/01springcloud/02_SpringCloud-Eureka","date":"2022-01-14T14:35:22.000Z","updated":"2022-05-22T15:01:03.891Z","comments":true,"path":"posts/402d692e.html","link":"","permalink":"https://mykkto.github.io/posts/402d692e.html","excerpt":"","text":"1、Eureka基础知识1、什么是服务治理 Spring Cloud 封装了 Netflix 公司开发的 Eureka 模块来实现服务治理 在传统的rpc远程调用框架中，管理每个服务与服务之间依赖关系比较复杂，管理比较复杂，所以需要使用服务治理，管理服务于服务之间依赖关系，可以实现服务调用、负载均衡、容错等，实现服务发现与注册。 2、什么是服务注册1、概念 Eureka采用了CS的设计架构，Eureka Server 作为服务注册功能的服务器，它是服务注册中心。而系统中的其他微服务，使用 Eureka的客户端连接到 Eureka Server并维持心跳连接。这样系统的维护人员就可以通过 Eureka Server 来监控系统中各个微服务是否正常运行。 在服务注册与发现中，有一个注册中心。当服务器启动的时候，会把当前自己服务器的信息 比如 服务地址通讯地址等以别名方式注册到注册中心上。另一方（消费者|服务提供者），以该别名的方式去注册中心上获取到实际的服务通讯地址，然后再实现本地RPC调用RPC远程调用框架核心设计思想：在于注册中心，因为使用注册中心管理每个服务与服务之间的一个依赖关系(服务治理概念)。在任何rpc远程框架中，都会有一个注册中心(存放服务地址相关信息(接口地址)) 2、图解 3、Eureka两组件1、EurekaServer提供服务注册服务各个微服务节点通过配置启动后，会在EurekaServer中进行注册，这样EurekaServer中的服务注册表中将会存储所有可用服务节点的信息，服务节点的信息可以在界面中直观看到。 2、EurekaClient通过注册中心进行访问是一个Java客户端，用于简化Eureka Server的交互，客户端同时也具备一个内置的、使用轮询(round-robin)负载算法的负载均衡器。在应用启动后，将会向Eureka Server发送心跳(默认周期为30秒)。如果Eureka Server在多个心跳周期内没有接收到某个节点的心跳，EurekaServer将会从服务注册表中把这个服务节点移除（默认90秒） 2、单机Eureka构建步骤1、eurekaServer端服务注册中心1、建modelcloud-eureka-server7001 2、写pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-eureka-server7001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--eureka-server--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--boot web actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--一般通用配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、改ymlserver: port: 7001 eureka: instance: hostname: localhost #eureka服务端的实例名称 client: #false表示不向注册中心注册自己。 register-with-eureka: false #false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务 fetch-registry: false service-url: #设置与Eureka Server交互的地址查询服务和注册服务都需要依赖这个地址。 defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 4、主启动@SpringBootApplication @EnableEurekaServer public class EurekaMain7001 { public static void main(String[] args) { SpringApplication.run (EurekaMain7001.class,args); } } 5、测试1、访问：http://localhost:7001/ 2、返回结果页面 No application available 没有服务被发现 O(∩_∩)O因为没有注册服务进来当然不可能有服务被发现 2、EurekaClient端provider-80011、建model(不变)cloud-provider-payment8001 2、写pom（增加）以前老版本，别再使用 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; 现在新版本,当前使用 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; 3、改yml(增加)eureka: client: #表示是否将自己注册进EurekaServer默认为true。 register-with-eureka: true #是否从EurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetchRegistry: true service-url: defaultZone: http://localhost:7001/eureka 4、主启动(添加)@EnableEurekaClient 5、测试（1）先要启动EurekaServer，再启动8001 （2）访问：http://localhost:7001/ 6、自我保护机制 3、EurekaClient端consumer-801、建model（不变）2、写pom（同上） &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--引入公共部分--&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; 3、改yml（同上）eureka: client: #表示是否将自己注册进EurekaServer默认为true。 register-with-eureka: true #是否从EurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetchRegistry: true service-url: defaultZone: http://localhost:7001/eureka 4、主启动（同上）@SpringBootApplication @EnableEurekaClient public class PaymentMain8001 { public static void main(String[] args) { SpringApplication.run (PaymentMain8001.class, args); } } 5、测试（1）先要启动EurekaServer，再启动80 （2）访问：http://localhost/consumer/payment/get/1 3、集群Eureka构建步骤1、Eureka集群原理说明1、图解 2、问题：微服务RPC远程服务调用最核心的是什么3、解决方案：高可用，试想你的注册中心只有一个only one，会导致整个为服务环境不可用，所以 解决办法：搭建Eureka注册中心集群 ，实现负载均衡+故障容错 2、EurekaServer集群环境构建步骤1、建model新建cloud-eureka-server7002，参考7001 2、写pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-eureka-server7002&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--eureka-server--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--boot web actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--一般通用配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、修配置由于本地主机只有一台，为了模拟两台（多台)，则将 多个ip（域名eureka7001.com,eureka7002.com) 指向本地(127.0.0.1) 1、找到对应的配置目录C:\\Windows\\System32\\drivers\\etc 2、写入配置文件 127.0.0.1 eureka7001.com127.0.0.1 eureka7002.com 4、改yml1、7001server: port: 7001 eureka: instance: hostname: eureka7001.com #eureka服务端的实例名称 client: register-with-eureka: false #false表示不向注册中心注册自己。 fetch-registry: false #false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务 service-url: defaultZone: http://eureka7002.com:7002/eureka/ 2、7002server: port: 7002 eureka: instance: hostname: eureka7002.com #eureka服务端的实例名称 client: register-with-eureka: false #false表示不向注册中心注册自己。 fetch-registry: false #false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务 service-url: defaultZone: http://eureka7001.com:7001/eureka/ 5、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer; @SpringBootApplication @EnableEurekaServer public class EurekaMain7002 { public static void main(String[] args) { SpringApplication.run (EurekaMain7002.class,args); } } 3、支付8001发布到Eureka集群1、修改yml主要修改一处：defaultZone: server: port: 8001 spring: application: name: cloud-payment-service datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: jdbc:mysql://localhost:3306/spring_cloud?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: a1b2c3 eureka: client: #表示是否将自己注册进EurekaServer默认为true。 register-with-eureka: true #是否从EurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetchRegistry: true service-url: #defaultZone: http://localhost:7001/eureka defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka # 集群版 mybatis: mapperLocations: classpath:mapper/*.xml type-aliases-package: com.kk.springclond.entities 4、订单80发布到Eureka集群1、修改yml主要修改一处：defaultZone: server: port: 80 spring: application: name: cloud-consumer-service eureka: client: #表示是否将自己注册进EurekaServer默认为true。 register-with-eureka: true #是否从EurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetchRegistry: true service-url: #defaultZone: http://localhost:7001/eureka defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka # 集群版 5、测试流程测试以上配置是否生效 1、启动集群先要启动EurekaServer，7001/7002服务 2、启动生产者再要启动服务提供者provider，8001 3、启动消费者再要启动消费者，80 4、测试http://localhost/consumer/payment/get/1 6、支付8001集群构建【8002】1、方式一：直接把整份8001 copy出一个新的，需改yml ，port即可【推荐】 server: port: 8002 2、方式二：（1）打开idea配置，取消勾选单一服务按钮 （2）修改yml server: port: 8002 （3）启动 7、负载均衡1、订单80调用调整在调用的时候不能写死成ip+端口，需要使用服务名：cloud-payment-service 2、@LoadBalanced注解使用@LoadBalanced注解赋予RestTemplate负载均衡的能力 修改配置信息添加注解【80端口】 8、测试负载均衡1、启动顺序说明（1）先要启动EurekaServer，7001/7002服务 （2）再要启动服务提供者provider，8001/8002服务 2、访问http://localhost/consumer/payment/get/1 3、结果（1）达到负载效果 （2）8001/8002端口交替出现 4、小结Ribbon和Eureka整合后Consumer可以直接调用服务而不用再关心地址和端口号，且该服务还有负载功能了 4、actuator微服务信息完善1、主机名称:服务名称修改1、当前问题含有主机名名称 2、修改8001instance: instance-id: payment8001 完整 yml server: port: 8001 spring: application: name: cloud-payment-service datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: jdbc:mysql://localhost:3306/spring_cloud?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: a1b2c3 eureka: client: #表示是否将自己注册进EurekaServer默认为true。 register-with-eureka: true #是否从EurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetchRegistry: true service-url: #defaultZone: http://localhost:7001/eureka defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka # 集群版 instance: instance-id: payment8001 mybatis: mapperLocations: classpath:mapper/*.xml type-aliases-package: com.kk.springclond.entities 3、效果其实就是取别名 2、访问信息有IP信息提示1、问题：没有IP提示 2、修改8001prefer-ip-address: true #访问路径可以显示IP地址 3、效果 5、服务发现Discovery1、概述对于注册进eureka里面的微服务，可以通过服务发现来获得该服务的信息 2、修改8001的Controller1、增加@Resource private DiscoveryClient discoveryClient; @Value(\"${server.port}\") private String serverPort; /** * 查看注册服务的信息 * @return */ @GetMapping(value = \"/payment/discovery\") public Object discovery() { // 目前已经注册的微服务列表 List&lt;String&gt; services = discoveryClient.getServices ( ); for (String element : services) { log.info (element); } // 根据名称获取的微服务实例（就像类和对象的关系） List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances (\"CLOUD-PAYMENT-SERVICE\"); for (ServiceInstance element : instances) { log.info (element.getServiceId ( ) + \"\\t\" + element.getHost ( ) + \"\\t\" + element.getPort ( ) + \"\\t\" + element.getUri ( )); } return this.discoveryClient; } 2、全部package com.kk.springcloud.controller; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import com.kk.springcloud.service.PaymentService; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Value; import org.springframework.cloud.client.ServiceInstance; import org.springframework.cloud.client.discovery.DiscoveryClient; import org.springframework.web.bind.annotation.*; import javax.annotation.Resource; import java.util.List; @RestController @Slf4j /* * @Description: * @Author: 阿K * @CreateDate: 2022/1/16 18:11 * @Param: * @Return: **/ public class PaymentController { @Resource private PaymentService paymentService; @Resource private DiscoveryClient discoveryClient; @Value(\"${server.port}\") private String serverPort; /** * 查看注册服务的信息 * * @return */ @GetMapping(value = \"/payment/discovery\") public Object discovery() { // 目前已经注册的微服务列表 List&lt;String&gt; services = discoveryClient.getServices ( ); for (String element : services) { log.info (element); } // 根据名称获取的微服务实例（就像类和对象的关系） List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances (\"CLOUD-PAYMENT-SERVICE\"); for (ServiceInstance element : instances) { log.info (element.getServiceId ( ) + \"\\t\" + element.getHost ( ) + \"\\t\" + element.getPort ( ) + \"\\t\" + element.getUri ( )); } return this.discoveryClient; } @PostMapping(value = \"/payment/create\") public CommonResult create(@RequestBody Payment payment) { int result = paymentService.create (payment); log.info (\"*****插入结果1：\" + result + \"111\"); if (result &gt; 0) { //成功 return new CommonResult (200, \"插入数据库成功\", result); } else { return new CommonResult (444, \"插入数据库失败\", null); } } @GetMapping(value = \"/payment/get/{id}\") public CommonResult getPaymentById(@PathVariable(\"id\") Long id) { Payment payment = paymentService.getPaymentById (id); log.info (\"*****查询结果：\" + payment); if (payment != null) { //说明有数据，能查询成功 return new CommonResult (200, \"查询成功8081\", payment); } else { return new CommonResult (444, \"没有对应记录，查询ID：\" + id, null); } } } 3、8001主启动1、增加@EnableDiscoveryClient 2、全部package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; @SpringBootApplication @EnableEurekaClient// 此注解后期若是不用 Eureka，将被下方注解所代替 @EnableDiscoveryClient// 服务注册发现 public class PaymentMain8001 { public static void main(String[] args) { SpringApplication.run (PaymentMain8001.class, args); } } 4、测试1、启动顺序先要启动EurekaServer，再启动8001主启动类，需要稍等一会儿 2、访问http://localhost:8001/payment/discovery 6、Eureka自我保护1、故障现象保护模式主要用于一组客户端和Eureka Server之间存在网络分区场景下的保护。一旦进入保护模式，Eureka Server将会尝试保护其服务注册表中的信息，不再删除服务注册表中的数据，也就是不会注销任何微服务。 如果在Eureka Server的首页看到以下这段提示，则说明Eureka进入了保护模式：EMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY’RE NOT.RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE 2、导致原因此举属于CAP里面的AP分支 一句话：某时刻某一个微服务不可用了，Eureka不会立刻清理，依旧会对该微服务的信息进行保存 1、问题一：为什么会产生Eureka自我保护机制？ 为了防止EurekaClient可以正常运行，但是 与 EurekaServer网络不通情况下，EurekaServer不会立刻将EurekaClient服务剔除 2、问题二：什么是自我保护模式？ 默认情况下，如果EurekaServer在一定时间内没有接收到某个微服务实例的心跳，EurekaServer将会注销该实例（默认90秒）。但是当网络分区故障发生(延时、卡顿、拥挤)时，微服务与EurekaServer之间无法正常通信，以上行为可能变得非常危险了——因为微服务本身其实是健康的，此时本不应该注销这个微服务。Eureka通过“自我保护模式”来解决这个问题——当EurekaServer节点在短时间内丢失过多客户端时（可能发生了网络分区故障），那么这个节点就会进入自我保护模式。 3、怎么禁止自我保护1、注册中心7001（1）出厂默认，自我保护机制是开启的 eureka.server.enable-self-preservation=true （2）使用eureka.server.enable-self-preservation = false 可以禁用自我保护模式 server: port: 7001 eureka: instance: hostname: eureka7001.com #eureka服务端的实例名称 client: register-with-eureka: false #false表示不向注册中心注册自己。 fetch-registry: false #false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务 service-url: defaultZone: http://eureka7002.com:7002/eureka/ server: #关闭自我保护机制，保证不可用服务被及时踢除 enable-self-preservation: false eviction-interval-timer-in-ms: 2000 （3）效果 2、生产者80011、默认（1）单位为秒(默认是30秒) eureka.instance.lease-renewal-interval-in-seconds=30 （2）单位为秒(默认是90秒) eureka.instance.lease-expiration-duration-in-seconds=90 2、配置 server: port: 8001 spring: application: name: cloud-payment-service datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: jdbc:mysql://localhost:3306/spring_cloud?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: a1b2c3 eureka: client: #表示是否将自己注册进EurekaServer默认为true。 register-with-eureka: true #是否从EurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetchRegistry: true service-url: #defaultZone: http://localhost:7001/eureka defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka # 集群版 instance: instance-id: payment8001 prefer-ip-address: true #访问路径可以显示IP地址 #心跳检测与续约时间 #开发时设置小些，保证服务关闭后注册中心能即使剔除服务 #Eureka客户端向服务端发送心跳的时间间隔，单位为秒(默认是30秒) lease-renewal-interval-in-seconds: 1 #Eureka服务端在收到最后一次心跳后等待时间上限，单位为秒(默认是90秒)，超时将剔除服务 lease-expiration-duration-in-seconds: 2 mybatis: mapperLocations: classpath:mapper/*.xml type-aliases-package: com.kk.springclond.entities 3、测试（1）先启动7001，在启动8001 （2）再关闭8001，发现服务已经被删除了 7、Eureka停更``https://github.com/Netflix/eureka/wiki` 技术选型可以考虑 zookeeper、nacos(alibaba)","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"服务注册与发现","slug":"服务注册与发现","permalink":"https://mykkto.github.io/tags/%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0/"},{"name":"Eureka","slug":"Eureka","permalink":"https://mykkto.github.io/tags/Eureka/"}],"author":"mykk"},{"title":"SpringCloud 项目构建 and 技术选型","slug":"03-java分布式/01springcloud/01_SpringCloud-Build","date":"2022-01-12T15:42:15.000Z","updated":"2022-05-22T15:01:03.891Z","comments":true,"path":"posts/9df20094.html","link":"","permalink":"https://mykkto.github.io/posts/9df20094.html","excerpt":"","text":"1、版本 2、官网地址【Spring Cloud】1、英文https://cloud.spring.io/spring-cloud-static/Hoxton.SR1/reference/htmlsingle/ 2、中文https://www.bookstack.cn/read/spring-cloud-docs/docs-index.md 3、springboothttps://docs.spring.io/spring-boot/docs/2.2.2.RELEASE/reference/htmlsingle/ 3、项目搭建-父工程构建 父工程坐标 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;!-- 统一管理jar包版本 --&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt; &lt;lombok.version&gt;1.16.18&lt;/lombok.version&gt; &lt;mysql.version&gt;5.1.47&lt;/mysql.version&gt; &lt;druid.version&gt;1.1.16&lt;/druid.version&gt; &lt;mybatis.spring.boot.version&gt;1.3.0&lt;/mybatis.spring.boot.version&gt; &lt;/properties&gt; &lt;!-- 子模块继承之后，提供作用：锁定版本+子modlue不用写groupId和version --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--spring boot 2.2.2--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--spring cloud Hoxton.SR1--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--spring cloud alibaba 2.1.0.RELEASE--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;${mysql.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;${druid.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${mybatis.spring.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;${junit.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;${log4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;${lombok.version}&lt;/version&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;addResources&gt;true&lt;/addResources&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 4、项目搭建-Rest微服务工程构建1、坐标&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-provider-payment8001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.alibaba/druid --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-jdbc --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-devtools --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.projectlombok/lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-test --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 2、ymlserver: port: 8001 spring: application: name: cloud-payment-service datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: jdbc:mysql://localhost:3306/spring_cloud?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: a1b2c3 mybatis: mapperLocations: classpath:mapper/*.xml type-aliases-package: com.kk.springclond.entities 3、主启动@SpringBootApplication public class PaymentMain8001 { public static void main(String[] args) { SpringApplication.run (PaymentMain8001.class, args); } } 4、业务类1、建表CREATE TABLE `payment` ( `id` bigint NOT NULL AUTO_INCREMENT , `serial` varchar(255) NULL , PRIMARY KEY (`id`) ) 2、实体（entity）（1）通用返回结果实体@Data @AllArgsConstructor @NoArgsConstructor public class CommonResult&lt;T&gt; { private Integer code; private String message; private T data; public CommonResult(Integer code, String message) { this(code,message,null); } } （2）Payment@Data @AllArgsConstructor @NoArgsConstructor public class Payment { private Long id; private String serial; } 3、dao层1、接口PaymentDao编写package com.kk.springcloud.dao; import com.kk.springcloud.entities.Payment; import org.apache.ibatis.annotations.Mapper; import org.apache.ibatis.annotations.Param; @Mapper public interface PaymentDao { public int create(Payment payment); //写 public Payment getPaymentById(@Param(\"id\") Long id); //读取 } 2、mybatis的映射文件PaymentMapper.xml（1）路径src\\main\\resources\\mapper\\PaymentMapper.xml （2）头文件&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;mapper namespace=\"com.kk.springcloud.dao.PaymentDao\"&gt; &lt;insert id=\"create\" parameterType=\"com.kk.springcloud.entities.Payment\" useGeneratedKeys=\"true\" keyProperty=\"id\"&gt; insert into payment(serial) values(${serial}); &lt;/insert&gt; &lt;resultMap id=\"BaseResultMap\" type=\"com.kk.springcloud.entities.Payment\"&gt; &lt;id column=\"id\" property=\"id\" jdbcType=\"BIGINT\"&gt;&lt;/id&gt; &lt;id column=\"serial\" property=\"serial\" jdbcType=\"VARCHAR\"&gt;&lt;/id&gt; &lt;/resultMap&gt; &lt;select id=\"getPaymentById\" parameterType=\"Long\" resultMap=\"BaseResultMap\"&gt; select * from payment where id=#{id} &lt;/select&gt; &lt;/mapper&gt; 4、service1、接口package com.kk.springcloud.service; import com.kk.springcloud.entities.Payment; import org.apache.ibatis.annotations.Param; public interface PaymentService { public int create(Payment payment); //写 public Payment getPaymentById(@Param(\"id\") Long id); //读取 } 2、实现类package com.kk.springcloud.service.impl; import com.kk.springcloud.dao.PaymentDao; import com.kk.springcloud.entities.Payment; import com.kk.springcloud.service.PaymentService; import org.springframework.stereotype.Service; import javax.annotation.Resource; @Service public class PaymentServiceImpl implements PaymentService { @Resource private PaymentDao paymentDao; public int create(Payment payment) { return paymentDao.create (payment); } public Payment getPaymentById(Long id) { return paymentDao.getPaymentById (id); } } 5、controllerpackage com.kk.springcloud.controller; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import com.kk.springcloud.service.PaymentService; import lombok.extern.slf4j.Slf4j; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; @RestController @Slf4j public class PaymentController { @Resource private PaymentService paymentService; @PostMapping(value = \"/payment/create\") public CommonResult create(Payment payment) { int result = paymentService.create (payment); log.info (\"*****插入结果：\" + result); if (result &gt; 0) { //成功 return new CommonResult (200, \"插入数据库成功\", result); } else { return new CommonResult (444, \"插入数据库失败\", null); } } @GetMapping(value = \"/payment/get/{id}\") public CommonResult getPaymentById(@PathVariable(\"id\") Long id) { Payment payment = paymentService.getPaymentById (id); log.info (\"*****查询结果：\" + payment); if (payment != null) { //说明有数据，能查询成功 return new CommonResult (200, \"查询成功\", payment); } else { return new CommonResult (444, \"没有对应记录，查询ID：\" + id, null); } } } 5、测试1、插入：使用post请求才能被插入，所以在url上无效，可以使用postmanhttp://localhost:8001/payment/create?serial=mykk02 2、查询：get请求，url，postman皆可http://localhost:8001/payment/get/1 5、热部署1、子工程 pom上面的依赖已经有加了，是这个 2、父工程 pom插件上面的依赖已经有加了，是这个 3、设置自动编译 4、开启自动更新1、打开设置面板ctrl + shift + alt + /同时按住，点击第一个Registry... 2、两个打勾 5、重启 IDEA6、项目搭建-Order订单微服务构建1、坐标&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-consumer-order80&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-devtools --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.projectlombok/lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-test --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 2、ymlserver: port: 80 3、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class OrderMain80 { public static void main(String[] args) { SpringApplication.run (OrderMain80.class,args); } } 4、业务类1、创建entities 将cloud-provider-payment8001工程下的entities包下的两个实体类复制过来 2、RestTemplate1、官网： https://docs.spring.io/spring-framework/docs/5.2.2.RELEASE/javadoc-api/org/springframework/web/client/RestTemplate.html 2、是什么 3、怎么用 3、配置类ApplicationContextConfig package com.kk.springcloud.config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.web.client.RestTemplate; @Configuration public class ApplicationContextConfig { @Bean public RestTemplate getRestTemplate(){ return new RestTemplate(); } } 4、创建 controllerpackage com.kk.springcloud.controller; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import lombok.extern.slf4j.Slf4j; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import javax.annotation.Resource; @RestController @Slf4j public class OrderController { public static final String PAYMENT_URL = \"http://localhost:8001\"; @Resource private RestTemplate restTemplate; @GetMapping(\"/consumer/payment/create\") public CommonResult&lt;Payment&gt; create(Payment payment) { return restTemplate.postForObject (PAYMENT_URL + \"/payment/create\", payment, CommonResult.class); //写操作 } @GetMapping(\"/consumer/payment/get/{id}\") public CommonResult&lt;Payment&gt; getPayment(@PathVariable(\"id\") Long id) { return restTemplate.getForObject (PAYMENT_URL + \"/payment/get/\" + id, CommonResult.class); } } 5、测试1、先启动cloud-provider-payment80012、再启动cloud-consumer-order803、测试消费者接口http://localhost/consumer/payment/get/1 注意点：被调用的生产者接口传参记得加注解 7、项目重构1、观察问题1、系统中有重复部分，重构 2、新建公共模块【cloud-api-commons】1、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-devtools --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/cn.hutool/hutool-all --&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;5.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 2、实体将订单模块和支付模块公共实体放到这里 3、改造订单和支付1、删除各自的原先有过的entities文件夹2、各自分别引入公共模块&lt;!--引入公共部分--&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; 7、项目模块结构图","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"搭建","slug":"搭建","permalink":"https://mykkto.github.io/tags/%E6%90%AD%E5%BB%BA/"}],"author":"mykk"},{"title":"南城故人","slug":"02-informalessay/01duanzi/01_nanchengguren","date":"2022-01-10T17:33:22.000Z","updated":"2022-01-11T12:37:38.397Z","comments":true,"path":"posts/f2c0d8e3.html","link":"","permalink":"https://mykkto.github.io/posts/f2c0d8e3.html","excerpt":"","text":"摘自：南城故人 第8期内容： 18岁，你读了大学。20岁，你大二结束，开始悔恨自己前两年幼稚的行为于是开始努力22岁你大学毕业了，却发现找不到一份令自己满意的工作26岁，你看着身边的人都结了婚婚礼的份子钱逐年递增春节回家，父母从带你串亲戚变成了带你去见相亲对象见了十几个姑娘你每次都觉得和那个她比差了一点28岁那年，你遇到了一个和你遭遇差不多的姑娘你们有一搭没一搭的聊着她说：你还不错你喝了一口可乐说：你也是你还不确定喜不喜欢她双方家长就已经摆好了订婚宴结婚的前一周，你和朋友出去喝酒你说，不想结婚朋友说，你啊，就是想太多。谁不是这么过来的？ 29岁，你们终于结了婚婚礼办的不大不小，朋友来的不多不少攒了几年想要去实现理想的钱搭在了这一场百人的私人庙会上婚礼进行到中间司仪带着标准的商业化微笑对着台下的亲朋喊道要不要让他们亲一个！台下那些人跟着一起起哄不知道为什么你简简单单的亲了一口俩人恢复到了一开始的站位你小声说了一句：我爱你那个昨天还看不惯你倒腾模型的新娘愣了一下说：我也爱你你不确定她是不是对你说的就像你不确定是不是对她说的一样婚礼结束后，并没有你想象的浪漫你听着外屋的新娘一笔一笔的算着份子钱想着不过才两年，怎么就变成这样了想着想着，洞房夜就睡着了 30岁，她怀孕了辞掉了工作，在家养胎你在公司逐渐有了点地位手里管着十来个人独立负责一个项目结婚前陪嫁的那辆20万左右的车也变成了你一个人的独享但你依然不敢放松每次加班电话那头都是抱怨与委屈但你不能争辩什么谁让她怀了你的孩子在这一刻不论是她的父母还是你的父母都无条件的站在这一边31岁，孩子落地了前前后后连孕检带住院费花了10万块钱不过无所谓你看着你的孩子，怎么看怎么喜欢高兴的仿佛这是你的新生32岁，这是人生最不愿意重复的一年平均睡眠3小时孩子每一个小时都要闹腾一次第二天拖着睡不醒的眼睛去上班老板说你上班不干活回家媳妇说你不干活你想了半天不明白，那谁干活呢？那辆开了3年的车成为了你真正的家你不在抱怨路上拥堵的交通你甚至开始希望再多堵一会回到家，你关了发动机在车上点了一根烟这是你每天最幸福的十分钟车前是功名利禄，车尾是柴米油盐 35岁 你因为身体越来越差加班越来越少晋升的速度也越来越缓慢那天下班，媳妇告诉你孩子要上幼儿园了双语的一个月3000你皱了皱眉头，那边就已经不耐烦了“四单元的老王家孩子，一个月6000”“你已经这样了，你想让孩子也输？”你没说话，回屋给媳妇转了6000块钱这笔钱，你原本打算给自己过个生日，买个新电脑 38岁，孩子上了一年级老师说一年级最关键，打好基础很重要你笑着说，是是是，老师您多照顾新生接待的老师看着你不明事理的脸给你指了一条明路“课外辅导班，一个月2200”40岁的时候，孩子上了三年级老师说，三年级，最关键，承上启下很重要你笑着说：是是是，正打算再报个补习班 44岁，孩子上了初中有一天回到家，她对你说爸爸，我想学钢琴你没什么犹豫的你以为这些年，你已经习惯了但那句“爸爸现在买不起”你始终说不出口好在孩子比较懂事她说：爸爸没事，要不我先学陶笛也可以你看着这么懂事的孩子，却开心不起来 46岁，孩子上了一个不好不差的高中有一天你在开会，接到了老师的电话电话里说你的孩子在学校打架了叫你去一趟你唯唯诺诺的和那个比你还小5岁的领导请了个假到学校又被老师训了一通无非台词就是那一句你们做家长的就知道工作，能不能陪陪孩子你看着这个老师，有点可笑好像当时说：家长在外辛苦点多赚点钱让孩子多补补课的和他不是一个人 50岁，孩子上了大学很争气，是一个一本他学的专业你有点看不懂你只知道工作不一定好找而且学费还死贵你和他深夜想聊聊准备了半斤白酒，一碟花生米你说着那些曾经你最讨厌的话还是要为以后工作着想挑个热门的专业活着比热爱重要你们从交流变成了争吵你发现，你老了老到可能都打不过这个18岁的孩子你说不过他，只能说一句：我是你爸爸！孩子看着你，知道再怎么争辩都没用这场确立你最后威严的酒局不欢而散你听的不真切在孩子回自己屋的路上好像叨叨了一句“我不想活的像你一样”怎么就哭了呢？50岁的人了一定是酒太辣了，对不对一定是酒太辣了 55岁，孩子工作了，似乎有一点理解你了但你却反了过来，你说不要妥协56岁，孩子也结婚了你问他喜欢那个姑娘么他愣了愣说：喜欢吧60岁，辛苦了一辈子，想出去走走身边的那个人过了30年你依旧分不清到底喜不喜欢你们开始规划旅游路线这么多年了你们还是存在分歧，还是在争吵某个瞬间，你觉得这样可能也挺好一切都准备好了儿子说：爸妈，我工作太忙了可以帮我照顾一下孩子么你们退了机票，又回到了30年前 70岁，孩子的孩子也长大了，不用天天操心了你下定决心说：一定要去玩一趟可是手边的拐杖只能支持你走到楼下的花园75岁，你在医院的病床上身边聚满了人，你迷迷糊糊的看见医生摇了摇头周围那些人神情肃穆你明白了，你要死掉了你没有感到一丝害怕你突然问自己，我到底是什么时候死掉的呢？你想起来30岁的那场婚礼原来，那时候，你就死掉了吧 依照惯例死前的3秒，你的大脑要走马灯倒叙你这75个年头的一生画面一张一张的过1秒2秒两秒过去了你面无表情的看着这两秒内的回忆第3秒突然你笑了原来已经回到了15岁的那一年 你看见一个男孩他叼着一袋牛奶，背着书包从另一个女孩家的阳台下跑过那个男孩朝窗户里看了看那是15岁的你暗恋的那个女孩子你想不起来她长什么样子了最后一秒你努力的回忆着然后终于笑了出来3秒过去了身边的人突然间开始嚎啕大哭你可能听不清了你最后听到的嘈杂的声音是一群十五六的少年 起着哄说的答应他答应他答应他不爱你，不度生 热评：取一位账号已注销的评论：“有些人27岁就死了，直到72岁才被埋上”。能够想清楚过去，抓得住现在，放眼在未来吧，做一个能活到72岁的糊涂蛋。","categories":[{"name":"生活碎片化-段子","slug":"生活碎片化-段子","permalink":"https://mykkto.github.io/categories/%E7%94%9F%E6%B4%BB%E7%A2%8E%E7%89%87%E5%8C%96-%E6%AE%B5%E5%AD%90/"}],"tags":[{"name":"生活","slug":"生活","permalink":"https://mykkto.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"段子","slug":"段子","permalink":"https://mykkto.github.io/tags/%E6%AE%B5%E5%AD%90/"},{"name":"感慨","slug":"感慨","permalink":"https://mykkto.github.io/tags/%E6%84%9F%E6%85%A8/"}],"author":"mykk"},{"title":"SpringCloud and Alibaba合集","slug":"03-java分布式/01springcloud/00_SpringCloud","date":"2022-01-10T16:42:15.000Z","updated":"2022-05-22T15:01:03.891Z","comments":true,"path":"posts/58914314.html","link":"","permalink":"https://mykkto.github.io/posts/58914314.html","excerpt":"","text":"案例代码仓库https://gitee.com/TK_LIMR/springcloud2021To2021.git 分解的目录1、项目构建and技术选型2、Eureka服务注册与发现4、Consul服务注册与发现5、Ribbon负载均衡服务调用6、OpenFeign服务接口调用7、Hystrix断路器8、zuul路由网关9、Gateway新一代网关10、Seata处理分布式事务11、Sentinel实现熔断与限流12、Nacos服务注册和配置中心13、Sleuth分布式请求链路追踪14、Stream消息驱动15、Bus 消息总线16、config分布式配置中心食用技巧1、同时启动多个SpringbootIDEA SpringBoot多个项目 开启 RunDashboard， 在项目根目录 .idea 文件夹 中 workspace.xml文件中加入 &lt;component name=\"RunDashboard\"&gt; &lt;option name=\"configurationTypes\"&gt; &lt;set&gt; &lt;option value=\"SpringBootApplicationConfigurationType\" /&gt; &lt;/set&gt; &lt;/option&gt; &lt;/component&gt; 2、本地hosts配置windown 10位置：C:\\Windows\\System32\\drivers\\etc","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud-alibaba","slug":"springcloud-alibaba","permalink":"https://mykkto.github.io/tags/springcloud-alibaba/"},{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"合集","slug":"合集","permalink":"https://mykkto.github.io/tags/%E5%90%88%E9%9B%86/"}],"author":"mykk"},{"title":"KK语录（日记）","slug":"02-informalessay/02_语录","date":"2022-01-10T15:12:19.000Z","updated":"2022-01-11T13:41:21.196Z","comments":true,"path":"posts/bd37926a.html","link":"","permalink":"https://mykkto.github.io/posts/bd37926a.html","excerpt":"","text":"","categories":[{"name":"生活碎片化","slug":"生活碎片化","permalink":"https://mykkto.github.io/categories/%E7%94%9F%E6%B4%BB%E7%A2%8E%E7%89%87%E5%8C%96/"}],"tags":[{"name":"语录","slug":"语录","permalink":"https://mykkto.github.io/tags/%E8%AF%AD%E5%BD%95/"},{"name":"日记","slug":"日记","permalink":"https://mykkto.github.io/tags/%E6%97%A5%E8%AE%B0/"},{"name":"话痨","slug":"话痨","permalink":"https://mykkto.github.io/tags/%E8%AF%9D%E7%97%A8/"}],"author":"mykk"},{"title":"美文","slug":"02-informalessay/01_美文","date":"2022-01-10T14:33:12.000Z","updated":"2022-01-11T14:21:18.841Z","comments":true,"path":"posts/c3e91221.html","link":"","permalink":"https://mykkto.github.io/posts/c3e91221.html","excerpt":"","text":"","categories":[{"name":"生活碎片化","slug":"生活碎片化","permalink":"https://mykkto.github.io/categories/%E7%94%9F%E6%B4%BB%E7%A2%8E%E7%89%87%E5%8C%96/"}],"tags":[{"name":"美文","slug":"美文","permalink":"https://mykkto.github.io/tags/%E7%BE%8E%E6%96%87/"}],"author":"mykk"},{"title":"生活碎片文章集合汇总","slug":"01-菜单/03_随笔（语录）","date":"2022-01-10T13:22:55.000Z","updated":"2022-05-22T15:01:03.899Z","comments":true,"path":"posts/1565718c.html","link":"","permalink":"https://mykkto.github.io/posts/1565718c.html","excerpt":"","text":"1、美文2、语录3、电影4、美图5、心得","categories":[{"name":"文章菜单合集","slug":"文章菜单合集","permalink":"https://mykkto.github.io/categories/%E6%96%87%E7%AB%A0%E8%8F%9C%E5%8D%95%E5%90%88%E9%9B%86/"}],"tags":[{"name":"生活","slug":"生活","permalink":"https://mykkto.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"总纲","slug":"总纲","permalink":"https://mykkto.github.io/tags/%E6%80%BB%E7%BA%B2/"},{"name":"分享","slug":"分享","permalink":"https://mykkto.github.io/tags/%E5%88%86%E4%BA%AB/"}],"author":"mykk"},{"title":"(新)技术文章集合汇总","slug":"01-菜单/02_新菜单集合","date":"2022-01-09T14:55:55.000Z","updated":"2022-05-22T15:01:03.836Z","comments":true,"path":"posts/f747eac7.html","link":"","permalink":"https://mykkto.github.io/posts/f747eac7.html","excerpt":"","text":"一、技术（较为系统编排）1、java数据结构与算法 ★11 https://www.jianshu.com/p/929ca9e209e8 2、java设计模式https://www.jianshu.com/p/63df8cd03619 8、java单体架构技术栈https://www.jianshu.com/p/0a4a1ced23c7 9、java分布式架构技术栈https://www.jianshu.com/p/00aa796bb5b8 10、框架之外技术栈汇总https://www.jianshu.com/p/d0167f082cbf N1、内力篇汇总0-java内力——总纲 - 简书 (jianshu.com) 11、Liunxhttps://www.jianshu.com/p/409970d8d0f1 12、前端大杂烩https://www.jianshu.com/p/82fa0c99e019 13、各项目整合分解大杂烩https://www.jianshu.com/p/d30b07569dc3 14、面试题汇总：技术=面试题+项目总结 ★https://www.jianshu.com/p/5e3b81aef034 15、一些不错的网站：https://www.jianshu.com/p/53bf0d4a930d 16、随性记录一小点随性记录一小点 2021-07-15至未来 7、工具代码备份UT-工具代码 JDK各版本演变 4、netty 5、JVM【重量级】 n、大数据n、前端n、golangn、以太坊n、区块链n、scala 2、工作，博客，公众号等所学技术汇总3、心得（工作）4、语录（感悟）","categories":[{"name":"文章菜单合集","slug":"文章菜单合集","permalink":"https://mykkto.github.io/categories/%E6%96%87%E7%AB%A0%E8%8F%9C%E5%8D%95%E5%90%88%E9%9B%86/"}],"tags":[{"name":"简书","slug":"简书","permalink":"https://mykkto.github.io/tags/%E7%AE%80%E4%B9%A6/"},{"name":"技术总纲","slug":"技术总纲","permalink":"https://mykkto.github.io/tags/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BA%B2/"}],"author":"mykk"},{"title":"(旧)简书文章过往两年纲要","slug":"01-菜单/01_旧菜单合集","date":"2022-01-09T11:19:19.000Z","updated":"2022-05-22T15:01:03.842Z","comments":true,"path":"posts/c3e91221.html","link":"","permalink":"https://mykkto.github.io/posts/c3e91221.html","excerpt":"","text":"1、技术（较为系统编排）1、java数据结构与算法 ★https://www.jianshu.com/p/929ca9e209e8 2、java设计模式https://www.jianshu.com/p/63df8cd03619 8、java单体架构技术栈https://www.jianshu.com/p/0a4a1ced23c7 9、java分布式架构技术栈https://www.jianshu.com/p/00aa796bb5b8 10、框架之外技术栈汇总https://www.jianshu.com/p/d0167f082cbf N1、内力篇汇总0-java内力——总纲 - 简书 (jianshu.com) 11、Liunxhttps://www.jianshu.com/p/409970d8d0f1 12、前端大杂烩https://www.jianshu.com/p/82fa0c99e019 13、各项目整合分解大杂烩https://www.jianshu.com/p/d30b07569dc3 14、面试题汇总：技术=面试题+项目总结 ★https://www.jianshu.com/p/5e3b81aef034 15、一些不错的网站：https://www.jianshu.com/p/53bf0d4a930d 16、随性记录一小点随性记录一小点 2021-07-15至未来 7、工具代码备份UT-工具代码 JDK各版本演变 4、netty 5、JVM【重量级】 n、大数据n、前端n、golangn、以太坊n、区块链n、scala 2、工作，博客，公众号等所学技术汇总3、心得（工作）4、语录（感悟）","categories":[{"name":"文章菜单合集","slug":"文章菜单合集","permalink":"https://mykkto.github.io/categories/%E6%96%87%E7%AB%A0%E8%8F%9C%E5%8D%95%E5%90%88%E9%9B%86/"}],"tags":[{"name":"简书","slug":"简书","permalink":"https://mykkto.github.io/tags/%E7%AE%80%E4%B9%A6/"},{"name":"技术总纲","slug":"技术总纲","permalink":"https://mykkto.github.io/tags/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BA%B2/"}],"author":"mykk"}],"categories":[{"name":"docker","slug":"docker","permalink":"https://mykkto.github.io/categories/docker/"},{"name":"大数据","slug":"大数据","permalink":"https://mykkto.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"项目-尚融宝","slug":"项目-尚融宝","permalink":"https://mykkto.github.io/categories/%E9%A1%B9%E7%9B%AE-%E5%B0%9A%E8%9E%8D%E5%AE%9D/"},{"name":"高阶篇","slug":"高阶篇","permalink":"https://mykkto.github.io/categories/%E9%AB%98%E9%98%B6%E7%AF%87/"},{"name":"面试题","slug":"面试题","permalink":"https://mykkto.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"中间件","slug":"中间件","permalink":"https://mykkto.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"缓存中间件","slug":"缓存中间件","permalink":"https://mykkto.github.io/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"计算机语言","slug":"计算机语言","permalink":"https://mykkto.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%AF%AD%E8%A8%80/"},{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"},{"name":"博客","slug":"博客","permalink":"https://mykkto.github.io/categories/%E5%8D%9A%E5%AE%A2/"},{"name":"数据库","slug":"数据库","permalink":"https://mykkto.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"生活碎片化-段子","slug":"生活碎片化-段子","permalink":"https://mykkto.github.io/categories/%E7%94%9F%E6%B4%BB%E7%A2%8E%E7%89%87%E5%8C%96-%E6%AE%B5%E5%AD%90/"},{"name":"生活碎片化","slug":"生活碎片化","permalink":"https://mykkto.github.io/categories/%E7%94%9F%E6%B4%BB%E7%A2%8E%E7%89%87%E5%8C%96/"},{"name":"文章菜单合集","slug":"文章菜单合集","permalink":"https://mykkto.github.io/categories/%E6%96%87%E7%AB%A0%E8%8F%9C%E5%8D%95%E5%90%88%E9%9B%86/"}],"tags":[{"name":"技术","slug":"技术","permalink":"https://mykkto.github.io/tags/%E6%8A%80%E6%9C%AF/"},{"name":"记录","slug":"记录","permalink":"https://mykkto.github.io/tags/%E8%AE%B0%E5%BD%95/"},{"name":"集群","slug":"集群","permalink":"https://mykkto.github.io/tags/%E9%9B%86%E7%BE%A4/"},{"name":"主从","slug":"主从","permalink":"https://mykkto.github.io/tags/%E4%B8%BB%E4%BB%8E/"},{"name":"可视化","slug":"可视化","permalink":"https://mykkto.github.io/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/"},{"name":"docker-compose","slug":"docker-compose","permalink":"https://mykkto.github.io/tags/docker-compose/"},{"name":"dockerfile","slug":"dockerfile","permalink":"https://mykkto.github.io/tags/dockerfile/"},{"name":"docker网络","slug":"docker网络","permalink":"https://mykkto.github.io/tags/docker%E7%BD%91%E7%BB%9C/"},{"name":"Flink","slug":"Flink","permalink":"https://mykkto.github.io/tags/Flink/"},{"name":"hadoop","slug":"hadoop","permalink":"https://mykkto.github.io/tags/hadoop/"},{"name":"kafka","slug":"kafka","permalink":"https://mykkto.github.io/tags/kafka/"},{"name":"sentinel","slug":"sentinel","permalink":"https://mykkto.github.io/tags/sentinel/"},{"name":"redis","slug":"redis","permalink":"https://mykkto.github.io/tags/redis/"},{"name":"gatway","slug":"gatway","permalink":"https://mykkto.github.io/tags/gatway/"},{"name":"数据字典","slug":"数据字典","permalink":"https://mykkto.github.io/tags/%E6%95%B0%E6%8D%AE%E5%AD%97%E5%85%B8/"},{"name":"nginx","slug":"nginx","permalink":"https://mykkto.github.io/tags/nginx/"},{"name":"springboot","slug":"springboot","permalink":"https://mykkto.github.io/tags/springboot/"},{"name":"vue","slug":"vue","permalink":"https://mykkto.github.io/tags/vue/"},{"name":"合集","slug":"合集","permalink":"https://mykkto.github.io/tags/%E5%90%88%E9%9B%86/"},{"name":"金融","slug":"金融","permalink":"https://mykkto.github.io/tags/%E9%87%91%E8%9E%8D/"},{"name":"项目","slug":"项目","permalink":"https://mykkto.github.io/tags/%E9%A1%B9%E7%9B%AE/"},{"name":"jvm","slug":"jvm","permalink":"https://mykkto.github.io/tags/jvm/"},{"name":"字节码","slug":"字节码","permalink":"https://mykkto.github.io/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"},{"name":"原理","slug":"原理","permalink":"https://mykkto.github.io/tags/%E5%8E%9F%E7%90%86/"},{"name":"java","slug":"java","permalink":"https://mykkto.github.io/tags/java/"},{"name":"分布式","slug":"分布式","permalink":"https://mykkto.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"数据库","slug":"数据库","permalink":"https://mykkto.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"ShardingSphere","slug":"ShardingSphere","permalink":"https://mykkto.github.io/tags/ShardingSphere/"},{"name":"分库分表","slug":"分库分表","permalink":"https://mykkto.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"},{"name":"jdbc","slug":"jdbc","permalink":"https://mykkto.github.io/tags/jdbc/"},{"name":"击穿、击穿、穿透","slug":"击穿、击穿、穿透","permalink":"https://mykkto.github.io/tags/%E5%87%BB%E7%A9%BF%E3%80%81%E5%87%BB%E7%A9%BF%E3%80%81%E7%A9%BF%E9%80%8F/"},{"name":"BloomFilter","slug":"BloomFilter","permalink":"https://mykkto.github.io/tags/BloomFilter/"},{"name":"分布式锁","slug":"分布式锁","permalink":"https://mykkto.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"},{"name":"redlock","slug":"redlock","permalink":"https://mykkto.github.io/tags/redlock/"},{"name":"lua","slug":"lua","permalink":"https://mykkto.github.io/tags/lua/"},{"name":"openresty","slug":"openresty","permalink":"https://mykkto.github.io/tags/openresty/"},{"name":"springcloud-alibaba","slug":"springcloud-alibaba","permalink":"https://mykkto.github.io/tags/springcloud-alibaba/"},{"name":"seata","slug":"seata","permalink":"https://mykkto.github.io/tags/seata/"},{"name":"分布式事务","slug":"分布式事务","permalink":"https://mykkto.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"},{"name":"blog","slug":"blog","permalink":"https://mykkto.github.io/tags/blog/"},{"name":"部署","slug":"部署","permalink":"https://mykkto.github.io/tags/%E9%83%A8%E7%BD%B2/"},{"name":"小姿势","slug":"小姿势","permalink":"https://mykkto.github.io/tags/%E5%B0%8F%E5%A7%BF%E5%8A%BF/"},{"name":"熔断器","slug":"熔断器","permalink":"https://mykkto.github.io/tags/%E7%86%94%E6%96%AD%E5%99%A8/"},{"name":"限流","slug":"限流","permalink":"https://mykkto.github.io/tags/%E9%99%90%E6%B5%81/"},{"name":"nacos","slug":"nacos","permalink":"https://mykkto.github.io/tags/nacos/"},{"name":"AQS","slug":"AQS","permalink":"https://mykkto.github.io/tags/AQS/"},{"name":"多线程","slug":"多线程","permalink":"https://mykkto.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"JUC","slug":"JUC","permalink":"https://mykkto.github.io/tags/JUC/"},{"name":"oracle","slug":"oracle","permalink":"https://mykkto.github.io/tags/oracle/"},{"name":"docker","slug":"docker","permalink":"https://mykkto.github.io/tags/docker/"},{"name":"安装","slug":"安装","permalink":"https://mykkto.github.io/tags/%E5%AE%89%E8%A3%85/"},{"name":"服务注册与发现","slug":"服务注册与发现","permalink":"https://mykkto.github.io/tags/%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0/"},{"name":"配置中心","slug":"配置中心","permalink":"https://mykkto.github.io/tags/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"},{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"服务跟踪","slug":"服务跟踪","permalink":"https://mykkto.github.io/tags/%E6%9C%8D%E5%8A%A1%E8%B7%9F%E8%B8%AA/"},{"name":"sleuth","slug":"sleuth","permalink":"https://mykkto.github.io/tags/sleuth/"},{"name":"消息驱动","slug":"消息驱动","permalink":"https://mykkto.github.io/tags/%E6%B6%88%E6%81%AF%E9%A9%B1%E5%8A%A8/"},{"name":"stream","slug":"stream","permalink":"https://mykkto.github.io/tags/stream/"},{"name":"bus","slug":"bus","permalink":"https://mykkto.github.io/tags/bus/"},{"name":"节点链接","slug":"节点链接","permalink":"https://mykkto.github.io/tags/%E8%8A%82%E7%82%B9%E9%93%BE%E6%8E%A5/"},{"name":"config","slug":"config","permalink":"https://mykkto.github.io/tags/config/"},{"name":"路由网关","slug":"路由网关","permalink":"https://mykkto.github.io/tags/%E8%B7%AF%E7%94%B1%E7%BD%91%E5%85%B3/"},{"name":"alibaba","slug":"alibaba","permalink":"https://mykkto.github.io/tags/alibaba/"},{"name":"gateway","slug":"gateway","permalink":"https://mykkto.github.io/tags/gateway/"},{"name":"linux","slug":"linux","permalink":"https://mykkto.github.io/tags/linux/"},{"name":"mysql","slug":"mysql","permalink":"https://mykkto.github.io/tags/mysql/"},{"name":"netflix","slug":"netflix","permalink":"https://mykkto.github.io/tags/netflix/"},{"name":"zuul","slug":"zuul","permalink":"https://mykkto.github.io/tags/zuul/"},{"name":"断路器","slug":"断路器","permalink":"https://mykkto.github.io/tags/%E6%96%AD%E8%B7%AF%E5%99%A8/"},{"name":"Hystrix","slug":"Hystrix","permalink":"https://mykkto.github.io/tags/Hystrix/"},{"name":"远程调用服务","slug":"远程调用服务","permalink":"https://mykkto.github.io/tags/%E8%BF%9C%E7%A8%8B%E8%B0%83%E7%94%A8%E6%9C%8D%E5%8A%A1/"},{"name":"openfeign","slug":"openfeign","permalink":"https://mykkto.github.io/tags/openfeign/"},{"name":"负载均衡","slug":"负载均衡","permalink":"https://mykkto.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"ribbon","slug":"ribbon","permalink":"https://mykkto.github.io/tags/ribbon/"},{"name":"hexo","slug":"hexo","permalink":"https://mykkto.github.io/tags/hexo/"},{"name":"github","slug":"github","permalink":"https://mykkto.github.io/tags/github/"},{"name":"seo","slug":"seo","permalink":"https://mykkto.github.io/tags/seo/"},{"name":"百度","slug":"百度","permalink":"https://mykkto.github.io/tags/%E7%99%BE%E5%BA%A6/"},{"name":"谷歌","slug":"谷歌","permalink":"https://mykkto.github.io/tags/%E8%B0%B7%E6%AD%8C/"},{"name":"Consul","slug":"Consul","permalink":"https://mykkto.github.io/tags/Consul/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://mykkto.github.io/tags/Zookeeper/"},{"name":"Eureka","slug":"Eureka","permalink":"https://mykkto.github.io/tags/Eureka/"},{"name":"搭建","slug":"搭建","permalink":"https://mykkto.github.io/tags/%E6%90%AD%E5%BB%BA/"},{"name":"生活","slug":"生活","permalink":"https://mykkto.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"段子","slug":"段子","permalink":"https://mykkto.github.io/tags/%E6%AE%B5%E5%AD%90/"},{"name":"感慨","slug":"感慨","permalink":"https://mykkto.github.io/tags/%E6%84%9F%E6%85%A8/"},{"name":"语录","slug":"语录","permalink":"https://mykkto.github.io/tags/%E8%AF%AD%E5%BD%95/"},{"name":"日记","slug":"日记","permalink":"https://mykkto.github.io/tags/%E6%97%A5%E8%AE%B0/"},{"name":"话痨","slug":"话痨","permalink":"https://mykkto.github.io/tags/%E8%AF%9D%E7%97%A8/"},{"name":"美文","slug":"美文","permalink":"https://mykkto.github.io/tags/%E7%BE%8E%E6%96%87/"},{"name":"总纲","slug":"总纲","permalink":"https://mykkto.github.io/tags/%E6%80%BB%E7%BA%B2/"},{"name":"分享","slug":"分享","permalink":"https://mykkto.github.io/tags/%E5%88%86%E4%BA%AB/"},{"name":"简书","slug":"简书","permalink":"https://mykkto.github.io/tags/%E7%AE%80%E4%B9%A6/"},{"name":"技术总纲","slug":"技术总纲","permalink":"https://mykkto.github.io/tags/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BA%B2/"}]}