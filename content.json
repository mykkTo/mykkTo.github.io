{"meta":{"title":"jack","subtitle":"jackの博客","description":"java | 计算机与网络 | 简书作者","author":"jack","url":"https://mykkto.github.io","root":"/"},"pages":[{"title":"404","date":"2019-08-10T08:41:10.000Z","updated":"2022-01-06T14:09:33.725Z","comments":true,"path":"404.html","permalink":"https://mykkto.github.io/404.html","excerpt":"","text":""},{"title":"","date":"2022-01-06T14:09:33.869Z","updated":"2022-01-06T14:09:33.869Z","comments":true,"path":"baidu_verify_xxxxxxx.html","permalink":"https://mykkto.github.io/baidu_verify_xxxxxxx.html","excerpt":"","text":"wvlc3L96QK"},{"title":"","date":"2022-01-06T14:09:33.871Z","updated":"2022-01-06T14:09:33.871Z","comments":true,"path":"google1xxxxxxx0.html","permalink":"https://mykkto.github.io/google1xxxxxxx0.html","excerpt":"","text":"google-site-verification: google110e5e5e14c8dcf0.html"},{"title":"放松一下","date":"2019-08-10T08:41:10.000Z","updated":"2022-01-06T14:09:33.745Z","comments":true,"path":"List/index.html","permalink":"https://mykkto.github.io/List/index.html","excerpt":"","text":"影音资源共享"},{"title":"archives","date":"2019-10-24T16:00:00.000Z","updated":"2022-01-06T14:09:33.867Z","comments":true,"path":"archives/index.html","permalink":"https://mykkto.github.io/archives/index.html","excerpt":"","text":""},{"title":"about","date":"2019-10-24T16:00:00.000Z","updated":"2022-01-06T14:09:33.867Z","comments":true,"path":"about/index.html","permalink":"https://mykkto.github.io/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-10-24T16:00:00.000Z","updated":"2022-01-06T14:09:33.869Z","comments":true,"path":"categories/index.html","permalink":"https://mykkto.github.io/categories/index.html","excerpt":"","text":""},{"title":"统计","date":"2020-10-31T02:11:28.000Z","updated":"2022-01-06T14:09:33.869Z","comments":true,"path":"census/index.html","permalink":"https://mykkto.github.io/census/index.html","excerpt":"","text":""},{"title":"留言板","date":"2022-01-06T15:45:01.231Z","updated":"2022-01-06T15:45:01.231Z","comments":true,"path":"contact/index.html","permalink":"https://mykkto.github.io/contact/index.html","excerpt":"","text":"畅所欲言 在这里可以留下你的足迹，欢迎在下方留言，欢迎交换友链，一起交流学习！ 友链 jackの友链信息 博客名称: jckの博客 博客网址: https://mykkto.github.io/"},{"title":"友链","date":"2019-07-19T08:42:10.000Z","updated":"2022-01-06T14:09:33.871Z","comments":true,"path":"friends/index.html","permalink":"https://mykkto.github.io/friends/index.html","excerpt":"","text":""},{"title":"资源分享","date":"2019-07-19T08:40:27.000Z","updated":"2022-01-06T14:09:33.872Z","comments":true,"path":"resource/index.html","permalink":"https://mykkto.github.io/resource/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-07-19T08:40:27.000Z","updated":"2022-01-06T14:09:33.873Z","comments":true,"path":"tags/index.html","permalink":"https://mykkto.github.io/tags/index.html","excerpt":"","text":""},{"title":"相册","date":"2022-01-08T15:55:11.896Z","updated":"2022-01-06T14:09:33.734Z","comments":true,"path":"List/galleries/index.html","permalink":"https://mykkto.github.io/List/galleries/index.html","excerpt":"","text":""},{"title":"视频","date":"2019-08-10T08:41:10.000Z","updated":"2022-01-06T14:09:33.745Z","comments":true,"path":"List/movies/index.html","permalink":"https://mykkto.github.io/List/movies/index.html","excerpt":"","text":""},{"title":"听听音乐","date":"2019-07-19T08:40:27.000Z","updated":"2022-01-06T14:09:33.746Z","comments":true,"path":"List/music/index.html","permalink":"https://mykkto.github.io/List/music/index.html","excerpt":"","text":""},{"title":"听听音乐","date":"2019-07-19T08:40:27.000Z","updated":"2022-01-06T14:09:33.747Z","comments":true,"path":"List/tools/index.html","permalink":"https://mykkto.github.io/List/tools/index.html","excerpt":"","text":""},{"title":"二次元风","date":"2022-01-06T14:09:33.735Z","updated":"2022-01-06T14:09:33.735Z","comments":true,"path":"List/galleries/二次元风/index.html","permalink":"https://mykkto.github.io/List/galleries/%E4%BA%8C%E6%AC%A1%E5%85%83%E9%A3%8E/index.html","excerpt":"","text":""},{"title":"乖巧小狗","date":"2022-01-06T14:09:33.734Z","updated":"2022-01-06T14:09:33.734Z","comments":true,"path":"List/galleries/乖巧小狗/index.html","permalink":"https://mykkto.github.io/List/galleries/%E4%B9%96%E5%B7%A7%E5%B0%8F%E7%8B%97/index.html","excerpt":"","text":""},{"title":"动漫人物","date":"2022-01-06T14:09:33.736Z","updated":"2022-01-06T14:09:33.736Z","comments":true,"path":"List/galleries/动漫人物/index.html","permalink":"https://mykkto.github.io/List/galleries/%E5%8A%A8%E6%BC%AB%E4%BA%BA%E7%89%A9/index.html","excerpt":"","text":""},{"title":"动漫插画","date":"2022-01-06T14:09:33.737Z","updated":"2022-01-06T14:09:33.737Z","comments":true,"path":"List/galleries/动漫插画/index.html","permalink":"https://mykkto.github.io/List/galleries/%E5%8A%A8%E6%BC%AB%E6%8F%92%E7%94%BB/index.html","excerpt":"","text":""},{"title":"动漫风景","date":"2022-01-06T14:09:33.738Z","updated":"2022-01-06T14:09:33.738Z","comments":true,"path":"List/galleries/动漫风景/index.html","permalink":"https://mykkto.github.io/List/galleries/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%99%AF/index.html","excerpt":"","text":""},{"title":"城市风光","date":"2022-01-06T14:09:33.739Z","updated":"2022-01-06T14:09:33.739Z","comments":true,"path":"List/galleries/城市风光/index.html","permalink":"https://mykkto.github.io/List/galleries/%E5%9F%8E%E5%B8%82%E9%A3%8E%E5%85%89/index.html","excerpt":"","text":""},{"title":"呆萌猫咪","date":"2022-01-06T14:09:33.738Z","updated":"2022-01-06T14:09:33.738Z","comments":true,"path":"List/galleries/呆萌猫咪/index.html","permalink":"https://mykkto.github.io/List/galleries/%E5%91%86%E8%90%8C%E7%8C%AB%E5%92%AA/index.html","excerpt":"","text":""},{"title":"清新花卉","date":"2022-01-06T14:09:33.740Z","updated":"2022-01-06T14:09:33.740Z","comments":true,"path":"List/galleries/清新花卉/index.html","permalink":"https://mykkto.github.io/List/galleries/%E6%B8%85%E6%96%B0%E8%8A%B1%E5%8D%89/index.html","excerpt":"","text":""},{"title":"炫酷跑车","date":"2022-01-08T15:55:21.871Z","updated":"2022-01-06T14:09:33.742Z","comments":true,"path":"List/galleries/炫酷跑车/index.html","permalink":"https://mykkto.github.io/List/galleries/%E7%82%AB%E9%85%B7%E8%B7%91%E8%BD%A6/index.html","excerpt":"","text":""},{"title":"璀璨星空","date":"2022-01-06T14:09:33.743Z","updated":"2022-01-06T14:09:33.743Z","comments":true,"path":"List/galleries/璀璨星空/index.html","permalink":"https://mykkto.github.io/List/galleries/%E7%92%80%E7%92%A8%E6%98%9F%E7%A9%BA/index.html","excerpt":"","text":""},{"title":"自然风景","date":"2022-01-06T14:09:33.744Z","updated":"2022-01-06T14:09:33.744Z","comments":true,"path":"List/galleries/自然风景/index.html","permalink":"https://mykkto.github.io/List/galleries/%E8%87%AA%E7%84%B6%E9%A3%8E%E6%99%AF/index.html","excerpt":"","text":""},{"title":"甜美食品","date":"2022-01-06T14:09:33.743Z","updated":"2022-01-06T14:09:33.743Z","comments":true,"path":"List/galleries/甜美食品/index.html","permalink":"https://mykkto.github.io/List/galleries/%E7%94%9C%E7%BE%8E%E9%A3%9F%E5%93%81/index.html","excerpt":"","text":""}],"posts":[{"title":"面试题-03(关于Cloud)","slug":"05-面试题/02-大厂面试题/面试题_03","date":"2023-02-15T14:28:51.000Z","updated":"2023-04-12T15:41:49.238Z","comments":true,"path":"posts/45f5cab5.html","link":"","permalink":"https://mykkto.github.io/posts/45f5cab5.html","excerpt":"","text":"前言：鸣谢给站长投稿问题的同行朋友，居多都是小伙伴面试被问到的问题，以及扩展 本章针对 中高开岗位题目甄选，如有不足还请评论区指教，感谢！ 目录： 你有过SpringCloud ？ 注册中心 那几款？对比？ 服务发现流程，原理？ 熔断器 那几款？对比？ MySQL 执行流程（5.7 ） 一、你有过SpringCloud ？当然，如果按照厂商分为两种：Netflix 和 alibaba ；如果按照技术栈则分为，注册中心、配置中心、网关、熔断器、服务调用、分布式事务、链路追踪等，不过核心的组件有五大，cloud是 eureka,feign,ribbon,hystrix,zuul，alibbaba:nacos,sentinel,gateway. 社区活跃，你在生产上遇到的问题不是第一个遇到，教程多 1、常规题（放松版）1.Nacos如何支撑阿里内部数十万服务注册压力Nacos内部接收到注册的请求时，不会立即写数据，而是将服务注册的任务放入一个阻塞队列就立即响应给客户端。然后利用线程池读取阻塞队列中的任务，异步来完成实例更新，从而提高并发写能力。 2.Nacos如何避免并发读写冲突问题Nacos在更新实例列表时，会采用CopyOnWrite技术，首先将旧的实例列表拷贝一份，然后更新拷贝的实例列表，再用更新后的实例列表来覆盖旧的实例列表。 这样在更新的过程中，就不会对读实例列表的请求产生影响，也不会出现脏读问题了。 3.Nacos与Eureka的区别有哪些 实例类型：Nacos的实例有永久和临时实例之分；而Eureka只支持临时实例 健康检测：Nacos对临时实例采用心跳模式检测，对永久实例采用主动请求来检测；Eureka只支持心跳模式 服务发现：Nacos支持定时拉取和订阅推送两种模式；Eureka只支持定时拉取模式 CAP理论：eureka只支持AP，nacos支持CP和AP两种 nacos是根据配置识别CP或AP模式,如果注册Nacos的client节点注册时是ephemeral=true即为临时节点,那么Naocs集群对这个client节点效果就是AP,反之则是CP,即不是临时节点 #false为永久实例，true表示临时实例开启，注册为临时实例 spring.cloud.nacos.discovery.ephemeral=true 连接方式： nacos使用的是netty和服务直接进行连接,属于长连接 eureka是使用定时发送和服务进行联系,属于短连接 4.Sentinel的限流与Gateway的限流有什么差别限流算法常见的有三种实现：滑动时间窗口、令牌桶算法、漏桶算法。Gateway则采用了基于Redis实现的令牌桶算法。 而Sentinel内部却比较复杂： 默认限流模式是基于滑动时间窗口算法 排队等待的限流模式则基于漏桶算法 而热点参数限流则是基于令牌桶算法 5.Sentinel的线程隔离与Hystix的线程隔离有什么差别Hystix默认是基于线程池实现的线程隔离，每一个被隔离的业务都要创建一个独立的线程池，线程过多会带来额外的CPU开销，性能一般，但是隔离性更强。 Sentinel是基于信号量（计数器）实现的线程隔离，不用创建线程池，性能较好，但是隔离性一般。 1、注册中心 ====Eureka=====包含2个组件：eureka server 和eureka client 注册中心，包含了服务发现、治理等功能。@EnableEurekaServer，作为注册中心； @EnableEurekaClient，作为服务的提供者、或消费者。下面分析下服务发现和治理。 1、注册服务于发现流程（eureka） 当EurekaClient启动后，首先会执行服务注册。 EurekaClient将服务信息封装成InstanceInfo对象，通过EurekaHttpClient调用register方法发送POST请求执行服务注册 EurekaServer提供了基于Jersey的Rest风格的接口，在ApplicationResource类中提供了addInstance方法用来接收注册信息。如果注册服务器信息通过校验，将服务信息保存至本地注册表。数据结构为双层ConcurrentHashMap，外层map：key是应用名，内层map：key是应用实例信息编号，value是InstanceInfo EurekaClient接收并解析注册结果，判断httpResponse的statusCode，如果是204则代表注册成功 调用replicateToPeers方法将此次注册信息复制到对等的Eureka节点 客户端注册：Eureka客户端在启动时，首先会创建一个心跳的定时任务，定时向服务端发送心跳信息，服务端会对客户端心跳做出响应，如果响应状态码为404时，表示服务端没有该客户端的服务信息，那么客户端则会向服务端发送注册请求。 服务端如何保存客户端注册信息：客户端通过Jersey框架，将自己的注册信息发送给服务端，服务端保存在一个ConcurrentHashMap对象中。 客户端如何拉取服务端已保存的服务信息：客户端通过一个定时任务定时向服务端拉取信息，每次拉取后刷新本地已保存的信息，需要使用时直接从本地获取。 2、Eureka心跳机制心跳机制 客户端每隔30s想服务端发送一次心跳，告诉服务端自己还活着。 服务剔除机制 如果开了自我保护机制，那么所有的客户端包括没有长时间没有发送心跳的客户端都不会被剔除。没开自我保护机制，注册到eureka的服务可能由于内存溢出或网络故障等原因使得服务不能正常的工作，而服务注册中心并未收到“服务下线”的请求。服务注册中心在启动时会创建一个定时任务，默认每隔一段时间（默认为60秒）将当前清单中超时（默认为90秒）没有续约的服务剔除，这个操作被称为失效剔除 Eureka为什么要采用自我保护机制 在分布式系统的CAP理论中，Eureka采用的AP，也就是Eureak保证了服务的可用性（A），而舍弃了数据的一致性（C）。当网络发生分区时，客户端和服务端的通讯将会终止，那么服务端在一定的时间内将收不到大部分的客户端的一个心跳，如果这个时候将这些收不到心跳 3、Eureka定时任务拉取服务器注册实例 该任务通过 ScheduledExecutorService 来实现任务调度，执行周期默认为 60 秒一次 获取的方式有两种，全量获取和增量获取。第一次全量获取，后续增量获取；获取到服务器注册实例信息后，保存、或更新到本地 续约该任务通过 ScheduledExecutorService 来实现任务调度，默认周期为 30 秒一次，通过 renew() 方法发起续约请求。将 AppName、AppId、以及InstanceInfo作为参数，通过EurekaHttpClient发送Http请求 EurekaServer 通过 renewLease() 方法接收续约请求首先根据AppName从注册表中获取对应的服务信息，并更新一些属性如renewsLastMin、lastUpdateTimestampEurekaServer 返回结果，200 或者 404，EurekaClient 接收续约结果；如果是 404 则发起一次 register 请求；如果是 200 则表示续约成功 =====Nacos=====1、Nacos 中的保护阈值作用假如现在有一个服务，本来有10个实例，但是现在挂掉了8个，剩下2个正常实例，此时本来由10个实例处理的流量，就全部交给这个两个正常实例来处理了，此时这两个实例很有可能是处理不过来的，最终导致被压垮，为了应对这种情况； Nacos提供了保护阈值这个功能，我们可以给某个服务设置一个0-1的阈值，比如0.5，那就表示，一旦实例中只剩下一半的健康实例了，比如10个实例，只剩下5个健康实例了，那么消费者在进行服务发现时，则会把该服务的所有实例，也包括不健康的实例都拉取到本地，然后再从所有实例中进行负载均衡，选出一个实例进行调用，在这种情况下，选出来的即可能是一个健康的实例，也可能是挂掉的实例，但是通过这种方式，很好的保护的剩下的健康实例，至少保证了一部分请求能正常的访问，而不至于所有请求都不能正常访问，这就是Nacos中的保护阈值，同时，这个功能在Spring Cloud Tencent中叫全死全活。 2、Nacos中的负载均衡Nacos的负载均衡指的是，在进行服务发现时进行负载均衡，正常情况下，会根据服务名从Nacos中拉取所有的实例信息，拉取实例时，根据随机策略只拉取到所有实例中的某一个，这就是Nacos中的负载均衡，它跟Ribbon的负载均衡并不冲突，可以理解为Ribbon的负载均衡是发生在Nacos的负载均衡之后的 3、Nacos的就近访问是什么在Nacos中，一个服务可以有多个实例，并且可以给实例设置cluster-name，就是可以再进一步的给所有实例划分集群，那如果现在某个服务A想要调用服务B，那么Naocs会看调用服务A的实例是属于哪个集群的，并且调用服务B时，那就会调用同样集群下的服务B实例，根据cluster-name来判断两个实例是不是同一个集群，这就是Nacos的就近访问 4、Nacos中保证的是CP还是AP通常我们说，Nacos技能保证CP，也能保证AP，具体看如何配置，但其实只不过是Nacos中的注册中心能保证CP或AP，Nacos中的配置中心其实没什么CP或AP，因为配置中心的数据是存在一个Mysql中的，只有注册中心的数据需要进行集群节点之间的同步，从而涉及到是CP还是AP，如果注册的节点是临时节点，那么就是AP，如果是非临时节点，那么就是CP，默认是临时节点。 5、如何理解Nacos中的命名空间在Nacos中，不管是配置还是服务，都是属于某一个命名空间中的，默认情况下是pulibc的，可以在Nacos中新增命名空间，也就相当于开辟了另外一套存放服务和配置的地方，命名空间之间是独立的，完全不冲突的，所以我们可以利用Nacos中的命名空间来实现不同环境、不同租户之间的服务注册和配置 6、你觉得注册中心应该是CP还是AP大部分情况下，注册中心应该是AP；如果注册中心是CP的，那么我们向注册中心注册实例或移除实例时，都要等待注册中心集群中的数据达到一致后，才算注册或移除成功，而这是比较耗时的，随着业务应用规模的增大，应用频繁的上下线，会影响到服务发现的效率以及服务调用了； 而如果注册中心是AP的，那么注册中心集群不管出现了什么情况，就算集群节点之间数据出现了不一致，对于业务应用而言，可能拉取到了一个已经下线了的服务节点，但是微服务框架或组件都提供了服务容错和重试功能，也可以避免这个问题。 而如果是AP，对于注册中心而言就不需要消耗太多实时性来保证数据一致性了，既保证最终一致性就可以了，这样注册中心的压力会小一点； Zookeeper（CP）来作为注册中心，但是如果集群中如果大多数节点挂掉了，就算还剩下一些Zookeeper节点，这些节点也是不能提供服务的，所以这个也不太合适，所以综合来看，注册中心应该保证AP会更好，就像Euraka、Nacos他们默认保证的就是AP。 ===Zookeeper====1、是什么zookeeper是一个分布式协调工具，为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。 2、8大应用场景（1）数据发布与订阅（配置中心） 发布与订阅即所谓的配置管理，顾名思义就是将数据发布到ZooKeeper节点上，供订阅者动态获取 数据，实现配置信息的集中式管理和动态更新。例如全局的配置信息，地址列表等就非常适合使 用。 数据发布/订阅的一个常见的场景是配置中心，发布者把数据发布到 ZooKeeper 的一个或一系列的 节点上，供订阅者进行数据订阅，达到动态获取数据的目的。 全局配置信息通常有3个特性： 数据量小 数据内容变化频繁 集群中各机器配置共享、一致 ZooKeeper 采用的是推拉结合的方式。 推: 服务端会推给注册了监控节点的客户端 Wathcer 事件通知 拉: 客户端获得通知后，然后主动到服务端拉取最新的数据 （2）分布式锁 处于不同节点上不同的服务，它们可能需要顺序的访问一些资源，这里需要一把分布式的锁。 分布式锁具有以下特性：写锁、读锁、时序锁。 写锁：在zk上创建的一个临时的无编号的节点。由于是无序编号，在创建时不会自动编号，导致只 能客户端有一个客户端得到锁，然后进行写入。 读锁：在zk上创建一个临时的有编号的节点，这样即使下次有客户端加入是同时创建相同的节点 时，他也会自动编号，也可以获得锁对象，然后对其进行读取。 时序锁：在zk上创建的一个临时的有编号的节点根据编号的大小控制锁。 （3）负载均衡 这里说的负载均衡是指软负载均衡。在分布式环境中，为了保证高可用性，通常同一个应用或同一个服务的提供方都会部署多份，达到对等服务。而消费者就需要在这些对等的服务器中选择一个来执行相关的业务逻辑，其中比较典型的是消息中间件中的生产者，消费者负载均衡。 消息中间件中发布者和订阅者的负载均衡，linkedin 开源的 KafkaMQ 和阿里开源的 metaq 都是通过 zookeeper 来做到生产者、消费者的负载均衡。这里以metaq为例如讲下： 生产者负载均衡：metaq 发送消息的时候，生产者在发送消息的时候必须选择一台 broker 上的一个分区来发送消息，因此metaq 在运行过程中，会把所有 broker和对应的分区信息全部注册到ZK指定节点上，默认的策略是一个依次轮询的过程，生产者在通过ZK获取分区列表之后，会按照 brokerId和partition的顺序排列组织成一个有序的分区列表，发送的时候按照从头到尾循环往复的方式选择一个分区来发送消息。 消费负载均衡： 在消费过程中，一个消费者会消费一个或多个分区中的消息，但是一个分区只会由一个消费者来消费。MetaQ的消费策略是： 每个分区针对同一个group只挂载一个消费者。 如果同一个group的消费者数目大于分区数目，则多出来的消费者将不参与消费。 如果同一个group的消费者数目小于分区数目，则有部分消费者需要额外承担消费任务。 在某个消费者故障或者重启等情况下，其他消费者会感知到这一变化（通过 zookeeper watch消费者列表），然后重新进行负载均衡，保证所有的分区都有消费者进行消费。 （4）命名服务 作为分布式命名服务，命名服务是指通过指定的名字来获取资源或者服务的地址，利用ZooKeeper 创建一个全局的路径，这个路径就可以作为一个名字，指向集群中的集群，提供的服务的地址，或者一个远程的对象等等 （5）分布式协调/通知 Zookeeper中特有的Watcher注册于异步通知机制，能够很好地实现分布式环境下不同机器，甚至不同系统之间的协调与通知，从而实现对数据变更的实时处理。通常的做法是不同的客户端都对Zookeeper上的同一个数据节点进行Watcher注册，监听数据节点的变化（包括节点本身和子节点），若数据节点发生变化，那么所有订阅的客户端都能够接收到相应的Watcher通知，并作出相应处理。 在绝大多数分布式系统中，系统机器间的通信无外乎心跳检测、工作进度汇报和系统调度。这三种类型的机器通信方式都可以使用zookeeper来实现： 1、心跳检测，不同机器间需要检测到彼此是否在正常运行，可以使用Zookeeper实现机器间的心跳检测，基于其临时节点特性（临时节点的生存周期是客户端会话，客户端若当即后，其临时节点自然不再存在），可以让不同机器都在Zookeeper的一个指定节点下创建临时子节点，不同的机器之间可以根据这个临时子节点来判断对应的客户端机器是否存活。通过Zookeeper可以大大减少系统耦合。 2、工作进度汇报，通常任务被分发到不同机器后，需要实时地将自己的任务执行进度汇报给分发系统，可以在Zookeeper上选择一个节点，每个任务客户端都在这个节点下面创建临时子节点，这样不仅可以判断机器是否存活，同时各个机器可以将自己的任务执行进度写到该临时节点中去，以便中心系统能够实时获取任务的执行进度。 3、系统调度，Zookeeper能够实现如下系统调度模式：分布式系统由控制台和一些客户端系统两部分构成，控制台的职责就是需要将一些指令信息发送给所有的客户端，以控制他们进行相应的业务逻辑，后台管理人员在控制台上做一些操作，实际上就是修改Zookeeper上某些节点的数据，Zookeeper可以把数据变更以时间通知的形式发送给订阅客户端。 （6）集群管理 Zookeeper的两大特性（节点特性和watcher机制）： 1、客户端如果对Zookeeper的数据节点注册Watcher监听，那么当该数据及诶单内容或是其子节点列表发生变更时，Zookeeper服务器就会向订阅的客户端发送变更通知。 2、对在Zookeeper上创建的临时节点，一旦客户端与服务器之间的会话失效，那么临时节点也会被自动删除。 机器在线率有较高要求的场景，能够快速对集群中机器变化作出响应。这样的场景中，往往有一个监控系统，实时检测集群机器是否存活。过去的做法通常是：监控系统通过某种手段（比如ping）定时检测每个机器，或者每个机器自己定时向监控系统汇报“我还活着”。这种做法可行，但是存在两个比较明显的问题： 集群中机器有变动的时候，牵连修改的东西比较多。 有一定的延时。 利用ZooKeeper有两个特性，就可以实时另一种集群机器存活性监控系统。可以实现集群机器存活监控系统，若监控系统在/clusterServers节点上注册一个Watcher监听，那么但凡进行动态添加机器的操作，就会在/clusterServers节点下创建一个临时节点：/clusterServers/[Hostname]，这样，监控系统就能够实时监测机器的变动情况。 下面通过分布式日志收集系统的典型应用来学习Zookeeper如何实现集群管理。 分布式日志收集系统的核心工作就是收集分布在不同机器上的系统日志，在典型的日志系统架构设计中，整个日志系统会把所有需要收集的日志机器分为多个组别，每个组别对应一个收集器，这个收集器其实就是一个后台机器，用于收集日志，对于大规模的分布式日志收集系统场景，通常需要解决两个问题： 1、变化的日志源机器 2、变化的收集器机器 无论是日志源机器还是收集器机器的变更，最终都可以归结为如何快速、合理、动态地为每个收集器分配对应的日志源机器。 a、注册收集器机器，在Zookeeper上创建一个节点作为收集器的根节点，例如/logs/collector的收集器节点，每个收集器机器启动时都会在收集器节点下创建自己的节点，如/logs/collector/[Hostname] b、任务分发，所有收集器机器都创建完对应节点后，系统根据收集器节点下子节点的个数，将所有日志源机器分成对应的若干组，然后将分组后的机器列表分别写到这些收集器机器创建的子节点，如/logs/collector/host1（持久节点）上去。这样，收集器机器就能够根据自己对应的收集器节点上获取日志源机器列表，进而开始进行日志收集工作。 c、状态汇报，完成任务分发后，机器随时会宕机，所以需要有一个收集器的状态汇报机制，每个收集器机器上创建完节点后，还需要再对应子节点上创建一个状态子节点，如/logs/collector/host/status（临时节点），每个收集器机器都需要定期向该结点写入自己的状态信息，这可看做是心跳检测机制，通常收集器机器都会写入日志收集状态信息，日志系统通过判断状态子节点最后的更新时间来确定收集器机器是否存活。 d、动态分配，若收集器机器宕机，则需要动态进行收集任务的分配，收集系统运行过程中关注/logs/collector节点下所有子节点的变更，一旦有机器停止汇报或有新机器加入，就开始进行任务的重新分配，此时通常由两种做法： 1、全局动态分配，当收集器机器宕机或有新的机器加入，系统根据新的收集器机器列表，立即对所有的日志源机器重新进行一次分组，然后将其分配给剩下的收集器机器。 2、局部动态分配，每个收集器机器在汇报自己日志收集状态的同时，也会把自己的负载汇报上去，如果一个机器宕机了，那么日志系统就会把之前分配给这个机器的任务重新分配到那些负载较低的机器，同样，如果有新机器加入，会从那些负载高的机器上转移一部分任务给新机器 （8）分布式队列 分布式队列分为两种： 1、当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达，这种是同步队 列。 a）一个job由多个task组成，只有所有任务完成后，job才运行完成。 b）可为job创建一个/job目录，然后在该目录下，为每个完成的task创建一个临时的Znode，一旦 临时节点数目达到task总数，则表明job运行完成。 2、队列按照FIFO方式进行入队和出队操作，例如实现生产者和消费者模型。 3、Zookeeper的工作原理Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做 Zab协议。 Zab协议有两种模式，它们 分别是恢复模式（选主）和广播模式（同步）。 Zookeeper 是通过 Zab 协议来保证分布式事务的最终一致性。Zab协议要求每个 Leader 都要经历三个阶段：发现，同步，广播。 当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server 完成了和 leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的 系统状态。 为了保证事务的顺序一致性，zookeeper采用了递增的事务id号（zxid）来标识事务。所有的提议 （proposal）都在被提出的时候加上了zxid。实现中zxid是一个64位的数字，它高32位是epoch用 来标识leader关系是否改变，每次一个leader被选出来，它都会有一个新的epoch（纪元），标识当前属于那个leader的统治时期。低32位用于递增计数。 epoch：可以理解为皇帝的年号，当新的皇帝leader产生后，将有一个新的epoch年号。 每个Server在工作过程中有三种状态： LOOKING：当前Server不知道leader是谁，正在搜寻。 LEADING：当前Server即为选举出来的leader。 FOLLOWING：leader已经选举出来，当前Server与之同步。 4、Zookeeper 的通知机制是Zookeeper 允许客户端向服务端的某个 znode 注册一个 Watcher 监听，当服务端的一些指定事件 触发了这个 Watcher ，服务端会向指定客户端发送一个事件通知来实现分布式的通知功能，然后客 户端根据 Watcher 通知状态和事件类型做出业务上的改变。 大致分为三个步骤： 客户端注册 Watcher 1、调用 getData、getChildren、exist 三个 API ，传入Watcher 对象。 2、标记请求 request ，封装 Watcher 到 WatchRegistration 。 3、封装成 Packet 对象，发服务端发送 request 。 4、收到服务端响应后，将 Watcher 注册到 ZKWatcherManager 中进行管理。 5、 请求返回，完成注册。 服务端处理 Watcher 1、服务端接收 Watcher 并存储。 2、Watcher 触发 3、调用 process 方法来触发 Watcher 。 客户端回调 Watcher 1，客户端 SendThread 线程接收事件通知，交由 EventThread 线程回调Watcher 。 2，客户端 的 Watcher 机制同样是一次性的，一旦被触发后，该 Watcher 就失效了。 client 端会对某个 znode 建立一个 watcher 事件，当该 znode 发生变化时，这些 client 会收 到 zk 的通知，然后 client 可以根据 znode 变化来做出业务上的改变等。 5、Zookeeper 对节点的 watch 监听通知是永久的吗一次性的。无论是服务端还是客户端，一旦一个 Watcher 被触发， Zookeeper 都会将其从 相应的存储中移除。这样的设计有效的减轻了服务端的压力，不然对于更新非常频繁的节点，服务 端会不断的向客户端发送事件通知，无论对于网络还是服务端的压力都非常大。 6、Zookeeper 集群中有哪些角色 7、Zookeeper 集群中Server有哪些工作状态LOOKING 寻找 Leader 状态；当服务器处于该状态时，它会认为当前集群中没有 Leader ，因此需要进入 Leader 选举状态 FOLLOWING 跟随者状态；表明当前服务器角色是 Follower LEADING 领导者状态；表明当前服务器角色是 Leader OBSERVING 观察者状态；表明当前服务器角色是 Observer 8、9、10、11、12、13、14、15、16、17、18、2、熔断器1、对比图3、网关4、5、二、Mysql高级面基高级特性本周整理大纲：1、执行流程（5.7 and 8.0 暂不整理），逻辑架构（三层）；图、概述，白话总结2、存储引擎（InnoDB MyISAM （核心对比图）…边缘5种简述-了解）；装逼：阿里自定义引擎：Xtradb3、索引迭代设计（是非聚簇索引，二级、联合索引），索引使用常见（11 yes 7 not）；边缘所以你接口对比（HASH、AVL、B、B+）、Explain调优阿里、三范式 ER模型N、事务（显式、隐式），锁（表锁：S锁、X锁、意向锁、自增锁、元数据锁；行锁：记录锁、间隙锁、临键锁、插入意向锁；乐观悲观锁…..） 扩展待定？ 1| 精简1、执行流程SQL流程 sql语句 -&gt; 查询缓存 -&gt; 解析器 -&gt; 优化器 -&gt; 执行器 完整流程 客户端程序 connectors &gt;&gt; 连接池 &gt;&gt; SQL接口 &gt;&gt; 解析器 &gt;&gt; 优化器 &gt;&gt; 查询缓存 &gt;&gt; 插件式存储引擎 &gt;&gt; File（文件系统/日志文件） 客户端程序 : 包括一些mysql工具如：native 或者语言工具如：php 、go 、python 连接池 : 提供多个用户客户端和服务端交互的线程 SQL接口 : 接收sql命令，返回查询结果 解析器 : 进行sql语法的解析、语意解析、生成语法树 优化器 : mysql核心组件，对sql命令进行优化 缓存 : 以key -&gt; value方式缓存查询结果 (如果查询sql指令有缓存直接在SQL接口部分返回缓存结果) 存储引擎 : 与底层文件进行交互，查询数据文件系统、日志文件等 mysql server三层架构 1、连接层 mysql服务器有专门的tcp连接池限制最大连接数，采用长连接模式复用tcp连接，进行连接交互 2、服务层 Interface 接口 解析器 查询优化器 查询缓存组件 3、引擎层 插件式的存储引擎层，真正的负责了mysql中数据的存储和提取，对物理服务器级别维护的底层数据执行操作，服务器通过api与存储引擎通信。不同的存储引擎具有的功能不同，支持二开引擎【阿里：Xtradb】 2、聚簇索引和非聚簇索引对比： 聚簇索引叶子节点存储的是行数据；而非聚簇索引叶子节点存储的是聚簇索引（通常是主键 ID）。 聚簇索引查询效率更高，而非聚簇索引需要进行回表查询，因此性能不如聚簇索引。 聚簇索引一般为主键索引，而主键一个表中只能有一个，因此聚簇索引一个表中也只能有一个，而非聚簇索引则没有数量上的限制 聚簇索引 id 对应的 B+ 树如下图所示： 在 student 中非聚簇索引 class_id 对应 B+ 树如下图所示： 3、存储引擎对比图： MyISAM 与 InnoDB两种引擎中索引的区别 ① 在InnoDB存储引擎中，我们只需要根据主键值对聚簇索引进行一次查找就能找到对应的记录，而在MyISAM中却需要进行一次回表操作，意味着MyISAM中建立的索引相当于全部都是二级索引。 ② InnoDB的数据文件本身就是索引文件，而MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。 ③ InnoDB的非聚簇索引data域存储相应记录主键的值，而MyISAM索引记录的是地址。换句话说，InnoDB的所有非聚簇索引都引用主键作为data域。 ④ MyISAM的回表操作是十分快速的，因为是拿着地址偏移量直接到文件中取数据的，反观InnoDB是通过获取主键之后再去聚簇索引里找记录，虽然说也不慢，但还是比不上直接用地址去访问。 ⑤ InnoDB要求表必须有主键（MyISAM可以没有）。如果没有显式指定，则MySQL系统会自动选择一个可以非空且唯一标识数据记录的列作为主键。如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整型。 补充1：InnoDB的逻辑结构图： 4、为什么覆盖索引不用回表一级索引：聚簇索引即主键索引二级索引：非聚簇索引 一级B+Tree：叶子节点保存着键（id的值）和数据（全部字段的值）二级B+Tree：叶子节点保存着键（索引字段的值）和数据（主键索引值） 查询 一级索引，根据一级B+Tree查询到数据，直接返回数据查询 二级索引，根据二级B+Tree查询到对应的聚簇索引，再根据聚簇索引在一级B+Tree里查询到相应数据 查询 一级索引只需要扫描一次B+Tree。查询 二级索引需要扫描两次B+Tree。根据二级B+Tree扫描的结果，再去一级B+Tree里进行扫描就叫回表操作。 如果使用组合索引，就可以利用覆盖索引避免回表操作例如：表一共有五个字段：a（主键索引），b_c_d（组合索引），e（没有索引） 如果用户查询时只查 b,c,d 例：SELECT b, c, d FROM table WHERE b = 3 AND c = 7 AND d = 5; 因为查询的字段 b,c,d的值（B+Tree里的键） 已经在B+Tree里了，所以就可以直接返回，不用再拿聚簇索引去一级B+Tree里进行查询如果查询字段为 a,b,c,d 因为a为主键索引，也保存再二级B+Tree的叶子节点里，所以也不用回表查询如果查询字段为 a,b,c,d,e 因为e没有在这个二级B+Tree里，所以需要进行回表操作，拿着主键索引再去一级B+Tree里进行查询。 5、B+tree时间复杂度：O(logN) B+Tree是B-Tree的变种，我们以一颗最大度数（max-degree）为4阶（4指针3key）的b+tree为例 最终我们看到，B+Tree 与 B-Tree相比，主要有以下三点区别： 所有的数据都会出现在叶子节点。 叶子节点形成一个单向链表。 非叶子节点仅仅起到索引数据作用，具体的数据都是在叶子节点存放的。 MySQL索引数据结构对经典的B+Tree进行了优化。在原B+Tree的基础上，增加一个指向相邻叶子节点的链表指针，就形成了带有顺序指针的B+Tree，提高区间访问的性能，利于排序。 6、SQL优化（慢SQL优化）第一步：可以用 explain 查看执行计划 常见案例优化： 1-1、insert insert into tb_test values(1,'tom'); insert into tb_test values(2,'cat'); insert into tb_test values(3,'jerry'); 优化，通过手动控制事务 start transaction; insert into tb_test values(1,'Tom'),(2,'Cat'),(3,'Jerry'); insert into tb_test values(4,'Tom'),(5,'Cat'),(6,'Jerry'); insert into tb_test values(7,'Tom'),(8,'Cat'),(9,'Jerry'); commit; 1-2、大批量插入数据 -- 客户端连接服务端时，加上参数 -–local-infile mysql –-local-infile -u root -p -- 设置全局参数local_infile为1，开启从本地加载文件导入数据的开关 set global local_infile = 1; -- 执行load指令将准备好的数据，加载到表结构中 load data local infile '/root/sql1.log' into table tb_user fields terminated by ',' lines terminated by '\\n' ; 主键顺序插入性能高于乱序插入 2-1、主键优化 满足业务需求的情况下，尽量降低主键的长度。 插入数据时，尽量选择顺序插入，选择使用AUTO_INCREMENT自增主键。（单调递增，高并发ID：雪花算法） 尽量不要使用UUID做主键或者是其他自然主键，如身份证号。 业务操作时，避免对主键的修改。 3-1、order by 优化 根据排序字段建立合适的索引，多字段排序时，也遵循最左前缀法则。 尽量使用覆盖索引 多字段排序, 一个升序一个降序，此时需要注意联合索引在创建时的规则（ASC/DESC） 如果不可避免的出现filesort，大数据量排序时，可以适当增大排序缓冲区大小 sort_buffer_size(默认256k 科普： 1、最左前缀法则（最左原则）： 比如，age 字段有索引，phone 没有索引，那么排序的时候，先写age 写在左边 2、Using filesort and Using index MySQL的排序，有两种方式： Using filesort : 通过表的索引或全表扫描，读取满足条件的数据行，然后在排序缓冲区sort buffer中完成排序操作，所有不是通过索引直接返回排序结果的排序都叫 FileSort 排序。 Using index : 通过有序索引顺序扫描直接返回有序数据，这种情况即为 using index，不需要额外排序，操作效率高。 对于以上的两种排序方式，Using index的性能高，而Using filesort的性能低，我们在优化排序操作时，尽量要优化为 Using index。 3、覆盖索引： 尽量使用覆盖索引，减少select *。那么什么是覆盖索引呢？覆盖索引是指查询使用了索引，且需要返回的列，在该索引中已经全部能够找到 4-1、 group by ** **优化 在分组操作时，可以通过索引来提高效率 分组操作时，索引的使用也是满足最左前缀法则的 5-1、limit ** **优化 一般分页查询时，通过创建 覆盖索引 能够比较好地提高性能，可以通过覆盖索引加子查询形式进行优化 explain select * from tb_sku t , (select id from tb_sku order by id limit 2000000,10) a where t.id = a.id; 6-1、count 优化 按照效率排序的话，count(字段) &lt; count(主键 id) &lt; count(1) ≈ count(*)，所以尽量使用 count(*)。 7-1、update 优化 我们主要需要注意一下update语句执行时的注意事项。(加索引的字段) update course set name = 'javaEE' where id = 1 ; 当我们在执行删除的SQL语句时，会锁定id为1这一行的数据，然后事务提交之后，行锁释放。 但是当我们在执行如下SQL时。(未加索引的字段) update course set name = 'SpringBoot' where name = 'PHP' ; 当我们开启多个事务，在执行上述的SQL时，我们发现行锁升级为了表锁。 导致该update语句的性能大大降低。 InnoDB的行锁是针对索引加的锁，不是针对记录加的锁 ,并且该索引不能失效，否则会从行锁升级为表锁 。 7、索引失效1、索引列运算 2、字符串不加引号 我们会明显的发现，如果字符串不加单引号，对于查询结果，没什么影响，但是数据库存在隐式类型转换，索引将失效 3、模糊查询 在like模糊查询中，在关键字后面加%，索引可以生效。而如果在关键字前面加了%，索引将会失效。 4、or 连接条件 当or连接的条件，左右两侧字段都有索引时，索引才会生效 5、数据分布影响 （1）基本数值，数据不同 MySQL在查询时，会评估使用索引的效率与走全表扫描的效率，如果走全表扫描更快，则放弃索引，走全表扫描。 因为索引是用来索引少量数据的，如果通过索引查询返回大批量的数据，则还不如走全表扫描来的快，此时索引就会失效 （2）is null 、 is not null 接下来，我们做一个操作将profession字段值全部更新为null，再次看下执行计划 最终我们看到，一模一样的SQL语句，先后执行了两次，结果查询计划是不一样的，为什么会出现这种 现象，这是和数据库的数据分布有关系。查询时MySQL会评估，走索引快，还是全表扫描快，如果全表扫描更快，则放弃索引走全表扫描。 因此，is null 、is not null是否走索引，得具体情况具体分析，并不是固定的 （3）总结： 数据分布会根据索引数据量和全表扫描快慢比较，哪个快走哪里 8、索引设计原则 针对于数据量较大，且查询比较频繁的表建立索引。 针对于常作为查询条件（where）、排序（order by）、分组（group by）操作的字段建立索引 尽量选择区分度高的列作为索引，尽量建立唯一索引，区分度越高，使用索引的效率越高。 (eg:0,1那种状态不要建立 如果是字符串类型的字段，字段的长度较长，可以针对于字段的特点，建立前缀索引。 尽量使用联合索引，减少单列索引，查询时，联合索引很多时候可以覆盖索引，节省存储空间，避免回表，提高查询效率。 要控制索引的数量，索引并不是多多益善，索引越多，维护索引结构的代价也就越大，会影响增删改的效率。 三、MQ执行流程 、消息可靠性投递（现有企业封装了。。。）-小总结、 1、常规1、什么是MQ，优缺点消息队列 异步处理，提高吞吐量 应用解耦，比如发送短信 流量削峰，可以通过消息队列长度控制请求量 增加系统复杂度，需要保证消息不重复消费，保证一致性，消息可靠性 2、什么是RabbitMq？为什么用？应用场景？基于erlang语言开发，基于AMQP协议的消息中间件 社区活跃，国内使用的公司也多，吞吐量万级到十万级别，完善的管理界面。成熟的消息队列。 应用场景：服务间异步通信，顺序消费，定时任务，请求削峰 3、RabbitMQ基本概念?Exchange 交换机 Queue 消息队列 Binding 绑定，将交换机和队列按路由规则绑定起来 Routing Key 路由关键字，exchange根据这个关键字进行消息投递 VHost 相当于某个数据库 Producer 消息生产者 Consumer 消息消费者 4、RabbitMq工作模式？ 简单模式 HelloWorld ：一个生产者、一个消费者，不需要设置交换机（使用默认的交换机）。 工作队列模式 Work Queue ：一个生产者、多个消费者（竞争关系），不需要设置交换机（使用默认的交换机）。 发布订阅模式 Publish/subscribe ：需要设置类型为 fanout 的交换机，并且交换机和队列进行绑定，当发送消息到交换机后，交换机会将消息发送到绑定的队列。 路由模式 Routing ：需要设置类型为 direct 的交换机，交换机和队列进行绑定，并且指定 routing key，当发送消息到交换机后，交换机会根据 routing key 将消息发送到对应的队列。 通配符模式 Topic ：需要设置类型为 topic 的交换机，交换机和队列进行绑定，并且指定通配符方式的 routing key，当发送消息到交换机后，交换机会根据 routing key 将消息发送到对应的队列。 5、RabbitMq如何保证消息有序性?一个队列对应一个消费者 6、RabbitMq如何保证消费不会被重复消费？根据业务来，比如订单有状态。或者定义唯一标识，消费后缓存到redis。在此消费时候判断一下redis。 7、RabbitMQ如何保证消息的可靠性?生产者丢失消息： 1.使用事务机制，牺牲性能 2.使用confirm模式，发送成功之后，会返回ack到生产者 消息队列丢失消息： 1.消息持久化 Exchange 设置持久化 ,Queue 设置持久化，durable设置为true Message持久化发送：发送消息设置发送模式deliveryMode=2，代表持久化消息 消费者丢失消息 1.ACK确认机制 消费者确认消费后，RabbitMq才会将消息删除 8、RabbitMQ部署方式?1.单机模式 2.普通集群(主从) 3.镜像集群 9、什么是RocketMQ？java开发，面向互联网集群化，功能丰富，对在线业务的响应时延做了很多的优化，大多数情况下可以做到毫秒级的响应，每秒钟大概能处理几十万条消息 10、RocketMq实现消息事务的流程？1.服务A发送一个半事务消息(half 消息)到RocketMq中,保证服务A和RocketMq正常通信,无法正常通信则回滚,正常则开始本地事务，处理本地业务逻辑并提交事务. 2.事务提交成功则向RocketMq发送提交，表示将 half 消息提交，将 half 消息写入到磁盘.事务提交失败则向RocketMq发送回滚，删除 half 消息. 3.如果RocketMq指定时间没有收到提交或者回滚消息，将尝试调用服务A提供的一个接口来判断half 消息对于的业务是否成功，成功则持久化，失败则删除 4.服务B消费RocketMq中的消息，处理本地业务，提交事务 11、RocketMq的half 消息是什么？half消息只有被提交后才会被消费者消费 12、为什么要先发送 half 消息？为了保证服务 A 和 RocketMq之间是否能正常通信 13、如果服务 A 本地事务执行失败了会怎么样？本地事务进行回滚，在向 RocketMq发送 rollback 操作。 14、服务 B 本地事务提交失败了会怎么样？可以进行多次重试，直到成功。如果重试多次后，还是提交失败，那么 MQ 会在一定时间后，继续将这条消息推送给服务 B，服务 B 就可以继续执行本地事务并提交了，直到成功。保证最终一致性 15、如何保证RocketMq消息不丢失?生产阶段只要发送返回ok状态就代表成功, 异步发送在回调中可以检查发送状态ok就代表成功, 存储阶段修改刷盘策略为同步刷盘。默认情况下是异步刷盘的。 集群部署，一主多从。默认异步复制，设置同步复制，牺牲性能 主节点设置同步复制 brokerRole=SYNC_MASTER 2、进阶1、Rabbitmq 执行流程 Broker：接收和分发消息的应用，RabbitMQ Server就是 Message Broker Virtual host：出于多租户和安全因素设计的，把 AMQP 的基本组件划分到一个虚拟的分组中，类似于网 络中的 namespace 概念。当多个不同的用户使用同一个 RabbitMQ server 提供的服务时，可以划分出多 个vhost，每个用户在自己的 vhost 创建 exchange／queue 等 Connection：publisher／consumer 和 broker 之间的 TCP 连接 Channel：如果每一次访问 RabbitMQ 都建立一个 Connection，在消息量大的时候建立 TCP Connection 的开销将是巨大的，效率也较低。Channel 是在 connection 内部建立的逻辑连接，如果应用程序支持多线 程，通常每个thread创建单独的 channel 进行通讯，AMQP method 包含了channel id 帮助客户端和 message broker 识别 channel，所以 channel 之间是完全隔离的。Channel 作为轻量级的 Connection 极大减少了操作系统建立 TCP connection 的开销 Exchange：message 到达 broker 的第一站，根据分发规则，匹配查询表中的 routing key，分发消息到 queue 中去。常用的类型有：direct (point-to-point), topic (publish-subscribe) and fanout (multicast) Queue：消息最终被送到这里等待 consumer 取走 Binding：exchange 和 queue 之间的虚拟连接，binding 中可以包含 routing key。Binding 信息被保存到 exchange 中的查询表中，用于 message 的分发依据 2、MQ消息可靠性投递0、主要实现步骤 生产者确认机制 消费者确认机制 持久化（交换机，队列，消息） 失败重试机制 消息堆积问题 1、生产者消息确认 （1）publisher-comfirm：消息成功发送到exchange，返回ack消息发送失败，没有到达交换机，返回nack消息，发送过程中出现异常，没有收到回执 （2）消息成功发送到exchange，但没有路由到queue，回调ReturnCallback （3）确认机制发送消息时，需要给每个消息设置一个全局唯一id，以区分不同消息，避免ack冲突 2、消费者确认机制 RabbitMQ是阅后即焚机制，RabbitMQ确认消息被消费者消费后会立刻删除。 而RabbitMQ是通过消费者回执来确认消费者是否成功处理消息的：消费者获取消息后，应该向RabbitMQ发送ACK回执，表明自己已经处理消息。 设想这样的场景： 1）RabbitMQ投递消息给消费者 2）消费者获取消息后，返回ACK给RabbitMQ 3）RabbitMQ删除消息 4）消费者宕机，消息尚未处理 这样，消息就丢失了。因此消费者返回ACK的时机非常重要。 而SpringAMQP则允许配置三种确认模式： •manual：手动ack，需要在业务代码结束后，调用api发送ack。 •auto：自动ack，由spring监测listener代码是否出现异常，没有异常则返回ack；抛出异常则返回nack •none：关闭ack，MQ假定消费者获取消息后会成功处理，因此消息投递后立即被删除 由此可知： none模式下，消息投递是不可靠的，可能丢失 auto模式类似事务机制，出现异常时返回nack，消息回滚到mq；没有异常，返回ack manual：自己根据业务情况，判断什么时候该ack 一般，我们都是使用默认的auto即可 3、持久化 （1）交换机持久化 RabbitMQ中交换机默认是非持久化的，mq重启后就丢失。 SpringAMQP中可以通过代码指定交换机持久化： @Bean public DirectExchange simpleExchange(){ // 三个参数：交换机名称、是否持久化、当没有queue与其绑定时是否自动删除 return new DirectExchange(\"simple.direct\", true, false); } 事实上，默认情况下，由SpringAMQP声明的交换机都是持久化的。 可以在RabbitMQ控制台看到持久化的交换机都会带上D的标示： （2）队列持久化 RabbitMQ中队列默认是非持久化的，mq重启后就丢失。 SpringAMQP中可以通过代码指定交换机持久化： @Bean public Queue simpleQueue(){ // 使用QueueBuilder构建队列，durable就是持久化的 return QueueBuilder.durable(\"simple.queue\").build(); } 事实上，默认情况下，由SpringAMQP声明的队列都是持久化的。 可以在RabbitMQ控制台看到持久化的队列都会带上D的标示： （3）消息持久化 利用SpringAMQP发送消息时，可以设置消息的属性（MessageProperties），指定delivery-mode： 1：非持久化 2：持久化 默认情况下，SpringAMQP发出的任何消息都是持久化的，不用特意指定。 4、失败重试机制 步骤： 本地重试机制 -》 死信队列 4-1、本地重试 我们可以利用Spring的retry机制，在消费者出现异常时利用本地重试，而不是无限制的requeue到mq队列。 修改consumer服务的application.yml文件，添加内容： spring: rabbitmq: listener: simple: retry: enabled: true # 开启消费者失败重试 initial-interval: 1000ms # 初始的失败等待时长为1秒 multiplier: 1 # 失败的等待时长倍数，下次等待时长 = multiplier * last-interval max-attempts: 3 # 最大重试次数 stateless: true # true无状态；false有状态。如果业务中包含事务，这里改为false 结论： 开启本地重试时，消息处理过程中抛出异常，不会requeue到队列，而是在消费者本地重试 重试达到最大次数后，Spring会返回ack，消息会被丢弃 4-2、失败策略 在之前的测试中，达到最大重试次数后，消息会被丢弃，这是由Spring内部机制决定的。 在开启重试模式后，重试次数耗尽，如果消息依然失败，则需要有MessageRecovery接口来处理，它包含三种不同的实现： RejectAndDontRequeueRecoverer：重试耗尽后，直接reject，丢弃消息。默认就是这种方式 ImmediateRequeueMessageRecoverer：重试耗尽后，返回nack，消息重新入队 RepublishMessageRecoverer：重试耗尽后，将失败消息投递到指定的交换机（死信，惰性，异常交换机） 比较优雅的一种处理方案是RepublishMessageRecoverer，失败后将消息投递到一个指定的，专门存放异常消息的队列，后续由人工集中处理。 1）在consumer服务中定义处理失败消息的交换机和队列 @Bean public DirectExchange errorMessageExchange(){ return new DirectExchange(\"error.direct\"); } @Bean public Queue errorQueue(){ return new Queue(\"error.queue\", true); } @Bean public Binding errorBinding(Queue errorQueue, DirectExchange errorMessageExchange){ return BindingBuilder.bind(errorQueue).to(errorMessageExchange).with(\"error\"); } 2）定义一个RepublishMessageRecoverer，关联队列和交换机 @Bean public MessageRecoverer republishMessageRecoverer(RabbitTemplate rabbitTemplate){ return new RepublishMessageRecoverer(rabbitTemplate, \"error.direct\", \"error\"); } 4-3、死信队列 什么样的消息会成为死信？ 消息被消费者reject或者返回nack ，拒绝 消息超时未消费（TTL） 普通队列满了（可指定到死信，不是一定死信也可以是惰性） 如果这个包含死信的队列配置了dead-letter-exchange属性，指定了一个交换机，那么队列中的死信就会投递到这个交换机中，而这个交换机称为死信交换机（Dead Letter Exchange，检查DLX） 队列将死信投递给死信交换机时，必须知道两个信息： 死信交换机名称 死信交换机与死信队列绑定的RoutingKey 这样才能确保投递的消息能到达死信交换机，并且正确的路由到死信队列。 4-4、死信作为重试机制策略 在失败重试策略中，默认的RejectAndDontRequeueRecoverer会在本地重试次数耗尽后，发送reject给RabbitMQ，消息变成死信，被丢弃。 我们可以给simple.queue添加一个死信交换机，给死信交换机绑定一个队列。这样消息变成死信后也不会丢弃，而是最终投递到死信交换机，路由到与死信交换机绑定的队列。 // 声明普通的 simple.queue队列，并且为其指定死信交换机：dl.direct @Bean public Queue simpleQueue2(){ return QueueBuilder.durable(\"simple.queue\") // 指定队列名称，并持久化 .deadLetterExchange(\"dl.direct\") // 指定死信交换机 .build(); } // 声明死信交换机 dl.direct @Bean public DirectExchange dlExchange(){ return new DirectExchange(\"dl.direct\", true, false); } // 声明存储死信的队列 dl.queue @Bean public Queue dlQueue(){ return new Queue(\"dl.queue\", true); } // 将死信队列 与 死信交换机绑定 @Bean public Binding dlBinding(){ return BindingBuilder.bind(dlQueue()).to(dlExchange()).with(\"simple\"); } 消费者确认模式: auto acknowledge-mode: auto 特征: 当消息不能被消费时,会重新入队,再次投递给消费者进行被消费 default-requeue-rejected: false # 拒绝消息重新入队,如果队列绑定了死信交换机则消息会投递到死信交换机并路由到死信队列 本地重试：底下是三种方案，不是三个步骤，需要注意 ​ 当本地重试次数耗尽时,如果当前队列没有绑定死信交换机或错误队列,则消息丢弃​ 如果提供了异常队列,则消息投递到异常对象​ 如果队列绑定了死信交换机,则消息以死信的形式存放到死信队列 5、惰性队列 5-1、堆积问题 当生产者发送消息的速度超过了消费者处理消息的速度，就会导致队列中的消息堆积，直到队列存储消息达到上限。之后发送的消息就会成为死信，可能会被丢弃，这就是消息堆积问题。 解决消息堆积思路： 增加更多消费者，提高消费速度。也就是我们之前说的work queue模式 在消费者内开启线程池加快消息处理速度 扩大队列容积，提高堆积上限 5-2、惰性队列 从RabbitMQ的3.6.0版本开始，就增加了Lazy Queues的概念，也就是惰性队列。惰性队列的特征如下： 接收到消息后直接存入磁盘而非内存 消费者要消费消息时才会从磁盘中读取并加载到内存 支持数百万条的消息存储 5-2-1、基于命令行设置lazy-queue 而要设置一个队列为惰性队列，只需要在声明队列时，指定x-queue-mode属性为lazy即可。可以通过命令行将一个运行中的队列修改为惰性队列： rabbitmqctl set_policy Lazy \"^simple.queue$\" '{\"queue-mode\":\"lazy\"}' --apply-to queues 命令解读： rabbitmqctl ：RabbitMQ的命令行工具 set_policy ：添加一个策略 Lazy ：策略名称，可以自定义 \"^lazy-queue$\" ：用正则表达式匹配队列的名字 '{\"queue-mode\":\"lazy\"}' ：设置队列模式为lazy模式 --apply-to queues：策略的作用对象，是所有的队列 5-2-2、基于@Bean声明lazy-queue 5-2-3、基于@RabbitListener声明LazyQueue 小结： 消息堆积问题的解决方案？ 队列上绑定多个消费者，提高消费速度 使用惰性队列，可以再mq中保存更多消息 惰性队列的优点有哪些？ 基于磁盘存储，消息上限高 没有间歇性的page-out，性能比较稳定 惰性队列的缺点有哪些？ 基于磁盘存储，消息时效性会降低 性能受限于磁盘的IO 四、Redis缓存一致性问题、十大数据结构 1、常规（放松版）1、redis有哪些数据结构?字符串String、字典Hash、列表List、集合Set、有序集合SortedSet HyperLogLog ：网站的UV统计 Geo：获取位置的距离 Bitmap:位图 Stream：消息队列 2、为什么要用redis?可以做缓存，耗时间的sql，且不频繁变动的可以缓存到redis，提高响应速度 提高并发，大量的请求先请求到redis，而不是直接请求到数据库 可以做分布式锁。 3、什么是分布式锁？setnx来获取锁，expire来添加过期时间，防止资源占用过久 4、找出redis中以某个前缀开头的大量的key？keys xx* 使用keys会造成阻塞 scan 0 match key1111* count 20 不会造成阻塞 5、如何使用redis做消息队列？list结构作为队列，rpush生产消息，lpop消费消息，需要自己实现阻塞。blpop没有消息会阻塞，等到消息到来。 6、大量的key在同一时间过期，需要注意什么？redis可能会出现卡顿现象，并发量大可能出现缓存雪崩，可以在过期时间添加一个随机数 7、什么是缓存穿透，缓存击穿？缓存穿透：对空值缓存，设置可访问的名单（白名单），采用布隆过滤器 缓存击穿: 一个key过期时，大量请求打到数据库。加互斥锁和热点数据不过期。 8、redis的线程模型？redis使用文件事件处理器，它是一个单线程的，采用io多路复用程序监听多个socket， 将产生事件的socket压入内存队列，事件分派器根据事件类型选择对应的事件处理器进行处理。 9、redis 为什么使用单进程、单线程也很快?1.基于内存的操作 2.使用了 I/O 多路复用模型 3.单线程可以避免不必要的上下文切换和竞争条件 10、redis过期策略?定期删除+惰性删除。 定期删除：每隔一段时间删除 惰性删除：获取的时候判断是否过期 11、redis的内存淘汰机制？ noeviction: 当内存不足时，新写入操作会报错 allkeys-lru：当内存不足时，移除最近最少使用的 key（这个是最常用的）。 allkeys-random：当内存不足时，随机移除某个 key。 volatile-lru：当内存不足时，在设置了过期时间的键中，移除最近最少使用的 key。 volatile-random：当内存不足时，在设置了过期时间的键中，随机移除某个 key。 volatile-ttl：当内存不足时，在设置了过期时间的键中，有更早过期时间的 key 优先移除 12、redis 的持久化有哪几种方式？Rdb：rdb会周期性对redis的数据进行持久化 Aof：将每条写入命令写入日志中，在redis重启的时候通过日志文件重构数据 Rdb会产生多个文件，每个文件代表某一个时刻的redis数据。对于aof来说，基于rdb恢复数据会更快。 redis 故障Rdb会丢失更多的数据，Rdb快照都是隔5分钟或者更长时间生成，而aof每隔一秒就会执行一次，所以只会丢失一秒钟的数据。 13、如何保证缓存和数据库一致？读的时候先读缓存，没有的话读数据库，放入缓存，返回结果。更新的时候先更新数据库，然后删除缓存。 为什么是删除而不是更新? 因为更新可能是更新一个或几个字段，缓存可能缓存的是一个结果集。 先更新数据库，在删除缓存，如果缓存删除失败？ 解决方案:先删除缓存，在删除数据库，删除数据库失败那数据还是没变。 14、redis 的并发竞争问题是什么？如何解决这个问题？了解redis 事务的 CAS 方案吗？多个客户端同事写一个key，造成数据不一致 redis天然支持乐观锁 watch 监控key，multi开始事务,在执行exec命令前值被修改则会回滚。 15、Redis 的 LRU 算法怎么实现的?拿到n个key，和缓冲池中的key比较最大空闲时间，比缓存池的key最大空闲时间还大，则替换缓存池的key，然后从缓存池中移除最大空闲时间的key。 16、Redis 怎么保证高可用、有哪些集群模式？主从，哨兵，集群 1.主从复制 1.开启配置 在 slave 直接执行命令：slaveof 在 slave 配置文件中加入：slaveof 使用启动命令：–slaveof 2.建立套接字(socket)连接 3.发送PING命令 4.身份验证 5.发送CAPA(同步复制的能力) 6.数据同步 7.命令传播 出现故障需要手动更改配置 2.哨兵 哨兵（Sentinel） 是 Redis 的高可用性解决方案，由多个哨兵监控主服务器。监控的主服务器故障的时候，可以将从服务器升级为主服务器 3.集群 哨兵模式的缺点就是所有的数据都放在一台服务器上，无法比较好的进行水平扩展。 集群模式： 去中心化，将数据按槽存储分布在多个 Redis 节点上。集群共有 16384 个槽，每个节点负责处理部分槽。 所有的 Redis 节点彼此互联，通过 PING-PONG 机制来进行节点间的心跳检测。 主节点故障时，从节点向所有有投票的主节点发起选举，获得票数&gt;2n+1则升级为主节点. 2、二阶（散装）———概述———-1、Redis有哪些优缺点优点 读写性能优异， Redis能读的速度是110000次/s，写的速度是81000次/s。 支持数据持久化，支持AOF和RDB两种持久化方式。 支持事务，Redis的所有操作都是原子性的，同时Redis还支持对几个操作合并后的原子性执行。 数据结构丰富，除了支持string类型的value外还支持hash、set、zset、list等数据结构。 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。 缺点 数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。 Redis 不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。 主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。 Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。 2、为什么要用 Redis /为什么要用缓存主要从“高性能”和“高并发”这两点来看待这个问题。 高性能：假如用户第一次访问数据库中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据存在数缓存中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据即可！ 高并发：直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。（用户会话信息，字典数据，网关黑白名单…） 3、为什么要用 Redis 而不用 map/guava 做缓存?缓存分为本地缓存和分布式缓存。以 Java 为例，使用自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。 使用 redis 或 memcached 之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持 redis 或 memcached服务的高可用，整个程序架构上较为复杂。 4、Redis为什么这么快1、完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是O(1)； 2、数据结构简单，对数据操作也简单，Redis 中的数据结构是专门进行设计的； 3、采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗； 4、使用多路 I/O 复用模型，非阻塞 IO； 5、使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求； —–数据结构—-1、应用场景 计数器 可以对 String 进行自增自减运算，从而实现计数器功能。Redis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。 缓存 将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。 会话缓存 可以使用 Redis 来统一存储多台应用服务器的会话信息。当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。 全页缓存（FPC） 除基本的会话token之外，Redis还提供很简便的FPC平台。以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。 查找表 例如 DNS 记录就很适合使用 Redis 进行存储。查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。 消息队列(发布/订阅功能) List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息。不过最好使用 Kafka、RabbitMQ 等消息中间件。 分布式锁实现 在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。 其它 Set 可以实现交集、并集等操作，从而实现共同好友等功能。ZSet 可以实现有序性操作，从而实现排行榜等功能。 ——————————————–两种分点上为功能，下为结构——————————————————– expire：设置key的过期时间 persist：设置key永久有效 5种基础数据类型：String、List、Set、Zset、Hash。 三种特殊的数据类型： HyperLogLogs（基数统计）， Bitmaps (位图) ， geospatial （地理位置) String（字符串）： 底层数据结构：SDS即动态字符串，最大容量512M，每次最多扩容1M，是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或序列化的对象应用场景：分布式锁、计数器(如访问次数、点赞转发数量)常用方法：set 、get、strlen 、incr 、 decr 、setnx、setex、exists list（双向列表）： 特点：单值多键，用来存储多个有序的字符串，一个列表最多可以存储2^32-1个元素。可以实现队列和栈底层数据结构：快表应用场景：消息队列 、文章列表常用方法：lpush 、lrang 、rpush 、lpop 、rpop 、llen、lindex、rpoplpush、linsert Hash（哈希）： 底层数据结构：压缩列表、哈希表。特点：指v（值）本身又是一个键值对（k-v）结构应用场景：缓存用户信息、购物车等。常用方法：hset 、hget 、hkeys 、hvals 、hmset 、hmget 、hgetAll 、hlen 、hdel 、hsetnx 、hexists set（集合）： 特点：用来保存多个的字符串元素，但是不允许重复元素，元素是无序的。可以实现并集、交集、差集的操作底层数据结构：哈希表、整数集应用场景：抽奖、共同关注、QQ内推等。常用方法：sadd 、smembers 、sismember 、scard 、srem 、srandmember、spop、smove、sdiff、sinter、sunion zset（有序集合）： 特点：有序不重复的集合。和 set 相⽐sorted set 增加了⼀个权重参数 score，可以根据score进行排序，但score是可以重复的，value是不可以重复的。底层数据结构：压缩列表、跳表应用场景：排行榜、抖音热搜常用方法：zadd 、zrange 、zrangebyscore(按score从小到大) 、zrem 、zcard 、zcount 、zrevrange(按score从大到小） —–持久化—-1、Redis 的持久化机制是什么？各自的优缺点？Redis 提供两种持久化机制 RDB（默认） 和 AOF 机制: RDB：是Redis DataBase缩写快照 RDB是Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件为dump.rdb。通过配置文件中的save参数来定义快照的周期。 优点： 1、只有一个文件 dump.rdb，方便持久化。 2、容灾性好，一个文件可以保存到安全的磁盘。 3、性能最大化，fork 子进程来完成写操作，让主进程继续处理命令，所以是 IO 最大化。使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 redis 的高性能 4.相对于数据集大时，比 AOF 的启动效率更高。 缺点： 1、数据安全性低。RDB 是间隔一段时间进行持久化，如果持久化之间 redis 发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候) 2、AOF（Append-only file)持久化方式：是指所有的命令行记录以 redis 命令请 求协议的格式完全持久化存储)保存为 aof 文件。 AOF：持久化 AOF持久化(即Append Only File持久化)，则是将Redis执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志中文件恢复数据。 当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。 优点： 安全，所有写入的数据都不会丢失。 AOF文件易读，可修改。 详情了解： 1、数据安全，aof 持久化可以配置 appendfsync 属性，有 always，每进行一次 命令操作就记录到 aof 文件中一次。 2、通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性问题。 3、AOF 机制的 rewrite 模式。AOF 文件没被 rewrite 之前（文件过大时会对命令 进行合并重写），可以删除其中的某些命令（比如误操作的 flushall） 缺点： 1、AOF 文件比 RDB 文件大，且恢复速度慢。 2、数据集大的时候，比 rdb 启动效率低。 优缺点是什么？ AOF文件比RDB更新频率高，优先使用AOF还原数据。 AOF比RDB更安全也更大 RDB性能比AOF好 如果两个都配了优先加载AOF 2、如何选择合适的持久化方式 一般来说， 如果想达到足以媲美PostgreSQL的数据安全性，你应该同时使用两种持久化功能。在这种情况下，当 Redis 重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。 如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以只使用RDB持久化。 有很多用户都只使用AOF持久化，但并不推荐这种方式，因为定时生成RDB快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快，除此之外，使用RDB还可以避免AOF程序的bug。 如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化方式。 3、Redis持久化数据和缓存怎么做扩容 如果Redis被当做缓存使用，使用一致性哈希实现动态扩容缩容。 如果Redis被当做一个持久化存储使用，必须使用固定的keys-to-nodes映射关系，节点的数量一旦确定不能变化。否则的话(即Redis节点需要动态变化的情况），必须使用可以在运行时进行数据再平衡的一套系统，而当前只有Redis集群可以做到这样。 —过期键的删除策略—1、Redis的过期键的删除策略我们都知道，Redis是key-value数据库，我们可以设置Redis中缓存的key的过期时间。Redis的过期策略就是指当Redis中缓存的key过期了，Redis如何处理。 过期策略通常有以下三种： 定时过期：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。 惰性过期：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。 定期过期：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。(expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。) Redis中同时使用了惰性过期和定期过期两种过期策略。 2、对过期的数据怎么处理呢?除了缓存服务器自带的缓存失效策略之外（Redis默认的有6中策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种： 定时去清理过期的缓存； 当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。 两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！具体用哪种方案，大家可以根据自己的应用场景来权衡。 —内存相关—1、MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。 2、Redis的内存淘汰策略有哪些Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据。 全局的键空间选择性移除 noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。（这个是最常用的） allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。 设置过期时间的键空间选择性移除 volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。 volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。 volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。 总结 Redis的内存淘汰策略的选取并不会影响过期的key的处理。内存淘汰策略用于处理内存不足时的需要申请额外空间的数据；过期策略用于处理过期的缓存数据。 3、Redis的内存用完了会发生什么如果达到设置的上限，Redis的写命令会返回错误信息（但是读命令还可以正常返回。）或者你可以配置内存淘汰机制，当Redis达到内存上限时会冲刷掉旧的内容。 4、Redis如何做内存优化可以好好利用Hash,list,sorted set,set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起。尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key，而是应该把这个用户的所有信息存储到一张散列表里面 补充：但是注意 key粒度要足够细（xxx-yy-zzz-***） —线程模型—1、Redis线程模型Redis基于Reactor模式开发了网络事件处理器，这个处理器被称为文件事件处理器（file event handler）。它的组成结构为4部分：多个套接字、IO多路复用程序、文件事件分派器、事件处理器。因为文件事件分派器队列的消费是单线程的，所以Redis才叫单线程模型。 文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字， 并根据套接字目前执行的任务来为套接字关联不同的事件处理器。 当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时， 与操作相对应的文件事件就会产生， 这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。 虽然文件事件处理器以单线程方式运行， 但通过使用 I/O 多路复用程序来监听多个套接字， 文件事件处理器既实现了高性能的网络通信模型， 又可以很好地与 redis 服务器中其他同样以单线程方式运行的模块进行对接， 这保持了 Redis 内部单线程设计的简单性。 —–事务—–Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。 总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。 0、站长简书，redis事务（还有lua秒杀案例）https://www.jianshu.com/p/879efff5f7b4 从输入Multi命令开始(开启事务)，输入的命令都会依次进入命令队列中，但不会执行，直到输入Exec后，Redis会将之前的命令队列中的命令依次执行。 组队的过程中可以通过discard来放弃组队 （1）组队案例 127.0.0.1:6379&gt; multi OK 127.0.0.1:6379(TX)&gt; set k1 v1 QUEUED 127.0.0.1:6379(TX)&gt; set k2 v2 QUEUED 127.0.0.1:6379(TX)&gt; exec 1) OK 2) OK （2）放弃组队 127.0.0.1:6379&gt; multi OK 127.0.0.1:6379(TX)&gt; set k1 v1 QUEUED 127.0.0.1:6379(TX)&gt; set k2 v2 QUEUED 127.0.0.1:6379(TX)&gt; discard 1) OK （3）任何一个组队失败，都不会执行 127.0.0.1:6379&gt; multi OK 127.0.0.1:6379(TX)&gt; set k1 v1 QUEUED 127.0.0.1:6379(TX)&gt; set k2 v2 QUEUED 127.0.0.1:6379(TX)&gt; set k3 (error) ERR wrong number of arguments for 'set' command 127.0.0.1:6379(TX)&gt; exec (error) EXECABORT Transaction discarded because of previous errors. 3、事务的错误处理 （1）组队中某个命令出现了报告错误，执行时整个的所有队列都会被取消。（就是上面3的操作） （2）如果执行阶段某个命令报出了错误，则只有报错的命令不会被执行，而其他的命令都会执行，不会回滚。 案例：字符串+1 127.0.0.1:6379&gt; multi OK 127.0.0.1:6379(TX)&gt; set k1 v1 QUEUED 127.0.0.1:6379(TX)&gt; incr k1 QUEUED 127.0.0.1:6379(TX)&gt; exec 1) OK 2) (error) ERR value is not an integer or out of range 1、相关命令 MULTI ：开启事务，redis会将后续的命令逐个放入队列中，然后使用EXEC命令来原子化执行这个命令系列。 EXEC：执行事务中的所有操作命令。 DISCARD：取消事务，放弃执行事务块中的所有命令。 WATCH：监视一个或多个key,如果事务在执行前，这个key(或多个key)被其他命令修改，则事务被中断，不会执行事务中的任何命令。 UNWATCH：取消WATCH对所有key的监视。 2、执行的3个阶段 开启：以MULTI开始一个事务 入队：将多个命令入队到事务中，接到这些命令并不会立即执行，而是放到等待执行的事务队列里面 执行：由EXEC命令触发事务 3、Redis 对 ACID的支持性理解 原子性atomicity Redis官方文档给的理解是，Redis的事务是原子性的：所有的命令，要么全部执行，要么全部不执行。而不是完全成功。 一致性consistency redis事务可以保证命令失败的情况下得以回滚，数据能恢复到没有执行之前的样子，是保证一致性的，除非redis进程意外终结。 隔离性Isolation redis事务是严格遵守隔离性的，原因是redis是单进程单线程模式(v6.0之前），可以保证命令执行过程中不会被其他客户端命令打断。但是，Redis不像其它结构化数据库有隔离级别这种设计。 持久性Durability redis事务是不保证持久性的，这是因为redis持久化策略中不管是RDB还是AOF都是异步执行的，不保证持久性是出于对性能的考虑。 4、Redis事务支持隔离性吗Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，Redis 的事务是总是带有隔离性的。 5、Redis事务保证原子性吗，支持回滚吗Redis中，单条命令是原子性执行的，但事务不保证原子性，且没有回滚。事务中任意命令执行失败，其余的命令仍会被执行。 6、Redis事务其他实现 基于Lua脚本，Redis可以保证脚本内的命令一次性、按顺序地执行，其同时也不提供事务运行错误的回滚，执行过程中如果部分命令运行错误，剩下的命令还是会继续运行完 基于中间标记变量，通过另外的标记变量来标识事务是否执行完成，读取数据时先读取该标记变量判断是否事务执行完成。但这样会需要额外写代码实现，比较繁琐 ——集群方案——-1、主从复制单机的 redis，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑读高并发的。因此架构做成主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的读请求全部走从节点。这样也可以很轻松实现水平扩容，支撑读高并发。 redis replication -&gt; 主从架构 -&gt; 读写分离 -&gt; 水平扩容支撑读高并发 redis replication 的核心机制 redis 采用异步方式复制数据到 slave 节点，不过 redis2.8 开始，slave node 会周期性地确认自己每次复制的数据量； 一个 master node 是可以配置多个 slave node 的； slave node 也可以连接其他的 slave node； slave node 做复制的时候，不会 block(阻塞) master node 的正常工作；（异步所以不会block） slave node 在做复制的时候，也不会 block 对自己的查询操作，它会用旧的数据集来提供服务；但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了； slave node 主要用来进行横向扩容，做读写分离，扩容的 slave node 可以提高读的吞吐量。 注意，如果采用了主从架构，那么建议必须开启 master node 的持久化，不建议用 slave node 作为 master node 的数据热备，因为那样的话，如果你关掉 master 的持久化，可能在 master 宕机重启的时候数据是空的，然后可能一经过复制， slave node 的数据也丢了。 另外，master 的各种备份方案，也需要做。万一本地的所有文件丢失了，从备份中挑选一份 rdb 去恢复 master，这样才能确保启动的时候，是有数据的，即使采用了后续讲解的高可用机制，slave node 可以自动接管 master node，但也可能 sentinel 还没检测到 master failure，master node 就自动重启了，还是可能导致上面所有的 slave node 数据被清空。 作用： 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务，分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。 高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。 主从库之间采用的是读写分离的方式。 读操作：主库、从库都可以接收； 写操作：首先到主库执行，然后，主库将写操作同步给从库 全量（同步）复制：比如第一次同步时 增量（同步）复制：只会把主从库网络断连期间主库收到的命令，同步给从库 Redis 全量复制的三个阶段（redis 主从复制的核心原理）： 当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。 如果这是 slave node 初次连接到 master node，那么会触发一次 full resynchronization 全量复制。此时 master 会启动一个后台线程，开始生成一份 RDB 快照文件， 同时还会将从客户端 client 新收到的所有写命令缓存在内存中。RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先写入本地磁盘，然后再从本地磁盘加载到内存中， 接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。 slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。 所有的slave节点数据的复制和同步都由master节点来处理，会照成master节点压力太大，使用主从从结构来解决 阿K站长提示；一下3阶段看下理解就好，面试上面这些点回答 第一阶段：主从库间建立连接、协商同步的过程，主要是为全量复制做准备。在这一步，从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了。 具体来说，从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。psync 命令包含了主库的 runID 和复制进度 offset 两个参数。runID，是每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设为“？”。offset，此时设为 -1，表示第一次复制。主库收到 psync 命令后，会用 FULLRESYNC 响应命令带上两个参数：主库 runID 和主库目前的复制进度 offset，返回给从库。从库收到响应后，会记录下这两个参数。这里有个地方需要注意，FULLRESYNC 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库。 第二阶段：主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的 RDB 文件。 具体来说，主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。否则，Redis 的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中。为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作。 第三个阶段：主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。 Redis 增量复制的流程： Redis 为什么主从全量复制使用RDB而不使用AOF？ 1、RDB文件内容是经过压缩的二进制数据（不同数据类型数据做了针对性优化），文件很小。而AOF文件记录的是每一次写操作的命令，写操作越多文件会变得很大，其中还包括很多对同一个key的多次冗余操作。在主从全量数据同步时，传输RDB文件可以尽量降低对主库机器网络带宽的消耗，从库在加载RDB文件时，一是文件小，读取整个文件的速度会很快，二是因为RDB文件存储的都是二进制数据，从库直接按照RDB协议解析还原数据即可，速度会非常快，而AOF需要依次重放每个写命令，这个过程会经历冗长的处理逻辑，恢复速度相比RDB会慢得多，所以使用RDB进行主从全量复制的成本最低。 2、假设要使用AOF做全量复制，意味着必须打开AOF功能，打开AOF就要选择文件刷盘的策略，选择不当会严重影响Redis性能。而RDB只有在需要定时备份和主从全量复制数据时才会触发生成一次快照。而在很多丢失数据不敏感的业务场景，其实是不需要开启AOF的。 Redis 为什么还会有从库的从库的设计？ 一次全量复制中，对于主库来说，需要完成两个耗时的操作：生成 RDB 文件和传输 RDB 文件。 如果从库数量很多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量复制。fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。此外，传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。那么，有没有好的解决方法可以分担主库压力呢？ 其实是有的，这就是“主 - 从 - 从”模式。 在刚才介绍的主从库模式中，所有的从库都是和主库连接，所有的全量复制也都是和主库进行的。现在，我们可以通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上。 简单来说，我们在部署主从集群的时候，可以手动选择一个从库（比如选择内存资源配置较高的从库），用于级联其他的从库。然后，我们可以再选择一些从库（例如三分之一的从库），在这些从库上执行如下命令，让它们和刚才所选的从库，建立起主从关系。 replicaof 所选从库的IP 6379 这样一来，这些从库就会知道，在进行同步时，不用再和主库进行交互了，只要和级联的从库进行写操作同步就行了，这就可以减轻主库上的压力，如下图所示： 2、哨兵模式哨兵的核心功能是主节点的自动故障转移。下图是一个典型的哨兵集群监控的逻辑图：（自动化主从架构） 哨兵的作用： 监控（Monitoring）：哨兵会不断地检查主节点和从节点是否运作正常。 自动故障转移（Automatic failover）：当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。 配置提供者（Configuration provider）：客户端在初始化时，通过连接哨兵来获得当前Redis服务的主节点地址。 通知（Notification）：哨兵可以将故障转移的结果发送给客户端。 其中，监控和自动故障转移功能，使得哨兵可以及时发现主节点故障并完成转移；而配置提供者和通知功能，则需要在与客户端的交互中才能体现。 3、集群模式redis 集群模式的工作原理能说一下么？在集群模式下，redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？ 简介 Redis Cluster是一种服务端Sharding（分片）技术，3.0版本开始正式提供。Redis Cluster并没有使用一致性hash，而是采用slot(槽)的概念，一共分成16384个槽。将请求发送到任意节点，接收到请求的节点会将查询请求发送到正确的节点上执行 方案说明 通过哈希的方式，将数据分片，每个节点均分存储一定哈希槽(哈希值)区间的数据，默认分配了16384 个槽位 每份数据分片会存储在多个互为主从的多节点上 数据写入先写主节点，再同步到从节点(支持配置为阻塞同步) 同一分片多个节点间的数据不保持一致性 读取数据时，当客户端操作的key没有分配在该节点上时，redis会返回转向指令，指向正确的节点 扩容时时需要需要把旧节点的数据迁移一部分到新节点 在 redis cluster 架构下，每个 redis 要放开两个端口号，比如一个是 6379，另外一个就是 加1w 的端口号，比如 16379。 16379 端口号是用来进行节点间通信的，也就是 cluster bus 的东西，cluster bus 的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus 用了另外一种二进制的协议，gossip 协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。 基本通信原理，节点间的内部通信机制： 集群元数据的维护有两种方式：集中式、Gossip 协议。redis cluster 节点间采用 gossip 协议进行通信。 分布式寻址算法: hash 算法（大量缓存重建） 一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡） redis cluster 的 hash slot 算法 优点 无中心架构，支持动态扩容，对业务透明 具备Sentinel的监控和自动Failover(故障转移)能力 客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可 高性能，客户端直连redis服务，免去了proxy代理的损耗 缺点 运维也很复杂，数据迁移需要人工干预 只能使用0号数据库 不支持批量操作(pipeline管道操作) 分布式逻辑和存储模块耦合等 3-1、基于客户端分配Redis Sharding是Redis Cluster出来之前，业界普遍使用的多Redis实例集群方法。其主要思想是采用哈希算法将Redis数据的key进行散列，通过hash函数，特定的key会映射到特定的Redis节点上。Java redis客户端驱动jedis，支持Redis Sharding功能，即ShardedJedis以及结合缓存池的ShardedJedisPool 优点 优势在于非常简单，服务端的Redis实例彼此独立，相互无关联，每个Redis实例像单服务器一样运行，非常容易线性扩展，系统的灵活性很强 缺点 由于sharding处理放到客户端，规模进一步扩大时给运维带来挑战。 客户端sharding不支持动态增删节点。服务端Redis实例群拓扑结构有变化时，每个客户端都需要更新调整。连接不能共享，当应用规模增大时，资源浪费制约优化 3-2、基于代理服务器分片客户端发送请求到一个代理组件，代理解析客户端的数据，并将请求转发至正确的节点，最后将结果回复给客户端 特征 透明接入，业务程序不用关心后端Redis实例，切换成本低 Proxy 的逻辑和存储的逻辑是隔离的 代理层多了一次转发，性能有所损耗 业界开源方案 Twtter开源的Twemproxy 豌豆荚开源的Codis 4、生产环境中的 redis 是怎么部署的redis cluster，10 台机器，5 台机器部署了 redis 主实例，另外 5 台机器部署了 redis 的从实例，每个主实例挂了一个从实例，5 个节点对外提供读写服务，每个节点的读写高峰qps可能可以达到每秒 5 万，5 台机器最多是 25 万读写请求/s。 机器是什么配置？32G 内存+ 8 核 CPU + 1T 磁盘，但是分配给 redis 进程的是10g内存，一般线上生产环境，redis 的内存尽量不要超过 10g，超过 10g 可能会有问题。 5 台机器对外提供读写，一共有 50g 内存。 因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，redis 从实例会自动变成主实例继续提供读写服务。 你往内存里写的是什么数据？每条数据的大小是多少？商品数据，每条数据是 10kb。100 条数据是 1mb，10 万条数据是 1g。常驻内存的是 200 万条商品数据，占用内存是 20g，仅仅不到总内存的 50%。目前高峰期每秒就是 3500 左右的请求量。 其实大型的公司，会有基础架构的 team 负责缓存集群的运维。 5、说说Redis哈希槽的概念Redis集群没有使用一致性hash,而是引入了哈希槽的概念，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。 6、Redis集群会有写操作丢失吗？为什么？Redis并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作。 7、三种集群模式总结详情看站长简书： 主从，哨兵：https://www.jianshu.com/p/f6f386a62b7d 集群：https://www.jianshu.com/p/d875a53b0167 因为 Redis 集群有两种，一种是主从复制，一种是 Redis Cluster，我不清楚您 问的是哪一种。 按照我的理解，我认为您可能说的是 Redis 哨兵集群和 Redis Cluster 的区别。 对于这个问题，我认为可以从 3 个方面来回答 ，Redis 哨兵集群是基于主从复制来实现的，所以它可以实现读写分离，分担 Redis 读操作的压力 ，而 Redis Cluster 集群的 Slave 节点只是实现冷备机制，它只有在 Master 宕机 之后才会工作。 Redis 哨兵集群无法在线扩容，所以它的并发压力受限于单个服务器的资源配置。 Redis Cluster 提供了基于 Slot 槽的数据分片机制，可以实现在线扩容提升写数 据的性能从集群架构上来说，Redis 哨兵集群是一主多从， 而 Redis Cluster 是多主多从 —-分区—–1、Redis是单线程的，如何提高多核CPU的利用率可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的， 所以，如果你想使用多个CPU，你可以考虑一下分片（shard） 2、为什么要做Redis分区分区可以让Redis管理更大的内存，Redis将可以使用所有机器的内存。如果没有分区，你最多只能使用一台机器的内存。分区使Redis的计算能力通过简单地增加计算机得到成倍提升，Redis的网络带宽也会随着计算机和网卡的增加而成倍增长。 3、你知道有哪些Redis分区实现方案 客户端分区就是在客户端就已经决定数据会被存储到哪个redis节点或者从哪个redis节点读取。大多数客户端已经实现了客户端分区。 代理分区 意味着客户端将请求发送给代理，然后代理决定去哪个节点写数据或者读数据。代理根据分区规则决定请求哪些Redis实例，然后根据Redis的响应结果返回给客户端。redis和memcached的一种代理实现就是Twemproxy 查询路由(Query routing) 的意思是客户端随机地请求任意一个redis实例，然后由Redis将请求转发给正确的Redis节点。Redis Cluster实现了一种混合形式的查询路由，但并不是直接将请求从一个redis节点转发到另一个redis节点，而是在客户端的帮助下直接redirected到正确的redis节点。 4、Redis分区有什么缺点 涉及多个key的操作通常不会被支持。例如你不能对两个集合求交集，因为他们可能被存储到不同的Redis实例（实际上这种情况也有办法，但是不能直接使用交集指令）。 同时操作多个key,则不能使用Redis事务. 分区使用的粒度是key，不能使用一个非常长的排序key存储一个数据集（The partitioning granularity is the key, so it is not possible to shard a dataset with a single huge key like a very big sorted set） 当使用分区的时候，数据处理会非常复杂，例如为了备份你必须从不同的Redis实例和主机同时收集RDB / AOF文件。 分区时动态扩容或缩容可能非常复杂。Redis集群在运行时增加或者删除Redis节点，能做到最大程度对用户透明地数据再平衡，但其他一些客户端分区或者代理分区方法则不支持这种特性。然而，有一种预分片的技术也可以较好的解决这个问题。 —–分布式问题—–1、Redis实现分布式锁（站长的简书）https://www.jianshu.com/p/2e995df9ccbc 分布式锁主流的实现方案： 基于数据库实现分布式锁 基于缓存（Redis等） 基于Zookeeper每一种分布式锁解决方案都有各自的优缺点： 性能：redis最高 可靠性：zookeeper最高这里，我们就基于redis实现分布式锁。 （1）redis:命令：setnx 设置锁：setnx key val 设置成功，返回 1 。设置失败，返回 0 ；使用SETNX命令获取锁，若返回0（key已存在，锁已存在）则获取失败，反之获取成功 127.0.0.1:6379&gt; setnx username vv1 (integer) 1 127.0.0.1:6379&gt; setnx username vv2 (integer) 0 127.0.0.1:6379&gt; setnx username vv1 (integer) 0 127.0.0.1:6379&gt; setnx username vv1 (integer) 0 del解除锁 127.0.0.1:6379&gt; del username (integer) 1 127.0.0.1:6379&gt; setnx username vv2 (integer) 1 127.0.0.1:6379&gt; setnx username vv2 (integer) 0 127.0.0.1:6379&gt; setnx username vv2 (integer) 0 expire设置过期时间，ttl查看过期时间 127.0.0.1:6379&gt; expire username 19 (integer) 1 127.0.0.1:6379&gt; ttl username (integer) 14 127.0.0.1:6379&gt; ttl username (integer) 12 127.0.0.1:6379&gt; ttl username (integer) 11 127.0.0.1:6379&gt; ttl username (integer) 11 127.0.0.1:6379&gt; ttl username (integer) 9 ttl 为 -2 已经过期，-1 是永久生效 127.0.0.1:6379&gt; ttl username (integer) -2 127.0.0.1:6379&gt; setnx username vv2 (integer) 1 127.0.0.1:6379&gt; setnx username vv2 (integer) 0 127.0.0.1:6379&gt; setnx username vv2 (integer) 0 ★ 既上锁又设置过期时间( nx 上锁，ex 过期时间) 127.0.0.1:6379&gt; set age 10 nx ex 11 OK 127.0.0.1:6379&gt; ttl age (integer) 7 127.0.0.1:6379&gt; ttl age (integer) 5 使用SETNX完成同步锁的流程及事项如下： 使用SETNX命令获取锁，若返回0（key已存在，锁已存在）则获取失败，反之获取成功 为了防止获取锁后程序出现异常，导致其他线程/进程调用SETNX命令总是返回0而进入死锁状态，需要为该key设置一个“合理”的过期时间 释放锁，使用DEL命令将锁数据删除 其实最佳方案是：Redission框架实现分布式锁 2、如何解决 Redis 的并发竞争 Key 问题所谓 Redis 的并发竞争 Key 的问题也就是多个系统同时对一个 key 进行操作，但是最后执行的顺序和我们期望的顺序不同，这样也就导致了结果的不同！ 推荐一种方案：分布式锁（zookeeper 和 redis 都可以实现分布式锁）。（如果不存在 Redis 的并发竞争 Key 问题，不要使用分布式锁，这样会影响性能） 基于zookeeper临时有序节点可以实现的分布式锁。大致思想为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。完成业务流程后，删除对应的子节点释放锁。 在实践中，当然是从以可靠性为主。所以首推Zookeeper。 3、分布式Redis是前期做还是后期规模上来了再做好？为什么？既然Redis是如此的轻量（单实例只使用1M内存），为防止以后的扩容，最好的办法就是一开始就启动较多实例。即便你只有一台服务器，你也可以一开始就让Redis以分布式的方式运行，使用分区，在同一台服务器上启动多个实例。 一开始就多设置几个Redis实例，例如32或者64个实例，对大多数用户来说这操作起来可能比较麻烦，但是从长久来看做这点牺牲是值得的。 这样的话，当你的数据不断增长，需要更多的Redis服务器时，你需要做的就是仅仅将Redis实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）。一旦你添加了另一台服务器，你需要将你一半的Redis实例从第一台机器迁移到第二台机器。 4、什么是 RedLockRedis 官方站提出了一种权威的基于 Redis 实现分布式锁的方式名叫 Redlock，此种方式比原先的单节点的方法更安全。它可以保证以下特性： 安全特性：互斥访问，即永远只有一个 client 能拿到锁 避免死锁：最终 client 都可能拿到锁，不会出现死锁的情况，即使原本锁住某资源的 client crash 了或者出现了网络分区 容错性：只要大部分 Redis 节点存活就可以正常提供服务 ——缓存异常——1、热点key缓存中的一个Key(比如一个促销商品)，在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。 解决方案 对缓存查询加锁，如果KEY不存在，就加锁，然后查DB入缓存，然后解锁；其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询 ———其他———1、缓存与数据库双写时的数据一致性三种方式：（详情可以看一下参考博客，这里站长做了减法） 先更新数据库，再更新缓存 先删除缓存，再更新数据库 先更新数据库，再删除缓存（主） 一、先更新数据库，再更新缓存 容易出现脏读 以及浪费性能（不推荐） 二、先删缓存，再更新数据库 1、存在问题： 该方案会导致不一致的原因是：同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形： （1）请求A进行写操作前，先删除缓存 （2）请求B查询发现缓存不存在 （3）请求B去数据库查询得到旧值 （4）请求B将旧值写入缓存 （5）请求A将新值写入数据库 上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。 2、解决方案：延时双删策略：性能差，吞吐量降低 public void write(String key,Object data){ ​ redis.delKey(key); ​ db.updateData(data); ​ Thread.sleep(1000); ​ redis.delKey(key); ​ } 转化为中文描述就是： （1）先淘汰缓存 （2）再写数据库 （3）休眠1秒，再次淘汰缓存 三、先更新数据库，再删缓存： ​ 方案一：MQ 流程如下所示： （1）更新数据库数据； （2）缓存因为种种问题删除失败 （3）将需要删除的key发送至消息队列 （4）自己消费消息，获得需要删除的key （5）继续重试删除操作，直到成功 ​ 然而，该方案有一个缺点，对业务线代码造成大量的侵入。于是有了方案二，在方案二中，启动一个订阅程序去订阅数据库的binlog，获得需要操作的数据。在应用程序中，另起一段程序，获得这个订阅程序传来的信息，进行删除缓存操作。 ​ 方案二：Canal 流程如下图所示： （1）更新数据库数据 （2）数据库会将操作信息写入binlog日志当中 （3）订阅程序提取出所需要的数据以及key （4）另起一段非业务代码，获得该信息 （5）尝试删除缓存操作，发现删除失败 （6）将这些信息发送至消息队列 （7）重新从消息队列中获得该数据，重试操作 备注说明：上述的订阅binlog程序在mysql中有现成的中间件叫canal，可以完成订阅binlog日志的功能。另外，重试机制，博主是采用的是消息队列的方式。如果对一致性要求不是很高，直接在程序中另起一个线程，每隔一段时间去重试即可，这些大家可以灵活自由发挥，只是提供一个思路。 2、假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来使用keys指令可以扫出指定模式的key列表。 对方接着追问：如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？ 这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。 3、使用Redis做过异步队列吗，是如何实现的使用list类型保存数据信息，rpush生产消息，lpop消费消息，当lpop没有消息时，可以sleep一段时间，然后再检查有没有信息，如果不想sleep的话，可以使用blpop, 在没有信息的时候，会一直阻塞，直到信息的到来。redis可以通过pub/sub主题订阅模式实现一个生产者，多个消费者，当然也存在一定的缺点，当消费者下线时，生产的消息会丢失。 4、Redis如何实现延时队列使用sortedset，使用时间戳做score, 消息内容作为key,调用zadd来生产消息，消费者使用zrangbyscore获取n秒之前的数据做轮询处理。 5、Redis回收进程如何工作 一个客户端运行了新的命令，添加了新的数据。 Redis检查内存使用情况，如果大于maxmemory的限制， 则根据设定好的策略进行回收。 一个新的命令被执行，等等。 所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下。 如果一个命令的结果导致大量内存被使用（例如很大的集合的交集保存到一个新的键），不用多久内存限制就会被这个内存使用量超越。 6、Redis回收使用的是什么算法LRU算法，不具体展开了 五、分布式事务1、常规（放松解压版）1、事务的特性1.原子性 要么一起成功要么一起失败 2.一致性 事务执行前后数据保持一致性状态 3.隔离性 多个事务之间是隔离的，互相不影响 4.持久性 事务一旦提交数据的改变是持久的 2、分布式事务和分布式锁的区别分布式事务是解决流程化的问题，分布式锁是解决资源占用问题 3、mysql如何实现本地事务1.通过数据库锁的机制，保障事务的隔离性； 2.通过 Redo Log（重做日志）来，保障事务的持久性； 3.通过 Undo Log （撤销日志）来，保障事务的原子性； 4.通过 Undo Log （撤销日志）来，保障事务的一致性； 4、什么是分布式事务分布式事务保证分布式系统的数据一致性，分布式系统上一次大的操作由多个小的操作完成，每个小操作都在不同的应用执行，分布式事务就是要保证这些操作要么失败，要么成功 5、什么是cap定理web服务无法同时满足cap定理 c 一致性性(Consistency):更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致，不能存在中间状态。 a 可用性(Availability):系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。 p 分区容错性(Partition tolerance):即使出现单个组件无法可用，操作依然可以完成 6、什么是数据一致性数据更新成功返回客户端之后，所有节点的数据保持一致，没有中间状态 强一致性：时刻保证数据一致性 最终一致性：一段时间后保证数据一致性 弱一致性：允许存在部分数据不一致 7、为什么分布式系统无法同时保证一致性和可用性对于分布式系统而言，分区容错性是一个最基本的要求，因此基本上我们在设计分布式系统的时候只能从一致性（C）和可用性（A）之间进行取舍 8、什么是base定理cap定理的a和p的延伸，通过牺牲一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态 9、什么是刚性事务和柔性事务刚性事务：通常无业务改造，强一致性，原生支持回滚/隔离性，低并发，适合短事务 XA 协议（2PC、JTA、JTS）、3PC，但由于同步阻塞，处理效率低，不适合大型网站分布式场景 柔性事务：不要求强一致性，而是要求最终一致性，允许有中间状态，也就是Base理论 TCC/FMT、Saga（状态机模式、Aop模式）、本地事务消息、消息事务（半消息） 10、什么是XAXA ，强一致性，在整个过程中，数据一直锁住状态，即从prepare到commit、rollback的整个过程中，TM一直把持折数据库的锁，如果有其他人要修改数据库的该条数据，就必须等待锁的释放，存在长事务风险。 11、分布式事务有哪些解决方案一、2pc：二阶段提交，强一致性设计，引入一个事务协调者的角色来协调管理各参与者（也可称之为各本地资源）的提交和回滚，二阶段分别指的是准备和提交两个阶段。同步阻塞，存在长事务风险 【准备提交阶段-提交阶段】 二、3pc：在2pc之后多加入预提交阶段，和超时。预提交阶段主要是询问事务参与者是否能正常有条件的执行 【准备提交阶段-预提交阶段-提交阶段】 三、Tcc：2PC 和 3PC 都是数据库层面的，而 TCC 是业务层面的分布式事务，需要自己实现Try - Confirm - Cancel三个方法，存在代码入侵业务紧耦合问题 Try 指的是预留，即资源的预留和锁定，注意是预留。 Confirm 指的是确认操作，这一步其实就是真正的执行了。 Cancel 指的是撤销操作，可以理解为把预留阶段的动作撤销了。 四、消息事务：RocketMQ很好支持消息事务,本地执行事务前发送消息，本地事务失败则丢弃消息，本地执行成功，消息订阅方执行本地事务，成功之后消费消息。 12、2pc和3pc的区别3pc多加入预提交阶段，和超时 13、Seata 的at模式 Seata AT分为两阶段，主要逻辑全部在第一阶段，第二阶段主要做回滚或日志清理的工作。 会在每个数据库中维护undo_log表 @GlobalTransactional 注解表示开启分布式事务 14、2pc和Seata的at区别at模式是增强版的2pc，第一阶段业务数据和回滚日志记录在同一个本地事务中提交,提交之后就会释放资源 15、Seata的四种模式2、进阶1、设计：1ID+3组件（seata）1、ID全局唯一的事务ID：Transaction ID XID 2、组件Transaction Coordinator (TC)【程序员】 事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚； Transaction Manager (TM)【经理】 控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议； Resource Manager (RM)【用户】 控制分支事务，负责分支注册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚 XID【程序】 2、处理过程 AT模式主要分为两个阶段： 一阶段： 解析SQL，获取SQL类型（CRUD）、表信息、条件(where) 等相关信息查询前镜像(改变之前的数据)，根据解析得到的条件信息，生成查询语句，定位数据执行业务SQL，更新数据查询后镜像（改变后的数据），根据前镜像的结果，通过主键都给你为数据插入回滚日志，将前后镜像数据以及业务SQL等信息，组织成一条回滚日志记录，插入到undo Log表中提交前，向TC注册分支，申请全局锁本地事务提交，业务数据的更细腻和生成的undoLog一起提交将本地事务提交的结果通知给TC 二阶段： 如果TC收到的是回滚请求 开启本地事务，通过XID和BranchID查找到对应的undo Log记录根据undoLog中的前镜像和业务SQL的相关信息生成并执行回滚语句提交本地事务，将本地事务的执行结果（分支事务回滚的信息）通知给TC如果没问题，执行提交操作 收到TC分支提交请求，将请求放入到一个异步任务的队列中，马上返回提交成功的结果给TC异步任务阶段的分支提交请求删除undoLog中记录 3、分布式事务的实现方式1、六、Spring1、热身题1.什么是spring?一个轻量级开源框架，简化开发。核心是ioc控制反转和aop面向切面编程。 简化开发: 通过切面和模板减少重复性代码，通过依赖注入创建对象，实现松耦合 2.什么是ioc和aop？ioc控制反转，实现对象的耦合关系的管理，将对象的依赖关系交给ioc管理。 aop面向切面编程,动态非侵入的方式增强服务。 3.aop的实现机制？静态代理和动态代理，两者区别是静态代理是事先已经定义好的，动态代理是在程序运行的时候创建的 动态代理：分为jdk动态代理和cglib动态代理。 4.jdk动态代理和cglib动态代理的区别?jdk动态代理通过实现被代理对象的接口，cglib动态代理通过继承被代理对象实现 jdk动态代理只能代理实现接口的类，cglib动态代理只能代理没有被final修饰的类和方法 jdk动态代理通过反射机制实现，cglib动态代理通过fastClass机制实现 5.aop有哪些通知类型？前置通知 Before Advice:在方法前切入 后置通知 After Advice:在方法后切入 正常返回通知 After Returning Advice:在方法返回后切入，抛出异常则不会切入 异常通知 After Throwing Advice:抛出异常时切入 环绕通知 Around Advice:在方法执行前后切入，可以中断或忽略原有流程的执行 6.aop有哪些运用场景?1.全局异常处理 2.防止接口重复提交 3.接口幂等性 4.日志记录 5.事务 7.aop的实现？@Aspect定义切面类 @Pointcut定义切入点 定义通知类型 @Befor @After @Arounr @AfterReturning @AfterThrowing 8.spring有哪些优缺点?1.ioc将对象的创建和依赖交给ioc容器，方便解耦，简化开发 2.aop面向切面编程，非入侵方式增强服务，减少重复代码 3.声明式事务，方便测试 4.方便集成各种优秀框架 缺点：配置繁琐，依赖反射影响性能，入门时间长 9.spring有哪些模块组成？1.spring jdbc 2.spring core 3.sping beans 4.spring aop 5.spring web 6.spring test 10.spring框架用到哪些设计模式？1.工厂模式 2.单例模式 3.模板方法 4.代理模式 等 11.spring中有哪些不同类型的事件? 上下文更新事件（ContextRefreshedEvent）：在调用ConfigurableApplicationContext 接口中的refresh()方法时被触发。 上下文开始事件（ContextStartedEvent）：当容器调用ConfigurableApplicationContext的Start()方法开始/重新开始容器时触发该事件。 上下文停止事件（ContextStoppedEvent）：当容器调用ConfigurableApplicationContext的Stop()方法停止容器时触发该事件。 上下文关闭事件（ContextClosedEvent）：当ApplicationContext被关闭时触发该事件。容器被关闭时，其管理的所有单例Bean都被销毁。 请求处理事件（RequestHandledEvent）：在Web应用中，当一个http请求（request）结束触发该事件。如果一个bean实现了ApplicationListener接口，当一个ApplicationEvent 被发布以后，bean会自动被通知。 12.BeanFactory 和 ApplicationContext有什么区别？BeanFactory 是基础ioc容器，拥有基本的ioc容器功能 ApplicationContext 是BeanFactory 的子类，拥有BeanFactory 的全部功能。还扩展了其他功能:国际化 BeanFactory 采用延迟加载bean，ApplicationContext一次性加载bean BeanFactory和ApplicationContext都支持 BeanPostProcessor、BeanFactoryPostProcessor。 BeanFactory 需要手动注册。ApplicationContext自动注册 13.spring有哪些依赖注入方式?1.构造器注入 2.set注入 构造器参数实现强制依赖，setter方法实现可选依赖 14.什么是spring beans?就是java 对象,它们被Spring IOC容器初始化，装配，管理。 15.一个spring bean定义包含什么?bean的创建, 生命周期，依赖 16.spring bean的作用域?通知设置bean的 scope属性来定义bean的作用域,作用域类型有: 1.singleton : bean在每个ioc容器中只有一个实例。 2.prototype：一个bean的定义可以有多个实例。(开销大) 3.request：每次http请求都会创建一个bean(基于web的Spring ApplicationContext情形下有效) 4.session：在一个HTTP Session中，一个bean定义对应一个实例。(基于web的Spring ApplicationContext情形下有效) 5.global-session：在一个全局的HTTP Session中，一个bean定义对应一个实例。(基于web的Spring ApplicationContext情形下有效) 17.spring 中的单例bean是线程安全么?不是线程安全，大部分单例bean是无状态的，比如 dao 类，某种程度来说也是安全的。 18.spring bean的生命周期?1.实例化，创建bean对象 2.属性填充 3.初始化 3.1.实现了xxxAware类型的接口，通过不同类型的Aware接口拿到Spring容器的资源 3.1.1.简单的aware类型接口 BeanNameAware BeanClassLoaderAware BeanFactoryAware 3.2.实现了beanPostProcessor接口，则会在初始化前后回调postProcessBeforeInitialzation和postProcessAfterInitialization方法 3.3.配置了init-mothod方法，则会执行配置的方法 4.销毁 4.1.bean实现了DisposableBean，则会回调destroy方法 4.2.配置了destroy-method方法，则会执行配置的方法 19.@Autowired和@Resource?1.@Autowired默认按类型装配，查询结果为一个时，直接装配。查询结果为多个时，按名称装配。查询不到则报错。不报错则设置属性required=false。可以配和@Qualifier 按名字装配 2.@Resource默认按名字装配，找不到则按照类型装配。指定name属性则按名称装配，找不到则报错。指定type则按照类型装配，找不到则报错 20.FactoryBean 和 BeanFactory有什么区别？BeanFactory 是 Bean 的工厂， ApplicationContext 的父类，IOC 容器的核心，负责生产和管理 Bean 对象。 FactoryBean 是 Bean，可以通过实现 FactoryBean 接口定制实例化 Bean 的逻辑，通过代理一个Bean对象，对方法前后做一些操作。 21.Spring 如何解决循环依赖？spring通过三级缓存解决循环依赖: singletonObjects 一级缓存，用于保存实例化、注入、初始化完成的bean实例 earlySingletonObjects 二级缓存，用于保存实例化完成的bean实例 singletonFactories 三级缓存，用于保存bean创建工厂，以便于后面扩展有机会创建代理对象。 22.为什么要三级缓存？二级缓存不行么?三级缓存是为了保证不管什么时候使用的都是同一个对象。 如果使用二级缓存，多线程情况下可能获取的对象不一致 23.spring解决循环依赖的方法?使用@Lazy注解，延迟加载 使用@DependsOn注解，指定加载先后关系 24.spring的事务传播方式？required 当前没有事务则创建事务，存在事务则加入。 requires_new 不管有没事务都会创建一个新的事务执行。 supports 存在事务则加入，不存在则已非事务只想。 not_supported 以非事务执行，存在事务则挂起 mandatory 存在事务则加入，不存在则报错 never 以非事务执行，存在事务则报错 nested 存在事务则嵌套事务执行 25.spring 事务的隔离级别?default 使用数据库设置的 read_uncommitted 读未提交(出现幻读、脏读、不可重复读) read_committed 读已提交,读的都是别的事务已提交的（会造成幻读、不可重复读）sql server默认级别 repeatable_read 可重复读，保证多次读取同一个数据时，其值都和事务开始时候的内容是一致，禁止读取到别的事务未提交的数据（会造成幻读) serializable 串行，代价最高最可靠的隔离级别，该隔离级别能防止脏读、不可重复读、幻读。 脏读 ：表示一个事务能够读取另一个事务中还未提交的数据。 不可重复读 ：是指在一个事务内，多次读同一数据。读取的数据不一致 幻读 ：指同一个事务内多次查询返回的结果集不一样。 26 .什么是spring mvc?基于java实现了mvc设计模式请求驱动类型的轻量级框架，把模型，视图，控制器分离出来。将web层进行职责解耦，简化开发 27.spring mvc工作原理？1.用户发送请求到前端控制器(DispatcherServlet) 2.前端控制器调用处理器映射器(HandlerMapping) 3.处理器映射器根据url找到对应的处理器（Handler），生成处理器对象，如果有拦截器一起返回给前端控制器 4.前端控制器调用处理器适配器（HandlerAdapter），经过适配器调用后端控制器 5.执行完毕后返回ModelAndView，处理器适配器将结果返回前端控制器 6.前端控制器传给试图解析器（ViewResolver）进行解析,返回具体的视图(view)，进行渲染返回给用户 28.spring ioc容器构建流程?1.获取一个新的bean工厂，通常是applicationContext 2.加载和解析spring配置文件，解析bean对象封装成beanDefinition放到本地缓存 3.实例化和调用beanFactoryPostProcessor的BeanDefinitionRegistryPostProcessor的扩展方法 4.实例化beanPostProcessor,加载到beanFactory中。在bean的初始化前后触发扩展点postProcessBeforeInitialization() / postProcessAfterInitialization() 5.实例化所有剩余的bean，包括创建bean，属性填充，初始化 6.完成容器刷新，推送上下文刷新事件(contextRefresEvent)到监听器 29.spring boot启动流程？1.创建springApplication实例以及初始化 2.通过SpringFactoriesLoader加载监听器,发布EventPublishingRunListener.starting()事件； 3.创建和配置Environment，触发ConfigFileApplicationListener监听器,加载application.properties/yml配置文件 4.创建ApplicationContext,容器刷新的事前准备，容器刷新(ioc容器创建流程)，发布上下文刷新完毕事件 5.发布SpringBoot程序已启动事件ApplicationStartedEvent 6.调用ApplicationRunner和CommandLineRunner 7.最后发布refresh完毕、runner执行完毕的事件 30.spring事务实现的原理?通过aop+threadLocal+try/catch实现: 动态代理：基本所有要进行逻辑增强的地方都会用到动态代理，AOP 底层也是通过动态代理实现。 ThreadLocal：主要用于线程间的资源隔离，以此实现不同线程可以使用不同的数据源、隔离级别等等。 try/catch：最终是执行 commit 还是 rollback，是根据业务逻辑处理是否抛出异常来决定。 31.spring常见的扩展点?1.BeanFactoryPostProcessor postProcessBeanFactory 方法，在加载完 Bean 定义之后，创建 Bean 实例之前被触发，通常使用该扩展点来加载一些自己的 bean 定义。 2.BeanPostProcessor postProcessBeforeInitialization 方法，执行 bean 的初始化方法前被触发； postProcessAfterInitialization 方法，执行 bean 的初始化方法后被触发。 2.InitializingBean afterPropertiesSet 方法，在 bean 的属性填充之后，初始化方法（init-method）之前被触发 3.DisposableBean destroy 方法，在 bean 的销毁阶段被触发，该方法的作用基本等同于 destroy-method，主用用于执行销毁相关操作。 32.springboot如何实现自动装配?启动类中@SpringbootApplicaiton 注解是一个组合注解，里面有一个@EnableAutoConfiguration注解。 这个注解类中使用@Import注解加载EnableAutoConfigurationImportSelector类。这个类是在spring-autoConfig包中。他会加载包中的spring.factories文件内定义的autoconfiguration类。 33.如何自己实现一个starter?starter简单来说就是将一个繁琐的操作打包成一个jar，让你直接加入这个依赖，省去繁琐的步骤 创建一个starter项目 创建一个ConfigurationProperties用于保存你的配置信息（ 创建一个AutoConfiguration，引用定义好的配置信息；在AutoConfiguration中实现所有starter应该完成的操作，并且把这个类加入spring.factories配置文件中进行声明 打包项目，之后在一个SpringBoot项目中引入该项目依赖，然后就可以使用该starter了 2、—N、设计题1、MQ实现异步秒杀1、介绍场景：一万件商品同时被一万人秒杀成功，会导致瞬间上万请求访问到订单数据库中创建订单。此时对数据库的压力就会很大。 方案：引入RocketMQ进行削峰处理。 每个请求进来在Redis中秒杀库存成功，就认为需要生成订单，此时发送一个消息到RocketMQ中去。 然后让普通订单系统从RocketMQ中消费秒杀成功的消息进行处理。对于MQ来说，这种上万的消息积压很容易就扛下来了，只要过了高峰期，订单系统很快就能消费、处理完。这个过程中不会对订单数据库造成过大的压力 2、架构图 3、总结 在前端/客户端设置秒杀答题，错开大量人下单的时间，组织作弊器刷单 独立出来一套秒杀系统，专门负责处理秒杀请求 优先基于Redis进行高并发的库存扣减，一旦库存扣完则秒杀结束 秒杀结束之后，Nginx层过滤掉无效的请求，大幅度削减转发到后端的流量 瞬时生成的大量下单请求直接进入RocketMQ进行削峰，订单系统慢慢拉取消息完成下单操作 秒杀系统补充：1、大量用户先进来页面详情页面，走CDN静态化加速，到Nginx集群（动静分离），其次去Redis集群加载秒杀数据（这个数据可以提交前缓存预热），然后到页面渲染，这个过程中理论是没有经过后端服务系统渲染，直接前端渲染，其实可以后端渲染（不建议）2、大量系统下单，先到前端秒杀答题（当然也有的可以通过Nginx对请求切分分批），然后把无效请求经过Nginx集群过滤；有效请求进入秒杀系统，关于库存数据会提交预热到Redis集群进行库存扣除，大量成功的订单进入RocketMQ进行削峰，订单系统慢慢拉取完成下单操作 2、RocketMQ事务最终一致性1、执行流程图 1、首先服务 A 发送一个半事务消息(也称 half 消息)至 MQ 中。为什么要先发送一个 half 消息呢？这是为了保证服务 A 和 MQ 之间的通信正常，如果无法正常通信，则服务 A 可以直接返回一个异常，也就不用处理后面的逻辑的了。 2、如果 half 消息发送成功，MQ 收到这个 half 消息后，会返回一个 success 响应给服务 A。 3、服务 A 接收到 MQ 返回的 success 响应后，开始处理本地的业务逻辑，并提交本地事务。 4、如果服务 A 本地事务提交成功，则会向 MQ 中发送 commit，表示将 half 消息提交，MQ 就会执行第 5 步操作；如果服务 A 本地事务提交失败，则直接回滚本地事务，并向 MQ 中发送 rollback，表示将之前的 half 消息进行回滚，MQ 接收到 rollback 消息后，就会将 half 消息删除。 5、如果 commit，则将 half 消息写入到磁盘。 6、如果 MQ 长时间没有接收到 commit 或者 rollback 消息，例如：服务 A 在处理本地业务时宕机了，或者发送的 commit、rollback 因为在弱网环境，数据丢失了。那么 MQ 就会在一定时间后尝试调用服务 A 提供的一个接口，通过这个接口来判断 half 消息的状态。所以服务 A 提供的接口，需要实现的业务逻辑是：通过数据库中对应数据的状态来判断，之前的 half 消息对应的业务是否执行成功。如果 MQ 从这个接口中得知 half 消息执行成功了，那么 MQ 就会将 half 消息持久化到本地磁盘，如果得知没有执行成功，那么就会将 half 消息删除。 7、服务 B 从 MQ 中消费到对应的消息。 8、服务 B 处理本地业务逻辑，然后提交本地事务。 2、问答题Q: half 消息是个啥？ A: 它和我们正常发送的普通消息是一样的，都是存储在 MQ 中，唯一不同的是 half 在 MQ 中不会立马被消费者消费到，除非这个 half 消息被 commit 了。(至于为什么未 commit 的 half 消息无法被消费者读取到，这是因为在 MQ 内部，对于事务消息而言，在 commit 之前，会先放在一个内部队列中，只有 commit 了，才会真正将消息放在消费者能读取到的 topic 队列中) Q: 为什么要先发送 half 消息？ A: 前面已经解释过了，主要是为了保证服务 A 和 MQ 之间是否能正常通信，如果两者之间都不能正常通信，后面还玩个锤子，直接返回异常就可以了。 Q: 如果 MQ 接收到了 half 消息，但是在返回 success 响应的时候，因为网络原因，导致服务 A 没有接收到 success 响应，这个时候是什么现象？ A: 当服务 A 发送 half 消息后，它会等待 MQ 给自己返回 success 响应，如果没有接收到，那么服务 A 也会直接结束，返回异常，不再执行后续逻辑。不执行后续逻辑，这样服务 A 也就不会提交 commit 消息给 MQ，MQ 长时间没接收到 commit 消息，那么它就会主动回调服务 A 的一个接口，服务 A 通过接口，查询本地数据后，发现这条消息对应的业务并没有正常执行，那么就告诉 MQ，这个 half 消息不能 commit，需要 rollback，MQ 知道后，就将 half 消息进行删除。 Q: 如果服务 A 本地事务执行失败了，怎么办？ A: 服务 A 本地事务执行失败后，先对自己本地事务进行回滚，然后再向 MQ 发送 rollback 操作。 Q: 服务 A 本地事务提交成功或失败后，向 MQ 发送的 commit 或者 rollback 消息，因为网络问题丢失了，又该怎么处理？ A: 和上一个问题一样，MQ 长时间没有接收到 half 消息的 commit 或者 rollback 消息，MQ 会主动回调服务 A 的接口，通过这个接口来判断自己该对这个 half 消息如何处理。 Q: 前面说的全是事务消息的实现流程，这和事务消息如何保证数据的最终一致性有什么关系呢？ A: 有关系。首先，服务 A 执行本地事务并提交和向 MQ 中发送消息这是两个写操作，然后通过 RocketMQ 的事务消息，我们保证了这两个写操作要么都执行成功，要么都执行失败。然后让其他系统，如服务 B 通过消费 MQ 中的消息，然后再去执行自己本地的事务，这样到最后，服务 A 和服务 B 这两个系统的数据状态是不是达到了一致？这就是最终一致性的含义。 如果要求服务 A 和服务 B 的数据状态，在服务 A 返回给客户端之间，这两者就达到一致，这是强一致性，RocketMQ 是没法保证强一致性的。 目前通过「可靠消息来保证数据的最终一致性」是很多大厂都采用的方案，基本都是通过 MQ 和补偿机制来保证数据的一致性。（所谓的可靠消息，就是消息不丢失，如何保证 MQ 的消息不丢失，下篇文章会写，这也是面试常考题） Q: 服务 B 本地事务提交失败了，怎么办？ A: 如果服务 B 本地事务提交失败了，可以进行多次重试，直到成功。如果重试多次后，还是提交失败，例如此时服务 B 对应的 DB 宕机了，这个时候只要服务 B 不向 MQ 提交本次消息的 offset 即可。如果不提交 offset，那么 MQ 会在一定时间后，继续将这条消息推送给服务 B，服务 B 就可以继续执行本地事务并提交了，直到成功。这样，依旧是保证了服务 A 和服务 B 数据的最终一致性。 3、T、散列1、乱打 问题：库存为啥分为 锁定库存什么的，没有这个锁定库存的话，抢购成功，直接可销售库存 -1 ，已销售库存 + 1 不也可以嘛，为啥redis的秒杀产品 和 数据库商品表，都要加上什么锁定库存呢？ 答：库存分为锁定库存和可销售库存的原因是为了避免超卖和重复销售的情况发生。在秒杀场景中，由于用户的并发量非常高，可能会导致多个用户同时下单成功，但实际上库存只有一个，如果不加锁定库存的机制，就会导致超卖的情况。而且，在用户下单之后，订单并不一定会立即支付，如果将可销售库存减去，就有可能会出现订单未支付但库存已被扣减的情况，这也是需要锁定库存的原因。所以，在秒杀场景中，为了保证库存的正确性和售后服务的质量，需要对库存进行细分和管理。 问题：Hystrix 为啥每次请求都用自己的线程 答：Hystrix 是一种基于线程隔离的断路器模式实现。为了实现线程隔离，Hystrix 会在每个被保护的依赖服务调用中创建一个新的线程池，每次请求都会被分配到这个线程池中的一个线程中执行。这样做的好处是，即使被保护的依赖服务调用发生故障或延迟，也不会影响其他请求的执行，从而提高了系统的可靠性和稳定性。 Hystrix 还可以对每个线程池进行配置，比如可以设置线程池的大小、队列的容量等参数，以达到更好的资源利用和负载均衡效果。因此，每次请求都使用自己的线程，可以更好地实现线程隔离，保障系统的可靠性和稳定性。 问题：在seata分布式事务框架下，如果一个分布式事务分表调用A、B、C服务，A、B调用成功，C调用失败，进行回滚。在回滚的时候，A、B有没有提交到数据库持久化？ 答：其实已经成功了，但是seata底层自动生成用来回滚的sql，把你之前执行的数据库更新，给做一个反向操作 问题：这个可靠消息最终一致性的核心思想是消息防丢吗？那RabbitMQ使用手动ACK也可以实现消息防丢，因此RabbitMQ也算是能实现可靠消息最终一致性吗？ 总感觉我理解错了。答：对的，其实每个MQ都有自己的功能，往后看，即使没有RocketMQ，自己做点开发，也能实现类似的效果 问题：基于内存分段生成订单号方案我觉得稍微复杂一些，而且还需要依靠数据库中的表来处理max id，这种内存分段的方案跟直接用redis的incr生成一个自增的数字相比有什么好处吗，直接用redis处理更简单，而且性能也很高 答：redis的操作是需要去建立网络连接的，内存操作直接在内存中获取的，性能快很多 问题：订单引入状态机后有什么好处呢，不用的话会有什么问题？状态机为什么要选用squirrel框架呢？答：这样的好处就是将订单状态流转和对应的业务处理解耦，并且也不会再有一堆繁杂的 if…else 操作，每当需要新的订单状态流转操作的时候，可以去编写对应的一套operator和processor组件来完成，和已有业务的分离度很高。squirrel框架 集成简单上手快，功能全面 问题：商品考核我认为就是，运营会针对线上商品的一些销售数据情况作分析，比如上架了一批薯条，这个月销量很好，那我们就多进点货物，少那就少进点，但是针对海量的商品，也不能一个个给肉眼去审核，在审核时候有配置模版啥的，引入审核配置规则，比如一个配置模版里边有商品ID=》规则模版这样的。 不知道我的理解对不对? 答：您的理解是正确的。商品考核通常是基于线上销售数据对商品进行评估和分析，以便运营人员做出更加明智的决策，比如调整商品的进货量、价格等，以提高销售业绩和利润。 对于海量商品的考核，手工审核确实是不切实际的。因此，可以引入自动化的审核配置规则，这些规则可以通过配置模板来实现，比如基于商品ID、销售额、库存、售后服务质量等指标来设计规则，从而更加高效地进行商品考核。在具体实现过程中，可以使用机器学习和数据分析技术，从大量数据中挖掘出有效规律和模式，提高商品考核的准确性和效率。 问题：提交订单，会发一个延迟消息，如果一直订单未支付，到了触发的时候，恰好用户点击付款了，此时并发同时过来，是不是要在支付和取消的时候都要加分布式锁，那如果真的此时取消了，是不是只能通知用户，订单已取消，请重新下单吗 答：对于订单支付的延迟消息，确保订单支付的一致性和正确性是非常重要的。在并发情况下，确保数据的一致性和正确性通常需要使用分布式锁来避免冲突。在订单取消的情况下，可以采用异步通知的方式向用户发送消息，告知订单已取消，并提醒用户重新下单。在实际实现中，可以使用消息队列等技术来实现延迟消息和异步通知，保证订单支付的正确性和用户体验。 问题：我看好多书都参考&lt;深入理解java内存模型&gt;一书叫了StoreStore, StoreLoad, LoadLoad, LoadStore, 但是我发现还有一种叫法叫Release Barrier , Store Barrier, Acquire Barrier? 这两种叫法以什么为基准叫的???内存屏障是怎么分类的？？？ 答：内存屏障是指在编程中使用的一种同步机制，它能够确保在程序中特定位置处的内存操作按照特定顺序执行，从而保证了多线程环境下的可见性和有序性。 在Java内存模型中，内存屏障按照功能被划分为四种：Load Barrier（读屏障）、Store Barrier（写屏障）、StoreLoad Barrier（写-读屏障）和LoadStore Barrier（读-写屏障）。这些屏障的作用如下： Load Barrier（读屏障）：它用于确保某个线程在读取某个变量时，能够看到其他线程对该变量的更新。Store Barrier（写屏障）：它用于确保某个线程在修改某个变量时，对其他线程的修改可见。StoreLoad Barrier（写-读屏障）：它用于确保某个线程在写入某个变量后，之后读取该变量时，能够看到其他线程在写入该变量之前的操作。LoadStore Barrier（读-写屏障）：它用于确保某个线程在读取某个变量时，之前的写入操作对其他线程可见。另外，Release Barrier 和 Acquire Barrier 是一种更高层次的内存屏障概念，它们是基于前面提到的四种内存屏障而定义的。Release Barrier 和 Acquire Barrier 分别用于确保某个线程的写操作对其他线程可见和确保某个线程的读操作看到其他线程的写操作。在Java内存模型中，Release Barrier 对应的是 Store Store Barrier 和 StoreLoad Barrier，而 Acquire Barrier 对应的是 LoadLoad Barrier 和 LoadStore Barrier。 内存屏障的分类是根据其功能不同来划分的，而 Release Barrier 和 Acquire Barrier 则是一种更高层次的概念，它们是基于前面提到的四种内存屏障而定义的。 问题2：能不能下订单的时候不推mq，在用户支付的成功后再向其他系统推送mq消息呢?如果延迟推送，用户刚下单就支付了，岂不是要等半个小时，才能收到红包系统发的红包? 答：这是两条消息，一个是你创建订单了，完了有一个订单创建通知，你可以30分钟后消费这个消息，判断你的订单是否已经超过30分钟还没支付;另外一个是如果已经支付了，有一个订单支付的消息，然后你很多系统可以消费这个消息，做后续的处理 2、闲聊1、离职原因 薪资一方面，其次是触碰更多的是边缘技术，能成长的空间有限 虽说能碰到一些核心技术，但是成长也比较缓慢，不是长久之策 舒适圈待久了，有些迫切的危机感， 望得到更多的挑战和学习机会 2、参考 ↓MySQL 执行流程 :https://blog.csdn.net/qwer123451234123/article/details/124344299 数据结构可视化演变： https://www.cs.usfca.edu/~galles/visualization/BPlusTree.html B+Tree时间复杂度：https://blog.csdn.net/yunduanyou/article/details/128233801 1.8流操作题：https://blog.csdn.net/Thinkingcao/article/details/108664921 MySQL中的聚簇索引和非聚簇索引：https://www.jb51.net/article/251419.htm MySQL存储引擎：https://blog.csdn.net/promsing/article/details/126157969 MySQL覆盖索引为什么不用回表：https://blog.csdn.net/muwenbofx/article/details/123259858 慢SQL解决： https://www.qycn.com/xzx/article/9300.html https://baijiahao.baidu.com/s?id=1746620518356199899&amp;wfr=spider&amp;for=pc SpringCloud与Dubbo的区别：https://blog.csdn.net/weixin_51291483/article/details/109212137/ CND加速：https://www.likecs.com/show-204294177.html#sc=1128秒杀设计：https://blog.csdn.net/weixin_42405670/article/details/118138802seata 面试题：简单版：https://zhuanlan.zhihu.com/p/470281769完整版：https://www.cnblogs.com/crazymakercircle/p/14375424.html#autoid-h4-6-3-0 Seata的四种模式： https://blog.csdn.net/wuyongde_0922/article/details/125333625 https://blog.csdn.net/m0_58600248/article/details/126271252 Spring 面试题：https://zhuanlan.zhihu.com/p/469797333MQ面试题：https://zhuanlan.zhihu.com/p/470984789 RocketMQ事务消息如何保证数据的最终一致性：https://blog.csdn.net/qq_42093488/article/details/114677515 七种分布式事务实现：https://blog.csdn.net/qq_36963950/article/details/108909780 redis数据结构：https://blog.csdn.net/mz474920631/article/details/125200050 TCC落地文章（有合集）：https://blog.csdn.net/weixin_44102992/article/details/126493034?spm=1001.2014.3001.5501 TCC和RocketMQ做分布式事务区别：https://zhuanlan.zhihu.com/p/183753774 redis之如何实现消息队列：https://blog.csdn.net/wang0907/article/details/127830591 分布式事务四种方案和对比：https://www.cnblogs.com/muxilaoshi/p/15429404.html seata AT和XA的区别：https://www.51cto.com/article/659139.html?u_atoken=908e9399-a703-4278-8438-3e2639de1e42&amp;u_asession=01cbB_xA5flpNlOFMXMMxwrHuPaiY7SlcCklCBZ6cSuxieaFEySACzsRygqqIcFf6yX0KNBwm7Lovlpxjd_P_q4JsKWYrT3W_NKPr8w6oU7K8PYmybX1Fb1-mAlyDPgbs_DvUNWlpfeCH_Z_6FnnXEnGBkFo3NEHBv0PZUm6pbxQU&amp;u_asig=05H6c_C18NzGqylFOgxYxOfyO9v0KX11HhF9UNuVuWDyDEKZsyCCsmlvOm93IX5QObFbfUNqdn8aQG1mI6aOKSs4Teqnna915rPIdR1R6vLUber5juuaXtMV73tq6jjhUPwNFoYr3TWz60hy4MRDOTCYy74sE94reA3i6Bm9SeXcv9JS7q8ZD7Xtz2Ly-b0kmuyAKRFSVJkkdwVUnyHAIJzdFdm6FtdJ6etcsGdFNqcU7WcMYF5aSO9Hw4ju-PP021VSW66CuWlZZ6ywL2zPMFnu3h9VXwMyh6PgyDIVSG1W8kCUCcLCVBKZk4XCs8ybF9IwNOrpX04BxodSt1A8Jz_TYwAep73xlDlF8jhaGyXHfBkISeMFkkfFA1VnMgsMutmWspDxyAEEo4kbsryBKb9Q&amp;u_aref=djAEUQI%2FtZgGE8x5s2Rr8%2BQuQKg%3D 金融项目seata说明：https://zhuanlan.zhihu.com/p/499041496 接口幂等性校验实现：https://blog.csdn.net/huchao_lingo/article/details/105540418 消息队列的可靠性：https://blog.csdn.net/m0_73859807/article/details/128861716 字节跳动，高可用、不重复消费、可靠传输、顺序消费、消息堆积：https://www.cnblogs.com/binghe001/p/14443360.html 站长简书：https://www.jianshu.com/p/2e995df9ccbc Redis面试题： https://zhuanlan.zhihu.com/p/567047691 https://www.cnblogs.com/javazhiyin/p/13839357.html Redis缓存一致性：https://blog.csdn.net/a745233700/article/details/88081219 hystrix中信号量和线程池：https://www.cnblogs.com/chihirotan/p/11368520.html nacos面试等参考：https://zhuanlan.zhihu.com/p/482632893 eureka: https://blog.csdn.net/lyc_liyanchao/article/details/120060221 https://blog.csdn.net/weixin_48227718/article/details/125620401 zookeeper: https://blog.csdn.net/weixin_43495317/article/details/123142595 https://blog.51cto.com/u_15127568/2713356 seata原理： https://blog.csdn.net/qq_14996421/article/details/125706271 redis原子性保证：https://blog.csdn.net/u013277209/article/details/126274656 binlog、redolog、undolog：https://zhuanlan.zhihu.com/p/474218953 FlinkCDC and ETL :https://blog.csdn.net/YiRan_Zhao/article/details/126946412 【精】Seata四种模式和原理（全）：http://www.360doc.com/content/22/0902/20/78411425_1046313419.shtml【精】Seata AT模式不适合高并发场景：https://www.cnblogs.com/ciel717/p/16190760.html【精】分布式事务全解：https://www.cnblogs.com/ciel717/p/16190481.html binlog详解：https://blog.csdn.net/m0_73311735/article/details/127935751 Redis6 IO多路复用+多线程：https://blog.csdn.net/weixin_39724194/article/details/128660990 seata案例，saga应用场景：https://www.cnblogs.com/yizhiamumu/p/16809386.html 并发线程数、QPS与平均耗时的关系：https://cloud.tencent.com/developer/article/1784548?ivk_sa=1024320u 正向代理和方向代理：https://baijiahao.baidu.com/s?id=1756527779282578683&amp;wfr=spider&amp;for=pc flink面试题：https://cloud.tencent.com/developer/article/1892515 https://blog.csdn.net/sinat_23225111/article/details/124495260","categories":[{"name":"面试题","slug":"面试题","permalink":"https://mykkto.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"面试","slug":"面试","permalink":"https://mykkto.github.io/tags/%E9%9D%A2%E8%AF%95/"}],"author":"mykk"},{"title":"JUC-深度面试题（粉丝投稿）","slug":"22-专栏/yjc/yjc01-2022 JUC 面试复盘","date":"2023-01-04T12:39:21.000Z","updated":"2023-02-26T14:16:15.266Z","comments":true,"path":"posts/ee9ed7cb.html","link":"","permalink":"https://mykkto.github.io/posts/ee9ed7cb.html","excerpt":"","text":"2022 JUC 复盘大纲目录[TOC] ComlpetableFutuer回顾Future1future 接口就是定义操作一步执行一些方法，如获得异步任务的执行结果。取消任务的执行，判断任务是否取消，判断任务是否执行完毕。2 它具体实现是FutureTask ,它同时实现了 Runnable 和Future 接口 。通过它构造方法方法可以传入 callable 和runnable 具体实现类。3 结论就是 通过futuretask 接可以现实性多线程的异步任务。4 futuretask 结合线程池提供效率5futuretask 缺点： 1如果耗时很久的异步子线程处理完成之后 ，再去调用 get方法获取计算任务程序一切都正常，反之就会导致之线程阻塞。2isDone 方法 轮询容易导致cpu空转 耗损导致更多资源占用。6针对futuretask 的改进不需通过轮询的方式的判断的线程任务是否完成，通过回调通知函数。异步任务的步骤上的依赖（上一个步骤时下个步骤的前提）这就CompletableFutrure出来的伏笔。==考点 CompletableFutuer 调用 runAsync supplyAsync 等静态方法传入一个参数时候，它的线程池是什么？==在调用CompletableFutuer 静态方法默认不传入线程池的参数时候，CompletableFutuer 的ForkJoinpool 。codeExecutorService pool = Executors.newFixedThreadPool(3); try{ CompletableFuture.supplyAsync(()-&gt;{ try{TimeUnit.SECONDS.sleep(1);}catch(InterruptedException e){} System.out.println(Thread.currentThread().getName()+\"come in\"); int ruset = ThreadLocalRandom.current().nextInt(10); return ruset; },pool).whenComplete((v,e) -&gt;{ if (e==null ){//无异常情况 System.out.println(\"上部的计算结果时\"+v); } }).exceptionally(e -&gt;{ e.printStackTrace(); System.out.println(\"异常情况是\"); return null; }); System.out.println(\"主要线程忙其他任务去了\"); }catch(Exception e){ e.printStackTrace(); } finally { pool.shutdown();//关闭线程池 } ==考点 CompletableFuture 种方法get 和join 两个方法的区别==get 方法需要声明抛异常，二join 不需要 getNow是判断线程任务是是否完成，如果完成就返回完成的状态，如果没有就返回getNow的参数的的值，Handle这个方法可以获得正常和异常的参数结果。==考点 CompletableFuture 是否都一直调用默认的线程池吗，thenApply 和thenApplyAsync这两个方法有啥却别==如果有传入自定义的线程池就按照传入线程执行，当调 ThenRun 方法执行第二个任务时候，则第二个任务和第一个任务共用一个线程池，当调用ThenRunAsync 时候执行第二个任务时候，则第一任务使用自定义的线程池，从第二个任务开始使用的就是ForkJoin 线程池。==还有一种情况是 如果mian 线程执行，那么后续都由main线程执行不会切换线程池。系统优化原则减少切换，main 线程执行效率太快==public class CompleateFutureAPIDome { public static void main(String[] args) { ExecutorService pool = Executors.newFixedThreadPool(3);//自定义线程池 CompletableFuture.supplyAsync(()-&gt;{ try{ TimeUnit.SECONDS.sleep(1);}catch(InterruptedException e){} System.out.println(Thread.currentThread().getName()); System.out.println(\"1111\"); return 1; },pool).thenApply(f -&gt;{ System.out.println(Thread.currentThread().getName()); //当前线程池是pool System.out.println(\"222\"); return 2; }).thenApplyAsync(f -&gt;{//这个之后都是默认线程池 System.out.println(Thread.currentThread().getName());//当前线程池是 ForkJoin 线程池 System.out.println(\"333\"); return 3; }).whenComplete((v,e) -&gt;{ if (e==null){ System.out.println(\"打印出来是\"+v ); } }).exceptionally(e -&gt;{ e.printStackTrace(); return null; }); pool.shutdown(); } } Java 锁的哪些事==何为悲观锁何为乐观锁==悲观锁概念：大白话的，线程执行的任务其他线程一定会和它抢资源，因此在获取数据之前一定是加一把锁，确保数据安全没有背修改过。规则是先加锁。乐观锁的概念：线程执行的时候认为不会有其他线程和它抢占资源（其他线程不会修改数据），所以不会加锁。规则不会加锁，但是通过版本好的迭代或者CAS 自旋来判断。（比较并交换的状态）==根据8 锁用例场景总结==当对象同时多个synchronzied 方法，当某一时刻内，只要一个线程去调用其中的一个synchronzied 方法 其他线都要等待它执行完毕再执行。锁是当前对象this 因为对象是jvm 堆里面当没有产生竞争时候，各自拿自己锁的执行。static sychronzied 锁的是当前 类型模板。class (类锁) jvm 的方法区里面 只有唯一 一个对 同步代码块 锁的 sychronzied 括号的对象==总之根据锁不同，分析是对象锁还是，类锁，或者同步代码块，如果不同锁，不那么不会有竞争关系，各自执行各自互不相干扰，使用锁的原则用无锁尽量，实在不行就同代码块，在不行使用对象 ，最后才考虑类锁。锁粒度大小排序 到大 无锁 &lt; 同步代码块 &lt; 对象锁 &lt; 类锁====同步代码 反编译看 是用 javap -c 查看 底层sychronized morritorenter 和monitorexit,但为啥会两个 monitorexit==是唯一正常情况获得执行完毕释放锁，但要异常情况也可以释放锁。所以加两个的 monitorexit，二对象锁和类型 它们反编译之后可以看 ACC_SYCHRONIZED ,以及类锁==公平锁 和非公平锁==公平锁是指多个线程按照申请锁的顺序来获取锁，类似于排队买饭，先来后到，先来先服务，就是公平的，也就是队列非公平锁 是指多个线程不会 按照申请锁的顺序来获取锁，有的锁 插队，而且插队执行之后，可能会继续再来排队又插队相比其他线程不公平的抢夺cpu资源的。==为啥默认是非公平的，以及什么时候用公平什么时候用非公平==首先默认使用非公平的时候，系统减少线程切换次数。提高系统的性能，对于何为使用公平和非公平的。那根据具体业务具体分析例如医院挂号的可以使用公平保证没有每个人都被叫到，非公平例如等红绿灯时候主干道的车辆比较多，需要放行车辆次数多，次要干道车流少。甚至没有车。所以使用非公平让交通流畅==偏向锁==偏向锁:单线程竞争当线程A第一次竞争到锁时，通过操作修改Mark Word中的偏向线程ID、偏向模式如果不存在其他线程竞争，那么持有偏向锁的线程将永远不需要进行同步。（==减少用户态内核态切换==）作用： 当一段同步代码一直被同一个线程多次访问，由于只有一个线程那幺该线程在后续访问时便会自动获得锁。理论落地 在实际应用运行过程中发现，“锁总是同一个线程持有，很少发生竞争”，也就是说锁总是被第一个占用他的线程拥有，这个线程就是锁的偏向线程。 那么只需要在锁第一次被拥有的时候，记录下偏向线程ID。这样偏向线程就一直持有着锁(后续这个线程进入和退出这段加了同步锁的代码块时，不需要再次加锁和释放锁。而是直接会去检查锁的MarkWord里面是不是放的自己的线程ID)。如果相等，表示偏向锁是偏向于当前线程的，就不需要再尝试获得锁了，直到竞争发生才释放锁。以后每次同步，检查锁的偏向线程D与当前线程ID是否一致，如果一致直接进入同步。无需每次加锁解锁都去CAS更新对象头。如果自始至终使用锁的线程只有一个，很明显偏向锁几乎没有额外开销，性能极高。 如果不等，表示发生了竞争，锁已经不是总是偏向于同一个线程了，这个时候会尝试使用CAS来替换MarkWord里面的线程ID为新线程的ID， 竞争成功，表示之前的线程不存在了， Markword里面的线程ID为新线程的ID，锁不会升级，仍然为偏向锁，竞争失败，这时候可能需要升级变为轻量级锁，才能保证线程间公平竞争锁。注意，偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程是不会主动释放偏向锁的。技术实现: 技术实现：一个synchronized方法被一个线程抢到了锁时，那这个方法所在的对象就会在其所在的Mak Word中将偏向锁修改状态位，同时还会有占用前54位来存储线程指针作为标识。若该线程再次访问同一个synchronized方法时，该线程只需去对象头的Mark Word 中去判断一下是否有偏向锁指向本身的ID，无需再进入 Monitor 去竞争对象了。 ==轻量锁==定义：多线程竞争，但是任意时刻最多只有一个线程竞争，即不存在锁竞争太过激烈的情况，也就没有线程阻寨。作用：有线程来参与锁的竞争，但是获取锁的冲突时间极短本质就是自旋锁CAS==重量级锁==重量级锁原理指向互斥量 (重量级锁)的指针Java中synchronized的重量级锁，是基于进入和退出Monitor对象实现的。在编译时会将同步块的开始位置插入monitor enter指令，在结束位置插入monitor exit指令。当线程执行到monitor enter指令时，会尝试获取对象所对应的Monitor所有权，如果获取到了，即获取到了锁，会在Monitor的owner中存放当前线程的id，这样它将处于锁定状态，除非退出同步块，否则其他线程无法获取到这个Monitor。 ==自旋锁==自旋锁 (spinlock)CAS 是实现自旋锁的基础，CAS 利用 CPU 指令保证了操作的原子性，以达到锁的效果，至于自旋呢，看字面意思也很明白，自己旋转。是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，当线程发现锁被占用时，会不断循环判断锁的状态，直到获取。这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPUCAS 是实现自旋锁的基础，自旋翻译成人话就是循环，一般是用一个无限循环实现。这样一来，一个无限循环中，执行一个CAS 操作，当操作成功返回 true 时，循环结束;当返回 false 时，接着执行循环，继续尝试 CAS 操作，直到返回 true。 /*** * 实现一个自旋锁，复习CAS思想 * 自旋锁好处: 循坏比较获取没有类似wait的阻塞 * 水 * 通过CAS操作完成自旋锁，A线程先进来调用myLock方法自己持有锁5秒钟，B随后进来后发现￥当前有线程持有锁，所以只能通过自旋等待，直到A释放锁后B随后抢到。 */ public class LockSprnk { AtomicReference&lt;Thread&gt; atomicReference=new AtomicReference&lt;&gt;();//自定义类的原子引用 /** * 加锁方法 */ public void lockAtmot(){ Thread thread = Thread.currentThread(); System.out.println(Thread.currentThread().getName()+\" come in\"); while (!atomicReference.compareAndSet(null,thread)){//判断 是否有线程，没有就把当前放进去 } } /** * 解锁方法 */ public void unLockAtomit(){ Thread thread = Thread.currentThread(); atomicReference.compareAndSet(thread,null);//自旋看是否当前线程 是置空 System.out.println(Thread.currentThread().getName()+\"解锁成功\"); } public static void main(String[] args) { LockSprnk lockSprnk = new LockSprnk(); new Thread(() -&gt;{ lockSprnk.lockAtmot(); //休眠5毫秒 try{ TimeUnit.SECONDS.sleep(5);}catch(InterruptedException e){} lockSprnk.unLockAtomit(); },\"A\").start(); //暂停5秒 try{TimeUnit.SECONDS.sleep(2);}catch(InterruptedException e){} new Thread(() -&gt;{ lockSprnk.lockAtmot(); lockSprnk.unLockAtomit(); },\"B\").start(); } } CAS 的缺点：CPU的空转 以及 ABA 的问题（这又会引出时间戳的原子类）==读写锁==ReentrantReadWriteLock读写锁定义为:一个资源能够被多个读线程访问，或者被一个写线程访问，但是不能同时存在读写线程。（读写互斥，读读共享，读是独占锁读未完成写锁抢不到）==邮戳锁==StampedLockReentrantReadWriteLock的读锁被占用的时候，其他线程尝试获取写锁的时候会被阻塞。但是，StampedLock采取乐观获取后，其他线程尝试获取写锁时不会被阻塞，这其实是对读锁的优化，所以，在获取乐观读锁后，还需要对结果进行校验。==锁的降级==写锁的降级，降级成为了读锁 1 如果同一个线程持有了写锁，在没有释放写锁的情况下，它还可以继续获得读锁。这就是写锁的降级，降级成为了读锁。 2 规则惯例，先获取写锁，然后获取读锁，再释放写锁的 次序 3 如果释放了写锁，那么就完全转换为读锁。 ==可重入锁（递归锁）==指的是同一线程外层函数获得锁之后，内层递归函数仍然能获取该锁的代码，在同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁。（前提获得同一把锁） 可重入锁 分为隐式锁 和 显示锁 ： sychronized 关键字 使用的锁 默认可重入锁，显示锁 reentrLock 的lock 和unlock 锁的要成对出现，不然导致不能有效释放锁以至于线程被阻塞。==死锁==死锁的概念：两个或两个的线程争夺资源，而造成的相互等待 CodeObject a=new Object(); Object b=new Object(); new Thread(() -&gt;{ synchronized (a) { System.out.println(Thread.currentThread().getName()+\" A想想拿到b锁\"); try{TimeUnit.SECONDS.sleep(3);}catch(InterruptedException e){} synchronized (b){ System.out.println(Thread.currentThread().getName()+\" B想拿到A锁\"); } } },\"t1\").start(); new Thread(() -&gt;{ synchronized (b) { System.out.println(Thread.currentThread().getName()+\" B想想拿到A锁\"); synchronized (a){ System.out.println(Thread.currentThread().getName()+\" A想拿到B锁\"); } } },\"t2\").start(); 死锁的诊断 JPS -l 列所有的线程id 再根据 jstack 线程id好诊断 图形化诊断 死锁 线程中断机制==考点：线程如何中断运行 ,请用简单的code 编写。当调用 interrupt()是否马上停止线程呢 ，对比一下isinterrupt和静态interrupt他们的方法有什么区别==public static void main(String[] args) { Thread t1 = new Thread(() -&gt; { while (true) { //是否中断 if (Thread.currentThread().isInterrupted()){ System.out.println(\"线程+\" + Thread.currentThread().isInterrupted()); break; } try{TimeUnit.SECONDS.sleep(1);}catch(InterruptedException e){ e.printStackTrace(); Thread.currentThread().interrupt(); //睡眠中断异常的 导致死循环 一定要再调用一次，把标志位改过程（重点）原因是把t2中断标志位给清除了，只有InterruptedException 异常就会中断标志位标识 } System.out.println(\"线程没有停止\"); } }, \"t1\"); t1.start(); // System.out.println(Thread.currentThread().isInterrupted()); try{ TimeUnit.MICROSECONDS.sleep(5);}catch(InterruptedException e){} new Thread(() -&gt;{ t1.interrupt(); //中断 调用这个方法 变更中断的标志位（中断是一种协商机制，不是立即停止线程的活得，而是被中断的线程自己停止） },\"t2\").start(); } 中断的总结:具体来说，当对一个线程，调用 interrupt() 时:1如果线程处于正常活动状态，那么会将该线程的中断标志设置为 true，仅此而已。被设置中断标志的线程将继续正常运行，不受影响。所以，interrupt() 并不能真正的中断线程，需要被调用的线程自己进行配合才行2如果线程处于被阻塞状态(例如处于sleep,wait, join 等状态)，在别的线程中调用当前线程对象的interrupt方法,那么线程将立即退出被阻塞状态，并抛出一个InterruptedException异常。 中断interrupt 的静态 方法他 会中两个事情，一个测试当前线程是否被中断了，还有一个是将当前线程中断把标志位改为false 。清除线程的中断状态 ，实例方法isterrup 和interrup 它们底层都是调用的 相同的方法，只不过静态方法主动清除标志位。LockSuppotLockSupport 是前面的对线程的等待和唤醒 的优化，前面Object自带的 wait 和notfiy Lock中的 await 和signalsychorizied 里面 wait notfiy 需要成对出现，并且放在同步sychcorized 修饰的代码块里面。否则也会报异常。condition 中 lock await 和signal 也是一样要 lock unlock 里面的 顺序也不能调换。由此优化的LockSupport 背景。LockSupport是用来创建锁和其他同步类的基本线程阻寒原语。一个线程阻塞工具类，所有的方法都是静态方法，可以让线程在任意位置阻塞，阻塞之后也有对应的唤醒方法。归根结_ockSupport是LockSupport调用的Unsafe中的native代码。_ockSupport 提供park()和unpark()方法实现阻塞线程和解除线程阻塞的过程ockSupport和每个使用它的线程都有一个许可(permit)关联。每个线程都有一个相关的permit, permit最多只有一个，重复调用unpark也不会积累凭证。形象的理解线程阻塞需要消耗凭证(permit)，这个凭证最多只有1个。当调用 park方法时 如果有凭证，则会直接消耗掉这个凭证然后正常退出;如果无凭证，就必须阻寒等待凭证可用;而unpark则相反，它会增加一个凭证，但凭证最多只能有1个，累加无效。==考点 为什么可以突破wait/notify的原有调用顺序? 为什么唤醒两次后阻塞两次==为什么可以突破wait/notify的原有调用顺序?因为unpark获得了一个凭证，之后再调用park方法，就可以名正言顺的凭证消费，故不会阻塞。先发放了凭证后续可以畅通无阻。为什么唤醒两次后阻塞两次，但最终结果还会阻塞线程?因为凭证的数量最多为 1，连续调用两次 unpark 和 调用一次 unpark 效果一样，只会增加一个凭证:而调用两次 park却需要消费两个凭证，证不够，不能放行。==为什么wait必须写在同步代码块中？==避免 CPU 切换到其他程，而其他线程又提前执行了 notify 方法，那这样就达不到我们的预期（先 wait 再由其他程来唤醒），所以需要一个同步锁来保护==sleep()与wait()的区别？==主要有四个方面区别 sleep() 属于Thread类，wait() 属于Object类 sleep() 不会释放对象锁，wait() 会释放对象锁 sleep() 必须指定时间，wait() 可指定也可以不指定 sleep() 可以使用在任何代码块，wait() 必须在同步方法或同步代码块中使用 ==为什么wait要定义在Object中而不定义在Thread中？==Java的锁是对象级别的，不是线程级别的sleep() 休眠指的就是线程休眠，所以在Thread类==Sychronized和lock有什么区别？用新的Lock有什么好处？举例说说== 原始构成： Synchronized是关键字属于JVM层面monitorenter (底层是通过monitor对象来完成，其实和wait/notify等方法也依赖于monitor对象只有在同步块或者方法中才能调用wait/notify等方法)monitorExit(有两个，一个是正常退出一个是异常退出) Lock是具体类 (java.utilconcurrentlocks.Lock) 是api层面的锁 使用方法： synchronized不需要用户去手动释放锁，当synchronized代码执行完成后系统会自动让线程释放对锁的占用 ReentrantLock则需要用户去手动释放锁，若没有主动释放锁，就有可能导致出现死锁现象需要lock()和unlock()方法配合try/finally语句块来完成 等待是否可中断 Synchronized不可中断，除非抛出异常或者正常运行完成 除非抛出异常或者正常运行完成 设置超时方法tryLock(long timeoutTimeUnit unit) lockInterruptibly()放代码块中，调用interrupt0)方法可中断 锁绑定多个条件Condition synchronized没有 ReentrantLock用来实现分组唤醒需要唤醒的线程们，可以精确唤醒，而不是像synchronized要么随机唤醒一个先后曾要么唤醒全部线程。 java内存模型 之 jMM因为有这么多级的缓存(cpu和物理主内存的速度不一致的).CPU的运行并不是直接操作内存而是先把内存里边的数据读到缓存，而内存的读和写操作的时候就会造成不一致的问题jVM规范中试图定义一种Java内存模型 java Memory Model，简称JMM)来屏蔽掉各种硬件和操作系统的内存访问差异以实现让Java程序在各种平台下都能达到一致的内存访问效果。所以，推导出我们需要知道JMMJMM(Java内存模型Java Memory Mode，简称JMM)本身是一种抽象的概念并不真实存在它仅仅描述的是一组约定或规范，通过这组现范定义了程序中(尤其是多线程)各人变量的读写访问方式并决定一个线程对共享变量的写入何时以及如何变成对另一个线程可见，关建技术点都是围绕多线程的原子性、可见性和有序性展开的。原则:JMM的关键技术点都是围绕多线程的原子性、可见性和有序性展开的能干嘛?通过JMM来实现线程和主内存之间的抽象关系。屏蔽各个硬件平台和操作系统的内存访问差异以实现让Java程序在各种平台下都能达到一致的内存访问效果。考点==JMM 的三大特性是什么请对这三大特性 做一个说明吧==1. ==可见性 ：当一个线程更改了共享变量的值，其他线程能否立即知道共享变量发生了变更。JMM规定了共享变量存储在主内存中。系统主内存中共享变量被写入的时机不确定，多线程的环境下容易产生脏读。每个线程都有自己的工作内存，工作内存中保存了该线程使用变量的主内存副本拷贝，每个线程只能操作自己工作内存中的变量，不能直接读取主内存中的变量。不同线程不能直接访问对方工作内存中的变量，线程变量值的传递需要通过主内存来完成==2. ==原子性 ：指同一个操作不能被打断，多线程的环境下，操作不能被其他线程干扰==3. ==有序性 ：JAVA规范规定的JVM线程内部维持的顺序化语序，如果代码执行的最终结果与顺序执行的结果一致，那么指令执行的顺序与代码执行的顺序不一致 即指令重新排序====优点: JVM 根据处理器特性对机器指令重排 使机器指令更符合CPU的执行顺序 ，最大限度的发挥了机器性能====缺点：指令重排可以保证串行语义的一致，但不能保证多线程语义也一致== ==考点happens-before总原则理解==如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见而且第一个操作的执行顺序排在第二个操作之前。两个操作之间存在happens-before关系，并不意味着一定要按照happens-before原则制定的顺序来执行如果重排序之后的执行结果与按照happens-before关系来执行的结果一致，那么这种重排序并不非法。happens-before 原则具体版 .1次序规则: 一个线程内，按照代码顺序，写在前面的操作先行发生于写在后面的操作; 前一个操作的结果可以被后续的操作获取讲直白点就是前面一个操作把变量X赋值为1，那后面一个操作肯定能知道X已经变成了1 2.锁定规则: 个unLock操作先行发生于后面((这里的“后面”是指时间上的先后))对同一个锁的lock操作; 3.volatile变量规则:对一个volatile变量的写操作先行发生于后面对这个变量的读操作，前面的写对后面的读是可见的，这里的“后面”同样是指时间上的先后 4.传递规则:如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C 5.线程启动规则(Thread Start Rule):Thread对象的start()方法先行发生于此线程的每一个动作 6.线程中断规则(Thread Interruption Rule): 对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生;可以通过Thread.interrupted()检测到是否发生中断也就是说你要先调用interrupt()方法设置过中断标志位，我才能检测到中断发生 7.线程终止规则(Thread Termination Rule): 线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过isAlive()等手段检测线程是否已经终止执行 8.对象终结规则(Finalizer Rule): 对象没有完成初始化之前，是不能调用finalized0)方法的 volatile 和 JMM==考点被volatile修饰的变量有什么特点 ：可见性 有序性==volatile的内存语义（作用）：当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值立即刷新回主内存中。当读一个volatile变量时，JMM会把该线程对应的本地内存设置为无效，重新回到主内存中读取最新共享变所以volatile的写内存语义是直接刷新到主内存中，读的内存语义是直接从主内存中读取==考点的通过什么方式保证可以见性和有序性：是通过内存屏障==说说内存屏障原理（==重点==）再说内存屏障之前，先看看对于有序性的理解有序(禁重排) 重排序是指编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段，有时候会改变程序语句的先后顺序不存在数据依赖关系，可以重排序; 存在数据依赖关系，禁止重排序但重排后的指令绝对不能改变原有的串行语义!这点在并发设计中必须要重点考虑! 内存屏障的分类 粗分两种：读屏障 （在读指令之前插入读屏障，让工作内存或CPU高速缓存当中的缓存数据失效，重新回到主内存中获取最新数据）和写的屏障（在写指令之后插入写屏障，强制把写缓冲区的数据刷回到主内存中） 细分有四种： 屏障类型 指令示例 说明 LoadLoad Load1;LoadLoad;Load2 保证load1的读取操作在load2及后续读取操作之前执行 StoreStore Store1; StoreStore; Store2 在store2及其后的写操作执行前，保证store1的写操作已刷新到主内存 LoadStore Load1: LoadStore: Store2 在stroe2及其后的写操作执行前，保证load1的读操作已读取结束 StoreLoad Store1: Storeload: Load2 保证store1的写操作已刷新到主内存之后，load2及其后的读操作才能执行 Happens-before之volatile 的规则 策略 第一个操作 第二个操作: 普通读写 第二个操作: volatile读 第二个操作: volatile读 普通读写 普通读写 普通读写 不可以重排 volatile读 不可以重排 不可以重排 不可以重排 volatile写 可以重排 不可以重排 不可以重排 策略的记忆口诀 当第一个操作为volatle读时，不论第二个操作是什么，都不能重排序。这个操作保证了volatle读之后的操作不会被重排到volatile读之前。 当第二个操作为volatile写时，不论第一个操作是什么，都不能重排序。这个操作保证了volatile写之前的操作不会被重排到volatile写之后。 当第一个操作为volatile写时，第二个操作为volatile读时，不能重排。 读屏障的示意图 写屏障的示意图 volatie 变量写过程的 read: 作用于主内存，将变量的值从主内存传输到工作内存，主内存到工作内存 load: 作用于工作内存，将read从主内存传输的变量值放入工作内存变量副本中，即数据加载 use: 作用于工作内存，将工作内存变量副本的值传递给执行引擎，每当JVM遇到需要该变量的字节码指令时会执行该操作 assign: 作用于工作内存，将从执行引警接收到的值赋值给工作内存变量，每当JVM遇到一个给变量赋值字节码指令时会执行该操作 store: 作用于工作内存，将赋值完毕的工作变量的值写回给主内存 write:作用于主内存，将store传输过来的变量值赋值给主内存中的变量 ==由于上述6条只能保证单条指令的原子性，针对多条指令的组合性原子保证，没有大面积加锁，所以，JVM提供了另外两个原子指令== lock: 作用于主内存，将一个变量标记为一个线程独占的状态，只是写时候加锁，就只是锁了写变量的过程。 unlock: 作用于主内存，把一个处于锁定状态的变量释放，然后才能被其他线程占用 ==考点volatile 的使用场景== 单一赋值可以，but含复合运算赋值不可以(i++之类) 状态标志，判断业务是否结束 （变量可以用volatile 修饰） 开销较低的读，写锁策略 （再写使用sychornized 修饰 读的变量的使用volatile 修饰） AtomicIntegerFieldUpdater，AtomicLongFieldUpdater，AtomicReferenceFieldUpdater 更新的对象属性必须使用 public volatile 修饰符 DCL双端锁的发布 （单例模式的中双重检查） package com.atguigu.itdachang; public class SafeDoubleCheckSingleton{ private static SafeDoubleCheckSingleton singleton; //私育化构造方法 private SafeDoubleChecksingleton(){} } //双重锁没计 public static volatile SafeDoubleCheckSingleton getInstance(){ if (singleton == nu11){ //1.多线程并发创建对象时，会通过加锁保证只有一个线程能创建对象 synchronized (SafeDoubleCheckSingleton.class){ if (singleton == nu11){ //隐患，多线程环境下，由于重排序，该对象可能还未完成初始化就被其他线程读职 singleton = new SafeDoubleCheckSingleton(); } } } //2.对象创建完毕，执行getInstance()特不需要获职锁，直接返回创建对象 return singleton; } } 面试volatile 的时候，从这个点法上面区表述 volatile关键字保证可见性: 对一个被volatile关键字修改的变量 写操作的话，这个变量的最新值会立即刷新回到主内存中 读操作的话，总是能够读取到这个变量的最新值，也就是这个变量最后被修改的值 当某个线程收到通知，去读取volatile修饰的变量的值的时候，线程私有工作内存的数据失效，需要重新回到主内存中去读取最新的数据。 没有原子性 ：结合线程当操作复合运算++ i 的问题上，他们的步骤不是原子性，被其他线程修改 禁止重排序（有序性） ==凭啥就给我们volatile就会加内存屏障== 底层看volatile 修饰就添加 ACC_VOLATILE 程序就会按照这个加内存屏障 CAS概念compare and swap的缩写，中文翻译成比较并交换,实现并发算法时常用到的一种技术。 它包含三个操作数一一内存位置、预期原值及更新值。 执行CAS操作的时候，将内存位置的值与预期原值比较:如果相匹配，那么处理器会自动将该位置值更新为新值如果不匹配，处理器不做任何操作，多个线程同时执行CAS操作只有一个会成功。 CAS有3个操作数，位置内存值V，旧的预期值A，要修改的更新值B当且仅当旧的预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做或重来当它重来重试的这种行为成为----自旋! ! 认识CAS 要对底层的unsafa 核心类的了解Unsafe是CAS的核心类，由于Java方法无法直接访问底层系统，需要通过本地(native) 方法来访问，Unsafe相当于一个后门，基于该类可以直接操作特定内存的数据。Unsafe类存在于sun.misc包中，其内部方法操作可以像C的指针一样直接操作内存，因为Java中CAS操作的执行依赖于Unsafe类的方法。 注意Unsafe类中的所有方法都是native修饰的，也就是说Unsafe类中的法都直接调用操作系统底层资源执行相应作务 CAS并发原语体现在JAVA语言中就是sun.misc.Unsafe类中的核心方法。==调用UnSafe类中的CAS方法，JVM会帮我们实现出CAS汇编指令。这是一种完全依赖于硬件的功能，通过它实现了原子操作。再次强调，由于CAS是一种系统原语，原语属于操作系统用语范畴，是由若干条指令组成的，用于完成某个功能的一个过程，并且原语的执行必须是连续的，在执行过程中不允许被中断，也就是说CAS是一条CPU的原子指令，不会造成所谓的数据不一致问题==。 JUC 下的并发包的原子类volatile 解决多线程内存不可见问题对于一写多读，是可以解决变量同步问题，但是如果多写，同样无法解决线程安全问题。说明: 如果是 count+ +操作，使用如下类实现:AtomicInteger count = new AtomicInteger();count.addAndGet(1): 如果是JDK8，==推荐使用 LongAdder 对象，比 AtomicLong 性能更好==(减少乐观锁的重试次数)在LongAdder 和AtomicLong 它们在并发量低的时候，性能差不了多少。但在高并发的时候，LongAdder的基本思路就是分散热点，将value值分散到一个Ce数组中，不同线程会命中到数组的不同槽中，各个线程只对自己槽中的那个值进行CAS操作，这样热点就被分散了，冲突的概率就小很多。如果要获取真正的long值，只要将各个槽中的变量值累加返回。（内部一个base 变量，一个 cell[] 数组 ：base 是在低并发情况下，做CAS累加。如果一直自旋失败的话，那么就直接 创建Cell数组 来分担压力。每个cell的元素都存放不同不同线程的累加。最终把各个cell 数组元素的里面的值和base 相加。效率会一个base 处理数据快）说说AtomicStampedReference 和 AtomicMarkableReference 的区别 AtomicStampedReference 解决修改状态戳原 修改多次的原子更新 AtomicMarkableReference 解决一次的状态的修改的原子更新 TheadLocadl定义：ThreadLocal提供线程局部变量。这些变量与正常的变量不同，因为每一个线程在访问ThreadLocal实例的时候(通过其get或set方法)都有自己的、独立初始化的变量副本。ThreadLocal实例通常是类中的私有静态字段，使用它的目的是希望将状态(例如，用户ID或事务1D)与线程关联起来。作用实现每一个线程都有自己专属的本地变量副本(自己用自己的变量不麻烦别人，不和其他人共享，人人有份，人各一份), 主要解决了让每个线程绑定自己的值，通过使用get0和set方法，获取默认值或将其值更改为当前线程所存的副本的值从而避免了线程安全问题，比如我们之前讲解的8锁案例，资源类是使用同一部手机，多个线程抢夺同一部手机使用，假如人手一份是不是天下太平?? ==ThreadLocal考点==ThreadLocal中ThreadLocalMap的数据结构和关系?Thread 里面的包含一个ThreadLocal 引用 而ThreadLocal 里面有一个静态内部类TheadLocadlMap。 ThreadLocal为key 存放在value ThreadLocal的key是弱引用，这是为什么?弱引用相较于前面的强引用和软引用的的话，jvm 更会主动去回收ThreadLocalMap 的key 这样的不会到导致内存泄漏。 当function1方法执行完毕后，栈销毁强引用 tl 也就没有了。但此时线程的ThreadLocalMap里某个entry的key引用还指向这个对象若这个key引用是强引用，就会导致key指向的ThreadLocal对象及v指向的对象不能被gc回收，造成内存泄漏;若这个key引用是弱引用就大概率会减少内存泄漏的问题(还有一个key为nul的雷，第2个坑后面讲)。使用弱引用（合理），就可以使ThreadLocal对象在方法执行完毕后顺利被回收且Entry的key引用指向为null. ​ ThreadLocal内存泄露问题你知道吗? threadLocal中最后为什么要加remove方法?ThreadLocal自定义的变量用完需要remove 掉 ，减少线程的负担。特别线程池的复用导致线程内存泄漏 使用中 try -finally块回收。 使用弱引用的不能避免百分百，因为当ThreadLocal 的被回收之后，线程里面还有当key 为null 的value。而这些value一直ThraeadLocalmap强引用，这样的jvm 不能回收。如果在线程池复用的导内存泄漏。当使用 set 方法和get 以及 remove 方法 .都会先去判断key 是否为null ,如果是的就会把 key为null的value 给回收。避免内存泄漏和复用导致bug 手动remove 有必要的 对象内存布局之对象头对象头的构成运行时元数据 (Mark Word)哈希值 (HashCode)GC分代年龄锁状态标志线程持有的锁偏向线程ID偏向时间戳类型指针一一指向类元数据InstanceClass，确定该对象所属的类型实例数据 (Instance Data) :它是对急真正存储的有效信息，包括程序代码中定义的各种类型的字段(包括从父类继承下来的和本身拥有的字段) 锁的升级sychcornized锁:由对象头中的Mark Word根据锁标志位的不同而被复用及锁升级策略锁升级的背景java的线程是映射到操作系统原生线程之上的，如果要阳塞或唤醒一个线程就需要换作系统介入，需要在户态与核心态之间切换，这种切换会消料大量的系统资源，因为用户态与内核态都有各自专用的内存空间，专用的寄存器等，用户态切换至内核态需要传递给许多变量、参数给内核，内核也需要保护好用户态在切换时的一些寄存器值、变量等，以便内核态调用结束后切换回用户态继续工作。在Java早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁 (monitor)是依赖于底层的操作系统的Mutex Lock(系统互斥量)来实现的，挂起线程和恢复线程都需要转入内核态去完成，阳寒或唤醒一个Jaa线程需要换作系统切换CPU状态来完成，这种状态切换需要耗费处理器时间，如果同步代码块中内容过于简单，这种切换的时间可能比用户代码执行的时间还长”，时间成本相对较高，这也是为什么早期的synchronized效率低的原因Java 6之后，为了减少获得锁和释放锁所带来的性能消耗，引入了轻量级锁和偏向锁. Monitor可以理解为一种同步工具 ，也可理解为一种同步机制，常常被描述为一价Java对象。Java对象是天生的Monitor，每一个Java对象都有成为Monitor的潜质，因为在Jva的设计中，每一个Java对象自打娘胎里出来就带了一把看不见的锁，它叫做内部锁或者Monitor锁。 Monitor的本质是依赖于底层操作系统的Mutex Lock实现，操作系统实现线程之间的切换需要从用户态到内核态的转换，成本非常高。 锁的指向偏向锁: MarkWord存储的是偏向的线程ID;轻量锁: MarkWord存储的是指向线程栈中Lock Record的指针;重量锁: MarkWord存储的是指向堆中的monitor对象的指针;偏向锁的撤销当有另外线程逐步来竞争锁的时候，就不能再使用偏向锁了，要升级为轻量级锁竞争线程尝试CAS更新对象头失败，会等待到全局安全点《此时不会执行任何代码) 撤销偏向锁。偏向锁的撤销() 偏向锁使用一种等到竞争出现才释放锁的机制，只有当其他线程竞争锁时，持有偏向锁的原来线程才会被撤销撤销需要等待全局安全点(该时间点上没有字节码正在执行)，同时检查持有偏向锁的线程是否还在执行: 1第一个线程正在执行synchronized方法(处于同步块)，它还没有执行完，其它线程来抢夺，该偏向锁会被取消掉并出现锁升级此时轻量级锁由原持有偏向锁的线程持有，继续执行其同步代码，而正在竞争的线程会进入自旋等待获得该轻量级锁。 2第一个线程执行完成synchronized方法(退出同步块)，则将对象头设置成无锁状态并撤销偏向锁，重新偏向。 轻量锁轻量级锁的加锁JVM会为每个线程在当前线程的龙中创律用千存储锁记录的空间，官方成为Displaced Mark wrd。若一个线程获得锁时发现是量级锁，会把锁的MarkWord复制到自己的Displaced Mark Word里面。然后线程尝试用CAS将锁的MarkWord替换为指向锁记录的针。如果成功，当前线程获得锁，如果失败，表示Mark Word已经被替换成了其他线程的锁记录，说明在与其它线程竞争锁，当前程就尝试使用自旋来获取锁。自旋CAS:不断尝试去获取锁，能不升级就不往上捅，尽量不要阻塞轻量级锁的释放在释放锁时，当前线程会使用CAS操作将Displaced Mak Word的内容复制回锁的Mark Word里面。如果没有发生竞争，那么这个复制的操作会成功。如果有其他线程因为白旋多次导致轻量级锁升级成了重量级锁，那么CAS操作会失败，此时会释放锁并唤醒被阳的线程。重量级锁重量级锁原理指向互斥量 (重量级锁)的指针Java中synchronized的重量级锁，是基于进入和退出Monitor对象实现的。在编译时会将同步块的开始位置插入monitor enter指令，在结束位置插入monitor exit指令。当线程执行到monitor enter指令时，会尝试获取对象所对应的Monitor所有权，如果获取到了，即获取到了锁，会在Monitor的owner中存放当前线程的id，这样它将处于锁定状态，除非退出同步块，否则其他线程无法获取到这个Monitor。 锁升级的总结 ==在无锁状态下==，Mark Word中可以存储对象的identity hash code值。当对象的hashCode0)方法第一次被调用时，JVM会生成对应的dentity hash code值并将该值存储到Mark Word中。 ==对干偏白锁==，在线程获取偏向锁时，会用Thread ID和epoch值覆盖identity hash code所在的位置。如果一个对象的hashCode0)方法已经被调用过一次之后，这个对象不能被设置偏向锁。因为如果可以的化，那Mark Word中的identity hash code必然会被偏向线程id给覆盖，这就会造成同一个对象前后两次调用hashCode()方法得到的结果不一致。 ==升级为轻量级锁时==，JVM会在当前线程的栈顺中创律一个锁记录Lock Record)空间，用于存储锁对象的Mark Word拷贝，该据贝中可以包含identity hash code，所以轻量级锁可以和identity hash code共存，哈希码和GC年龄自然保存在此，释放锁后会将这些信息写回到对象头。 ==升级为重量级锁后==，Mark Word保存的重量级锁指针，代表重量级锁的bjectMonitor类里有字段记录非加锁状态下的Mark Word，锁释放后也会将信息写回到对象头。 AQS既然说到了排队等候机制，那么就一定会有某种队列形成，这样的队列是什么数据结构呢?如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中，这个队列就是AQS同步队列的抽象表现。它将要请求共享资源的线程及自身的等待状态封装成队列的结点对象(Node)，通过CAS、自旋以及LockSupport.park0)的方式，维护tate变量的状态，使并发达到同步的效果。 原理AQS使用一个volatie的int类型的成员变量来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作将每条要去抢占资源的线程封装成一个Node节点来实现锁的分配，通过CAS完成对State值的修改 AQS(AbstractQueuedSynchronizer) abstract static class Sync extends AbstractQueuedSynchronizer static final class NonfairSync extends Sync//非公平 static final class FairSync extends Sync //公平 //以非公平为例子跟踪 final void lock() { if (compareAndSetState(0, 1))//自旋修改状态 (Thread.currentThread());//把当前锁的持有则 else acquire(1); } =======================================第一部分===================================================================== /** 1尝试加锁 2加锁失败线程入队3线程入队后，线程进入阻塞 */ public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } //具体的子类实现NonfairSync protected final boolean tryAcquire(int acquires) { return nonfairTryAcquire(acquires); } /** *情况一 查看当前状态是否等于0，如果是就进入自旋尝试修改状态，并把当前线程 设置锁的拥有者。返回true, 当前线程的是否和锁的持有者一同一线程，是就更改锁的状态， */ final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; //更新锁的状态 if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; } return false; } ====================================================第二部分=================================================================== //加入对象等 private Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) {//不是第一创建队列，后续的节点进来直接就添加的双端队列的末尾 node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } enq(node); //入队，队列初始化 return node; } // 第一进入队列的 private Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // Must initialize if (compareAndSetHead(new Node())) //创建一个新的节点首尾相连 //自旋 tail = head; } else { node.prev = t; if (compareAndSetTail(t, node)) { // //自旋 t.next = node; //把刚进来的节点加入到队列 return t; } } } } //尝试获得锁，没有获得就阻塞等待唤醒 final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return interrupted; } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } //等待唤醒之前修改节点的等待状态 private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { int ws = pred.waitStatus; if (ws == Node.SIGNAL) return true; if (ws &gt; 0) { do { node.prev = pred = pred.prev; } while (pred.waitStatus &gt; 0); pred.next = node; } else { compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false; } //线程阻塞 中断机制 private final boolean parkAndCheckInterrupt() { LockSupport.park(this);//阻塞 return Thread.interrupted(); //中断标志获得锁的线程标志，协商。需要获得锁自行决定是否是否 } ====================================第三部分================================================================================ /*** 取消等待 */ private void cancelAcquire(Node node) { // Ignore if node doesn't exist if (node == null) return; node.thread = null; Node pred = node.prev; while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; //移除节点 Node predNext = pred.next; node.waitStatus = Node.CANCELLED; if (node == tail &amp;&amp; compareAndSetTail(node, pred)) {//尝试修改当前的的尾部 compareAndSetNext(pred, predNext, null); } else { int ws; if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; //修改 前面节点唤醒状态 pred.thread != null) { Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); } else { unparkSuccessor(node);//获得释放锁并改变status 的状态 } node.next = node; // help GC } } private void unparkSuccessor(Node node) { int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); //CAS 修改值 Node s = node.next; if (s == null || s.waitStatus &gt; 0) { s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; } if (s != null) LockSupport.unpark(s.thread);//解锁 } AQS定义两种资源共享方式：Exclusive（独占，只有一个线程能执行，如ReentrantLock）和Share（共享，多个线程可同时执行，如Semaphore/CountDownLatch）变量transient volatile Node headwaiter队列的头，刚开始时是一个啥都没有的结点，后面解锁一个去掉一个transient volatile Node tailwaiter队列的尾，第一次上锁没锁上的往后边插，每当一个倒霉蛋没有获得锁，就加入队列volatile int state不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可方法(未具体实现，只抛异常)tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回falsetryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回falsetryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false方法（已实现）acquire(int)public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } tryAcquire()尝试直接去获取资源，如果成功则直接返回（这里体现了非公平锁，每个线程获取锁时会尝试直接抢占加塞一次，而CLH队列中可能还有别的线程在等待）；addWaiter()将该线程加入等待队列的尾部，并标记为独占模式；acquireQueued()使线程阻塞在等待队列中获取资源，一直获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。(自旋)如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上。release(int)tryRelease(int)，tryRelease()都会成功的，因为这是独占模式，该线程来释放资源，那么它肯定已经拿到独占资源了，直接减掉相应量的资源即可(state-=arg)，也不需要考虑线程安全的问题。release是根据tryRelease()的返回值来判断线程是否已经完成资源释放。所以实现时，(state=0)，要返回true，否则返回false。unparkSuccessor(Node) 用LockSupport.unpark()方法唤醒队列中最欠扁的那个未放弃的线程。一般来说当前结点的后一个结点就是下一个，但是也可能后面的结点放弃了，这时从尾巴一直往前找，找到第一个能跑的就让他跑内部类Node变量volatile Node prev 前驱volatile Node next 后继volatile int waitStatus CANCELLED = 1：表示当前结点已取消调度。当timeout或被中断（响应中断的情况下），会触发变更为此状态，进入该状态后的结点将不会再变化。 默认值0 新节点入队时默认状态 SIGNAL = -1后继结点在等待当前结点唤醒，后记结点入队时，会将前驱结点更新未SIGNAL CONDITION = -2表示结点等待在Condition上，当其他线程调用了Condition的signal()方法后CONDITION状态的结点将从等待队列转移到同步队列中，等待获取同步锁 PROPAGATE = -3共享模式下，前继结点不仅会唤醒其后继结点，同时也可能会唤醒后继的后继结点。 Node nextWaitervolatile Thread thread+抢锁的线程 ConditionObject线程池==线程池用过吗？ThreadPoolExecutor谈谈你的理解==线程==优势== 线程池做的工作主要是控制运行的线程的数量.处理过程中将任务放入队列.然后在线程创建后启动这些任务如果线程数量超过了最大数量超出数量的线程排队等候,等其它线程执行完毕,再从队列中取出任务来执行。 它的主要特点为:线程复用;控制最大并发数:;管理线程 第一:降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗 第二:提高响应速度。当任务到达时,任务可以不需要的等到线程创建就能立即执行 第三:提高线程的可管理性。线程是稀缺资源如果无限制的创建,不仅会消耗系统资源还会降低系统的稳定性使用线程池可以进行统一的分配调优和监控 线程池如何使用Executors.newScheduledThreadPool()JDK1.8 Executors.newScheduledThreadPool(int)Executors.newFixedThreadPool(integer); 场景：执行长期的任务，性能好很多 主要的特点： public static ExecutorService newFixedThreadPool(int nThreads){ return new ThreadPoolExecutor(nThreads，nThreads,keepAliveTime:0L，TimeUnit.MILLISECONDSnew LinkedBlockingQueue&lt;Runnable&gt;()) } 创建一个定长线程池可控制线程最大并发数超出的线程会在队列中等待。 newFixedThreadPool创建的线程池 corePoolsize和 maximumPoolsize值是相等的它使用的 LinkedBlockingQueue xecutors.newSingleThreadExecutor(); 一个任务一个任务执行的场景 主要的特点： public static ExecutorService newSingleThreadExecutor(){ return new FinalizableDelegatedExecutorService(new ThreadPoolExecutor( corePoolSize: 1，maxmumPoolSize: 1keepAliveTime: 0LTimeUnit.MILLISECONDSnew LinkedBlockingQueue&lt;Runnable&gt;()) } 创建一个单线程化的线程池,它只会用唯一的工作线程来执行任务,保证所有任务按照指定顺序执行。 newSingleThreadExecutor将 corePoolsize和 maximumPoolsize都设置为1它使用的LinkedBlockingQueue Executors.newCachedThreadPool() 适用：执行很多短期异步的小程序或者负载比较轻的服务器 主要的特点： public static ExecutorService newCachedThreadPool(){ return new ThreadPoolExecutor( corePoolSize: 0,Integer.MAX VALUE,keepAliveTime: 60L，TimeUnit.SECONDSnew SynchronousQueue&lt;Runnable&gt;()); } 创建一个可缓存线程池,如果线程池长度超过处理需要,可灵活回收空闲线程,若无可回收,则新建线程。 newCachedThreadPool将 corePoolsize设置为0,将 maximumPoolsize设置为Integer.MAXVALUE使用的synchronousQueue,也就是说来了任务就创建线程运行当线程空闲超过60秒就销毁线程 ==线程池的几个重要参数介绍？==7大参数int corePoolSize 线程池中的常驻核心线程数 int maximumPoolSize 线程池能够容纳同时执行的最大线程数,此值必须大于等于1 long keepAliveTime在创建了线程池后,当有请求任务来之后,就会安排池中的线程去执行请求任务,近似理解为今日当值线程,当线程池中的线程数目达到 core PoolSize后就会把到达的任务放到缓有队列中 多余的空闲线程的存活时间。线程池数量超过 core poolsize时,当空闲时间达到 keepAliveTime值时 多余空闲线程会被销毁直到只剩下 core Poolsize个线程为止 TimeUnit unit keepAliveTime的单位 BlockingQueue workQueue 任务队列,被提交但尚未被执行的任务。 ThreadFactory threadFactory 生成线程池中工作线程的线程工厂,用于创建线程一般用默认的即可 RejectedExecutionHandler handler 拒绝策略,表示当队列满了并且工作线程大于等于线程池的最大线程数(maximumpoolsize)时拒绝请求执行的策略 ==考点线程池底层原理== 在创建了线程池后等待提交过来的任务请求 2当调用execute(方法添加一个请求任务时线程池会做如下判断 2.1如果正在运行的线程数量小于corePoolsize,那么马上创建线程运行这个任务 2.2如果正在运行的线程数量大于或等于corePoolsize那么将这个任务放入队列 2.3如果这时候队列满了且正在运行的线程数量还小于 maximumPoolsize那么还是要创建非核心线程立刻运行这个任务, 2.4如果队列满了且正在运行的线程数量大于或等于maximumPoolsize那么线程池会启动饱和拒绝策略来执行。 3当一个线程完成任务时,它会从队列中取下一个任务来执行 4当一个线程无事可做超过一定的时间( keepAliveTime)时线程池会==判断== 如果当前运行的线程数大于corePoolsize那么这个线程就被停掉所以线程池的所有任务完成后它最终会收缩到corePoolsize的大小 ==生产上你如何设置合理参数？==线程池的拒绝策略你谈谈什么是拒绝策略 等待队列也已经排满了,再也塞不下新任务了同时，线程池中的max线程也达到了,无法继续为新任务服务 这时候我们就需要==拒绝策略机制合理==的处理这个问题 JDK内置的拒绝策略 AbortPolicyl(默认):直接抛出 Rejected Execution Exception异常阻止系统正常运行。 CallerRunsPolicy:”调用者运行”一种调节机制,该策略傚不会抛弃任务,也不会抛出异常,而是将某些任务回退到调用者，从而降低新任务的流量 Discardoldest polic:抛弃队列中等待最久的任务,然后把当前任务加入队中尝试再次提交当前仼务。 DiscardPolicy:直接丢弃任务,不予任何处理也不抛出异常。如果允许任务丢失,这是最好的一种方案。 以上内置拒绝策略均实现了RejectedExecutionHandler接口 ==考点：你在工作中单一的/固定数的可变的三种创建线程池的方法,你用那个多?==一个都不用，我们生产上只能使用自定义的 Executors中JDK已经给你提供了，为什么不用? 来自阿里巴巴开发规范手册 [强制]**线程池不允许使用Executors 去创建，而是通过ThreadPoolExecutor 的方式，这样规避资源耗尽的风险。的处理方式让写的同学更加明确线程池的运行规则，*说明:Executors 返回的线程池对象的弊端如下:1)FixedThreadPool和 SingleThreadPool允许的请求队列长度为lntegerMAXVALUE，可能会堆积大量的请求，从而导致00M。2)CachedThreadPool 和 ScheduledThreadPoo1:允许的创建线程数量为Integer.MAXVALUE，可能会创建大量的线程，从而导致 OOM。 ==在工作中是如何使用线程池的,是否自定义过线程池使用== 按照Executors中的照猫画虎就好了，就是最大线程数不要用Integer.MaxValue ==合理配置线程池你是如何考虑的?== CPU密集型 CPU密集的意思是该任务需要大量的运算而没有阻塞CPU一直全速运行 CPU密集任务只有在真正的多核CPU上才可能得到加速(通过多线程)，而在单核CPU上(悲剧吧? = =!)无论你开几个模拟的多线程该任务都不可能得到加速因为CPU总的运算能力就那些。 CPU密集型任务配置尽可能少的线程数量一般公式:CPU核数+1个线程的线程池 IO密集型（1O蜜集型即该任务需要大量的IO 即大量的阻塞。） 由于10密集型任务线程并不是一直在执行任务则应配置尽可能多的线程如cPU核数”2 在单线程上运行IO密集型的任务会导致浪费大量的CPU运算能力浪费在等待所以在I0密集型任务中使用多线程可以大大的加速程序运行即使在单核CPU上这种加速主要就是利用了被浪费掉的阻塞时间 IO密集型时,大部分线程都阻塞故需要多配置线程数参考公式:CPU核数/1-阳塞系数阻塞系数在0.8~09之间比如8核CPU:8/(1-09)=80个线程数","categories":[{"name":"专刊篇","slug":"专刊篇","permalink":"https://mykkto.github.io/categories/%E4%B8%93%E5%88%8A%E7%AF%87/"}],"tags":[{"name":"juc","slug":"juc","permalink":"https://mykkto.github.io/tags/juc/"},{"name":"面试题","slug":"面试题","permalink":"https://mykkto.github.io/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"author":"杨江长"},{"title":"灰度发布方案","slug":"03-java分布式/08-网关/01-灰度发布方案","date":"2022-11-27T05:22:33.000Z","updated":"2022-12-12T13:20:39.169Z","comments":true,"path":"posts/f83c265d.html","link":"","permalink":"https://mykkto.github.io/posts/f83c265d.html","excerpt":"","text":"代码：https://gitee.com/TK_LIMR/springcloud2021To2021.git 目录：一、gateway 前置知识 什么是灰度发布 灰度发布落地方案 原理图 案例： 服务注册 构建网关 编写灰度用户 二、openresty Ⅰ、gateway 灰度一、前置知识1.nacos 服务注册与发现 2.本地负载均衡器算法 3.gateway 网关 4.ThreadLocal 1.什么是灰度发布？2.什么是灰度策略?3.灰度发布落地方案有哪些4.灰度发布架构设计原理 nginx+lua？5.如何基于GateWay+Nacos构建灰度环境6.GateWay负载均衡路由算法原理——改写7.如何重写本地负载均衡器，走灰度环境8.为何不基于nginx+lua实现？而使用GateWay9.代码落地实战：构建微服务灰度发布环境 二、什么是灰度发布灰度发布（又名金丝雀发布）是指在黑与白之间，能够平滑过渡的一种发布方式。在其上可以进行A/B testing，即让一部分用户继续用产品特性A，一部分用户开始用产品特性B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。 灰度期：灰度发布开始到结束期间的这一段时间，称为灰度期。 灰度发布能及早获得用户的意见反馈，完善产品功能，提升产品质量，让用户参与产品测试，加强与用户互动，降低产品升级所影响的用户范围。 整合服务注册中心 三、灰度发布落地方案1.nginx+lua+nacos 实现（需要懂lua脚本），通过nginx实现效率高【本bolg 有 lua 教程】 2.gateway+nacos+重写本地负载均衡器 （java实现）—java程序员推荐 性能没有直接 四、原理图五、案例Ⅱ、nginx 灰度一、二、三、四、五、参考文章 ↓docker-nacos单体（快速） https://www.jb51.net/article/248585.htm gatway: https://blog.csdn.net/u014001523/article/details/125400266 https://blog.csdn.net/qq_43692950/article/details/125226460?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-125226460-blog-125400266.pc_relevant_3mothn_strategy_recovery&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-125226460-blog-125400266.pc_relevant_3mothn_strategy_recovery&amp;utm_relevant_index=2 openresty:https://blog.csdn.net/u014001523/article/details/125400318 openfeign重写：https://www.itmuch.com/spring-cloud-sum/hystrix-threadlocal/","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"gateway","slug":"gateway","permalink":"https://mykkto.github.io/tags/gateway/"},{"name":"灰度发布","slug":"灰度发布","permalink":"https://mykkto.github.io/tags/%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83/"},{"name":"nginx","slug":"nginx","permalink":"https://mykkto.github.io/tags/nginx/"}],"author":"mykk"},{"title":"面试题-01","slug":"05-面试题/02-大厂面试题/面试题_01","date":"2022-10-22T08:16:56.000Z","updated":"2023-01-02T12:57:46.754Z","comments":true,"path":"posts/726c3129.html","link":"","permalink":"https://mykkto.github.io/posts/726c3129.html","excerpt":"","text":"目录： Spring-tx 事务失效场景 检查异常 错误的 try-catch 切面顺序 非public场景 父子容器 本类方法调用 原子性（锁失效） 数据库索引失效场景 源码：https://gitee.com/TK_LIMR/springcloud2021To2021 一、Spring-tx 事务失效场景1、检查异常1、失效场景这边构造一个不存在的文件流，造成异常模拟 数据库情况 很明显事务失效了 2、解决方案加上注解，实现有感知回滚 2、错误的 try-catch1、失效场景自己try 后，外部调用的方法，无感知，则提交了没有回滚 2、解决方案方法一： 当用 try-catch 出现异常的时候，显示的往上抛，让上层调用者感知 方法二： 调用事务方法，回滚功能，可以显示的提交或者回滚，回滚效果和向上抛异常时一样的 3、切面顺序1、失效场景基于检查异常+try-catch的处理后，使用了后置通知发现依然回滚失败 原因 主要因为先进入事务，然后进入后置(有异常)，在进入目标方法，此时后置并没有往事务上抛，所以无感知 2、解决方案（不推荐）设置后置的优先级高于事务，这样事务在后面运行，既可以感知到异常 方法一 在切面 catch 时候采用 检查异常 或者 try-catch 上面两种方法在 切面方法改动 方法二 设置优先级高于事务 4、非public场景1、失效场景方法设置为默认 非public ，事务失效 2、解决方案（不推荐）修改默认配置，默认true 只对 public 方法生效 5、父子容器1、失效场景简单来说就是放在 controller 上调用 service，也是开发中常见的场景 原因：子容器扫描范围过大，把未加事务配置的 service 扫描进来 2、解决方案在springboot遇不到，因为只有一个容器。通常出现在传统项目（spring+MVC整合的时候），会遇到扫描父子容器。Spring扫spring,MVC扫mvc自己的包，就不会出现这个问题，而不是直接扫整个上层包 6、本类方法调用1、失效场景本类两个方法相互调用 原因 本类调用，不经过代理，因此无法增强，导致两个事务公用一个 2、解决方案方法一 自己注入自己 方法二 从 Aop中代理调用 7、原子性（锁失效）1、失效场景Jmeter 模拟100个线程每秒 2、解决方案用 synchronize 能解决？？ 答案：不能 @Transactional 没有保证原子的原因： 事务的原子性仅覆盖 inset,update,delete ；select 语句不覆盖，select 方法不阻塞 @Transactional 导致 synchronize 失效的原因： synchronize 仅保证目标方法的原子性，环绕方法的还有 commit (事务提交)等操作，他们并未处于 sync 同步块中 方案1：（不推荐） 修改 synchronize 位置范围扩大至代理方法调用(上层并发接口位置) 方案2：（推荐） 修改 SQL 语句 把 select 替换成 select …for update 二、数据库索引失效场景1、like 以%开头，索引无效；当like前缀没有%，后缀有%时，索引有效 2、or语句前后没有同时使用索引 当or左右查询字段只有一个是索引，该索引失效，只有当or左右查询字段均为索引时，才会生效 3、组合索引，不是使用第一列索引，索引失效 4、如果列类型是字符串，那一定要在条件中将数据使用引号引用起来，否则不使用索引 数据类型出现隐式转化。如varchar不加单引号的话可能会自动转换为int型，使索引无效，产生全表扫描。 5、在索引字段上使用not，&lt;&gt;，!= 不等于操作符是永远不会用到索引的，因此对它的处理只会产生全表扫描。 优化方法： key&lt;&gt;0 改为 key&gt;0 or key&lt;0。 6、对索引字段进行计算操作 或者 字段上使用函数。 7、当全表扫描速度比索引速度快时，mysql会使用全表扫描，此时索引失效 三、1、2、3、4、5、参考 ↓springboot 配置 jdbctemplate :https://blog.csdn.net/u014553029/article/details/101130291 事务失效完整场景：https://www.csdn.net/tags/MtTagg3sMjU0NTEtYmxvZwO0O0OO0O0O.html 索引失效：https://m.php.cn/article/487049.html","categories":[{"name":"面试题","slug":"面试题","permalink":"https://mykkto.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"面试","slug":"面试","permalink":"https://mykkto.github.io/tags/%E9%9D%A2%E8%AF%95/"},{"name":"事务","slug":"事务","permalink":"https://mykkto.github.io/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"spring-tx","slug":"spring-tx","permalink":"https://mykkto.github.io/tags/spring-tx/"}],"author":"mykk"},{"title":"RabbitMQ-入门+实战篇","slug":"03-java分布式/06-消息队列/01-RabbitMQ","date":"2022-10-08T15:21:32.000Z","updated":"2022-11-12T15:07:08.042Z","comments":true,"path":"posts/faf1dfc8.html","link":"","permalink":"https://mykkto.github.io/posts/faf1dfc8.html","excerpt":"","text":"源代码位置https://gitee.com/TK_LIMR/springcloud2021To2021 目录： 入门 概述 快速入门案例 工作模式案例 整合Spring 整合SpringBoot 实战 高级特性 消息可靠性投递（生产者 -&gt; MQ） Consumer ACK (MQ -&gt; 消费者) 消费端限流 TTL 过期时间 死信队列 ★ 延迟队列 X 日志与监控（了解） X 消息可靠性分析与追踪（慎用） X 管理 应用问题 消息可靠性保障 消息补偿机制 消息幂等性处理 乐观锁解决方案 高可用集群搭建 Ⅰ、入门篇一、概述1、MQ概述是什么：MQ全称 Message Queue（消息队列），是在消息的传输过程中保存消息的容器。多用于分布式系统之间进行通信 小结： MQ，消息队列，存储消息的中间件 分布式系统通信两种方式：直接远程调用 和 借助第三方 完成间接通信 发送方称为生产者，接收方称为消费者 2、MQ优势和劣势1、优势 应用解耦 异步提速 削峰填谷 1-1、应用解耦 传统方式，订单系统要发送指定系统，或者打断指定系统的发送需要修改订单系统代码 引入 mq，发送给mq即可，选择或者打断指定系统发送只需要控制 topic规则即可，使得应用解耦，提升容错性和可维护性 1-2、异步提速 一个下单操作耗时：20 + 300 + 300 + 300 = 920ms ，用户点击完下单按钮后，需要等待920ms才能得到下单响应，太慢！ 用户点击完下单按钮后，只需等待25ms就能得到下单响应 (20 + 5 = 25ms)。 提升用户体验和系统吞吐量（单位时间内处理请求的数目） 1-3、削峰填谷 传统模式当大量并发来临，可能将系统冲垮 使用了 MQ 之后，限制消费消息的速度为1000，这样一来，高峰期产生的数据势必会被积压在 MQ 中，高峰 就被“削”掉了，但是因为消息积压，在高峰期过后的一段时间内，消费消息的速度还是会维持在1000，直到消费完积压的消息，这就叫做“填谷”。 1-4、小结 应用解耦：提高系统容错性和可维护性 异步提速：提升用户体验和系统吞吐量 削峰填谷：提高系统稳定性 2、劣势 系统可用性降低 系统复杂度变高 一致性问题 2-1、系统可用性降低系统引入的外部依赖越多，系统稳定性越差，需要保证可用的越多；一旦MQ宕机，就会对业务影响（如何保证高可用？？ 集群） 2-2、系统复杂度提高传统的系统是同步调用，现在通过MQ异步调用（如何保证消息没有重复消费，怎么处理消息丢失问题，以及消息的有序性） 2-3、一致性问题A系统处理完业务，通过MQ给 B,C,D 三个系统发送消息，如果B,C成功、D失败，如何保证消息数据的一致性？ 2-4、小结既然 MQ 有优势也有劣势，那么使用 MQ 需要满足什么条件呢？ 生产者不需要从消费者处获取反馈；上层不需要等待下层回调处理，才能让异步成为可能 容许短暂的不一致性 在解耦、提速、削峰方面的收益，大于管理MQ的成本 3、常见MQ对比 4、RabbitMQ简介1、架构图 2、组件说明（↑） Broker：接收和分发消息的应用，RabbitMQ Server就是 Message Broker Virtual host：出于多租户和安全因素设计的，把 AMQP 的基本组件划分到一个虚拟的分组中，类似于网 络中的 namespace 概念。当多个不同的用户使用同一个 RabbitMQ server 提供的服务时，可以划分出多 个vhost，每个用户在自己的 vhost 创建 exchange／queue 等 Connection：publisher／consumer 和 broker 之间的 TCP 连接 Channel：如果每一次访问 RabbitMQ 都建立一个 Connection，在消息量大的时候建立 TCP Connection 的开销将是巨大的，效率也较低。Channel 是在 connection 内部建立的逻辑连接，如果应用程序支持多线 程，通常每个thread创建单独的 channel 进行通讯，AMQP method 包含了channel id 帮助客户端和 message broker 识别 channel，所以 channel 之间是完全隔离的。Channel 作为轻量级的 Connection 极大减少了操作系统建立 TCP connection 的开销 Exchange：message 到达 broker 的第一站，根据分发规则，匹配查询表中的 routing key，分发消息到 queue 中去。常用的类型有：direct (point-to-point), topic (publish-subscribe) and fanout (multicast) Queue：消息最终被送到这里等待 consumer 取走 Binding：exchange 和 queue 之间的虚拟连接，binding 中可以包含 routing key。Binding 信息被保存到 exchange 中的查询表中，用于 message 的分发依据 3、RabbitMQ 6中工作模式简单模式、work queues、Publish/Subscribe 发布与订阅模式、Routing 路由模式、Topics 主题模式、RPC 远程调用模式（远程调用，不太算 MQ；不作介绍） 4、JMS JMS 即 Java 平台中关于面向消息中间件的API JMS 是 JavaEE 规范中的一种，类比JDBC 很多消息中间件都实现了JMS规范，例如：ActiveMQ。RabbitMQ 官方没有提供 JMS 的实现包，但是开源社区有 5、RabbitMQ小结 RabbitMQ 是基于 AMQP 协议使用 Erlang 语言开发的一款消息队列产品 RabbitMQ提供了6种工作模式，我们学习5种 AMQP 是协议，类比HTTP JMS 是 API 规范接口，类比 JDBC 二、快速入门1、步骤使用简单模式完成消息传递： ① 创建工程（生成者、消费者） ② 分别添加依赖 ③ 编写生产者发送消息 ④ 编写消费者接收消息 2、小结 在上图的模型中，有以下概念： P：生产者，也就是要发送消息的程序 C：消费者：消息的接收者，会一直等待消息到来（线程一直在监听） queue：消息队列，图中红色部分。类似一个邮箱，可以缓存消息；生产者向其中投递消息，消费者从其中取出消息 三、工作模式1、Work queues 工作队列模式 1、说明 Work Queues：与入门程序的简单模式相比，多了一个或一些消费端，多个消费端共同消费同一个队列中的消息 应用场景：对于任务过重或任务较多情况使用工作队列可以提高任务处理的速度。 2、代码 3、小结 在一个队列中如果有多个消费者，那么消费者之间对于同一个消息的关系是竞争的关系。 Work Queues 对于任务过重或任务较多情况使用工作队列可以提高任务处理的速度。例如：短信服务部署多个，只需要有一个节点成功发送即可。 2、Pub/Sub 订阅模式 在订阅模型中，多了一个 Exchange 角色，而且过程略有变化： P：生产者，也就是要发送消息的程序，但是不再发送到队列中，而是发给X（交换机） C：消费者，消息的接收者，会一直等待消息到来 Queue：消息队列，接收消息、缓存消息 X：Exchange：交换机，一方面，接收生产者发送的消息。另一方面，知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于Exchange的类型。Exchange有常见以下3种类型： Fanout：广播，将消息交给所有绑定到交换机的队列 Direct：定向，把消息交给符合指定routing key 的队列 Topic：通配符，把消息交给符合routing pattern（路由模式）的队列 Exchange（交换机）只负责转发消息，不具备存储消息的能力，因此如果没有任何队列与 Exchange 绑定，或者没有符合路由规则的队列，那么消息会丢失 小结： 交换机需要与队列进行绑定，绑定之后；一个消息可以被多个消费者都收到 发布订阅模式与工作队列模式的区别： 工作队列模式不用定义交换机，而发布/订阅模式需要定义交换机 发布/订阅模式的生产方是面向交换机发送消息，工作队列模式的生产方是面向队列发送消息(底层使用默认交换机) 发布/订阅模式需要设置队列和交换机的绑定，工作队列模式不需要设置，实际上工作队列模式会将队列绑定到默认的交换机 3、Routing 路由模式1、模式说明 队列与交换机的绑定，不能是任意绑定了，而是要指定一个 RoutingKey（路由key） 消息的发送方在向 Exchange 发送消息给 Consumer 时，也必须指定消息的 RoutingKey Exchange 不再把消息交给每一个绑定的队列，而是根据消息的 Routing Key 进行判断，只有队列的 Routingkey 与消息的 Routing key 完全一致，才会接收到消息 2、图解 P：生产者，向 Exchange 发送消息，发送消息时，会指定一个routing key X：Exchange（交换机），接收生产者的消息，然后把消息递交给与 routing key 完全匹配的队列 C1：消费者，其所在队列指定了需要 routing key 为 error 的消息 C2：消费者，其所在队列指定了需要 routing key 为 info、error、warning 的消息 3、代码 4、小结Routing 模式要求队列在绑定交换机时要指定 routing key，消息会转发到符合 routing key 的队列。 4、Topics 通配符模式1、说明 Q1 Queue：绑定的是 usa.# ，因此凡是以 usa. 开头的 routing key 都会被匹配到 Q2 Queue：绑定的是 #.news ，因此凡是以 .news 结尾的 routing key 都会被匹配 2、代码 3、小结Topic 主题模式可以实现 Pub/Sub 发布与订阅模式和 Routing 路由模式的功能，只是 Topic 在配置routing key 的时候可以使用通配符，显得更加灵活。 5、工作模式总结 简单模式 HelloWorld ：一个生产者、一个消费者，不需要设置交换机（使用默认的交换机）。 工作队列模式 Work Queue ：一个生产者、多个消费者（竞争关系），不需要设置交换机（使用默认的交换机）。 发布订阅模式 Publish/subscribe ：需要设置类型为 fanout 的交换机，并且交换机和队列进行绑定，当发送消息到交换机后，交换机会将消息发送到绑定的队列。 路由模式 Routing ：需要设置类型为 direct 的交换机，交换机和队列进行绑定，并且指定 routing key，当发送消息到交换机后，交换机会根据 routing key 将消息发送到对应的队列。 通配符模式 Topic ：需要设置类型为 topic 的交换机，交换机和队列进行绑定，并且指定通配符方式的 routing key，当发送消息到交换机后，交换机会根据 routing key 将消息发送到对应的队列。 四、Spring 整合 RabbitMQ1、代码1-1、生产者① 创建生产者工程 ② 添加依赖 ③ 配置整合 ④ 编写代码发送消息 1-2、消费者① 创建生产者工程 ② 添加依赖 ③ 配置整合 ④ 编写消息监听器 2、小结 使用 Spring 整合 RabbitMQ 将组件全部使用配置方式实现，简化编码 Spring 提供 RabbitTemplate 简化发送消息 API 使用监听机制简化消费者编码 五、SpringBoot 整合 RabbitMQ1、代码 Ⅱ、实战篇一、高级特性1、消息可靠性投递（生产者 -&gt; MQ） 1、概述在使用 RabbitMQ 的时候，作为消息发送方希望杜绝任何消息丢失或者投递失败场景。RabbitMQ 为我们提供了两种方式用来控制消息的投递可靠性模式。 确认模式 回退模式 rabbitmq 整个消息投递的路径为： producer —&gt; rabbitmq broker —&gt; exchange —&gt; queue —&gt; consumer 消息从 producer 到 exchange 则会返回一个 confirmCallback 的回调 消息从 exchange 到 queue 投递失败则返回一个 returnCallback 回调 我们可以利用这两个 callback 回调 控制消息的可靠性投递 2、代码 3、小结 设置ConnectionFactory的publisher-confirms=”true” 开启 确认模式 使用rabbitTemplate.setConfirmCallback设置回调函数。当消息发送到exchange后回 调confirm方法。在方法中判断ack，如果为true，则发送成功，如果为false，则发 送失败，需要处理 设置ConnectionFactory的publisher-returns=”true” 开启 退回模式 使用rabbitTemplate.setReturnCallback设置退回函数，当消息从exchange路由到 queue失败后，如果设置了rabbitTemplate.setMandatory(true)参数，则会将消息退 回给producer。并执行回调函数returnedMessage 在RabbitMQ中也提供了事务机制，但是性能较差，此处不做讲解。 使用channel下列方法，完成事务控制： txSelect(), 用于将当前channel设置成transaction模式 txCommit()，用于提交事务 txRollback(),用于回滚事务 2、Consumer AckMQ -&gt; 消费者 1、概述ack指Acknowledge，确认。 表示消费端收到消息后的确认方式。 有三种确认方式： • 自动确认：acknowledge=”none” • 手动确认：acknowledge=”manual” • 根据异常情况确认：acknowledge=”auto”，（这种方式使用麻烦，不作讲解） 其中自动确认是指，当消息一旦被Consumer接收到，则自动确认收到，并将相应 message RabbitMQ 的消息缓存中移除。但是在实际业务处理中，很可能消息接收到，业务处理出现异常，那么该消息就会丢失。如果设置了手动确认方式，则需要在业务处理成功后，调用channel.basicAck()，手动签收，如果出现异常，则调用channel.basicNack()方法，让其自动重新发送消息。 2、代码 3、小结 在rabbit:listener-container标签中设置acknowledge属性，设置ack方式 none：自动确认， manual：手动确认 如果在消费端没有出现异常，则调用channel.basicAck(deliveryTag,false);方法确认签收消息 如果出现异常，则在catch中调用 basicNack或 basicReject，拒绝消息，让MQ重新发送消息。 3、消息可靠性总结 持久化 exchange要持久化 queue要持久化 message要持久化 生产方确认Confirm 消费方确认Ack Broker高可用 4、消费端限流1、概念 2、代码 3、小结 在rabbit:listener-container 中配置 prefetch属性设置消费端一次拉取多少消息 消费端的确认模式一定为手动确认。acknowledge=”manual” 5、TTL 过期时间1、概述 TTL 全称 Time To Live（存活时间/过期时间） 当消息到达存活时间后，还没有被消费，会被自动清除 RabbitMQ可以对消息设置过期时间，也可以对整个队列（Queue）设置过期时间 2、代码 3、小结 设置队列过期时间使用参数：x-message-ttl，单位：ms(毫秒)，会对整个队列消息统一过期 设置消息过期时间使用参数：expiration。单位：ms(毫秒)，当该消息在队列头部时（消费时），会单独判断这一消息是否过期 如果两者都进行了设置，以时间短的为准 6、死信队列1、概述死信队列其实说的就是私信交换机 死信队列，英文缩写：DLX 。Dead Letter Exchange（死信交换机），当消息成为Dead message后，可以被重新发送到另一个交换机，这个交换机就是DLX 消息成为死信的三种情况： 队列消息长度到达限制； （能放10条，放了11条，1条超过被成为死信），可以设置队列存放的数量 消费者拒接消费消息，basicNack/basicReject；并且不把消息重新放入原目标队列,requeue=false； 原队列存在消息过期设置，消息到达超时时间未被消费； 队列绑定死信交换机 给队列设置参数： x-dead-letter-exchange 和 x-dead-letter-routing-key 2、代码 3、小结 死信交换机和死信队列和普通的没有区别 当消息成为死信后，如果该队列绑定了死信交换机，则消息会被死信交换机重新路由到死信队列 消息成为死信的三种情况 队列消息长度到达限制 消费者拒接消费消息，并且不重回队列 原队列存在消息过期设置，消息到达超时时间未被消费 7、延迟队列1、概念延迟队列，即消息进入队列后不会立即被消费，只有到达指定时间后，才会被消费 需求： 下单后，30分钟未支付，取消订单，回滚库存 新用户注册成功7天后，发送短信问候 实现方式： 定时器 延迟队列 很可惜，在RabbitMQ中并未提供延迟队列功能。 但是可以使用：TTL+死信队列 组合实现延迟队列的效果 2、代码 3、小结 延迟队列 指消息进入队列后，可以被延迟一定时间，再进行消费 RabbitMQ没有提供延迟队列功能，但是可以使用 ： TTL + DLX 来实现延迟队列效果 二、应用问题1、参考文献 ↓windown安装 rabbitmq ：https://blog.csdn.net/qq_25919879/article/details/113055350 docker 安装 rabbitmq：https://www.jb51.net/article/233585.htm docker 安装后 界面端功能缺失问题：https://blog.csdn.net/qq_45369827/article/details/115921401 springboot-rabbitmq 确认模式弃用配置：https://blog.csdn.net/z69183787/article/details/109371628 单元测试，发布确认回调 ack 总是 false：https://blog.csdn.net/dh554112075/article/details/90137869 spring-boot 死信队列：https://blog.csdn.net/weixin_52062043/article/details/127077941","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://mykkto.github.io/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"amqp","slug":"amqp","permalink":"https://mykkto.github.io/tags/amqp/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://mykkto.github.io/tags/rabbitmq/"}],"author":"mykk"},{"title":"Netty-实用篇","slug":"07-内力/02-网络框架/01-Netty实用篇","date":"2022-08-21T05:22:33.000Z","updated":"2022-11-12T15:07:08.027Z","comments":true,"path":"posts/bb8f1edf.html","link":"","permalink":"https://mykkto.github.io/posts/bb8f1edf.html","excerpt":"","text":"源代码位置https://gitee.com/TK_LIMR/springcloud2021To2021 目录： 网络编程 三次握手 基础后面会在其他文章更新 nio 三大组件 ByteBuffer详解 文件编程 网络编程 nio vs bio vs aio netty 入门 进阶 优化 实战 源码 Ⅰ、NIO一、三大组件1、Channel &amp; Bufferchannel 有一点类似于 stream，它就是读写数据的双向通道，可以从 channel 将数据读入 buffer，也可以将 buffer 的数据写入 channel，而之前的 stream 要么是输入，要么是输出，channel 比 stream 更为底层 常见的 Channel 有 FileChannel DatagramChannel SocketChannel ServerSocketChannel buffer 则用来缓冲读写数据，常见的 buffer 有 ByteBuffer MappedByteBuffer DirectByteBuffer HeapByteBuffer ShortBuffer IntBuffer LongBuffer FloatBuffer DoubleBuffer CharBuffer 2、Selectorselector 单从字面意思不好理解，需要结合服务器的设计演化来理解它的用途 2-1、多线程版设计 ⚠️ 多线程版缺点 内存占用高 线程上下文切换成本高 只适合连接数少的场景 2-2、线程池版设计 ⚠️ 线程池版缺点 阻塞模式下，线程仅能处理一个 socket 连接 仅适合短连接场景 2-3、selector 版设计selector 的作用就是配合一个线程来管理多个 channel，获取这些 channel 上发生的事件，这些 channel 工作在非阻塞模式下，不会让线程吊死在一个 channel 上。适合连接数特别多，但流量低的场景（low traffic） 调用 selector 的 select() 会阻塞直到 channel 发生了读写就绪事件，这些事件发生，select 方法就会返回这些事件交给 thread 来处理 二、ByteBuffer详解有一普通文本文件 data.txt，内容为 1234567890abcd 使用 FileChannel 来读取文件内容 package com.kk.netty.nio; import lombok.extern.slf4j.Slf4j; import java.io.IOException; import java.io.RandomAccessFile; import java.nio.ByteBuffer; import java.nio.channels.FileChannel; @Slf4j public class ChannelDemo1 { // public static void main(String[] args) { /** * try () 1.7的语法糖，方便关闭 RandomAccessFile 资源 * FileChannel * 1、输入输出流，RandomAccessFile */ try (RandomAccessFile file = new RandomAccessFile (\"boot_netty/helloword/data.txt\", \"rw\")) { FileChannel channel = file.getChannel ( ); ByteBuffer buffer = ByteBuffer.allocate (10); do { // 准备缓冲区，向 buffer 写入 int len = channel.read (buffer); log.debug (\"读到字节数：{}\", len); if (len == -1) {// 没有内容了 break; } // 切换 buffer 读模式 // 翻转缓冲区，为写做准备 buffer.flip ( ); while (buffer.hasRemaining ( )) {// 是否还有剩余未读数据 byte b = buffer.get ( ); log.debug (\"{}\", (char) b); } // 切换 buffer 写模式 // 清楚缓冲区，为读做准备 buffer.clear ( ); } while (true); } catch (IOException e) { e.printStackTrace ( ); } } } 输出 19:02:52.712 [main] DEBUG com.kk.netty.nio.ChannelDemo1 - 读到字节数：1019:02:52.717 [main] DEBUG com.kk.netty.nio.ChannelDemo1 - 119:02:52.717 [main] DEBUG com.kk.netty.nio.ChannelDemo1 - 219:02:52.717 [main] DEBUG com.kk.netty.nio.ChannelDemo1 - 319:02:52.718 [main] DEBUG com.kk.netty.nio.ChannelDemo1 - 419:02:52.718 [main] DEBUG com.kk.netty.nio.ChannelDemo1 - 519:02:52.718 [main] DEBUG com.kk.netty.nio.ChannelDemo1 - 619:02:52.718 [main] DEBUG com.kk.netty.nio.ChannelDemo1 - 719:02:52.718 [main] DEBUG com.kk.netty.nio.ChannelDemo1 - 819:02:52.718 [main] DEBUG com.kk.netty.nio.ChannelDemo1 - 919:02:52.718 [main] DEBUG com.kk.netty.nio.ChannelDemo1 - 019:02:52.718 [main] DEBUG com.kk.netty.nio.ChannelDemo1 - 读到字节数：619:02:52.718 [main] DEBUG com.kk.netty.nio.ChannelDemo1 - a19:02:52.718 [main] DEBUG com.kk.netty.nio.ChannelDemo1 - b19:02:52.718 [main] DEBUG com.kk.netty.nio.ChannelDemo1 - c19:02:52.718 [main] DEBUG com.kk.netty.nio.ChannelDemo1 - d19:02:52.718 [main] DEBUG com.kk.netty.nio.ChannelDemo1 -19:02:52.718 [main] DEBUG com.kk.netty.nio.ChannelDemo1 - 19:02:52.718 [main] DEBUG com.kk.netty.nio.ChannelDemo1 - 读到字节数：-1 1、ByteBuffer 步骤 向 buffer 写入数据，例如调用 channel.read(buffer) 调用 flip() 切换至读模式 从 buffer 读取数据，例如调用 buffer.get() 调用 clear() 或 compact() 切换至写模式 重复 1~4 步骤 2、ByteBuffer 结构ByteBuffer 有以下重要属性 capacity 容量 position 写入位置，移动的游标 limit 写入或者读取限制（根据读写模式切换决定） 1、开始 2、写模式下，position 是写入位置，limit 等于容量，下图表示写入了 4 个字节后的状态 3、flip 动作发生后，position 切换为读取位置，limit 切换为读取限制 4、读取 4 个字节后，状态 5、clear 动作发生后，状态 6、compact 方法，是把未读完的部分向前压缩，然后切换至写模式 💡 调试工具类package com.kk.netty.nio; import io.netty.util.internal.StringUtil; import java.nio.ByteBuffer; import static io.netty.util.internal.MathUtil.isOutOfBounds; import static io.netty.util.internal.StringUtil.NEWLINE; public class ByteBufferUtil { private static final char[] BYTE2CHAR = new char[256]; private static final char[] HEXDUMP_TABLE = new char[256 * 4]; private static final String[] HEXPADDING = new String[16]; private static final String[] HEXDUMP_ROWPREFIXES = new String[65536 &gt;&gt;&gt; 4]; private static final String[] BYTE2HEX = new String[256]; private static final String[] BYTEPADDING = new String[16]; static { final char[] DIGITS = \"0123456789abcdef\".toCharArray ( ); for (int i = 0; i &lt; 256; i++) { HEXDUMP_TABLE[i &lt;&lt; 1] = DIGITS[i &gt;&gt;&gt; 4 &amp; 0x0F]; HEXDUMP_TABLE[(i &lt;&lt; 1) + 1] = DIGITS[i &amp; 0x0F]; } int i; // Generate the lookup table for hex dump paddings for (i = 0; i &lt; HEXPADDING.length; i++) { int padding = HEXPADDING.length - i; StringBuilder buf = new StringBuilder (padding * 3); for (int j = 0; j &lt; padding; j++) { buf.append (\" \"); } HEXPADDING[i] = buf.toString ( ); } // Generate the lookup table for the start-offset header in each row (up to 64KiB). for (i = 0; i &lt; HEXDUMP_ROWPREFIXES.length; i++) { StringBuilder buf = new StringBuilder (12); buf.append (NEWLINE); buf.append (Long.toHexString (i &lt;&lt; 4 &amp; 0xFFFFFFFFL | 0x100000000L)); buf.setCharAt (buf.length ( ) - 9, '|'); buf.append ('|'); HEXDUMP_ROWPREFIXES[i] = buf.toString ( ); } // Generate the lookup table for byte-to-hex-dump conversion for (i = 0; i &lt; BYTE2HEX.length; i++) { BYTE2HEX[i] = ' ' + StringUtil.byteToHexStringPadded (i); } // Generate the lookup table for byte dump paddings for (i = 0; i &lt; BYTEPADDING.length; i++) { int padding = BYTEPADDING.length - i; StringBuilder buf = new StringBuilder (padding); for (int j = 0; j &lt; padding; j++) { buf.append (' '); } BYTEPADDING[i] = buf.toString ( ); } // Generate the lookup table for byte-to-char conversion for (i = 0; i &lt; BYTE2CHAR.length; i++) { if (i &lt;= 0x1f || i &gt;= 0x7f) { BYTE2CHAR[i] = '.'; } else { BYTE2CHAR[i] = (char) i; } } } /** * 打印所有内容 * * @param buffer */ public static void debugAll(ByteBuffer buffer) { int oldlimit = buffer.limit ( ); buffer.limit (buffer.capacity ( )); StringBuilder origin = new StringBuilder (256); appendPrettyHexDump (origin, buffer, 0, buffer.capacity ( )); System.out.println (\"+--------+-------------------- all ------------------------+----------------+\"); System.out.printf (\"position: [%d], limit: [%d]\\n\", buffer.position ( ), oldlimit); System.out.println (origin); buffer.limit (oldlimit); } /** * 打印可读取内容 * * @param buffer */ public static void debugRead(ByteBuffer buffer) { StringBuilder builder = new StringBuilder (256); appendPrettyHexDump (builder, buffer, buffer.position ( ), buffer.limit ( ) - buffer.position ( )); System.out.println (\"+--------+-------------------- read -----------------------+----------------+\"); System.out.printf (\"position: [%d], limit: [%d]\\n\", buffer.position ( ), buffer.limit ( )); System.out.println (builder); } private static void appendPrettyHexDump(StringBuilder dump, ByteBuffer buf, int offset, int length) { if (isOutOfBounds (offset, length, buf.capacity ( ))) { throw new IndexOutOfBoundsException ( \"expected: \" + \"0 &lt;= offset(\" + offset + \") &lt;= offset + length(\" + length + \") &lt;= \" + \"buf.capacity(\" + buf.capacity ( ) + ')'); } if (length == 0) { return; } dump.append ( \" +-------------------------------------------------+\" + NEWLINE + \" | 0 1 2 3 4 5 6 7 8 9 a b c d e f |\" + NEWLINE + \"+--------+-------------------------------------------------+----------------+\"); final int startIndex = offset; final int fullRows = length &gt;&gt;&gt; 4; final int remainder = length &amp; 0xF; // Dump the rows which have 16 bytes. for (int row = 0; row &lt; fullRows; row++) { int rowStartIndex = (row &lt;&lt; 4) + startIndex; // Per-row prefix. appendHexDumpRowPrefix (dump, row, rowStartIndex); // Hex dump int rowEndIndex = rowStartIndex + 16; for (int j = rowStartIndex; j &lt; rowEndIndex; j++) { dump.append (BYTE2HEX[getUnsignedByte (buf, j)]); } dump.append (\" |\"); // ASCII dump for (int j = rowStartIndex; j &lt; rowEndIndex; j++) { dump.append (BYTE2CHAR[getUnsignedByte (buf, j)]); } dump.append ('|'); } // Dump the last row which has less than 16 bytes. if (remainder != 0) { int rowStartIndex = (fullRows &lt;&lt; 4) + startIndex; appendHexDumpRowPrefix (dump, fullRows, rowStartIndex); // Hex dump int rowEndIndex = rowStartIndex + remainder; for (int j = rowStartIndex; j &lt; rowEndIndex; j++) { dump.append (BYTE2HEX[getUnsignedByte (buf, j)]); } dump.append (HEXPADDING[remainder]); dump.append (\" |\"); // Ascii dump for (int j = rowStartIndex; j &lt; rowEndIndex; j++) { dump.append (BYTE2CHAR[getUnsignedByte (buf, j)]); } dump.append (BYTEPADDING[remainder]); dump.append ('|'); } dump.append (NEWLINE + \"+--------+-------------------------------------------------+----------------+\"); } private static void appendHexDumpRowPrefix(StringBuilder dump, int row, int rowStartIndex) { if (row &lt; HEXDUMP_ROWPREFIXES.length) { dump.append (HEXDUMP_ROWPREFIXES[row]); } else { dump.append (NEWLINE); dump.append (Long.toHexString (rowStartIndex &amp; 0xFFFFFFFFL | 0x100000000L)); dump.setCharAt (dump.length ( ) - 9, '|'); dump.append ('|'); } } public static short getUnsignedByte(ByteBuffer buffer, int index) { return (short) (buffer.get (index) &amp; 0xFF); } } 调用案例package com.kk.netty.nio.demo; import java.nio.ByteBuffer; import static com.kk.netty.nio.ByteBufferUtil.debugAll; public class TestByteBufferReadWrite { public static void main(String[] args) { ByteBuffer buffer = ByteBuffer.allocate (10); System.out.println (\"1、先插入 a ，再插入 b c d\" ); // ASCLL码（十进制） 97 = 十六进制 0x61 = a buffer.put ((byte)0x61);// 写入一个字符 a debugAll(buffer);// 调试打印 buffer.put (new byte[]{0x62,0x63,0x64});// 写入字符 b c d debugAll(buffer);// 调试打印 System.out.println (\" 2、切换 读模式，取一个字符\" ); // 在没有切换为 读 模式的时候，直接拿是拿不到的 //System.out.println (buffer.get ( )); buffer.flip ();// 切换读模式 System.out.println (buffer.get ( ));// 取出一个，还剩3个 System.out.println (buffer.get ( ));// 取出一个，还剩2个 debugAll(buffer);// 调试打印 System.out.println (\"3、未读取的往前移(压缩),第3、4位会遗留二个63、64是因为没有清零，然后后面插入不影响，会从已有的后面插入\" ); buffer.compact (); debugAll(buffer);// 调试打印 System.out.println (\"4、插入两个字符，从已有的后面插入\" ); buffer.put (new byte[]{0x65,0x6f}); debugAll(buffer);// 调试打印 } } 3、ByteBuffer 常见 API 分配空间 向 buffer 写入数据 从 buffer 读取数据 mark 和 reset 字符串与 ByteBuffer 互转 Buffer 的线程安全 3-1、分配空间可以使用 allocate 方法为 ByteBuffer 分配空间，其它 buffer 类也有该方法 Bytebuffer buf = ByteBuffer.allocate(16); 3-2、buffer 写入数据有两种办法 调用 channel 的 read 方法 调用 buffer 自己的 put 方法 int readBytes = channel.read(buf); 和 buf.put((byte)127); 3-3、buffer 读取数据同样有两种办法 调用 channel 的 write 方法 调用 buffer 自己的 get 方法 int writeBytes = channel.write(buf); 和 byte b = buf.get(); get 方法会让 position 读指针向后走，如果想重复读取数据 可以调用 rewind 方法将 position 重新置为 0 或者调用 get(int i) 方法获取索引 i 的内容，它不会移动读指针 3-4、mark 和 resetmark 是在读取时，做一个标记，即使 position 改变，只要调用 reset 就能回到 mark 的位置 注意 rewind 和 flip 都会清除 mark 位置 3-5、字符串与 ByteBuffer 互转package com.kk.netty.nio.demo; import java.nio.ByteBuffer; import java.nio.CharBuffer; import java.nio.charset.Charset; import java.nio.charset.StandardCharsets; import static com.kk.netty.nio.ByteBufferUtil.debugAll; public class TestButeBufferApi { public static void main(String[] args) { ByteBuffer buffer1 = StandardCharsets.UTF_8.encode (\"你好\"); ByteBuffer buffer2 = Charset.forName (\"utf-8\").encode (\"你好\"); debugAll (buffer1); debugAll (buffer2); CharBuffer buffer3 = StandardCharsets.UTF_8.decode (buffer1); System.out.println (buffer3.getClass ( )); System.out.println (buffer3.toString ( )); } } 输出 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f | +--------+-------------------------------------------------+----------------+ |00000000| e4 bd a0 e5 a5 bd |...... | +--------+-------------------------------------------------+----------------+ +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f | +--------+-------------------------------------------------+----------------+ |00000000| e4 bd a0 e5 a5 bd |...... | +--------+-------------------------------------------------+----------------+ class java.nio.HeapCharBuffer 你好 3-6、Buffer 的线程安全 Buffer 是非线程安全的 4、Scattering Reads1、分散集中读分散读取，有一个文本文件 3parts.txt onetwothree 使用如下方式读取，可以将数据填充至多个 buffer package com.kk.netty.nio.demo; import java.io.IOException; import java.io.RandomAccessFile; import java.nio.ByteBuffer; import java.nio.channels.FileChannel; import static com.kk.netty.nio.ByteBufferUtil.debugAll; public class TestScatteringReads { public static void main(String[] args) { try (RandomAccessFile file = new RandomAccessFile (\"boot_netty/helloword/3parts.txt\", \"rw\")) { FileChannel channel = file.getChannel ( ); ByteBuffer a = ByteBuffer.allocate (3); ByteBuffer b = ByteBuffer.allocate (3); ByteBuffer c = ByteBuffer.allocate (5); channel.read (new ByteBuffer[]{a, b, c}); a.flip ( ); b.flip ( ); c.flip ( ); debugAll (a); debugAll (b); debugAll (c); } catch (IOException e) { e.printStackTrace ( ); } } } 结果 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f | +--------+-------------------------------------------------+----------------+ |00000000| 6f 6e 65 |one | +--------+-------------------------------------------------+----------------+ +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f | +--------+-------------------------------------------------+----------------+ |00000000| 74 77 6f |two | +--------+-------------------------------------------------+----------------+ +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f | +--------+-------------------------------------------------+----------------+ |00000000| 74 68 72 65 65 |three | +--------+-------------------------------------------------+----------------+ 2、分散集中写package com.kk.netty.nio.demo; import java.io.IOException; import java.io.RandomAccessFile; import java.nio.ByteBuffer; import java.nio.channels.FileChannel; import java.nio.charset.StandardCharsets; /** * 分散集中写 */ public class TestScatteringWrites { public static void main(String[] args) { ByteBuffer b1 = StandardCharsets.UTF_8.encode (\"hello\"); ByteBuffer b2 = StandardCharsets.UTF_8.encode (\"world\"); ByteBuffer b3 = StandardCharsets.UTF_8.encode (\"你好，世界\"); try (FileChannel file = new RandomAccessFile (\"boot_netty/helloword/2parts.txt\", \"rw\").getChannel ( )) { file.write (new ByteBuffer[]{b1, b2, b3}); } catch (IOException e) { e.printStackTrace ( ); } } } 5、Gathering Writes网络上有多条数据发送给服务端，数据之间使用 \\n 进行分隔但由于某种原因这些数据在接收时，被进行了重新组合，例如原始数据有3条为 Hello,world\\n I’m zhangsan\\n How are you?\\n 变成了下面的两个 byteBuffer (黏包，半包) Hello,world\\nI’m zhangsan\\nHo w are you?\\n 现在要求你编写程序，将错乱的数据恢复成原始的按 \\n 分隔的数据 package com.kk.netty.nio.demo; import java.nio.ByteBuffer; import static com.kk.netty.nio.ByteBufferUtil.debugAll; public class TestGatheringWrites { public static void main(String[] args) { ByteBuffer source = ByteBuffer.allocate (32); // 11 24 source.put (\"Hello,world\\nI'm zhangsan\\nHo\".getBytes ( )); split (source); source.put (\"w are you?\\nhaha!\\n\".getBytes ( )); split (source); } private static void split(ByteBuffer source) { source.flip ( ); // source.limit ( ) 缓冲区容量长度 for (int i = 0; i &lt; source.limit ( ); i++) { // 找到一条完整信息 if (source.get (i) == '\\n') { System.out.println (i); // 计算每个 \\n 词组的长度（换行符号 +1 - 游标起始位置） int length = i + 1 - source.position ( ); // 将这条完整信息存入新的 bytebuffer ByteBuffer target = ByteBuffer.allocate (length); // 从 source 读，向 target 写 for (int j = 0; j &lt; length; j++) { target.put (source.get ()); } debugAll (target); } } // 未读的往前移动 source.compact ( ); } } 三、文件编程1、FileChannel1、⚠️ FileChannel 工作模式 FileChannel 只能工作在阻塞模式下 2、获取不能直接打开 FileChannel，必须通过 FileInputStream、FileOutputStream 或者 RandomAccessFile 来获取 FileChannel，它们都有 getChannel 方法 通过 FileInputStream 获取的 channel 只能读 通过 FileOutputStream 获取的 channel 只能写 通过 RandomAccessFile 是否能读写根据构造 RandomAccessFile 时的读写模式决定 3、读取会从 channel 读取数据填充 ByteBuffer，返回值表示读到了多少字节，-1 表示到达了文件的末尾 int readBytes = channel.read(buffer); 4、写入写入的正确姿势如下， SocketChannel ByteBuffer buffer = ...; buffer.put(...); // 存入数据 buffer.flip(); // 切换读模式 while(buffer.hasRemaining()) { channel.write(buffer); } 在 while 中调用 channel.write 是因为 write 方法并不能保证一次将 buffer 中的内容全部写入 channel 5、位置获取当前位置 long pos = channel.position(); 设置当前位置 long newPos = ...; channel.position(newPos); 设置当前位置时，如果设置为文件的末尾 这时读取会返回 -1 这时写入，会追加内容，但要注意如果 position 超过了文件末尾，再写入时在新内容和原末尾之间会有空洞（00） 6、大小使用 size 方法获取文件的大小 7、强制写入操作系统出于性能的考虑，会将数据缓存，不是立刻写入磁盘。可以调用 force(true) 方法将文件内容和元数据（文件的权限等信息）立刻写入磁盘 2、两个 Channel 传输数据基础版：限制2g package com.kk.netty.nio.file; import java.io.FileInputStream; import java.io.FileOutputStream; import java.io.IOException; import java.nio.channels.FileChannel; public class TestFileChannel { public static void main(String[] args) { String FROM = \"boot_netty/helloword/data.txt\"; String TO = \"boot_netty/helloword/to.txt\"; long start = System.nanoTime ( ); try ( FileChannel from = new FileInputStream (FROM).getChannel ( ); FileChannel to = new FileOutputStream (TO).getChannel ( ); ) { // 数据 from 传输到 to*（就是一个拷贝过程） // 效率会比传统的原生api 高，底层会用操作系统的零拷贝进行优化 from.transferTo (0, from.size ( ), to); } catch (IOException e) { e.printStackTrace ( ); } long end = System.nanoTime ( ); System.out.println (\"transferTo 用时：\" + (end - start) / 1000_000.0); } } 优化版：循环插入，解决2g限制 package com.kk.netty.nio.file; import java.io.FileInputStream; import java.io.FileOutputStream; import java.io.IOException; import java.nio.channels.FileChannel; public class TestFileChannel { public static void main(String[] args) { String FROM = \"boot_netty/helloword/data.txt\"; String TO = \"boot_netty/helloword/to.txt\"; long start = System.nanoTime ( ); try ( FileChannel from = new FileInputStream (FROM).getChannel ( ); FileChannel to = new FileOutputStream (TO).getChannel ( ); ) { // 数据 from 传输到 to*（就是一个拷贝过程） // 效率会比传统的原生api 高，底层会用操作系统的零拷贝进行优化 long size = from.size ( ); // left 变量代表还剩余多少字节 for (long left = size; left &gt; 0; ) { System.out.println (\"position:\" + (size - left) + \" left:\" + left); left -= from.transferTo (size - left, left, to); } } catch (IOException e) { e.printStackTrace ( ); } long end = System.nanoTime ( ); System.out.println (\"transferTo 用时：\" + (end - start) / 1000_000.0); } } 3、Pathjdk7 引入了 Path 和 Paths 类 Path 用来表示文件路径 Paths 是工具类，用来获取 Path 实例 Path source = Paths.get(\"1.txt\"); // 相对路径 使用 user.dir 环境变量来定位 1.txt Path source = Paths.get(\"d:\\\\1.txt\"); // 绝对路径 代表了 d:\\1.txt Path source = Paths.get(\"d:/1.txt\"); // 绝对路径 同样代表了 d:\\1.txt Path projects = Paths.get(\"d:\\\\data\", \"projects\"); // 代表了 d:\\data\\projects . 代表了当前路径 .. 代表了上一级路径 例如目录结构如下 d: |- data |- projects |- a |- b 代码 Path path = Paths.get(\"d:\\\\data\\\\projects\\\\a\\\\..\\\\b\"); System.out.println(path); System.out.println(path.normalize()); // 正常化路径 会输出 d:\\data\\projects\\a\\..\\b d:\\data\\projects\\b 4、Files检查文件是否存在Path path = Paths.get(\"helloword/data.txt\"); System.out.println(Files.exists(path)); 创建一级目录Path path = Paths.get(\"helloword/d1\"); Files.createDirectory(path); 如果目录已存在，会抛异常 FileAlreadyExistsException 不能一次创建多级目录，否则会抛异常 NoSuchFileException 创建多级目录用Path path = Paths.get(\"helloword/d1/d2\"); Files.createDirectories(path); 拷贝文件Path source = Paths.get(\"helloword/data.txt\"); Path target = Paths.get(\"helloword/target.txt\"); Files.copy(source, target); 如果文件已存在，会抛异常 FileAlreadyExistsException 如果希望用 source 覆盖掉 target，需要用 StandardCopyOption 来控制 Files.copy(source, target, StandardCopyOption.REPLACE_EXISTING); 移动文件Path source = Paths.get(\"helloword/data.txt\"); Path target = Paths.get(\"helloword/data.txt\"); Files.move(source, target, StandardCopyOption.ATOMIC_MOVE); StandardCopyOption.ATOMIC_MOVE 保证文件移动的原子性 删除文件Path target = Paths.get(\"helloword/target.txt\"); Files.delete(target); 如果文件不存在，会抛异常 NoSuchFileException 删除目录Path target = Paths.get(\"helloword/d1\"); Files.delete(target); 如果目录还有内容，会抛异常 DirectoryNotEmptyException 遍历目录文件设计模式：访问者模式 public static void main(String[] args) throws IOException { // 目录个数 AtomicInteger direCount = new AtomicInteger ( ); // 文件个数 AtomicInteger fileCount = new AtomicInteger ( ); // 目录对象 Path path = Paths.get (\"C:\\\\Program Files\\\\Java\\\\jdk1.8.0_202\"); // 设计模式：访问者模式 Files.walkFileTree (path,new SimpleFileVisitor&lt;Path&gt;(){ // 获取目录 @Override public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException { System.out.println (dir ); direCount.incrementAndGet (); return super.preVisitDirectory (dir, attrs); } // 获取文件 @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException { System.out.println (file ); fileCount.incrementAndGet (); return super.visitFile (file, attrs); } } ); System.out.println(direCount); // 133 System.out.println(fileCount); // 1479 } 统计 jar 的数目 public static void main(String[] args) throws IOException { // 文件个数 AtomicInteger fileCount = new AtomicInteger ( ); // 目录对象 Path path = Paths.get (\"C:\\\\Program Files\\\\Java\\\\jdk1.8.0_202\"); // 设计模式：访问者模式 Files.walkFileTree (path,new SimpleFileVisitor&lt;Path&gt; (){ @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException { // 根据文件后缀筛选 if (file.toFile ().getName ().endsWith (\".jar\")){ fileCount.incrementAndGet (); } return super.visitFile (file, attrs); } }); System.out.println(fileCount); // 705 } 删除多级目录 public class TestRemoveFile { public static void main(String[] args) throws IOException { Path path = Paths.get (\"j:\\\\test\"); Files.walkFileTree (path,new SimpleFileVisitor&lt;Path&gt; (){ // 先删除文件 @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException { Files.delete (file); return super.visitFile (file, attrs); } // 再删除目录 @Override public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException { Files.delete (dir); return super.postVisitDirectory (dir, exc); } }); } } ⚠️ 删除很危险 删除是危险操作，确保要递归删除的文件夹没有重要内容 拷贝多级目录 public class TestCopyMultDirectory { public static void main(String[] args) throws IOException { String source = \"j:\\\\test\"; String target = \"j:\\\\testTemp\"; long start = System.currentTimeMillis (); Files.walk (Paths.get (source)).forEach (path -&gt; { try { String targetName = path.toString ( ).replace (source, target); // 如果是目录 if (Files.isDirectory (path)){ Files.createDirectories (Paths.get (targetName)); } // 如果是文件 else if (Files.isRegularFile (path)){ Files.copy (path,Paths.get (targetName)); } } catch (Exception e) { e.printStackTrace ( ); } }); long end = System.currentTimeMillis(); System.out.println(end - start); } } 四、网络编程1、非阻塞 vs 阻塞1.1、阻塞 阻塞模式下，相关方法都会导致线程暂停 ServerSocketChannel.accept 会在没有连接建立时让线程暂停 SocketChannel.read 会在没有数据可读时让线程暂停 阻塞的表现其实就是线程暂停了，暂停期间不会占用 cpu，但线程相当于闲置 单线程下，阻塞方法之间相互影响，几乎不能正常工作，需要多线程支持 但多线程下，有新的问题，体现在以下方面 32 位 jvm 一个线程 320k，64 位 jvm 一个线程 1024k，如果连接数过多，必然导致 OOM，并且线程太多，反而会因为频繁上下文切换导致性能降低 可以采用线程池技术来减少线程数和线程上下文切换，但治标不治本，如果有很多连接建立，但长时间 inactive，会阻塞线程池中所有线程，因此不适合长连接，只适合短连接 阻塞在哪里(人话) 1、连接的阻塞（accept） 2、写入数据的阻塞（read） 3、accept 的时候不能 read ,read 时候不能 accept ，这就是阻塞 4、一句话：这个线程没有发生，还会就会等待（反之：不会等待则是非阻塞） server@Slf4j public class Server { public static void main(String[] args) throws IOException { // 使用 nio 来理解阻塞模式，单线程 ByteBuffer buffer = ByteBuffer.allocate (16); // 1、创建服务端 ServerSocketChannel ssc = ServerSocketChannel.open ( ); // 2、绑定监听端口 ssc.bind (new InetSocketAddress (8080)); // 3、创建连接集合 List&lt;SocketChannel&gt; channels = new ArrayList&lt;&gt; ( ); // 循环运行等待 while(true){ log.debug (\"connection...\"); // 4、accept 建立与客户端连接， SocketChannel 用来与客户端之间通信 SocketChannel sc = ssc.accept ( );//阻塞方法，线程停止运行 log.debug(\"connected... {}\", sc); channels.add (sc); for (SocketChannel channel : channels) { // 5、接受客户端发送的数据 log.debug(\"before read... {}\", channel); channel.read (buffer);// 写入（阻塞方法，线程停止运行） buffer.flip ();//切换为读模式 debugRead(buffer);// 打印可读取的内容 buffer.clear ();// 切换为写模式 log.debug(\"after read...{}\", channel); } } } } clientpublic class Client { public static void main(String[] args) throws IOException { SocketChannel sc = SocketChannel.open ( ); sc.connect (new InetSocketAddress (\"localhost\",8080)); System.out.println (\"waiting...\" ); } } 1.2、非阻塞 非阻塞模式下，相关方法都会不会让线程暂停 在 ServerSocketChannel.accept 在没有连接建立时，会返回 null，继续运行 SocketChannel.read 在没有数据可读时，会返回 0，但线程不必阻塞，可以去执行其它 SocketChannel 的 read 或是去执行 ServerSocketChannel.accept 写数据时，线程只是等待数据写入 Channel 即可，无需等 Channel 通过网络把数据发送出去 但非阻塞模式下，即使没有连接建立，和可读数据，线程仍然在不断运行，白白浪费了 cpu 数据复制过程中，线程实际还是阻塞的（AIO 改进的地方） server：服务器端，客户端代码不变@Slf4j public class NotBlockServer { public static void main(String[] args) throws IOException { // 使用 nio 来理解阻塞模式，单线程 ByteBuffer buffer = ByteBuffer.allocate (16); // 1、创建服务端 ServerSocketChannel ssc = ServerSocketChannel.open ( ); ssc.configureBlocking (false);// 切换为非阻塞模式，默认为阻塞 // 2、绑定监听端口 ssc.bind (new InetSocketAddress (8080)); // 3、创建连接集合 List&lt;SocketChannel&gt; channels = new ArrayList&lt;&gt; ( ); // 循环运行等待 while (true) { log.debug (\"connection...\"); // 4、accept 建立与客户端连接， SocketChannel 用来与客户端之间通信 SocketChannel sc = ssc.accept ( );//非阻塞方法，线程继续运行 log.debug (\"connected... {}\", sc); channels.add (sc); for (SocketChannel channel : channels) { // 5、接受客户端发送的数据 // 如果没有读到数据，read 返回 0 int read = channel.read (buffer);// 写入（非阻塞方法，线程继续运行） if (read &gt; 0) { log.debug (\"before read... {}\", channel); buffer.flip ( );//切换为读模式 debugRead (buffer);// 打印可读取的内容 buffer.clear ( );// 切换为写模式 log.debug (\"after read...{}\", channel); } } } } } 多个客户端调试发现：其实不用的时候还在一直打印，CPU状态是打满的，自然也是性能的消耗 1.3、多路复用单线程可以配合 Selector 完成对多个 Channel 可读写事件的监控，这称之为多路复用 多路复用仅针对网络 IO、普通文件 IO 没法利用多路复用 如果不用 Selector 的非阻塞模式，线程大部分时间都在做无用功，而 Selector 能够保证 有可连接事件时才去连接 有可读事件才去读取 有可写事件才去写入 限于网络传输能力，Channel 未必时时可写，一旦 Channel 可写，会触发 Selector 的可写事件 2、Selector 好处 一个线程配合 selector 就可以监控多个 channel 的事件，事件发生线程采取处理。避免非阻塞模式下所做的无用功 让这个线程能够被充分的利用 节约了线程的数量 减少了线程上下文切换 1、创建Selector selector = Selector.open ( ); 2、绑定 Channel 事件也称之为注册事件，绑定的事件 selector 才回关心 channel.configureBlocking (false); // 根据常量值来选择绑定类型 SelectionKey.OP_ACCEPT SelectionKey key = channel.register (selector, 绑定事件); channel 必须在非阻塞模式下工作 FileChannel 没有非阻塞模式，所以不能配合 selector 使用 绑定的事件类型 connect - 客户端连接成功时触发 accept - 服务端成功连接时触发 read - 数据可读入时触发 write - 数据可写入时触发 3、监听 Channel 事件可以通过下面三种方法来监听是否有事件发生，方法的返回值代表有多少 channel 发生了事件。 方法一：阻塞直到绑定事件发生 int count = selector.select(); 方法二：阻塞直到绑定事件发生，或是超时（时间单位为 ms） int count = selector.select(long timeout) 方法三：不会阻塞，也就是不管有没有事件发生，就立即返回，自己根据返回值检查当前是否有事件发生。 int count = selector.selectNow(); 4、💡 select 何时不阻塞 事件发生时 客户端发起连接请求，会触发 accept事件 客户端发送数据过来，客户端正常，或者异常关闭时，都会触发 read 事件，另外如果发送的数据大于 buffer 缓冲区，会触发多次读取事件 channel 可写，会触发 write 事件 在 Linux 下 nio bug 发生时 调用 selector.wakeup()，唤醒 调用 selector.clone()，关闭 selector 所在线程 interrupt（打断，阻断，暂定） 3、处理 accept 事件主要用于建立连接 客户端代码package com.kk.netty.nio.network.selector; import java.io.IOException; import java.net.Socket; public class Client { public static void main(String[] args) { try (Socket socket = new Socket (\"localhost\", 8080)) { System.out.println (socket); socket.getOutputStream ( ).write (\"hello!\".getBytes ( )); System.in.read ( ); } catch (IOException e) { e.printStackTrace ( ); } } } 服务端代码package com.kk.netty.nio.network.selector; import lombok.extern.slf4j.Slf4j; import java.io.IOException; import java.net.InetSocketAddress; import java.nio.channels.SelectionKey; import java.nio.channels.Selector; import java.nio.channels.ServerSocketChannel; import java.util.Iterator; import java.util.Set; @Slf4j public class AcceptService { public static void main(String[] args) throws IOException { // 1、创建 selector 管理多个 channel Selector selector = Selector.open ( ); ServerSocketChannel channel = ServerSocketChannel.open ( ); channel.configureBlocking (false); // 2、建立 selector 和 channel 的联系(注册) channel.register (selector, SelectionKey.OP_ACCEPT); // SelectionKey 当事件发生后，通过它得到事件类型 和 哪个 channel 发生了该事件 SelectionKey ckey = channel.register (selector, 0, null); // key 只关注 accept 事件 // interestOps 只关注 ckey.interestOps (SelectionKey.OP_ACCEPT); log.debug (\"register key:{}\", ckey); channel.bind (new InetSocketAddress (8080)); while (true) { // 3、select 方法，没有事件发生，线程阻塞；有事件，才恢复运行 //select 在事件未处理的时候，它不会阻塞；事件发生后，要么处理或者取消，不能置之不理 selector.select ( ); // 4、处理事件，selectedKey 内部包含了所有发生的事件 Set&lt;SelectionKey&gt; keys = selector.selectedKeys ( ); // 遍历所有事件，逐一处理 Iterator&lt;SelectionKey&gt; iter = keys.iterator ( ); while (iter.hasNext ( )) { SelectionKey key = iter.next ( ); key.cancel ( ); } } } } 💡 事件发生后能否不处理事件发生后，要么处理，要么取消（cancel），不能什么都不做，否则下次该事件仍会触发，这是因为 nio底层使用的是水平触发 4、处理 read 事件servicepackage com.kk.netty.nio.network.selector; import lombok.extern.slf4j.Slf4j; import java.io.IOException; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.*; import java.util.Iterator; import java.util.Set; import static com.kk.netty.nio.ByteBufferUtil.debugRead; @Slf4j public class ReadService { // sscKey 、 scKey 一人一个管理员 public static void main(String[] args) throws IOException { // 1、创建 selector 管理多个 channel Selector selector = Selector.open ( ); ServerSocketChannel channel = ServerSocketChannel.open ( ); channel.configureBlocking (false); // 2、建立 selector 和 channel 的联系(注册) channel.register (selector, SelectionKey.OP_ACCEPT); // SelectionKey 当事件发生后，通过它得到事件类型 和 哪个 channel 发生了该事件 SelectionKey sscKey = channel.register (selector, 0, null); // key 只关注 accept 事件 // interestOps 只关注 sscKey.interestOps (SelectionKey.OP_ACCEPT); log.debug (\"register key:{}\", sscKey); channel.bind (new InetSocketAddress (8080)); while (true) { // 3、select 方法，没有事件发生，线程阻塞；有事件，才恢复运行 //select 在事件未处理的时候，它不会阻塞；事件发生后，要么处理或者取消，不能置之不理 selector.select ( ); // 4、处理事件，selectedKey 内部包含了所有发生的事件 Set&lt;SelectionKey&gt; keys = selector.selectedKeys ( ); // 遍历所有事件，逐一处理 Iterator&lt;SelectionKey&gt; iter = keys.iterator ( ); while (iter.hasNext ( )) { SelectionKey key = iter.next ( ); log.debug (\"key:{}\", key); // 5、区分事件类型 if (key.isAcceptable ( )) {// 如果是 accept ServerSocketChannel channelTest1 = (ServerSocketChannel) key.channel ( ); SocketChannel sc = channelTest1.accept ( ); sc.configureBlocking (false); SelectionKey scKey = sc.register (selector, 0, null); scKey.interestOps (SelectionKey.OP_READ); } else if (key.isReadable ( )) {// 如果是 read // 拿到触发的事件 channel SocketChannel channlTest2 = (SocketChannel) key.channel ( ); ByteBuffer buffer = ByteBuffer.allocate (16); channlTest2.read (buffer); buffer.flip ( ); debugRead (buffer); } // key.cancel ( ); } } } } 输出结果： 因为 select 用完 key 没有 remove() 4.1、为什么要remove 因为 select 在事件发生后，就会将相关的 key 放入 selectedKeys 集合，但不会在处理完后从 selectedKeys 集合中移除，需要我们自己编码删除。例如 第一次触发了 ssckey 上的 accept 事件，没有移除 ssckey 第二次触发了 sckey 上的 read 事件，但这时 selectedKeys 中还有上次的 ssckey ，在处理时因为没有真正的 serverSocket 连上了，就会导致空指针异常 4.2、remove 代码拿到后就删掉，方式重复事件处理（写在后面也可以） 4.3、处理客户端断开 4.4、不处理边界问题以 BIO 为案例代码service public class BoundaryService { public static void main(String[] args) throws Exception { ServerSocket ss = new ServerSocket (9000); while (true) { Socket socket = ss.accept ( ); InputStream in = socket.getInputStream ( ); // 这里这么写，有没有问题 byte[] arr = new byte[4]; while (true) { int read = in.read (arr); // 这里这么写，有没有问题 if (read == -1) { break; } System.out.println (new String (arr, 0, read)); } } } } client public class BoundDaryClient { public static void main(String[] args) { Socket socket = null; try { socket = new Socket (\"localhost\", 9000); OutputStream out = socket.getOutputStream ( ); out.write (\"hello\".getBytes ( )); out.write (\"world\".getBytes ( )); out.write (\"你好\".getBytes ( )); out.close ( ); } catch (IOException e) { e.printStackTrace ( ); } } } 输出 hell owor ld� �好 4.5、处理消息的边界（容量超出）容量超出，就需要考虑扩容问题，这边没去考虑缩容，nettry 会有适配这些问题 一种思路是固定消息长度，数据包大小一样，服务器按预定长度读取，缺点是浪费带宽 另一种思路是按分隔符拆分，缺点是效率低 TLV 格式，即 Type 类型、Length 长度、Value 数据，类型和长度已知的情况下，就可以方便获取消息大小，分配合适的 buffer，缺点是 buffer 需要提前分配，如果内容过大，则影响 server 吞吐量 Http 1.1 是 TLV 格式 Http 2.0 是 LTV 格式 **这边 service 会用到附件知识，会把 bytebuffer 作为事件注册到 SelectorKey 上 ** 既 ， register（t1,t2,t3）第三个参数上 service // sscKey 、 scKey 一人一个管理员 public static void main(String[] args) throws IOException { // 1、创建 selector 管理多个 channel Selector selector = Selector.open ( ); ServerSocketChannel ssc = ServerSocketChannel.open ( ); ssc.configureBlocking (false); // 2、建立 selector 和 channel 的联系(注册) ssc.register (selector, SelectionKey.OP_ACCEPT); // SelectionKey 当事件发生后，通过它得到事件类型 和 哪个 channel 发生了该事件 SelectionKey sscKey = ssc.register (selector, 0, null); // key 只关注 accept 事件 // interestOps 只关注 sscKey.interestOps (SelectionKey.OP_ACCEPT); log.debug (\"register key:{}\", sscKey); ssc.bind (new InetSocketAddress (8080)); while (true) { // 3、select 方法，没有事件发生，线程阻塞；有事件，才恢复运行 //select 在事件未处理的时候，它不会阻塞；事件发生后，要么处理或者取消，不能置之不理 selector.select ( ); // 4、处理事件，selectedKey 内部包含了所有发生的事件 Set&lt;SelectionKey&gt; keys = selector.selectedKeys ( ); // 遍历所有事件，逐一处理 Iterator&lt;SelectionKey&gt; iter = keys.iterator ( ); while (iter.hasNext ( )) { SelectionKey key = iter.next ( ); iter.remove ( ); log.debug (\"key:{}\", key); // 5、区分事件类型 if (key.isAcceptable ( )) {// 如果是 accept ServerSocketChannel channel = (ServerSocketChannel) key.channel ( ); SocketChannel sc = channel.accept ( ); sc.configureBlocking (false); ByteBuffer buffer = ByteBuffer.allocate (16);// attachment // 将一个 byteBuffer 作为附件关联到 selectionKey 上 SelectionKey scKey = sc.register (selector, 0, buffer); scKey.interestOps (SelectionKey.OP_READ); } else if (key.isReadable ( )) {// 如果是 read try { // 拿到触发的事件 channel SocketChannel channel = (SocketChannel) key.channel ( ); // 获取 selectionKey 上关联的事件 //ByteBuffer buffer = ByteBuffer.allocate (16); ByteBuffer buffer = (ByteBuffer) key.attachment ( ); // 如果是正常断开。read 的方法返回值是 -1 int read = channel.read (buffer); if (read == -1) { key.cancel ( ); } else { // 压缩读取一次，确保数据完整 split (buffer); // 如果游标的起始相等，说明容量已满，需要扩容 if (buffer.position ( ) == buffer.limit ( )) { // 扩容两倍 ByteBuffer newBuffer = ByteBuffer.allocate (buffer.capacity ( ) * 2); buffer.flip ( ); newBuffer.put (buffer); key.attach (newBuffer); } } } catch (Exception e) { e.printStackTrace ( ); // 因为客户端断开了，因此需要将 key 取消（从 selector 得keys 集合中真正删除） key.cancel ( ); } } } } } client public static void main(String[] args) throws IOException { SocketChannel sc = SocketChannel.open (); sc.connect (new InetSocketAddress (\"localhost\", 8080)); SocketAddress address = sc.getLocalAddress ( ); sc.write (Charset.defaultCharset ().encode (\"0123456789abcdef\")); sc.write (Charset.defaultCharset ().encode (\"012345Q\\n6789abcdef3333\\n\")); } 4.6、ByteBuffer 大小分配 每个 channel 都需要记录可能被切分的消息，因为 ByteBuffer 不能被多个 channel 共同使用，因此需要为每个 channel 维护一个独立的 ByteBuffer ByteBuffer 不能太大，比如一个 ByteBuffer 1Mb 的话，要支持百万连接就要 1Tb 内存，因此需要设计大小可变的 ByteBuffer 一种思路是首先分配一个较小的 buffer，例如 4k，如果发现数据不够，再分配 8k 的 buffer，将 4k buffer 内容拷贝至 8k buffer，优点是消息连续容易处理，缺点是数据拷贝耗费性能，参考实现 http://tutorials.jenkov.com/java-performance/resizable-array.html 另一种思路是用多个数组组成 buffer，一个数组不够，把多出来的内容写入新的数组，与前面的区别是消息存储不连续解析复杂，优点是避免了拷贝引起的性能损耗 5、处理 write 事件一次性无法写完的例子 非阻塞模式下，无法保证把 buffer 中所有数据都写入 channel，因此需要追踪 write 方法的返回值（代表实际写入字节数） 用 selector 监听所有 channel 的可写事件，每个 channel 都需要一个 key 来跟踪 buffer，但这样又会导致占用内存过多，就有两阶段策略 当消息处理器第一次写入消息时，才将 channel 注册到 selector 上 selector 检查 channel 上的可写事件，如果所有的数据写完了，就取消 channel 的注册 如果不取消，会每次可写均会触发 write 事件 service public class WriteServer { public static void main(String[] args) throws Exception { ServerSocketChannel ssc = ServerSocketChannel.open ( ); ssc.configureBlocking (false); ssc.bind (new InetSocketAddress (8080)); Selector selector = Selector.open ( ); ssc.register (selector, SelectionKey.OP_ACCEPT); while (true) { selector.select ( ); Iterator&lt;SelectionKey&gt; iter = selector.selectedKeys ( ).iterator ( ); while (iter.hasNext ( )) { SelectionKey key = iter.next ( ); iter.remove ( ); if (key.isAcceptable ( )) { SocketChannel sc = ssc.accept ( ); sc.configureBlocking (false); SelectionKey scKey = sc.register (selector, SelectionKey.OP_READ); // 1、向客户端发送大量数据 StringBuffer sb = new StringBuffer ( ); for (int i = 0; i &lt; 3000000; i++) { sb.append (\"a\"); } ByteBuffer buffer = Charset.defaultCharset ( ).encode (sb.toString ( )); // 2、返回值代表实际写入的字节数 int write = sc.write (buffer); System.out.println (\"实际写入字节:\" + write); // 3、判断是否有剩余内容 if (buffer.hasRemaining ( )) { // 4、关注可写事件(1+4) // read 1 write 4 scKey.interestOps (scKey.interestOps ( ) + SelectionKey.OP_WRITE); // 5、把未写完的数据 挂到 scKey上 scKey.attach (buffer); } } else if (key.isWritable ( )) { ByteBuffer buffer = (ByteBuffer) key.attachment ( ); SocketChannel sc = (SocketChannel) key.channel ( ); int write = sc.write (buffer); System.out.println (\"实际写入字节:\" + write); if (!buffer.hasRemaining ( )) {// 写完了(切换为读模式) key.interestOps (key.interestOps ( ) - SelectionKey.OP_WRITE); // 需要清除 buffer key.attach (null); } } } } } } client public class WriteClient { public static void main(String[] args) throws IOException { SocketChannel sc = SocketChannel.open ( ); sc.connect (new InetSocketAddress (8080)); // 接收数据 int count = 0; while (true) { ByteBuffer buffer = ByteBuffer.allocate (1 &lt;&lt; 20); count += sc.read (buffer); System.out.println (count ); buffer.clear (); } } } 💡 write 为何要取消只要向 channel 发送数据时，socket 缓冲可写，这个事件会频繁触发; 因此应当只在 socket 缓冲区写不下时再关注可写事件，数据写完之后再取消关注 6、多线程优化1、编码思路 两个线程之间传递数据，用队列在中间进行传输（这里用安全队列），netty底层也是 根据处理器数量，轮训（这边1.8的api jvm 有问题，在jdk 10的时候才修复） 单线程配一个选择器，专门处理 accept 事件 创建 cpu 核心数的线程，每个线程配一个选择器，轮流处理 read 事件 2、如何拿到 cpu 个数 Runtime.getRuntime().availableProcessors() 如果工作在 docker 容器下，因为容器不是物理隔离的，会拿到物理 cpu 个数，而不是容器申请时的个数 这个问题直到 jdk 10 才修复，使用 jvm 参数 UseContainerSupport 配置， 默认开启 @Slf4j public class MultiThreadServer { public static void main(String[] args) throws IOException{ Thread.currentThread ().setName (\"boss\"); ServerSocketChannel ssc = ServerSocketChannel.open ( ); ssc.configureBlocking (false); Selector boos = Selector.open ( ); SelectionKey boosKey = ssc.register (boos, 0, null); boosKey.interestOps (SelectionKey.OP_ACCEPT); ssc.bind (new InetSocketAddress (8080)); // 1、创建固定数量的 worker 并初始化 // Runtime.getRuntime ().availableProcessors () 处理器数量 Worker[] workers = new Worker[Runtime.getRuntime ().availableProcessors ()]; for (int i = 0; i &lt; workers.length; i++) { workers[i] = new Worker (\"WORKER-\"+i); } AtomicInteger index = new AtomicInteger (); while (true) { boos.select (); Iterator&lt;SelectionKey&gt; iter = boos.selectedKeys ( ).iterator ( ); while (iter.hasNext ( )) { SelectionKey key = iter.next ( ); iter.remove (); if (key.isAcceptable ( )) { SocketChannel sc = ssc.accept ( ); sc.configureBlocking (false); log.debug(\"connected...{}\", sc.getRemoteAddress()); // 2. 关联 selector log.debug(\"before register...{}\", sc.getRemoteAddress()); // 轮训 workers[index.getAndIncrement ()%workers.length].register (sc); log.debug(\"after register...{}\", sc.getRemoteAddress()); } } } } static class Worker implements Runnable { private Thread thread; private Selector selector; private String name; private volatile boolean start = false;// 还未初始化 private ConcurrentLinkedQueue&lt;Runnable&gt; queue = new ConcurrentLinkedQueue&lt;&gt; ( ); private Worker(String name) { this.name = name; } // 初始化线程 和 selector public void register(SocketChannel sc) throws IOException { if (!start) { selector = Selector.open ( ); thread = new Thread (this, name); thread.start ( ); start = true; } // 唤醒 select 方法 boos selector.wakeup ( ); // boos sc.register (selector, SelectionKey.OP_READ, null); } @Override public void run() { while (true) { try { selector.select ( );// worker-0 阻塞 Iterator&lt;SelectionKey&gt; iter = selector.selectedKeys ( ).iterator ( ); while (iter.hasNext ( )) { SelectionKey key = iter.next ( ); iter.remove ( ); if (key.isReadable ( )) { ByteBuffer buffer = ByteBuffer.allocate (16); SocketChannel channel = (SocketChannel) key.channel ( ); log.debug (\"read...{}\", channel.getRemoteAddress ( )); channel.read (buffer); buffer.flip ( ); debugAll (buffer); } } } catch (IOException e) { e.printStackTrace ( ); } } } } } 7、UDP UDP 是无连接的，client 发送数据不会管 server 是否开启 server 这边的 receive 方法会将接收到的数据存入 byte buffer，但如果数据报文超过 buffer 大小，多出来的数据会被默默抛弃 五、Nio vs Bio or Aio1、stream vs channel stream 不会自动缓冲数据，channel 会利用系统提供的发送缓冲区、接收缓冲区（更为底层） stream 仅支持阻塞 API，channel 同时支持阻塞、非阻塞 API，网络 channel 可配合 selector 实现多路复用 二者均为全双工，即读写可以同时进行 2、IO模型3、零拷贝3-1、传统IO问题传统的 IO 将一个文件通过 socket 写出 File f = new File(\"helloword/data.txt\"); RandomAccessFile file = new RandomAccessFile(file, \"r\"); byte[] buf = new byte[(int)f.length()]; file.read(buf); Socket socket = ...; socket.getOutputStream().write(buf); 内部工作流程是这样的： java 本身并不具备 IO 读写能力，因此 read 方法调用后，要从 java 程序的用户态切换至内核态，去调用操作系统（Kernel）的读能力，将数据读入内核缓冲区。这期间用户线程阻塞，操作系统使用 DMA（Direct Memory Access）来实现文件读，其间也不会使用 cpu DMA 也可以理解为硬件单元，用来解放 cpu 完成文件 IO 从内核态切换回用户态，将数据从内核缓冲区读入用户缓冲区（即 byte[] buf），这期间 cpu 会参与拷贝，无法利用 DMA 调用 write 方法，这时将数据从用户缓冲区（byte[] buf）写入 socket 缓冲区，cpu 会参与拷贝 接下来要向网卡写数据，这项能力 java 又不具备，因此又得从用户态切换至内核态，调用操作系统的写能力，使用 DMA 将 socket 缓冲区的数据写入网卡，不会使用 cpu 可以看到中间环节较多，java 的 IO 实际不是物理设备级别的读写，而是缓存的复制，底层的真正读写是操作系统来完成的 用户态与内核态的切换发生了 3 次，这个操作比较重量级 数据拷贝了共 4 次 3-2、NIO优化通过 DirectByteBuf ByteBuffer.allocate(10) HeapByteBuffer 使用的还是 java 内存 ByteBuffer.allocateDirect(10) DirectByteBuffer 使用的是操作系统内存 大部分步骤与优化前相同，不再赘述。唯有一点：java 可以使用 DirectByteBuf 将堆外内存映射到 jvm 内存中来直接访问使用 这块内存不受 jvm 垃圾回收的影响，因此内存地址固定，有助于 IO 读写 java 中的 DirectByteBuf 对象仅维护了此内存的虚引用，内存回收分成两步 DirectByteBuf 对象被垃圾回收，将虚引用加入引用队列 通过专门线程访问引用队列，根据虚引用释放堆外内存 减少了一次数据拷贝，用户态与内核态的切换次数没有减少 进一步优化（底层采用了 linux 2.1 后提供的 sendFile 方法），java 中对应着两个 channel 调用 transferTo/transferFrom 方法拷贝数据 java 调用 transferTo 方法后，要从 java 程序的用户态切换至内核态，使用 DMA将数据读入内核缓冲区，不会使用 cpu 数据从内核缓冲区传输到 socket 缓冲区，cpu 会参与拷贝 最后使用 DMA 将 socket 缓冲区的数据写入网卡，不会使用 cpu 可以看到 只发生了一次用户态与内核态的切换 数据拷贝了 3 次 进一步优化（linux 2.4） java 调用 transferTo 方法后，要从 java 程序的用户态切换至内核态，使用 DMA将数据读入内核缓冲区，不会使用 cpu 只会将一些 offset 和 length 信息拷入 socket 缓冲区，几乎无消耗 使用 DMA 将 内核缓冲区的数据写入网卡，不会使用 cpu 整个过程仅只发生了一次用户态与内核态的切换，数据拷贝了 2 次。所谓的【零拷贝】，并不是真正无拷贝，而是在不会拷贝重复数据到 jvm 内存中，零拷贝的优点有 更少的用户态与内核态的切换 不利用 cpu 计算，减少 cpu 缓存伪共享 零拷贝适合小文件传输 4、AIOAIO 用来解决数据复制阶段的阻塞问题 同步意味着，在进行读写操作时，线程需要等待结果，还是相当于闲置 异步意味着，在进行读写操作时，线程不必等待结果，而是将来由操作系统来通过回调方式由另外的线程来获得结果 异步模型需要底层操作系统（Kernel）提供支持 Windows 系统通过 IOCP 实现了真正的异步 IO Linux 系统异步 IO 在 2.6 版本引入，但其底层实现还是用多路复用模拟了异步 IO，性能没有优势 5、Ⅱ、Netty一、入门1、概述1、Nerry是什么Netty 是一个异步的、基于事件驱动的网络应用框架，用于快速开发可维护、高性能的网络服务器和客户端 2、优势 Netty vs NIO，工作量大，bug 多 需要自己构建协议 解决 TCP 传输问题，如粘包、半包 epoll 空轮询导致 CPU 100% 对 API 进行增强，使之更易用，如 FastThreadLocal =&gt; ThreadLocal，ByteBuff =&gt; ByteBuffer Netty vs 其它网络应用框架 Mina 由 apache 维护，将来 3.x 版本可能会有较大重构，破坏 API 向下兼容性，Netty 的开发迭代更迅速，API 更简洁、文档更优秀 久经考验，18年，Netty 版本 2.x 2004 3.x 2008 4.x 2013 5.x 已废弃（没有明显的性能提升，维护成本高） 3、地位Netty 在 Java 网络应用框架中的地位就好比：Spring 框架在 JavaEE 开发中的地位 以下的框架都使用了 Netty，因为它们有网络通信需求！ Cassandra - nosql 数据库 Spark - 大数据分布式计算框架 Hadoop - 大数据分布式存储框架 RocketMQ - ali 开源的消息队列 ElasticSearch - 搜索引擎 gRPC - rpc 框架 Dubbo - rpc 框架 Spring 5.x - flux api 完全抛弃了 tomcat ，使用 netty 作为服务器端 Zookeeper - 分布式协调框架 2、Hello World1、目标开发一个简单的服务器端和客户端 客户端向服务器端发送 hello, world 服务器仅接收，不返回 加入依赖 &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.39.Final&lt;/version&gt; &lt;/dependency&gt; 2、服务端public class Service { public static void main(String[] args) throws Exception { new ServerBootstrap ( ) .group (new NioEventLoopGroup ( )) // 1 .channel (NioServerSocketChannel.class) // 2 .childHandler (new ChannelInitializer&lt;NioSocketChannel&gt; ( ) { // 3 protected void initChannel(NioSocketChannel ch) { ch.pipeline ( ).addLast (new StringDecoder ( )); // 5 ch.pipeline ( ).addLast (new SimpleChannelInboundHandler&lt;String&gt; ( ) { // 6 @Override protected void channelRead0(ChannelHandlerContext ctx, String msg) { System.out.println (msg); } }); } }).bind (8080); // 4 } } 1 处，创建 NioEventLoopGroup，可以简单理解为 线程池 + Selector 2 处，选择服务 Scoket 实现类，其中 NioServerSocketChannel 表示基于 NIO 的服务器端实现，其它实现还有 3 处，为啥方法叫 childHandler，是接下来添加的处理器都是给 SocketChannel 用的，而不是给 ServerSocketChannel。ChannelInitializer 处理器（仅执行一次），它的作用是待客户端 SocketChannel 建立连接后，执行 initChannel 以便添加更多的处理器 4 处，ServerSocketChannel 绑定的监听端口 5 处，SocketChannel 的处理器，解码 ByteBuf =&gt; String 6 处，SocketChannel 的业务处理器，使用上一个处理器的处理结果 3、客户端public class Client { public static void main(String[] args) throws InterruptedException { new Bootstrap ( ) .group (new NioEventLoopGroup ( )) // 1 .channel (NioSocketChannel.class) // 2 .handler (new ChannelInitializer&lt;Channel&gt; ( ) { // 3 @Override protected void initChannel(Channel ch) { ch.pipeline ( ).addLast (new StringEncoder ( )); // 8 } }) .connect (\"127.0.0.1\", 8080) // 4 .sync ( ) // 5 .channel ( ) // 6 .writeAndFlush (new Date ( ) + \": hello world!\"); // 7 } } 1 处，创建 NioEventLoopGroup，同 Server 2 处，选择客户 Socket 实现类，NioSocketChannel 表示基于 NIO 的客户端实现，其它实现还有 3 处，添加 SocketChannel 的处理器，ChannelInitializer 处理器（仅执行一次），它的作用是待客户端 SocketChannel 建立连接后，执行 initChannel 以便添加更多的处理器 4 处，指定要连接的服务器和端口 5 处，Netty 中很多方法都是异步的，如 connect，这时需要使用 sync 方法等待 connect 建立连接完毕 6 处，获取 channel 对象，它即为通道抽象，可以进行数据读写操作 7 处，写入消息并清空缓冲区 8 处，消息会经过通道 handler 处理，这里是将 String =&gt; ByteBuf 发出 数据经过网络传输，到达服务器端，服务器端 5 和 6 处的 handler 先后被触发，走完一个流程 4、梳理流程 5、详细解读 把 channel 理解为数据的通道 把 msg 理解为流动的数据，最开始输入是 ByteBuf，但经过 pipeline 的加工，会变成其它类型对象，最后输出又变成 ByteBuf 把 handler 理解为数据的处理工序 工序有多道，合在一起就是 pipeline，pipeline 负责发布事件（读、读取完成…）传播给每个 handler， handler 对自己感兴趣的事件进行处理（重写了相应事件处理方法） handler 分 Inbound 和 Outbound 两类 把 eventLoop 理解为处理数据的工人 工人可以管理多个 channel 的 io 操作，并且一旦工人负责了某个 channel，就要负责到底（绑定） 工人既可以执行 io 操作，也可以进行任务处理，每位工人有任务队列，队列里可以堆放多个 channel 的待处理任务，任务分为普通任务、定时任务 工人按照 pipeline 顺序，依次按照 handler 的规划（代码）处理数据，可以为每道工序指定不同的工人 3、组件1、EventLoop事件循环对象 EventLoop 本质是一个单线程执行器（同时维护了一个 Selector），里面有 run 方法处理 Channel 上源源不断的 io 事件。 它的继承关系比较复杂 一条线是继承自 j.u.c.ScheduledExecutorService 因此包含了线程池中所有的方法 另一条线是继承自 netty 自己的 OrderedEventExecutor， 提供了 boolean inEventLoop(Thread thread) 方法判断一个线程是否属于此 EventLoop 提供了 parent 方法来看看自己属于哪个 EventLoopGroup 事件循环组 EventLoopGroup 是一组 EventLoop，Channel 一般会调用 EventLoopGroup 的 register 方法来绑定其中一个 EventLoop，后续这个 Channel 上的 io 事件都由此 EventLoop 来处理（保证了 io 事件处理时的线程安全） 继承自 netty 自己的 EventExecutorGroup 实现了 Iterable 接口提供遍历 EventLoop 的能力 另有 next 方法获取集合中下一个 EventLoop 以一个简单的实现为例： // 内部创建了两个 EventLoop, 每个 EventLoop 维护一个线程 DefaultEventLoopGroup group = new DefaultEventLoopGroup(2); System.out.println(group.next()); System.out.println(group.next()); System.out.println(group.next()); 输出 io.netty.channel.DefaultEventLoop@60f82f98 io.netty.channel.DefaultEventLoop@35f983a6 io.netty.channel.DefaultEventLoop@60f82f98 也可以使用 for 循环 DefaultEventLoopGroup group = new DefaultEventLoopGroup(2); for (EventExecutor eventLoop : group) { System.out.println(eventLoop); } 输出 io.netty.channel.DefaultEventLoop@60f82f98 io.netty.channel.DefaultEventLoop@35f983a6 io.netty.channel.DefaultEventLoop@60f82f98 io.netty.channel.DefaultEventLoop@35f983a6 💡 优雅关闭优雅关闭 shutdownGracefully 方法。该方法会首先切换 EventLoopGroup 到关闭状态从而拒绝新的任务的加入，然后在任务队列的任务都处理完成后，停止线程的运行。从而确保整体应用是在正常有序的状态下退出的 2、NioEventLoop 处理普通任务NioEventLoop 除了可以处理 io 事件，同样可以向它提交普通任务 NioEventLoopGroup nioWorkers = new NioEventLoopGroup(2); log.debug(\"server start...\"); Thread.sleep(2000); nioWorkers.execute(()-&gt;{ log.debug(\"normal task...\"); }); 输出 22:30:36 [DEBUG] [main] c.i.o.EventLoopTest2 - server start... 22:30:38 [DEBUG] [nioEventLoopGroup-2-1] c.i.o.EventLoopTest2 - normal task... 可以用来执行耗时较长的任务 3、NioEventLoop 处理定时任务NioEventLoopGroup nioWorkers = new NioEventLoopGroup(2); log.debug(\"server start...\"); Thread.sleep(2000); nioWorkers.scheduleAtFixedRate(() -&gt; { log.debug(\"running...\"); }, 0, 1, TimeUnit.SECONDS); 输出 22:35:15 [DEBUG] [main] c.i.o.EventLoopTest2 - server start... 22:35:17 [DEBUG] [nioEventLoopGroup-2-1] c.i.o.EventLoopTest2 - running... 22:35:18 [DEBUG] [nioEventLoopGroup-2-1] c.i.o.EventLoopTest2 - running... 22:35:19 [DEBUG] [nioEventLoopGroup-2-1] c.i.o.EventLoopTest2 - running... 22:35:20 [DEBUG] [nioEventLoopGroup-2-1] c.i.o.EventLoopTest2 - running... ... 可以用来执行定时任务 2、Channelchannel 的主要作用 close() 可以用来关闭 channel closeFuture() 用来处理 channel 的关闭 sync 方法作用是同步等待 channel 关闭 而 addListener 方法是异步等待 channel 关闭 pipeline() 方法添加处理器 write() 方法将数据写入 writeAndFlush() 方法将数据写入并刷出 2.1、ChannelFuture这时刚才的客户端代码 new Bootstrap() .group(new NioEventLoopGroup()) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;Channel&gt;() { @Override protected void initChannel(Channel ch) { ch.pipeline().addLast(new StringEncoder()); } }) .connect(\"127.0.0.1\", 8080) .sync() .channel() .writeAndFlush(new Date() + \": hello world!\"); 现在把它拆开来看 ChannelFuture channelFuture = new Bootstrap() .group(new NioEventLoopGroup()) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;Channel&gt;() { @Override protected void initChannel(Channel ch) { ch.pipeline().addLast(new StringEncoder()); } }) .connect(\"127.0.0.1\", 8080); // 1 channelFuture.sync().channel().writeAndFlush(new Date() + \": hello world!\"); 1 处返回的是 ChannelFuture 对象，它的作用是利用 channel() 方法来获取 Channel 对象 注意 connect 方法是异步的，意味着不等连接建立，方法执行就返回了。因此 channelFuture 对象中不能【立刻】获得到正确的 Channel 对象 实验如下： ChannelFuture channelFuture = new Bootstrap() .group(new NioEventLoopGroup()) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;Channel&gt;() { @Override protected void initChannel(Channel ch) { ch.pipeline().addLast(new StringEncoder()); } }) .connect(\"127.0.0.1\", 8080); System.out.println(channelFuture.channel()); // 1 channelFuture.sync(); // 2 System.out.println(channelFuture.channel()); // 3 执行到 1 时，连接未建立，打印 [id: 0x2e1884dd] 执行到 2 时，sync 方法是同步等待连接建立完成 执行到 3 时，连接肯定建立了，打印 [id: 0x2e1884dd, L:/127.0.0.1:57191 - R:/127.0.0.1:8080] 除了用 sync 方法可以让异步操作同步以外，还可以使用回调的方式： ChannelFuture channelFuture = new Bootstrap() .group(new NioEventLoopGroup()) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;Channel&gt;() { @Override protected void initChannel(Channel ch) { ch.pipeline().addLast(new StringEncoder()); } }) .connect(\"127.0.0.1\", 8080); System.out.println(channelFuture.channel()); // 1 channelFuture.addListener((ChannelFutureListener) future -&gt; { System.out.println(future.channel()); // 2 }); 执行到 1 时，连接未建立，打印 [id: 0x749124ba] ChannelFutureListener 会在连接建立时被调用（其中 operationComplete 方法），因此执行到 2 时，连接肯定建立了，打印 [id: 0x749124ba, L:/127.0.0.1:57351 - R:/127.0.0.1:8080] 2.2、CloseFuturepackage com.kk.netty.basice.demo2; import io.netty.bootstrap.Bootstrap; import io.netty.channel.Channel; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelFutureListener; import io.netty.channel.ChannelInitializer; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.nio.NioSocketChannel; import io.netty.handler.codec.string.StringEncoder; import java.util.Date; public class ChannelFutureTest { public static void main(String[] args) throws InterruptedException { ChannelFuture channelFuture = new Bootstrap ( ) .group (new NioEventLoopGroup ( )) .channel (NioSocketChannel.class) .handler (new ChannelInitializer&lt;Channel&gt; ( ) { @Override protected void initChannel(Channel ch) { ch.pipeline ( ).addLast (new StringEncoder ( )); } }) .connect (\"127.0.0.1\", 8080); //channelFuture.sync ( ).channel ( ).writeAndFlush (new Date ( ) + \"hello!\"); channelFuture.channel ( ).writeAndFlush (new Date ( ) + \"hello!\"); System.out.println (channelFuture.channel ( )); // channelFuture.sync (); // System.out.println (channelFuture.channel () ); channelFuture.addListener ((ChannelFutureListener) future -&gt; { System.out.println (future.channel ( )); }); } } 💡 异步提升的是什么 看到这里会有疑问：为什么不在一个线程中去执行建立连接、去执行关闭 channel，那样不是也可以吗？非要用这么复杂的异步方式：比如一个线程发起建立连接，另一个线程去真正建立连接 还有同学会笼统地回答，因为 netty 异步方式用了多线程、多线程就效率高。其实这些认识都比较片面，多线程和异步所提升的效率并不是所认为的 思考下面的场景，4 个医生给人看病，每个病人花费 20 分钟，而且医生看病的过程中是以病人为单位的，一个病人看完了，才能看下一个病人。假设病人源源不断地来，可以计算一下 4 个医生一天工作 8 小时，处理的病人总数是：4 * 8 * 3 = 96 经研究发现，看病可以细分为四个步骤，经拆分后每个步骤需要 5 分钟，如下 因此可以做如下优化，只有一开始，医生 2、3、4 分别要等待 5、10、15 分钟才能执行工作，但只要后续病人源源不断地来，他们就能够满负荷工作，并且处理病人的能力提高到了 4 * 8 * 12 效率几乎是原来的四倍 要点 单线程没法异步提高效率，必须配合多线程、多核 cpu 才能发挥异步的优势 异步并没有缩短响应时间，反而有所增加 合理进行任务拆分，也是利用异步的关键 3、Future &amp; Promise在异步处理时，经常用到这两个接口 首先要说明 netty 中的 Future 与 jdk 中的 Future 同名，但是是两个接口，netty 的 Future 继承自 jdk 的 Future，而 Promise 又对 netty Future 进行了扩展 jdk Future 只能同步等待任务结束（或成功、或失败）才能得到结果 netty Future 可以同步等待任务结束得到结果，也可以异步方式得到结果，但都是要等任务结束 netty Promise 不仅有 netty Future 的功能，而且脱离了任务独立存在，只作为两个线程间传递结果的容器 功能/名称 jdk Future netty Future Promise cancel 取消任务 - - isCanceled 任务是否取消 - - isDone 任务是否完成，不能区分成功失败 - - get 获取任务结果，阻塞等待 - - getNow - 获取任务结果，非阻塞，还未产生结果时返回 null - await - 等待任务结束，如果任务失败，不会抛异常，而是通过 isSuccess 判断 - sync - 等待任务结束，如果任务失败，抛出异常 - isSuccess - 判断任务是否成功 - cause - 获取失败信息，非阻塞，如果没有失败，返回null - addLinstener - 添加回调，异步接收结果 - setSuccess - - 设置成功结果 setFailure - - 设置失败结果 3-1、JDK-future // jdk-future public static void test() throws ExecutionException, InterruptedException { // 1.线程池 ExecutorService executorService = Executors.newFixedThreadPool (2); // 2.提交任务 Future&lt;Integer&gt; future = executorService.submit (new Callable&lt;Integer&gt; ( ) { @Override public Integer call() throws InterruptedException { log.info (\"执行计算！\"); Thread.sleep (1000); return 50; } }); // 3、主线程通过 future获取结果 log.info (\"等待结果中......\"); log.info (\"结果为：{}\", future.get ( )); } 输出 10:08:46.201 [main] INFO com.kk.netty.basice.demo2.FutureAndPromise - 等待结果中……10:08:46.201 [pool-1-thread-1] INFO com.kk.netty.basice.demo2.FutureAndPromise - 执行计算！10:08:47.205 [main] INFO com.kk.netty.basice.demo2.FutureAndPromise - 结果为：50 3-2、netty-future // netty-future() public static void test11() throws ExecutionException, InterruptedException { NioEventLoopGroup group = new NioEventLoopGroup ( ); EventLoop eventLoop = group.next ( ); Future&lt;Integer&gt; future = eventLoop.submit (new Callable&lt;Integer&gt; ( ) { @Override public Integer call() throws InterruptedException { log.info (\"执行计算！\"); Thread.sleep (1000); return 50; } }); log.info (\"等待结果中......\"); //&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;同步&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; // 控制台打印是main线程打印 // log.info (\"结果为：{}\", future.get ( )); //&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;同步&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; //&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;异步&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; future.addListener (new GenericFutureListener&lt;Future&lt;? super Integer&gt;&gt; ( ) { @Override public void operationComplete(Future&lt;? super Integer&gt; future) throws Exception { // 控制台打印是 nioEventLoopGroup 线程组打印 log.info (\"结果为：{}\", future.getNow ( )); } }); //&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;异步&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; } 10:40:10.185 [main] INFO com.kk.netty.basice.demo2.FutureAndPromise - 等待结果中……10:40:10.189 [nioEventLoopGroup-2-1] INFO com.kk.netty.basice.demo2.FutureAndPromise - 执行计算！10:40:11.190 [nioEventLoopGroup-2-1] INFO com.kk.netty.basice.demo2.FutureAndPromise - 结果为：50 3-(1-2)小结无论是juc中的 future 还是 netty 中的 future 都是来自于 juc 上面两种获取的 future 方式 都是被动返回得到的，若要主动，此时可以用 netty 中的 Promise 3.1、同步处理任务成功 DefaultEventLoop eventExecutors = new DefaultEventLoop ( ); DefaultPromise&lt;Integer&gt; promise = new DefaultPromise&lt;&gt; (eventExecutors); eventExecutors.execute (() -&gt; { try { Thread.sleep (1000); } catch (InterruptedException e) { e.printStackTrace ( ); } log.debug (\"set success, {}\", 10); promise.setSuccess (10); }); log.debug (\"start...\"); log.debug (\"getNow:{}\", promise.getNow ( )); // 还没有结果 log.debug (\"get:{}\", promise.get ( )); } 输出 17:15:38.604 [main] DEBUG com.kk.netty.basice.demo2.FutureAndPromise - start…17:15:38.604 [main] DEBUG com.kk.netty.basice.demo2.FutureAndPromise - getNow:null17:15:39.605 [defaultEventLoop-1-1] DEBUG com.kk.netty.basice.demo2.FutureAndPromise - set success, 1017:15:39.605 [main] DEBUG com.kk.netty.basice.demo2.FutureAndPromise - get:10 3.2、异步处理任务成功DefaultEventLoop eventExecutors = new DefaultEventLoop ( ); DefaultPromise&lt;Integer&gt; promise = new DefaultPromise&lt;&gt; (eventExecutors); // 设置回调，异步接收结果 promise.addListener (future -&gt; { // 这里的 future 就是上面的 promise log.debug (\"getNow:{}\", future.getNow ( )); }); eventExecutors.execute (() -&gt; { try { Thread.sleep (1000); } catch (InterruptedException e) { e.printStackTrace ( ); } log.debug (\"set success, {}\", 10); promise.setSuccess (10); }); log.debug (\"start...\"); 输出 11:49:30 [DEBUG] [main] c.i.o.DefaultPromiseTest2 - start…11:49:31 [DEBUG] [defaultEventLoop-1-1] c.i.o.DefaultPromiseTest2 - set success, 1011:49:31 [DEBUG] [defaultEventLoop-1-1] c.i.o.DefaultPromiseTest2 - 10 3.3、同步处理任务失败 - sync &amp; getDefaultEventLoop eventExecutors = new DefaultEventLoop ( ); DefaultPromise&lt;Integer&gt; promise = new DefaultPromise&lt;&gt; (eventExecutors); eventExecutors.execute (() -&gt; { try { Thread.sleep (1000); } catch (InterruptedException e) { e.printStackTrace ( ); } RuntimeException e = new RuntimeException (\"error...\"); log.debug (\"set failure, {}\", e.toString ( )); promise.setFailure (e); }); log.debug (\"start...\"); log.debug (\"getNow:{}\", promise.getNow ( )); promise.get ( ); // sync() 也会出现异常，只是 get 会再用 ExecutionException 包一层异常 输出 12:11:07 [DEBUG] [main] c.i.o.DefaultPromiseTest2 - start…12:11:07 [DEBUG] [main] c.i.o.DefaultPromiseTest2 - null12:11:08 [DEBUG] [defaultEventLoop-1-1] c.i.o.DefaultPromiseTest2 - set failure, java.lang.RuntimeException: error…Exception in thread “main” java.util.concurrent.ExecutionException: java.lang.RuntimeException: error… at io.netty.util.concurrent.AbstractFuture.get(AbstractFuture.java:41) at com.itcast.oio.DefaultPromiseTest2.main(DefaultPromiseTest2.java:34)Caused by: java.lang.RuntimeException: error… at com.itcast.oio.DefaultPromiseTest2.lambda$main$0(DefaultPromiseTest2.java:27) at io.netty.channel.DefaultEventLoop.run(DefaultEventLoop.java:54) at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:745) 3.4、同步处理任务失败 - awaitDefaultEventLoop eventExecutors = new DefaultEventLoop ( ); DefaultPromise&lt;Integer&gt; promise = new DefaultPromise&lt;&gt; (eventExecutors); eventExecutors.execute (() -&gt; { try { Thread.sleep (1000); } catch (InterruptedException e) { e.printStackTrace ( ); } RuntimeException e = new RuntimeException (\"error...\"); log.debug (\"set failure, {}\", e.toString ( )); promise.setFailure (e); }); log.debug (\"start...\"); log.debug (\"getNow:{}\", promise.getNow ( )); promise.await ( ); // 与 sync 和 get 区别在于，不会抛异常 log.debug (\"result {}\", (promise.isSuccess ( ) ? promise.getNow ( ) : promise.cause ( )).toString ( )); 输出 12:18:53 [DEBUG] [main] c.i.o.DefaultPromiseTest2 - start…12:18:53 [DEBUG] [main] c.i.o.DefaultPromiseTest2 - null12:18:54 [DEBUG] [defaultEventLoop-1-1] c.i.o.DefaultPromiseTest2 - set failure, java.lang.RuntimeException: error…12:18:54 [DEBUG] [main] c.i.o.DefaultPromiseTest2 - result java.lang.RuntimeException: error… 3.5、异步处理任务失败DefaultEventLoop eventExecutors = new DefaultEventLoop ( ); DefaultPromise&lt;Integer&gt; promise = new DefaultPromise&lt;&gt; (eventExecutors); promise.addListener (future -&gt; { log.debug (\"result {}\", (promise.isSuccess ( ) ? promise.getNow ( ) : promise.cause ( )).toString ( )); }); eventExecutors.execute (() -&gt; { try { Thread.sleep (1000); } catch (InterruptedException e) { e.printStackTrace ( ); } RuntimeException e = new RuntimeException (\"error...\"); log.debug (\"set failure, {}\", e.toString ( )); promise.setFailure (e); }); log.debug (\"start...\"); 输出 12:04:57 [DEBUG] [main] c.i.o.DefaultPromiseTest2 - start…12:04:58 [DEBUG] [defaultEventLoop-1-1] c.i.o.DefaultPromiseTest2 - set failure, java.lang.RuntimeException: error…12:04:58 [DEBUG] [defaultEventLoop-1-1] c.i.o.DefaultPromiseTest2 - result java.lang.RuntimeException: error… 3.6、await 死锁检查DefaultEventLoop eventExecutors = new DefaultEventLoop ( ); DefaultPromise&lt;Integer&gt; promise = new DefaultPromise&lt;&gt; (eventExecutors); eventExecutors.submit (() -&gt; { System.out.println (\"1\"); try { promise.await ( ); // 注意不能仅捕获 InterruptedException 异常 // 否则 死锁检查抛出的 BlockingOperationException 会继续向上传播 // 而提交的任务会被包装为 PromiseTask，它的 run 方法中会 catch 所有异常然后设置为 Promise 的失败结果而不会抛出 } catch (Exception e) { e.printStackTrace ( ); } System.out.println (\"2\"); }); eventExecutors.submit (() -&gt; { System.out.println (\"3\"); try { promise.await ( ); } catch (Exception e) { e.printStackTrace ( ); } System.out.println (\"4\"); }); 输出 1234io.netty.util.concurrent.BlockingOperationException: DefaultPromise@47499c2a(incomplete)at io.netty.util.concurrent.DefaultPromise.checkDeadLock(DefaultPromise.java:384) 4、Handler &amp; PipelineChannelHandler 用来处理 Channel 上的各种事件，分为入栈、出栈两种。所有 ChannelHandler 被连成一串，就是 Pipeline 入站处理器通常是 ChannelInboundHandlerAdapter 的子类，主要用来读取客户端数据，写回结果 出站处理器通常是 ChannelOutboundHandlerAdapter 的子类，主要对写回结果进行加工 打个比喻，每个 Channel 是一个产品的加工车间，Pipeline 是车间中的流水线，ChannelHandler 就是流水线上的各道工序，而后面要讲的 ByteBuf 是原材料，经过很多工序的加工：先经过一道道入站工序，再经过一道道出站工序最终变成产品 先搞清楚顺序，服务端 new ServerBootstrap() .group(new NioEventLoopGroup()) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() { protected void initChannel(NioSocketChannel ch) { ch.pipeline().addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) { System.out.println(1); ctx.fireChannelRead(msg); // 1 } }); ch.pipeline().addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) { System.out.println(2); ctx.fireChannelRead(msg); // 2 } }); ch.pipeline().addLast(new ChannelInboundHandlerAdapter(){ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) { System.out.println(3); ctx.channel().write(msg); // 3 } }); ch.pipeline().addLast(new ChannelOutboundHandlerAdapter(){ @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) { System.out.println(4); ctx.write(msg, promise); // 4 } }); ch.pipeline().addLast(new ChannelOutboundHandlerAdapter(){ @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) { System.out.println(5); ctx.write(msg, promise); // 5 } }); ch.pipeline().addLast(new ChannelOutboundHandlerAdapter(){ @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) { System.out.println(6); ctx.write(msg, promise); // 6 } }); } }) .bind(8080); 客户端 new Bootstrap() .group(new NioEventLoopGroup()) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;Channel&gt;() { @Override protected void initChannel(Channel ch) { ch.pipeline().addLast(new StringEncoder()); } }) .connect(\"127.0.0.1\", 8080) .addListener((ChannelFutureListener) future -&gt; { future.channel().writeAndFlush(\"hello,world\"); }); 服务器端打印： 1 2 3 6 5 4 二、进阶1、2、3、三、源码1、2、3、Ⅲ、常识（面试）1、多线程缺点 内存占用高 线程上下文切换成本高 只适合连接数少的场景 2、线程池缺点 阻塞模式下，线程仅能处理一个 socket 连接 仅适合短连接场景 3、FileChannel 工作模式FileChannel 只能工作在阻塞模式下 4、5、6、7、8、参考文献 ↓try 1.7 ：https://blog.csdn.net/renvictory/article/details/108844745","categories":[{"name":"内力篇","slug":"内力篇","permalink":"https://mykkto.github.io/categories/%E5%86%85%E5%8A%9B%E7%AF%87/"}],"tags":[{"name":"netty","slug":"netty","permalink":"https://mykkto.github.io/tags/netty/"},{"name":"nio","slug":"nio","permalink":"https://mykkto.github.io/tags/nio/"},{"name":"网络编程","slug":"网络编程","permalink":"https://mykkto.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"}],"author":"mykk"},{"title":"随性记录一小点 2021-07-15至未来","slug":"00-blog/00_散列随手记","date":"2022-08-05T15:21:33.000Z","updated":"2023-04-22T12:44:06.463Z","comments":true,"path":"posts/cfd1312a.html","link":"","permalink":"https://mykkto.github.io/posts/cfd1312a.html","excerpt":"","text":"————简书原始地址————2021年07月15日pl/sql客户端bug 切换的用户的时候，会串掉（意思是显示上切换了，其实并没有）解决方案：必须重启客户端，切换用户 2021年07月26日idea git 小姿势，本地库拖回 2021年07月28日oracle 小知识：不小心删除了一张表数据，怎么办呢？ select * from 表名 as of timestamp sysdate-1/12 //查询两个小时前的删除的某张表 2021年08月22日并行：多个任务在同一时间点发生，并由不同的cpu进行处理，不互相抢占资源并发：多个任务在同一时间点内同时发生了，但由同一个cpu进行处理，互相抢占资源文章推荐：https://www.cnblogs.com/iamqiyue/p/14184769.html 2021年08月30日jsp 用0做字段状态，列表会出问题，会有默认值 2021年09月07日easyUI 嵌套对话框问题，对话框A弹出对话框B，A无法关闭。需要在A的关闭回调 打开B，也就是关闭A不能和打开B 写在一起，必须关闭A调用A的关闭回调之后再打开B。 2021年09月14日oracle 11g分组案例：1、group by user_id,PUNCH_DATE：通过用户id和日期分组2、listagg( TIME_INTERVAL ,’,’) within group (order by id) ：需要展示的字段（没有纳入分组规则的），order by id 通过 id 排序，或者可以自定义一个排序字段 select d.id,u.User_Id,u.User_Name,d.Punch_Date,d.Punch_Time,de.Dept_Name,d.time,d.remark,d.status,d.TIME_INTERVAL,d.PUNCH_STATUS from (select user_id,PUNCH_DATE， listagg( TIME_INTERVAL ,',') within group (order by id) as TIME_INTERVAL, listagg( STATUS,',') within group(order by id) as STATUS, listagg( id ,',') within group(order by id) as id, listagg( REMARK ,',') within group(order by id) as REMARK, listagg( PUNCH_TIME ,',') within group(order by id) as PUNCH_TIME, listagg( PUNCH_STATUS ,',') within group(order by id) as PUNCH_STATUS, listagg( time ,',') within group(order by id) as time from KQ_PUNCH_DAILY group by user_id,PUNCH_DATE) d inner join tbl_sys_user u on d.User_Id=u.USER_ID inner join tbl_sys_department de on de.dept_id=u.dept_id 2021年09月23日一、oracle 11g 存储过程分割字符串案例：纯分割 测试代码（先运行存储过程代码） SELECT * FROM TABLE( FUNC_ISM_GETSPLITSTR('_FUNC_CTP_LG_GEsss_s_ssssTSPNG_', '_')); 先创建变量 --创建变量 CREATE OR REPLACE TYPE \"ARRYTYPE1\" IS VARRAY(10000) OF VARCHAR(2000); 存储过程代码 CREATE OR REPLACE FUNCTION FUNC_ISM_GETSPLITSTR ( in_str IN VARCHAR2, --需分割的字符串 in_split IN VARCHAR2 --分隔符 ) RETURN arrytype1 AS v_count1 INTEGER; v_count2 INTEGER; v_strlist arrytype1; v_node VARCHAR2 (2000); BEGIN v_count2 := 0; v_strlist := arrytype1 (); IF (in_str IS NULL) OR (LENGTH (in_str) &lt;= 0) THEN RETURN NULL; END IF; FOR v_i IN 1 .. LENGTH (in_str) LOOP v_count1 := INSTRB (in_str, in_split, 1, v_i); v_count2 := INSTRB (in_str, in_split, 1, v_i + 1); v_node := SUBSTRB (in_str, v_count1 + 1, v_count2 - v_count1 - 1); IF v_node IS NULL THEN v_node := ''; END IF; IF (v_count2 = 0) OR (v_count2 IS NULL) THEN EXIT; ELSE v_strlist.EXTEND (); v_strlist (v_i) := v_node; v_node := ''; END IF; END LOOP; RETURN v_strlist; END FUNC_ISM_GETSPLITSTR; 输出结果 二、oracle 11g 存储过程分割字符串案例：分割+判断编写语句 CREATE OR REPLACE FUNCTION FUNC_ISM_GETSPLITSTR2 (-- 最终返回 1 发起部门，2 主办部门，3 协办部门 -- 写法存在一个问题，需要在开始节点和结束节点加上分隔符否则娶不到 -- _FUNC_CTP_LG_GEsss_s_ssssTSPNG_ 类似 这种格式 in_str IN VARCHAR2, --需分割的字符串 in_split IN VARCHAR2 --分隔符 ) RETURN VARCHAR2 AS v_count1 INTEGER; v_count2 INTEGER; v_count3 INTEGER;--计数器 v_node VARCHAR2 (2000); v_result VARCHAR2 (2000); v_resulttep VARCHAR2 (2000); in_strtep VARCHAR2 (2000); BEGIN in_strtep := in_split||in_str||in_split; v_count2 := 0; v_count3 := 0; v_result := '1'; v_resulttep :=''; IF (in_strtep IS NULL) OR (LENGTH (in_strtep) &lt;= 0) THEN RETURN NULL; END IF; FOR v_i IN 1 .. LENGTH (in_strtep) LOOP v_count1 := INSTRB (in_strtep, in_split, 1, v_i); v_count2 := INSTRB (in_strtep, in_split, 1, v_i + 1); v_node := SUBSTRB (in_strtep, v_count1 + 1, v_count2 - v_count1 - 1); IF v_node IS NULL THEN v_node := ''; elsif (v_node= '2') then v_count3 := v_count3 +1 ;-- 记得对节点判空，写在后头 ELSE v_resulttep := v_resulttep || v_node; END IF; IF (v_count2 = 0) OR (v_count2 IS NULL) THEN EXIT; ELSE v_strlist.EXTEND (); v_strlist (v_i) := v_node; v_node := ''; END IF; END LOOP; if ((LENGTH (in_str)-1)/2+1 = v_count3) then v_result := '2';END IF; RETURN v_result; END FUNC_ISM_GETSPLITSTR2; 结果对比输出：如果有一个 1所有都是1 ，如果 所有为 2 才能全部为2 三、单条SQL 映射输出（需要注意的是：不能是多条结果集，这个只是单条，接受类型为 varchar2 ） CREATE OR REPLACE FUNCTION \"FUNC_ISM_GETSPLITSTR2_TODAY2\" (-- 计算加3天后（跳过非同昨日），得到实际的 日期） -- 写法存在一个问题，需要在开始节点和结束节点加上分隔符否则娶不到 -- _FUNC_CTP_LG_GEsss_s_ssssTSPNG_ 类似 这种格式 in_str IN VARCHAR2 --需要被计算的日期 ) RETURN VARCHAR2 AS in_result VARCHAR2 (4000);-- in_temp VARCHAR2 (4000); in_year VARCHAR2 (4000); in_month VARCHAR2 (4000); in_day VARCHAR2 (4000); BEGIN in_temp := SUBSTR(in_str,1,4);sql select ID into in_result from TBL_TASKS_PERSONAL_SIDE WHERE ID='402881e57c968139017c969805df00d9'; RETURN in_temp; END FUNC_ISM_GETSPLITSTR2_TODAY2; 测试代码：SELECT FUNC_ISM_GETSPLITSTR2_TODAY2('2021-04-22') as aaa FROM TBL_TASKS_PERSONAL_MAIN ORACLE 存储过程INTO 多个变量 select f1,f2,f3 into v1,v2,v3 from tab1 2021年09月29日有的时候Java catch 用 e.getStackTrace ( );不出异常栈信息，可以使用e.printStackTrace ( );解决 2021年10月26日（1）oracle 分页 select * from ( select A.*,ROWNUM RN from ( SELECT * from DEP_TASK_VIEW) A where 1=1 and ROWNUM &lt;=10 ) WHERE RN &gt;= 1 （2）不仅如此 RN还可以当做唯一记录数ID使用，因视图合并出来的数据ID不是唯一的 select * from ( select A.*,ROWNUM RN from ( SELECT * from DEP_TASK_VIEW) A where 1=1 and ROWNUM &lt;=10 ) WHERE RN &gt;= 1 and RN in (2,3,5) 2021年10月29日日期期限计算节假日的存储过程，套用两个视图（1）函数 CREATE OR REPLACE FUNCTION \"FUNC_ISM_GETSPLITSTR2_TODAY2\" (-- 计算加3天后（跳过非同昨日），得到实际的 日期）才有该跳的第三条记录获取，而不是日期直接+3，筛选出只有工作日 in_str IN VARCHAR2 --需要被计算的日期 ) RETURN VARCHAR2 AS in_result VARCHAR2 (4000);-- 最终结果 in_temp VARCHAR2 (4000);-- 辅助筛选年 in_temp2 NUMBER;-- 辅助筛选年 +1 in_temp3 VARCHAR2 (4000);-- 辅助筛选月 in_temp33 NUMBER;-- 辅助筛选月 --处理精度 in_temp4 VARCHAR2 (4000);-- 辅助筛选日 in_temp44 NUMBER;-- 辅助筛选日 --处理精度 in_year VARCHAR2 (4000);--计算的年 in_month VARCHAR2 (4000);--计算的月 in_day VARCHAR2 (4000);--计算的日 in_rn1 VARCHAR2 (4000);--先找到词条日历的rownum,然后加3的记录数就是 in_rn12 VARCHAR2 (4000);-- 词条二（最终的），配合视图二 in_rn122 NUMBER; in_time VARCHAR2 (4000);-- 后缀的时间 BEGIN in_temp := SUBSTR(in_str,1,4); in_temp2 := \"TO_NUMBER\"(in_temp)+1; in_temp3 := SUBSTR(in_str,6,2); in_temp33 := \"TO_NUMBER\"(in_temp3); in_temp4 := SUBSTR(in_str,9,2); in_temp44 := \"TO_NUMBER\"(in_temp4); in_time := SUBSTR(in_str,11,99); SELECT RNN into in_rn1 from TASK_TEMP_DAY1 WHERE CALYEAR = in_temp AND CALENDAR_MONTH = in_temp33 AND CALENDAR_DAY = in_temp44; SELECT RNN2 into in_rn12 from TASK_TEMP_DAY2 WHERE RNN = in_rn1; in_rn122 := \"TO_NUMBER\"(in_rn12)+3; SELECT CALYEAR,CALENDAR_MONTH,CALENDAR_DAY into in_year,in_month,in_day from TASK_TEMP_DAY2 WHERE RNN2 = in_rn122; in_result := in_year||'-'; IF(in_month&lt;10) THEN in_result := in_result || '0'||in_month||'-'; ELSE in_result := in_result ||in_month||'-'; END IF; IF(in_day&lt;10) THEN in_result := in_result || '0'||in_day; ELSE in_result := in_result ||in_day; END IF; in_result := in_result ||in_time; RETURN in_result; END FUNC_ISM_GETSPLITSTR2_TODAY2; （2）TASK_TEMP_DAY1 SELECT ROWNUM RNN, \"CALYEAR\", \"ID\", \"CALENDAR_ID\", \"CALENDAR_MONTH\", \"CALENDAR_DAY\", \"CALENDAR_DATE_TYPE\", \"CALENDAR_MODIFY_PERSON\", \"CALENDAR_MODIFY_TIME\", \"BLANK0\", \"BLANK1\" FROM ( SELECT DE.*, CA.CALENDAR_YEAR CALYEAR FROM KQ_CALENDAR CA INNER JOIN KQ_CALENDAR_DETAIL DE ON CA.CALENDAR_ID = DE.CALENDAR_ID WHERE 1 = 1 AND CA.CALENDAR_CREATOR = '4028811d7057520301705756b3ca0050' ORDER BY CA.CALENDAR_YEAR ASC, DE.CALENDAR_MONTH ASC, DE.CALENDAR_DAY ASC ) -- 工作任务逾期计算节假日配合函数的视图(被查询的视图) （3）TASK_TEMP_DAY2 SELECT ROWNUM RNN2, \"RNN\", \"CALYEAR\", \"ID\", \"CALENDAR_ID\", \"CALENDAR_MONTH\", \"CALENDAR_DAY\", \"CALENDAR_DATE_TYPE\", \"CALENDAR_MODIFY_PERSON\", \"CALENDAR_MODIFY_TIME\", \"BLANK0\", \"BLANK1\" FROM TASK_TEMP_DAY1 WHERE CALENDAR_DATE_TYPE = '0' -- 工作任务逾期计算节假日配合函数的视图(被计算的视图) 2021年11月04日oracle 11g 写存储过程报错：ORA-00972 identifier is too long原因存储过程的命名过长，改短即可。 2021年11月05日oracle 11g 写存储过程 拼接单引号转义问题： in_str := '1'; -- 输出 1 in_str := '''1'''; -- 输出 '1' 2021年11月05日oracle 11g 写存储过程 SQL字符串 运行后赋值： v_idsaaa := SUBSTR(v_idsaaa,1,\"LENGTH\"(v_idsaaa)-1); in_timesiov := 'SELECT createTe_ from (SELECT listagg (createTe_, '','') WITHIN GROUP (ORDER BY ID_) AS createTe_ from ( select TO_CHAR ( create_, ''yyyy-mm-dd hh24:mi:ss'' ) createTe_ ,COMMITUSERID_,BUSINESSID_,NAME_,ID_ from jbpm_taskinstance WHERE BUSINESSID_=''402881f47ce4b52d017ce4bc73d30026'' and NAME_ =''进程1'' and COMMITUSERID_ in ('||v_idsaaa||')) GROUP BY BUSINESSID_,NAME_)' ; execute immediate in_timesiov into v_flag; -- execute immediate 用于执行 SQL语句 -- in_timesiov 是拼接出来的SQL语句 -- v_flag 接收语句返回的数据 2021年11月15日记录一个 echarts 柱形图的坑（1）渲染key的时候如果是整个数组过来，就会变成一坨 xAxis: { //data: [\"一般\",\"好\",\"非常好\"] data: dataKeyList }, （2）所以要使用遍历出来 xAxis: { data: [\"一般\",\"好\",\"非常好\"] }, 2021年11月30日SQL 自定义排序 select * from tbl_duty_user decode(u.postType,'1',4,'2',3,'3',2,'4',1) asc oracle 字段已逗号隔开分解为多条数据 https://blog.csdn.net/sofeien/article/details/80534557 No row with the given identifier exists: [com.jh.jcs.business.duty.model.TblDutyDetail#402881e57c7df2e5017c7df8d7c20138] HQL多對一脏数据问题 2021年12月13日关于SQL 搜索时间日期范围不可用 or String hql2 = \"from KqPunchDaily where punchDate like '%\" + DailyUtil.sameMonth ( )+ \"%' or punchDate like '%\" + DailyUtil.lastMonth ( )+ \"%' and punchStatus !=0 and userId in (\"+idstemp+\") \"; 以上3w数据要用 beginTime ，或者 &gt;, &lt;锁定范围时间 String hql1 = \"from KqLeaveForm where beginTime BETWEEN '\" + DailyUtil.sameMonth ( ) + \"' and '\" + DailyUtil.lastMonth ( ) + \"' and status ='1' and deptId = '\"+deptId+\"' \"; 2021年12月17日pl/SQL客户端乱码https://blog.csdn.net/gm371200587/article/details/81381825 2021年12月17日oracle合并表函数 Union：对两个结果集进行并集操作，不包括重复行，同时进行默认规则的排序； Union All：对两个结果集进行并集操作，包括重复行，不进行排序； Intersect：对两个结果集进行交集操作，不包括重复行，同时进行默认规则的排序； Minus：对两个结果集进行差操作，不包括重复行，同时进行默认规则的排序。 2021年12月20日定制排序：表，学生根据性别排序，如果是男的根据年龄升序，如果是女的根据体重desc，男的排在女的前面 order by 性别，case when 性别=男 then 年龄 end,case when 性别=女 then 体重 end desc ###参考博客https://www.cnblogs.com/sunice/p/10436725.html 2022-08-01dea sql 未连接检查 爆红取消样式配置：https://blog.csdn.net/a907691592/article/details/94724090 idea 自动生成序列号：https://www.jianshu.com/p/b4807c3efcb6 idea 配置 包排序– sort by type idea 书签技巧：https://www.studyweb.cn/detail/java_174180.html oracle 字符串分割：https://blog.csdn.net/qq_40230848/article/details/123417714 oracle 长字符串无法插入问题： https://blog.csdn.net/weixin_46266448/article/details/124351040 https://www.ssfiction.com/sqljc/630238.html 执行注意再 update 后面加 commit; 2022-08-21idea调试小技巧，evaluate：https://blog.csdn.net/xue_xiaofei/article/details/113197181 2022-11-05今天在做blog 静态移植，遇到一条linux 命令（删除子文件，除了某个文件和文件夹） rm -rf !(static|rmnotstatic.sh) 这条会删除当前目录的所有，除了括号中的文件和文件夹，运行没问题，但是放到 shell 脚本中 [root@VM-4-7-centos www]# sh rmnotstatic.sh rmnotstatic.sh: line 2: syntax error near unexpected token `(' rmnotstatic.sh: line 2: `rm -rf !(static|mnotstatic.sh)' 这个意思是：意外标记“（”附近出现语法错误，但是语法是没错的，猜想应该是没有转义，于是改成 #!/bin/bash rm -rf !\\(static\\|rmnotstatic.sh\\) 就可以！ 2022-11-22tnsnames.ora 文件解析说明： DB_NAME= (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = IP)(PORT = 端口号)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = 实例名称) ) ) 最终等于：ip 端口/实例名称 参考：https://www.cnblogs.com/wml-it/p/15175753.html 2022-11-23mybatis 声明实体字段注解用 @tablefield 不要用jdk的@cloumn 2022-12-20springboot集成nutzdao :https://www.codenong.com/cs106644689/ nutz扩展文档：https://www.wenjiangs.com/doc/nutz-dao-create nutz本地，maven本地引用jar：http://t.zoukankan.com/iceywu-p-12284695.htmlhttps://blog.csdn.net/weixin_43606226/article/details/124021874 2022-12-21idea sql表爆红解决：https://blog.csdn.net/qq_62497280/article/details/123741808 散装的疑难杂症1、链路A没问题，链路C没问题，完整ABC有问题，在没有日志可以看的情况下，考虑是否A异步，延迟，导致C拿不到A链路应该提供给C的消息（关于第三方交互延迟也需要考虑，特别是遇到异步的情况下） 2、新接口A慢，原始接口A快，考虑是否哪里有定时刷新缓存了一些数据","categories":[{"name":"docker","slug":"docker","permalink":"https://mykkto.github.io/categories/docker/"}],"tags":[{"name":"技术","slug":"技术","permalink":"https://mykkto.github.io/tags/%E6%8A%80%E6%9C%AF/"},{"name":"记录","slug":"记录","permalink":"https://mykkto.github.io/tags/%E8%AE%B0%E5%BD%95/"}],"author":"mykk"},{"title":"docker 操作篇","slug":"03-java分布式/02-容器/02_docker实操篇","date":"2022-07-05T15:17:13.000Z","updated":"2022-11-12T15:07:08.072Z","comments":true,"path":"posts/abdfa13a.html","link":"","permalink":"https://mykkto.github.io/posts/abdfa13a.html","excerpt":"","text":"————————— Docker 部署篇 ————————–〇、本章源代码https://gitee.com/TK_LIMR/springcloud2021To2021.git Ⅰ、DockerFile一、是什么1、官网https://docs.docker.com/engine/reference/builder 2、概述Dockerfile是用来构建Docker镜像的文本文件，是由一条条构建镜像所需的指令和参数构成的脚本。 3、步骤 编写Dockerfile文件 docker build命令构建镜像 docker run依镜像运行容器实例 二、DockerFile构建过程解析1、Dockerfile内容基础知识 每条保留字指令都必须为大写字母且后面要跟随至少一个参数 指令按照从上到下，顺序执行 #表示注释 每条指令都会创建一个新的镜像层并对镜像进行提交 2、Docker执行Dockerfile的大致流程 docker从基础镜像运行一个容器 执行一条指令并对容器作出修改 执行类似docker commit的操作提交一个新的镜像层 docker再基于刚提交的镜像运行一个新容器 执行dockerfile中的下一条指令直到所有指令都执行完成 3、小总结从应用软件的角度来看，Dockerfile、Docker镜像与Docker容器分别代表软件的三个不同阶段， Dockerfile是软件的原材料 Docker镜像是软件的交付品 Docker容器则可以认为是软件镜像的运行态，也即依照镜像运行的容器实例 Dockerfile面向开发，Docker镜像成为交付标准，Docker容器则涉及部署与运维，三者缺一不可，合力充当Docker体系的基石。 Dockerfile，需要定义一个Dockerfile，Dockerfile定义了进程需要的一切东西。Dockerfile涉及的内容包括执行代码或者是文件、环境变量、依赖包、运行时环境、动态链接库、操作系统的发行版、服务进程和内核进程(当应用进程需要和系统服务和内核进程打交道，这时需要考虑如何设计namespace的权限控制)等等; Docker镜像，在用Dockerfile定义一个文件之后，docker build时会产生一个Docker镜像，当运行 Docker镜像时会真正开始提供服务; Docker容器，容器是直接提供服务的。 三、DockerFile常用保留字指令 FROM：基础镜像，当前新镜像是基于哪个镜像的，指定一个已经存在的镜像作为模板，第一条必须是from MAINTAINER：镜像维护者的姓名和邮箱地址 RUN：容器构建时需要运行的命令，RUN是在 docker build时运行 shell格式：RUN yum -y install vim exec格式： EXPOSE：当前容器对外暴露出的端口 WORKDIR：指定在创建容器后，终端默认登陆的进来工作目录，一个落脚点 USER：指定该镜像以什么样的用户去执行，如果都不指定，默认是root ENV：用来在构建镜像过程中设置环境变量 ENV MY_PATH /usr/mytest 这个环境变量可以在后续的任何RUN指令中使用，这就如同在命令前面指定了环境变量前缀一样；也可以在其它指令中直接使用这些环境变量 比如：WORKDIR $MY_PATH ADD：将宿主机目录下的文件拷贝进镜像且会自动处理URL和解压tar压缩包 COPY：类似ADD，拷贝文件和目录到镜像中。将从构建上下文目录中 &lt;源路径&gt; 的文件/目录复制到新的一层的镜像内的 &lt;目标路径&gt; 位置 COPY src dest COPY [“src”, “dest”] &lt;src源路径&gt;：源文件或者源目录 &lt;dest目标路径&gt;：容器内的指定路径，该路径不用事先建好，路径不存在的话，会自动创建。 VOLUME：容器数据卷，用于数据保存和持久化工作 CMD：指定容器启动后的要干的事情 注意： Dockerfile 中可以有多个 CMD 指令，但只有最后一个生效，CMD 会被 docker run 之后的参数替换 它和前面RUN命令的区别 CMD是在docker run 时运行。 RUN是在 docker build时运行。 ENTRYPOINT：也是用来指定一个容器启动时要运行的命令 类似于 CMD 指令，但是ENTRYPOINT不会被docker run后面的命令覆盖，而且这些命令行参数会被当作参数送给 ENTRYPOINT 指令指定的程序 小总结 四、案例1、自定义镜像myCentosJava81、要求Centos7镜像具备vim+ifconfig+jdk8 准备：JDK8下载位置 https://mirrors.yangxingzhen.com/jdk/ 2、编写FROM centos:7 MAINTAINER jack&lt;mykkto.cn&gt; ENV MYPATH /usr/local WORKDIR $MYPATH #安装vim编辑器 RUN yum -y install vim #安装ifconfig命令查看网络IP RUN yum -y install net-tools #安装java8及lib库 RUN yum -y install glibc.i686 RUN mkdir /usr/local/java #ADD 是相对路径jar,把jdk-8u171-linux-x64.tar.gz添加到容器中,安装包必须要和Dockerfile文件在同一位置 ADD jdk-8u171-linux-x64.tar.gz /usr/local/java/ #配置java环境变量 ENV JAVA_HOME /usr/local/java/jdk1.8.0_171 ENV JRE_HOME $JAVA_HOME/jre ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATH ENV PATH $JAVA_HOME/bin:$PATH EXPOSE 80 CMD echo $MYPATH CMD echo \"success--------------ok\" CMD /bin/bash 3、构建docker build -t 新镜像名字:TAG docker build -t centosjava8:1.5 . 注意：上面TAG后面有个空格，有个点 命令： 成功： 4、运行docker run -it 新镜像名字:TAG docker run -it centosjava8:1.5 /bin/bash 5、总结UnionFS（联合文件系统）：Union文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下(unite several directories into a single virtual filesystem)。Union 文件系统是 Docker 镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。 特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录 2、虚悬镜像1、是什么仓库名、标签都是的镜像，俗称dangling image 写一个 2、查看docker image ls -f dangling=true 3、删除docker image prune 虚悬镜像已经失去存在价值，可以删 五、总结 Ⅱ、Docker 网络一、是什么1、默认docker不启动，默认网络情况 2、启动docker启动后，网络情况 二、命令1、All命令 2、主查看网络docker network ls 3、查看网络源数据docker network inspect XXX网络名字 4、删除网络docker network rm XXX网络名字 5、案例 三、能干嘛 容器间的互联和通信以及端口映射 容器IP变动时候可以通过服务名直接网络通信而不受到影响 四、网络模式1、列表1、是什么 bridge模式：使用–network bridge指定，默认使用docker0 host模式：使用–network host指定 none模式：使用–network none指定 container模式：使用–network container:NAME或者容器ID指定 2、规则docker容器内部的ip是有可能会发生改变的 说明 1、启动两个容器说明 2、docker inspect 容器ID or 容器名字 3、案例：3-1、bridge1、是什么Docker 服务默认会创建一个 docker0 网桥（其上有一个 docker0 内部接口），该桥接网络的名称为docker0，它在内核层连通了其他的物理或虚拟网卡，这就将所有容器和本地主机都放到同一个物理网络。Docker 默认指定了 docker0 接口 的 IP 地址和子网掩码，让主机和容器之间可以通过网桥相互通信。 #查看 bridge 网络的详细信息，并通过 grep 获取名称项 docker network inspect bridge | grep name ifconfig | grep docker 2、案例(1）说明： Docker使用Linux桥接，在宿主机虚拟一个Docker容器网桥(docker0)，Docker启动一个容器时会根据Docker网桥的网段分配给容器一个IP地址，称为Container-IP，同时Docker网桥是每个容器的默认网关。因为在同一宿主机内的容器都接入同一个网桥，这样容器之间就能够通过容器的Container-IP直接通信。 docker run 的时候，没有指定network的话默认使用的网桥模式就是bridge，使用的就是docker0。在宿主机ifconfig,就可以看到docker0和自己create的network(后面讲)eth0，eth1，eth2……代表网卡一，网卡二，网卡三……，lo代表127.0.0.1，即localhost，inet addr用来表示网卡的IP地址 网桥docker0创建一对对等虚拟设备接口一个叫veth，另一个叫eth0，成对匹配。 3.1 整个宿主机的网桥模式都是docker0，类似一个交换机有一堆接口，每个接口叫veth，在本地主机和容器内分别创建一个虚拟接口，并让他们彼此联通（这样一对接口叫veth pair）； 3.2 每个容器实例内部也有一块网卡，每个接口叫eth0； 3.3 docker0上面的每个veth匹配某个容器实例内部的eth0，两两配对，一一匹配。 通过上述，将宿主机上的所有容器都连接到这个内部网络上，两个容器在同一个网络下,会从这个网关下各自拿到分配的ip，此时两个容器的网络是互通的。 (2）命令： docker run -d -p 8081:8080 --name tomcat81 billygoo/tomcat8-jdk8 docker run -d -p 8082:8080 --name tomcat82 billygoo/tomcat8-jdk8 (3）验证： [root@VM-0-13-centos ~]# ip addr| tail -n 8 3-2、1、是什么直接使用宿主机的 IP 地址与外界进行通信，不再需要额外进行NAT 转换。 2、案例(1)说明 容器将不会获得一个独立的Network Namespace， 而是和宿主机共用一个Network Namespace。容器将不会虚拟出自己的网卡而是使用宿主机的IP和端口。 （2）命令 docker run -d --network host --name tomcat83 billygoo/tomcat8-jdk8 (3)无之前的配对显示了，看容器实例内部 (4)没有设置-p的端口映射了，如何访问启动的tomcat83 ? 就是默认端口，http://宿主机IP:8080/ 比如：tomcat 是 8080，nginx 是 80 ，mysql 是3306 3-3、none1、是什么禁用网络功能，只有lo标识(就是127.0.0.1表示本地回环) 2、案例docker run -d -p 8084:8080 --network none --name tomcat84 billygoo/tomcat8-jdk8 3-4、container1、是什么新建的容器和已经存在的一个容器共享一个网络ip配置而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的IP，而是和一个指定的容器共享IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。 2、案例Alpine Linux 是一款独立的、非商业的通用 Linux 发行版，专为追求安全性、简单性和资源效率的用户而设计。 可能很多人没听说过这个 Linux 发行版本，但是经常用 Docker 的朋友可能都用过，因为他小，简单，安全而著称，所以作为基础镜像是非常好的一个选择，可谓是麻雀虽小但五脏俱全，镜像非常小巧，不到 6M的大小，所以特别适合容器打包。 docker run -it -d --name alpine1 alpine /bin/sh docker run -it -d --network container:alpine1 --name alpine2 alpine /bin/sh 关闭alpine1，再看看alpine2 3-5、★ 自定义网络1、是什么字面意思，自定义的网络 2、案例一类：before docker run -d -p 8081:8080 --name tomcat81 billygoo/tomcat8-jdk8 docker run -d -p 8082:8080 --name tomcat82 billygoo/tomcat8-jdk8 上述成功启动并用docker exec进入各自容器实例内部 存在的问题：可以按照IP ping 通，但是无法用服务名 ping 通 二类：after 1、新建桥接网络 docker network create jack_network 2、新建容器加入上一步新建的自定义网络 docker run -d -p 8081:8080 --network jack_network --name tomcat81 billygoo/tomcat8-jdk8 docker run -d -p 8082:8080 --network jack_network --name tomcat82 billygoo/tomcat8-jdk8 3、测试互 ping 4、结论 自定义网络本身就维护好了主机名和ip的对应关系（ip和域名都能通） 五、Docker架构图解从其架构和运行流程来看，Docker 是一个 C/S 模式的架构，后端是一个松耦合架构，众多模块各司其职。 Docker 运行的基本流程为： 1 用户是使用 Docker Client 与 Docker Daemon 建立通信，并发送请求给后者。2 Docker Daemon 作为 Docker 架构中的主体部分，首先提供 Docker Server 的功能使其可以接受 Docker Client 的请求。3 Docker Engine 执行 Docker 内部的一系列工作，每一项工作都是以一个 Job 的形式的存在。4 Job 的运行过程中，当需要容器镜像时，则从 Docker Registry 中下载镜像，并通过镜像管理驱动 Graph driver将下载镜像以Graph的形式存储。5 当需要为 Docker 创建网络环境时，通过网络管理驱动 Network driver 创建并配置 Docker 容器网络环境。6 当需要限制 Docker 容器运行资源或执行用户指令等操作时，则通过 Execdriver 来完成。7 Libcontainer是一项独立的容器管理包，Network driver以及Exec driver都是通过Libcontainer来实现具体对容器进行的操作。 Ⅲ、Docker微服务实战一、创建一个普通模块1、建modeldocker_boot 2、改pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.5.6&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;docker_boot&lt;/artifactId&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt; &lt;lombok.version&gt;1.16.18&lt;/lombok.version&gt; &lt;mysql.version&gt;5.1.47&lt;/mysql.version&gt; &lt;druid.version&gt;1.1.16&lt;/druid.version&gt; &lt;mapper.version&gt;4.1.5&lt;/mapper.version&gt; &lt;mybatis.spring.boot.version&gt;1.3.0&lt;/mybatis.spring.boot.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--SpringBoot通用依赖模块--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--test--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- &lt;build &gt; 主要用于编译设置 --&gt; &lt;build&gt; &lt;!-- 定义打包成jar的名字 --&gt; &lt;!-- 这里如果不定义 , 打包成的jar名字格式为 : &lt;artifactId&gt; + &lt;version&gt; --&gt; &lt;finalName&gt;docker_jar&lt;/finalName&gt; &lt;plugins&gt; &lt;!--SpringBoot maven插件--&gt; &lt;!-- 可以将应用打成一个可执行的jar包 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;!-- 设置启动入口 --&gt; &lt;!-- manClass即使不配置 , SprinBoot也在打包的时候也清楚入口是哪个 , 其实不用配置 --&gt; &lt;configuration&gt; &lt;mainClass&gt;com.kk.DockerBootApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 3、写ymlserver: port: 6001 4、主启动package com.kk; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class DockerBootApplication { public static void main(String[] args) { SpringApplication.run (DockerBootApplication.class, args); } } 5、业务类package com.kk.controller; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.RestController; import java.util.UUID; @RestController public class OrderController { @Value(\"${server.port}\") private String port; @RequestMapping(\"/order/docker\") public String helloDocker() { return \"hello docker\" + \"\\t\" + port + \"\\t\" + UUID.randomUUID ( ).toString ( ); } @RequestMapping(value = \"/order/index\", method = RequestMethod.GET) public String index() { return \"服务端口号: \" + \"\\t\" + port + \"\\t\" + UUID.randomUUID ( ).toString ( ); } } 二、打 jar + dockerfile1、打包 2、编写Dockerfile# 基础镜像使用java FROM java:8 # 作者 MAINTAINER jack # VOLUME 指定临时文件目录为/tmp，在主机/var/lib/docker目录下创建了一个临时文件并链接到容器的/tmp VOLUME /tmp # 将jar包添加到容器中并更名为 jack_docker.jar ADD docker_jar.jar jack_docker.jar # 运行jar包 RUN bash -c 'touch /jack_docker.jar' ENTRYPOINT [\"java\",\"-jar\",\"/jack_docker.jar\"] #暴露6001端口作为微服务 EXPOSE 6001 3、构建镜像docker build -t jack_docker:1.6 . 4、运行容器docker run -d -p 6001:6001 jack_docker:1.6 5、访问测试 Ⅳ、Docker-compose容器编排一、概述1、是什么Docker-Compose是Docker官方的开源项目，快速构建多个容器，负责实现对Docker容器集群的快速编排。 2、安装1、下载：快速国内镜像 sudo curl -L https://get.daocloud.io/docker/compose/releases/download/1.25.1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose 2、安装 sudo chmod +x /usr/local/bin/docker-compose 3、测试 docker-compose --version 3、核心1、文件 docker-compose.yml 2、服务（service） 一个个应用容器实例，比如订单微服务、库存微服务、mysql容器、nginx容器或者redis容器 3、工程（project） 由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 二、步骤 编写Dockerfile定义各个微服务应用并构建出对应的镜像文件 使用 docker-compose.yml 定义一个完整业务单元，安排好整体应用中的各个容器服务。 最后，执行docker-compose up命令 来启动并运行整个应用程序，完成一键部署上线 三、命令 Compose常用命令docker-compose -h # 查看帮助docker-compose up # 启动所有docker-compose服务docker-compose up -d # 启动所有docker-compose服务并后台运行docker-compose down # 停止并删除容器、网络、卷、镜像。docker-compose exec yml里面的服务id # 进入容器实例内部 docker-compose exec docker-compose.yml文件中写的服务id /bin/bashdocker-compose ps # 展示当前docker-compose编排过的运行的所有容器docker-compose top # 展示当前docker-compose编排过的容器进程docker-compose logs yml里面的服务id # 查看容器输出日志docker-compose config # 检查配置docker-compose config -q # 检查配置，有问题才有输出docker-compose restart # 重启服务docker-compose start # 启动服务docker-compose stop # 停止服务 四、案例1、改造微服务1、建表 CREATE TABLE `t_user` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `username` varchar(50) NOT NULL DEFAULT '' COMMENT '用户名', `password` varchar(50) NOT NULL DEFAULT '' COMMENT '密码', `sex` tinyint(4) NOT NULL DEFAULT '0' COMMENT '性别 0=女 1=男 ', `deleted` tinyint(4) unsigned NOT NULL DEFAULT '0' COMMENT '删除标志，默认0不删除，1删除', `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间', `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间', PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT='用户表' 2、改pom &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.5.6&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;docker_boot&lt;/artifactId&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt; &lt;lombok.version&gt;1.16.18&lt;/lombok.version&gt; &lt;mysql.version&gt;5.1.47&lt;/mysql.version&gt; &lt;druid.version&gt;1.1.16&lt;/druid.version&gt; &lt;mapper.version&gt;4.1.5&lt;/mapper.version&gt; &lt;mybatis.spring.boot.version&gt;1.3.0&lt;/mybatis.spring.boot.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--guava Google 开源的 Guava 中自带的布隆过滤器--&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;23.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- redisson --&gt; &lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.13.4&lt;/version&gt; &lt;/dependency&gt; &lt;!--SpringBoot通用依赖模块--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--swagger2--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--SpringBoot与Redis整合依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--springCache--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--springCache连接池依赖包--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- jedis --&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--Mysql数据库驱动--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;!--SpringBoot集成druid连接池--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;${druid.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--mybatis和springboot整合--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${mybatis.spring.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 添加springboot对amqp的支持 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-codec&lt;/groupId&gt; &lt;artifactId&gt;commons-codec&lt;/artifactId&gt; &lt;version&gt;1.10&lt;/version&gt; &lt;/dependency&gt; &lt;!--通用基础配置junit/devtools/test/log4j/lombok/hutool--&gt; &lt;!--hutool--&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;5.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;${junit.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;${log4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;${lombok.version}&lt;/version&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!--persistence--&gt; &lt;dependency&gt; &lt;groupId&gt;javax.persistence&lt;/groupId&gt; &lt;artifactId&gt;persistence-api&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--通用Mapper--&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper&lt;/artifactId&gt; &lt;version&gt;${mapper.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- &lt;build &gt; 主要用于编译设置 --&gt; &lt;build&gt; &lt;!-- 定义打包成jar的名字 --&gt; &lt;!-- 这里如果不定义 , 打包成的jar名字格式为 : &lt;artifactId&gt; + &lt;version&gt; --&gt; &lt;finalName&gt;docker_jar&lt;/finalName&gt; &lt;plugins&gt; &lt;!--SpringBoot maven插件--&gt; &lt;!-- 可以将应用打成一个可执行的jar包 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;!-- 设置启动入口 --&gt; &lt;!-- manClass即使不配置 , SprinBoot也在打包的时候也清楚入口是哪个 , 其实不用配置 --&gt; &lt;configuration&gt; &lt;mainClass&gt;com.kk.DockerBootApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 3、application.properties.properties server.port=6001 # ========================alibaba.druid相关配置===================== spring.datasource.type=com.alibaba.druid.pool.DruidDataSource spring.datasource.driver-class-name=com.mysql.jdbc.Driver spring.datasource.url=jdbc:mysql://106.52.23.202:3306/db2022?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false spring.datasource.username=root spring.datasource.password=root spring.datasource.druid.test-while-idle=false # ========================redis相关配置===================== spring.redis.database=0 spring.redis.host=106.12.159.22 spring.redis.port=6379 spring.redis.password= spring.redis.lettuce.pool.max-active=8 spring.redis.lettuce.pool.max-wait=-1ms spring.redis.lettuce.pool.max-idle=8 spring.redis.lettuce.pool.min-idle=0 # ========================mybatis相关配置=================== mybatis.mapper-locations=classpath:mapper/*.xml mybatis.type-aliases-package=com.kk.docker.entities # ========================swagger===================== spring.swagger2.enabled=true 4、主启动 package com.kk; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import tk.mybatis.spring.annotation.MapperScan; @SpringBootApplication @MapperScan(\"com.kk.docker.mapper\") public class DockerBootApplication { public static void main(String[] args) { SpringApplication.run (DockerBootApplication.class, args); } } 5、业务类 5-1、config配置类 RedisConfig package com.kk.docker.config; import lombok.extern.slf4j.Slf4j; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer; import org.springframework.data.redis.serializer.StringRedisSerializer; import java.io.Serializable; @Configuration @Slf4j public class RedisConfig { /** * @param lettuceConnectionFactory * @return redis序列化的工具配置类，下面这个请一定开启配置 * 127.0.0.1:6379&gt; keys * * 1) \"ord:102\" 序列化过 * 2) \"\\xac\\xed\\x00\\x05t\\x00\\aord:102\" 野生，没有序列化过 */ @Bean public RedisTemplate&lt;String, Serializable&gt; redisTemplate(LettuceConnectionFactory lettuceConnectionFactory) { RedisTemplate&lt;String, Serializable&gt; redisTemplate = new RedisTemplate&lt;&gt; ( ); redisTemplate.setConnectionFactory (lettuceConnectionFactory); //设置key序列化方式string redisTemplate.setKeySerializer (new StringRedisSerializer ( )); //设置value的序列化方式json redisTemplate.setValueSerializer (new GenericJackson2JsonRedisSerializer ( )); redisTemplate.setHashKeySerializer (new StringRedisSerializer ( )); redisTemplate.setHashValueSerializer (new GenericJackson2JsonRedisSerializer ( )); redisTemplate.afterPropertiesSet ( ); return redisTemplate; } } SwaggerConfig package com.kk.docker.config; import org.springframework.beans.factory.annotation.Value; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import springfox.documentation.builders.ApiInfoBuilder; import springfox.documentation.builders.PathSelectors; import springfox.documentation.builders.RequestHandlerSelectors; import springfox.documentation.service.ApiInfo; import springfox.documentation.spi.DocumentationType; import springfox.documentation.spring.web.plugins.Docket; import springfox.documentation.swagger2.annotations.EnableSwagger2; import java.text.SimpleDateFormat; import java.util.Date; @Configuration @EnableSwagger2 public class SwaggerConfig { @Value(\"${spring.swagger2.enabled}\") private Boolean enabled; @Bean public Docket createRestApi() { return new Docket (DocumentationType.SWAGGER_2) .apiInfo (apiInfo ( )) .enable (enabled) .select ( ) .apis (RequestHandlerSelectors.basePackage (\"com.kk.docker\")) //你自己的package .paths (PathSelectors.any ( )) .build ( ); } public ApiInfo apiInfo() { return new ApiInfoBuilder ( ) .title (\"java 学习 docker\" + \"\\t\" + new SimpleDateFormat (\"yyyy-MM-dd\").format (new Date ( ))) .description (\"docker-compose\") .version (\"1.0\") .termsOfServiceUrl (\"https://www.mykkto.cn\") .build ( ); } } 5-2、新建entity User package com.kk.docker.entirys; import javax.persistence.Column; import javax.persistence.GeneratedValue; import javax.persistence.Id; import javax.persistence.Table; import java.util.Date; @Table(name = \"t_user\") public class User { @Id @GeneratedValue(generator = \"JDBC\") private Integer id; /** * 用户名 */ private String username; /** * 密码 */ private String password; /** * 性别 0=女 1=男 */ private Byte sex; /** * 删除标志，默认0不删除，1删除 */ private Byte deleted; /** * 更新时间 */ @Column(name = \"update_time\") private Date updateTime; /** * 创建时间 */ @Column(name = \"create_time\") private Date createTime; /** * @return id */ public Integer getId() { return id; } /** * @param id */ public void setId(Integer id) { this.id = id; } /** * 获取用户名 * * @return username - 用户名 */ public String getUsername() { return username; } /** * 设置用户名 * * @param username 用户名 */ public void setUsername(String username) { this.username = username; } /** * 获取密码 * * @return password - 密码 */ public String getPassword() { return password; } /** * 设置密码 * * @param password 密码 */ public void setPassword(String password) { this.password = password; } /** * 获取性别 0=女 1=男 * * @return sex - 性别 0=女 1=男 */ public Byte getSex() { return sex; } /** * 设置性别 0=女 1=男 * * @param sex 性别 0=女 1=男 */ public void setSex(Byte sex) { this.sex = sex; } /** * 获取删除标志，默认0不删除，1删除 * * @return deleted - 删除标志，默认0不删除，1删除 */ public Byte getDeleted() { return deleted; } /** * 设置删除标志，默认0不删除，1删除 * * @param deleted 删除标志，默认0不删除，1删除 */ public void setDeleted(Byte deleted) { this.deleted = deleted; } /** * 获取更新时间 * * @return update_time - 更新时间 */ public Date getUpdateTime() { return updateTime; } /** * 设置更新时间 * * @param updateTime 更新时间 */ public void setUpdateTime(Date updateTime) { this.updateTime = updateTime; } /** * 获取创建时间 * * @return create_time - 创建时间 */ public Date getCreateTime() { return createTime; } /** * 设置创建时间 * * @param createTime 创建时间 */ public void setCreateTime(Date createTime) { this.createTime = createTime; } } UserDTO package com.kk.docker.entirys; import io.swagger.annotations.ApiModel; import io.swagger.annotations.ApiModelProperty; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; import lombok.ToString; import java.io.Serializable; import java.util.Date; @NoArgsConstructor @AllArgsConstructor @Data @ApiModel(value = \"用户信息\") @ToString public class UserDTO implements Serializable { @ApiModelProperty(value = \"用户ID\") private Integer id; @ApiModelProperty(value = \"用户名\") private String username; @ApiModelProperty(value = \"密码\") private String password; @ApiModelProperty(value = \"性别 0=女 1=男 \") private Byte sex; @ApiModelProperty(value = \"删除标志，默认0不删除，1删除\") private Byte deleted; @ApiModelProperty(value = \"更新时间\") private Date updateTime; @ApiModelProperty(value = \"创建时间\") private Date createTime; /** * @return id */ public Integer getId() { return id; } /** * @param id */ public void setId(Integer id) { this.id = id; } /** * 获取用户名 * * @return username - 用户名 */ public String getUsername() { return username; } /** * 设置用户名 * * @param username 用户名 */ public void setUsername(String username) { this.username = username; } /** * 获取密码 * * @return password - 密码 */ public String getPassword() { return password; } /** * 设置密码 * * @param password 密码 */ public void setPassword(String password) { this.password = password; } /** * 获取性别 0=女 1=男 * * @return sex - 性别 0=女 1=男 */ public Byte getSex() { return sex; } /** * 设置性别 0=女 1=男 * * @param sex 性别 0=女 1=男 */ public void setSex(Byte sex) { this.sex = sex; } /** * 获取删除标志，默认0不删除，1删除 * * @return deleted - 删除标志，默认0不删除，1删除 */ public Byte getDeleted() { return deleted; } /** * 设置删除标志，默认0不删除，1删除 * * @param deleted 删除标志，默认0不删除，1删除 */ public void setDeleted(Byte deleted) { this.deleted = deleted; } /** * 获取更新时间 * * @return update_time - 更新时间 */ public Date getUpdateTime() { return updateTime; } /** * 设置更新时间 * * @param updateTime 更新时间 */ public void setUpdateTime(Date updateTime) { this.updateTime = updateTime; } /** * 获取创建时间 * * @return create_time - 创建时间 */ public Date getCreateTime() { return createTime; } /** * 设置创建时间 * * @param createTime 创建时间 */ public void setCreateTime(Date createTime) { this.createTime = createTime; } } 5-3 新建mapper 新建接口UserMapper package com.kk.docker.mapper; import com.kk.docker.entirys.User; import tk.mybatis.mapper.common.Mapper; public interface UserMapper extends Mapper&lt;User&gt; { } src\\main\\resources路径下新建mapper文件夹并新增UserMapper.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;mapper namespace=\"com.atguigu.docker.mapper.UserMapper\"&gt; &lt;resultMap id=\"BaseResultMap\" type=\"com.kk.docker.entirys.User\"&gt; &lt;!-- WARNING - @mbg.generated --&gt; &lt;id column=\"id\" jdbcType=\"INTEGER\" property=\"id\"/&gt; &lt;result column=\"username\" jdbcType=\"VARCHAR\" property=\"username\"/&gt; &lt;result column=\"password\" jdbcType=\"VARCHAR\" property=\"password\"/&gt; &lt;result column=\"sex\" jdbcType=\"TINYINT\" property=\"sex\"/&gt; &lt;result column=\"deleted\" jdbcType=\"TINYINT\" property=\"deleted\"/&gt; &lt;result column=\"update_time\" jdbcType=\"TIMESTAMP\" property=\"updateTime\"/&gt; &lt;result column=\"create_time\" jdbcType=\"TIMESTAMP\" property=\"createTime\"/&gt; &lt;/resultMap&gt; &lt;/mapper&gt; 5-4 新建service package com.kk.docker.service; import com.kk.docker.entirys.User; import com.kk.docker.mapper.UserMapper; import lombok.extern.slf4j.Slf4j; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.stereotype.Service; import javax.annotation.Resource; @Service @Slf4j public class UserService { public static final String CACHE_KEY_USER = \"user:\"; @Resource private UserMapper userMapper; @Resource private RedisTemplate redisTemplate; /** * addUser * * @param user */ public void addUser(User user) { //1 先插入mysql并成功 int i = userMapper.insertSelective (user); if (i &gt; 0) { //2 需要再次查询一下mysql将数据捞回来并ok user = userMapper.selectByPrimaryKey (user.getId ( )); //3 将捞出来的user存进redis，完成新增功能的数据一致性。 String key = CACHE_KEY_USER + user.getId ( ); redisTemplate.opsForValue ( ).set (key, user); } } /**F * findUserById * * @param id * @return */ public User findUserById(Integer id) { User user = null; String key = CACHE_KEY_USER + id; //1 先从redis里面查询，如果有直接返回结果，如果没有再去查询mysql user = (User) redisTemplate.opsForValue ( ).get (key); if (user == null) { //2 redis里面无，继续查询mysql user = userMapper.selectByPrimaryKey (id); if (user == null) { //3.1 redis+mysql 都无数据 //你具体细化，防止多次穿透，我们规定，记录下导致穿透的这个key回写redis return user; } else { //3.2 mysql有，需要将数据写回redis，保证下一次的缓存命中率 redisTemplate.opsForValue ( ).set (key, user); } } return user; } public void deleteUser(Integer id) { } public void updateUser(User user) { } public User findUserById2(Integer id) { return null; } } 5-5 新建controller package com.kk.docker.controller; import cn.hutool.core.util.IdUtil; import com.kk.docker.entirys.User; import com.kk.docker.entirys.UserDTO; import com.kk.docker.service.UserService; import io.swagger.annotations.Api; import io.swagger.annotations.ApiOperation; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.BeanUtils; import org.springframework.web.bind.annotation.*; import javax.annotation.Resource; import java.util.Random; @Api(description = \"用户User接口\") @RestController @Slf4j public class UserController { @Resource private UserService userService; @ApiOperation(\"数据库新增3条记录\") @RequestMapping(value = \"/user/add\", method = RequestMethod.POST) public void addUser() { for (int i = 1; i &lt;= 3; i++) { User user = new User ( ); user.setUsername (\"jack\" + i); user.setPassword (IdUtil.simpleUUID ( ).substring (0, 6)); user.setSex ((byte) new Random ( ).nextInt (2)); userService.addUser (user); } } @ApiOperation(\"删除1条记录\") @RequestMapping(value = \"/user/delete/{id}\", method = RequestMethod.POST) public void deleteUser(@PathVariable Integer id) { userService.deleteUser (id); } @ApiOperation(\"修改1条记录\") @RequestMapping(value = \"/user/update\", method = RequestMethod.POST) public void updateUser(@RequestBody UserDTO userDTO) { User user = new User ( ); BeanUtils.copyProperties (userDTO, user); userService.updateUser (user); } @ApiOperation(\"查询1条记录\") @RequestMapping(value = \"/user/find/{id}\", method = RequestMethod.GET) public User findUserById(@PathVariable Integer id) { return userService.findUserById2 (id); } } 6、打包 7、编写 Dockerfile # 基础镜像使用java FROM java:8 # 作者 MAINTAINER jack # VOLUME 指定临时文件目录为/tmp，在主机/var/lib/docker目录下创建了一个临时文件并链接到容器的/tmp VOLUME /tmp # 将jar包添加到容器中并更名为 jack_docker.jar ADD docker_jar.jar jack_docker.jar # 运行jar包 RUN bash -c 'touch /jack_docker.jar' ENTRYPOINT [\"java\",\"-jar\",\"/jack_docker.jar\"] #暴露6001端口作为微服务 EXPOSE 6001 8、构建镜像 docker build -t jack_docker:1.7 . 9、运行 docker run -d -p 6001:6001 --name jackto17 jack_docker:1.7 10、访问 swageer http://106.XX.XX.XXX:6001/swagger-ui.html 2、不用Compose 单独启动容器 redis 单独启动容器 mysql 单独启动容器 微服务 3、存在的问题 先后顺序要求固定，先mysql+redis才能微服务访问成功 多个run命令…… 容器间的启停或宕机，有可能导致IP地址对应的容器实例变化，映射出错，要么生产IP写死(可以但是不推荐)，要么通过服务调用 4、使用Compose1、编写 docker-compose.yml文件 version: \"3\" services: microService: image: jack_docker:1.8 container_name: ms01 ports: - \"6001:6001\" volumes: - /app/microService:/data networks: - mykk_net depends_on: - redis - mysql redis: image: redis:6.0.8 ports: - \"6379:6379\" volumes: - /app/redis/redis.conf:/etc/redis/redis.conf - /app/redis/data:/data networks: - mykk_net command: redis-server /etc/redis/redis.conf mysql: image: mysql:5.7 environment: MYSQL_ROOT_PASSWORD: 'a1b2c3' MYSQL_ALLOW_EMPTY_PASSWORD: 'no' MYSQL_DATABASE: 'db2022' MYSQL_USER: 'jack' MYSQL_PASSWORD: 'a1b2c3' ports: - \"3306:3306\" volumes: - /app/mysql/db:/var/lib/mysql - /app/mysql/conf/my.cnf:/etc/my.cnf - /app/mysql/init:/docker-entrypoint-initdb.d networks: - mykk_net command: --default-authentication-plugin=mysql_native_password #解决外部无法访问 networks: mykk_net: 2、第二次修改微服务工程 docker_boot 2-1 改 YML：通过服务名访问，IP无关 2-2 打包，编写 Dockerfile 2-3 构建镜像 docker build -t jack_docker:1.8 . 3、执行 docker-compose 执行 docker-compose up或者执行 docker-compose up -d 4、创建表 docker exec -it 容器实例id /bin/bash mysql -uroot -p create database db2022; use db2022; CREATE TABLE t_user ( id INT(10) UNSIGNED NOT NULL AUTO_INCREMENT, username VARCHAR(50) NOT NULL DEFAULT ‘’ COMMENT ‘用户名’, password VARCHAR(50) NOT NULL DEFAULT ‘’ COMMENT ‘密码’, sex TINYINT(4) NOT NULL DEFAULT ‘0’ COMMENT ‘性别 0=女 1=男 ‘, deleted TINYINT(4) UNSIGNED NOT NULL DEFAULT ‘0’ COMMENT ‘删除标志，默认0不删除，1删除’, update_time TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT ‘更新时间’, create_time TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT ‘创建时间’, PRIMARY KEY (id)) ENGINE=INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4 COMMENT=’用户表’; 5、关停docker-compose stop 五、命令(docker-compose) Compose常用命令docker-compose -h # 查看帮助docker-compose up # 启动所有docker-compose服务docker-compose up -d # 启动所有docker-compose服务并后台运行docker-compose down # 停止并删除容器、网络、卷、镜像。docker-compose exec yml里面的服务id # 进入容器实例内部 docker-compose exec docker-compose.yml文件中写的服务id /bin/bashdocker-compose ps # 展示当前docker-compose编排过的运行的所有容器docker-compose top # 展示当前docker-compose编排过的容器进程docker-compose logs yml里面的服务id # 查看容器输出日志dokcer-compose config # 检查配置dokcer-compose config -q # 检查配置，有问题才有输出docker-compose restart # 重启服务docker-compose start # 启动服务docker-compose stop # 停止服务 参考地址 ↓1、docker 加速（博主简书）url：https://www.jianshu.com/p/f554c85b25c1 2、DockerBuild报错：The command ‘/bin/sh -c yum install -y vim‘ returned a non-zero code: 1url：https://blog.csdn.net/weixin_53402685/article/details/125296621 3、docker-compose 日志输出url：https://www.cnblogs.com/sunstudy/articles/16340509.html","categories":[{"name":"docker","slug":"docker","permalink":"https://mykkto.github.io/categories/docker/"}],"tags":[{"name":"docker-compose","slug":"docker-compose","permalink":"https://mykkto.github.io/tags/docker-compose/"},{"name":"dockerfile","slug":"dockerfile","permalink":"https://mykkto.github.io/tags/dockerfile/"},{"name":"docker网络","slug":"docker网络","permalink":"https://mykkto.github.io/tags/docker%E7%BD%91%E7%BB%9C/"}],"author":"mykk"},{"title":"大数据-Flink流式计算框架(JAVA)","slug":"13-大数据/01-Flink/01_Flink技术栈","date":"2022-05-17T14:17:13.000Z","updated":"2023-04-10T14:35:35.049Z","comments":true,"path":"posts/1b79564d.html","link":"","permalink":"https://mykkto.github.io/posts/1b79564d.html","excerpt":"","text":"​ 0️⃣代码地址https://github.com/mykkTo/Flink_java.git Ⅰ、Flink 初识前言1、小笔记 1、在编码过程中，如果使用了lambda表达式需要注意泛型擦除，没有指明的话flink会抛出异常，因为对数据有严格要求 .returns(Types.String); 进行明确声明 2、数据倾斜：就是有的线程忙的忙死，有点线程闲的闲死，解决这个问题需要调用物理分区的算子（默认flink底层会调用），手动的话调用 shuffle() 方法（洗牌，随机分区），手动调用 rebalance() 方法（轮训分区），然而需要注意的是 keyBy（）方法是逻辑分区，总的6种还有自定义的，如果生产没有严重倾斜就不需要用这些。 3、有两个setParallelism(N) ​ env.setParallelism(N) 是设置N个物理分区 ​ print ().setParallelism(N)是设置N个线程在跑，富函数的话就会有4次生命周期 4、 一、基本概述1、概述Flink 是 Apache 基金会旗下的一个开源大数据处理框架。目前，Flink 已经成为各大公司大数据实时处理的发力重点，特别是国内以阿里为代表的一众互联网大厂都在全力投入，为 Flink 社区贡献了大量源码。如今 Flink 已被很多人认为是大数据实时处理的方向和未来，许多公司也都在招聘和储备掌握 Flink 技术的人才。 2、源起和设计理念Flink 起源于一个叫作 Stratosphere 的项目，它是由 3 所地处柏林的大学和欧洲其他一些大 学在 2010~2014 年共同进行的研究项目，由柏林理工大学的教授沃克尔·马尔科（Volker Markl） 领衔开发。2014 年 4 月，Stratosphere 的代码被复制并捐赠给了 Apache 软件基金会，Flink 就 是在此基础上被重新设计出来的。 在德语中，“flink”一词表示“快速、灵巧”。项目的 logo 是一只彩色的松鼠，当然了， 这不仅是因为 Apache 大数据项目对动物的喜好（是否联想到了 Hadoop、Hive？），更是因为 松鼠这种小动物完美地体现了“快速、灵巧”的特点。关于 logo 的颜色，还一个有趣的缘由： 柏林当地的松鼠非常漂亮，颜色是迷人的红棕色；而 Apache 软件基金会的 logo，刚好也是一 根以红棕色为主的渐变色羽毛。于是，Flink 的松鼠 Logo 就设计成了红棕色，而且拥有一个漂 亮的渐变色尾巴，尾巴的配色与 Apache 软件基金会的 logo 一致。这只松鼠色彩炫目，既呼应 了 Apache 的风格，似乎也预示着 Flink 未来将要大放异彩。 二、Flink 的应用Flink 是一个大数据流处理引擎，它可以为不同的行业提供大数据实时处理的解决方案。 随着 Flink 的快速发展完善，如今在世界范围许多公司都可以见到 Flink 的身影。 目前在全球范围内，北美、欧洲和金砖国家均是 Flink 的应用热门区域。当然，这些地区 其实也就是 IT、互联网行业较发达的地区。 Flink 在国内热度尤其高，一方面是因为阿里的贡献和带头效应，另一方面也跟中国的应 用场景密切相关。中国的人口规模与互联网使用普及程度，决定了对大数据处理的速度要求越 来越高，也迫使中国的互联网企业去追逐更高的数据处理效率。试想在中国，一个网站可能要 面对数亿的日活用户、每秒数亿次的计算峰值，这对很多国外的公司来说是无法想象的。而 Flink 恰好给我们高速准确的处理海量流式数据提供了可能。 1、企业中的应用Flink 为全球许多公司和企业的关键业务应用提供了强大的支持。 对于数据处理而言，任何行业、任何公司的需求其实都是一样的：数据规模大、实时性要 求高、确保结果准确、方便扩展、故障后可恢复——而这些要求，作为新一代大数据流式处理 引擎的 Flink 统统可以满足！这也正是 Flink 在全世界范围得到广泛应用的原因。 2、主要的应用场景 电商和市场营销 举例：实时数据报表、广告投放、实时推荐 在电商行业中，网站点击量是统计 PV、UV 的重要来源，也是如今“流量经济”的最主要 数据指标。很多公司的营销策略，比如广告的投放，也是基于点击量来决定的。另外，在网站上提供给用户的实时推荐，往往也是基于当前用户的点击行为做出的。 网站获得的点击数据可能是连续且不均匀的，还可能在同一时间大量产生，这是典型的数 据流。如果我们希望把它们全部收集起来，再去分析处理，就会面临很多问题：首先，我们需 要很大的空间来存储数据；其次，收集数据的过程耗去了大量时间，统计分析结果的实时性就 大大降低了；另外，分布式处理无法保证数据的顺序，如果我们只以数据进入系统的时间为准， 可能导致最终结果计算错误。 我们需要的是直接处理数据流，而 Flink 就可以做到这一点。 物联网（IOT） 举例：传感器实时数据采集和显示、实时报警，交通运输业 物联网是流数据被普遍应用的领域。各种传感器不停获得测量数据，并将它们以流的形式 传输至数据中心。而数据中心会将数据处理分析之后，得到运行状态或者报警信息，实时地显 示在监控屏幕上。所以在物联网中，低延迟的数据传输和处理，以及准确的数据分析通常很关 键。 交通运输业也体现了流处理的重要性。比如说，如今高铁运行主要就是依靠传感器检测数 据，测量数据包括列车的速度和位置，以及轨道周边的状况。这些数据会从轨道传给列车，再 从列车传到沿途的其他传感器；与此同时，数据报告也被发送回控制中心。因为列车处于高速 行驶状态，因此数据处理的实时性要求是极高的。如果流数据没有被及时正确处理，调整意见 和警告就不能相应产生，后果可能会非常严重。 物流配送和服务业 举例：订单状态实时更新、通知信息推送 在很多服务型应用中，都会涉及订单状态的更新和通知的推送。这些信息基于事件触发， 不均匀地连续不断生成，处理之后需要及时传递给用户。这也是非常典型的数据流的处理。 银行和金融业 举例：实时结算和通知推送，实时检测异常行为 银行和金融业是另一个典型的应用行业。用户的交易行为是连续大量发生的，银行面对的 是海量的流式数据。由于要处理的交易数据量太大，以前的银行是按天结算的，汇款一般都要 隔天才能到账。所以有一个说法叫作“银行家工作时间”，说的就是银行家不仅不需要 996，甚 至下午早早就下班了：因为银行需要早点关门进行结算，这样才能保证第二天营业之前算出准 确的账。这显然不能满足我们快速交易的需求。在全球化经济中，能够提供 24 小时服务变得 越来越重要。现在交易和报表都会快速准确地生成，我们跨行转账也可以做到瞬间到账，还可以接到实时的推送通知。这就需要我们能够实时处理数据流。 另外，信用卡欺诈的检测也需要及时的监控和报警。一些金融交易市场，对异常交易行为 的及时检测可以更好地进行风险控制；还可以对异常登录进行检测，从而发现钓鱼式攻击，从 而避免巨大的损失。 三、流式计算演变我们已经了解，Flink 的主要应用场景，就是 处理大规模的数据流。那为什么一定要用 Flink 呢？数据处理还有没有其他的方式？要解答这个疑惑，我们就需要先从流处理和批处理的概念 讲起。 1、流处理和批处理数据处理有不同的方式。 对于具体应用来说，有些场景数据是一个一个来的，是一组有序的数据序列，我们把它叫作“数据流”；而有些场景的数据，本身就是一批同时到来，是一个有限的数据集，这就是批量数据（有时也直接叫数据集）。 容易想到，处理数据流，当然应该“来一个就处理一个”，这种数据处理模式就叫作流处理；因为这种处理是即时的，所以也叫实时处理。与之对应，处理批量数据自然就应该一批读入、一起计算，这种方式就叫作批处理，也叫作离线处理。 那真实的应用场景中，到底是数据流更常见、还是批量数据更常见呢？ 生活中，这两种形式的数据都有，如图 1-4 所示。比如我们日常发信息，可以一句一句地 说，也可以写一大段一起发过去。一句一句的信息，就是一个一个的数据，它们构成的序列就是一个数据流；而一大段信息，是一组数据的集合，对应就是批量数据（数据集）。 当然，有经验的人都会知道，一句一句地发，你一言我一语，有来有往这才叫聊天；一大 段信息直接砸过去，别人看着都眼晕，很容易就没下文了——如果是很重要的整篇内容（比如 表白信），写成文档或者邮件发过去可能效果会更好。 所以我们看到，“聊天”这个生活场景，数据的生成、传递和接收处理，都是流式的；而 “写信”的场景，数据的生成尽管应该也是流式的（字总得一个个写），但我们可以把它们收集起来，统一传输、统一处理（当然我们还可以进一步较真：处理也是流式的，字得一个一个读）。 不论传输处理的方式是怎样的，数据的生成，一般都是流式的。 2、传统事务处理IT 互联网公司往往会用不同的应用程序来处理各种业务。比如内部使用的企业资源规划 （ERP）系统、客户关系管理（CRM）系统，还有面向客户的 Web 应用程序。这些系统一般都 会进行分层设计：“计算层”就是应用程序本身，用于数据计算和处理；而“存储层”往往是传统的关系型数据库，用于数据存储，如图 我们发现，这里的应用程序在处理数据的模式上有共同之处：接收的数据是持续生成的事 件，比如用户的点击行为，客户下的订单，或者操作人员发出的请求。处理事件时，应用程序 需要先读取远程数据库的状态，然后按照处理逻辑得到结果，将响应返回给用户，并更新数据库状态。一般来说，一个数据库系统可以服务于多个应用程序，它们有时会访问相同的数据库或表 对于各种事件请求，事务处理的方式能够保证实时响应，好处是一目了然的。但是我们知道，这样的架构对表和数据库的设计要求很高；当数据规模越来越庞大、系统越来越复杂时，可能需要对表进行重构，而且一次联表查询也会花费大量的时间，甚至不能及时得到返回结果。于是，作为程序员就只好将更多的精力放在表的设计和重构，以及 SQL 的调优上，而无法专注于业务逻辑的实现了——我们都知道，这种工作费力费时，却没法直接体现在产品上给老板看，简直就是噩梦。 那有没有更合理、更高效的处理架构呢？↓ 3、有状态的流处理不难想到，如果我们对于事件流的处理非常简单，例如收到一条请求就返回一个“收到”，那就可以省去数据库的查询和更新了。但是这样的处理是没什么实际意义的。在现实的应用中，往往需要还其他一些额外数据。我们可以把需要的额外数据保存成一个“状态”，然后针对这条数据进行处理，并且更新状态。在传统架构中，这个状态就是保存在数据库里的。这就是所谓的“有状态的流处理”。 为了加快访问速度，我们可以直接将状态保存在本地内存，如图所示。 当应用收到一个新事件时，它可以从状态中读取数据，也可以更新状态。而当状态是从内存中读写的时候，这就和访问本地变量没什么区别了，实时性可以得到极大的提升。 另外，数据规模增大时，我们也不需要做重构，只需要构建分布式集群，各自在本地计算就可以了，可扩展性也变得更好。 因为采用的是一个分布式系统，所以还需要保护本地状态，防止在故障时数据丢失。我们可以定期地将应用状态的一致性检查点（checkpoint）存盘，写入远程的持久化存储，遇到故障时再去读取进行恢复，这样就保证了更好的容错性。 4、有状态流架构1、事件驱动型（Event-Driven）应用 事件驱动型应用是一类具有状态的应用，它从一个或多个事件流提取数据，并根据到来的 事件触发计算、状态更新或其他外部动作。比较典型的就是以 Kafka 为代表的消息队列几乎都 是事件驱动型应用。 这其实跟传统事务处理本质上是一样的，区别在于基于有状态流处理的事件驱动应用，不 再需要查询远程数据库，而是在本地访问它们的数据，如图上所示，这样在吞吐量和延迟方 面就可以有更好的性能。 另外远程持久性存储的检查点保证了应用可以从故障中恢复。检查点可以异步和增量地完 成，因此对正常计算的影响非常小 2、数据分析（Data Analysis）型应用 所谓的数据分析，就是从原始数据中提取信息和发掘规律。传统上，数据分析一般是先将 数据复制到数据仓库（Data Warehouse），然后进行批量查询。如果数据有了更新，必须将最 新数据添加到要分析的数据集中，然后重新运行查询或应用程序。 如今，Apache Hadoop 生态系统的组件，已经是许多企业大数据架构中不可或缺的组成部 分。现在的做法一般是将大量数据（如日志文件）写入 Hadoop 的分布式文件系统（HDFS）、 S3 或 HBase 等批量存储数据库，以较低的成本进行大容量存储。然后可以通过 SQL-on-Hadoop 类的引擎查询和处理数据，比如大家熟悉的 Hive。这种处理方式，是典型的批处理，特点是 可以处理海量数据，但实时性较差，所以也叫离线分析。 如果我们有了一个复杂的流处理引擎，数据分析其实也可以实时执行。流式查询或应用程 序不是读取有限的数据集，而是接收实时事件流，不断生成和更新结果。结果要么写入外部数 据库，要么作为内部状态进行维护。 Apache Flink 同时支持流式与批处理的数据分析应用 与批处理分析相比，流处理分析最大的优势就是低延迟，真正实现了实时。另外，流处理 不需要去单独考虑新数据的导入和处理，实时更新本来就是流处理的基本模式。当前企业对流 式数据处理的一个热点应用就是实时数仓，很多公司正是基于 Flink 来实现的。 3、数据管道（Data Pipeline）型应用 如图，ETL 与数据管道之间的区别 ETL 也就是数据的提取、转换、加载，是在存储系统之间转换和移动数据的常用方法。 在数据分析的应用中，通常会定期触发 ETL 任务，将数据从事务数据库系统复制到分析数据 库或数据仓库。 所谓数据管道的作用与 ETL 类似。它们可以转换和扩展数据，也可以在存储系统之间移 动数据。不过如果我们用流处理架构来搭建数据管道，这些工作就可以连续运行，而不需要再 去周期性触发了。比如，数据管道可以用来监控文件系统目录中的新文件，将数据写入事件日 志。连续数据管道的明显优势是减少了将数据移动到目的地的延迟，而且更加通用，可以用于 更多的场景。 4、Lambda 架构 对于有状态的流处理，当数据越来越多时，我们必须用分布式的集群架构来获取更大的吞 吐量。但是分布式架构会带来另一个问题：怎样保证数据处理的顺序是正确的呢？ 对于批处理来说，这并不是一个问题。因为所有数据都已收集完毕，我们可以根据需要选 择、排列数据，得到想要的结果。可如果我们采用“来一个处理一个”的流处理，就可能出现 “乱序”的现象：本来先发生的事件，因为分布处理的原因滞后了。怎么解决这个问题呢？ 以 Storm 为代表的第一代分布式开源流处理器，主要专注于具有毫秒延迟的事件处理，特 点就是一个字“快”；而对于准确性和结果的一致性，是不提供内置支持的，因为结果有可能 取决于到达事件的时间和顺序。另外，第一代流处理器通过检查点来保证容错性，但是故障恢 复的时候，即使事件不会丢失，也有可能被重复处理——所以无法保证 exactly-once。 与批处理器相比，可以说第一代流处理器牺牲了结果的准确性，用来换取更低的延迟。而 批处理器恰好反过来，牺牲了实时性，换取了结果的准确 我们自然想到，如果可以让二者做个结合，不就可以同时提供快速和准确的结果了吗？正 是基于这样的思想，Lambda 架构被设计出来，如上图。我们可以认为这是第二代流处 理架构，但事实上，它只是第一代流处理器和批处理器的简单合并。 5、新一代流处理器 之前的分布式流处理架构，都有明显的缺陷，人们也一直没有放弃对流处理器的改进和完 善。终于，在原有流处理器的基础上，新一代分布式开源流处理器诞生了。为了与之前的系统 区分，我们一般称之为第三代流处理器，代表当然就是 Flink。 第三代流处理器通过巧妙的设计，完美解决了乱序数据对结果正确性的影响。这一代系统 还做到了精确一次（exactly-once）的一致性保障，是第一个具有一致性和准确结果的开源流 处理器。另外，先前的流处理器仅能在高吞吐和低延迟中二选一，而新一代系统能够同时提供 这两个特性。所以可以说，这一代流处理器仅凭一套系统就完成了 Lambda 架构两套系统的工 作，它的出现使得 Lambda 架构黯然失色。 除了低延迟、容错和结果准确性之外，新一代流处理器还在不断添加新的功能，例如高可 用的设置，以及与资源管理器（如 YARN 或 Kubernetes）的紧密集成等等。 四、Flink 的特性总结Flink 是第三代分布式流处理器，它的功能丰富而强大。 1、核心特性 高吞吐和低延迟。每秒处理数百万个事件，毫秒级延迟。 结果的准确性。Flink 提供了事件时间（event-time）和处理时间（processing-time） 语义。对于乱序事件流，事件时间语义仍然能提供一致且准确的结果。 精确一次（exactly-once）的状态一致性保证。 可以连接到最常用的存储系统，如 Apache Kafka、Apache Cassandra、Elasticsearch、 JDBC、Kinesis 和（分布式）文件系统，如 HDFS 和 S3。 高可用。本身高可用的设置，加上与 K8s，YARN 和 Mesos 的紧密集成，再加上从故 障中快速恢复和动态扩展任务的能力，Flink 能做到以极少的停机时间 7×24 全天候 运行 能够更新应用程序代码并将作业（jobs）迁移到不同的 Flink 集群，而不会丢失应用 程序的状态。 2、分层 API除了上述这些特性之外，Flink 还是一个非常易于开发的框架，因为它拥有易于使用的分层 API，整体 API 分层如图： 最底层级的抽象仅仅提供了有状态流，它将处理函数（Process Function）嵌入到了 DataStream API 中。底层处理函数（Process Function）与 DataStream API 相集成，可以对某 些操作进行抽象，它允许用户可以使用自定义状态处理来自一个或多个数据流的事件，且状态 具有一致性和容错保证。除此之外，用户可以注册事件时间并处理时间回调，从而使程序可以 处理复杂的计算。 实际上，大多数应用并不需要上述的底层抽象，而是直接针对核心 API（Core APIs） 进 行编程，比如 DataStream API（用于处理有界或无界流数据）以及 DataSet API（用于处理有界 数据集）。这些 API 为数据处理提供了通用的构建模块，比如由用户定义的多种形式的转换 （transformations）、连接（joins）、聚合（aggregations）、窗口（windows）操作等。 五、Flink vs Spark1、数据处理架构我们已经知道，数据处理的基本方式，可以分为批处理和流处理两种。 批处理针对的是有界数据集，非常适合需要访问海量的全部数据才能完成的计算工作，一 般用于离线统计。 流处理主要针对的是数据流，特点是无界、实时, 对系统传输的每个数据依次执行操作， 一般用于实时统计。 从根本上说，Spark 和 Flink 采用了完全不同的数据处理方式。可以说，两者的世界观是 截然相反的。 Spark 以批处理为根本，并尝试在批处理之上支持流计算；在 Spark 的世界观中，万物皆批次，离线数据是一个大批次，而实时数据则是由一个一个无限的小批次组成的。所以对于流处理框架 Spark Streaming 而言，其实并不是真正意义上的“流”处理，而是“微批次” （micro-batching）处理 1.无界数据流所谓无界数据流，就是有头没尾，数据的生成和传递会开始但永远不会结束，我们无法等待所有数据都到达，因为输入是无界的，永无止境，数据没有“都到达”的 时候。所以对于无界数据流，必须连续处理，也就是说必须在获取数据后立即处理。在处理无界流时，为了保证结果的正确性，我们必须能够做到按照顺序处理数据。 2.无界数据流有界数据流有明确定义的开始和结束，所以我们可以通过获取所有数据来处理有界流。处理有界流就不需要严格保证数据的顺序了，因为总可以对有界数据集进行排序。有界流的处理也就是批处理。 正因为这种架构上的不同，Spark 和 Flink 在不同的应用领域上表现会有差别。一般来说，Spark 基于微批处理的方式做同步总有一个“攒批”的过程，所以会有额外开销，因此无法在流处理的低延迟上做到极致。在低延迟流处理场景，Flink 已经有明显的优势。而在海量数据的批处理领域，Spark 能够处理的吞吐量更大，加上其完善的生态和成熟易用的 API，目前同样优势比较明显。 2、数据模型和运行架构 除了三观不合，Spark 和 Flink 在底层实现最主要的差别就在于数据模型不同。 Spark 底层数据模型是弹性分布式数据集（RDD），Spark Streaming 进行微批处理的底层 接口 DStream，实际上处理的也是一组组小批数据 RDD 的集合。可以看出，Spark 在设计上本 身就是以批量的数据集作为基准的，更加适合批处理的场景。 而 Flink 的基本数据模型是数据流（DataFlow），以及事件（Event）序列。Flink 基本上是 完全按照 Google 的 DataFlow 模型实现的，所以从底层数据模型上看，Flink 是以处理流式数 据作为设计目标的，更加适合流处理的场景。 数据模型不同，对应在运行处理的流程上，自然也会有不同的架构。Spark 做批计算，需 要将任务对应的 DAG 划分阶段（Stage），一个完成后经过 shuffle 再进行下一阶段的计算。而 Flink 是标准的流式执行模式，一个事件在一个节点处理完后可以直接发往下一个节点进行处理。 3、Spark 还是 FlinkSpark 和 Flink 可以说目前是各擅胜场，批处理领域 Spark 称王，而在流处理方面 Flink 当仁不让。具体到项目应用中，不仅要看是流处理还是 批处理，还需要在延迟、吞吐量、可靠性，以及开发容易度等多个方面进行权衡。 如果在工作中需要从 Spark 和 Flink 这两个主流框架中选择一个来进行实时流处理，我们更加推荐使用 Flink，主要的原因有： Flink 的延迟是毫秒级别，而 Spark Streaming 的延迟是秒级延迟。 Flink 提供了严格的精确一次性语义保证。 Flink 的窗口 API 更加灵活、语义更丰富。 Flink 提供事件时间语义，可以正确处理延迟数据。 Flink 提供了更加灵活的对状态编程的 API。 Ⅱ、Flink 部署一、Flink 快速上手1、创建项目(1.8)1、maven在项目的 pom 文件中，增加标签设置属性，然后增加标签引入需要的依赖。我们需要添加的依赖最重要的就是 Flink 的相关组件，包括 flink-java、 flink-streaming-java，以及 flink-clients（客户端，也可以省略）。另外，为了方便查看运行日志， 我们引入 slf4j 和 log4j 进行日志理。 &lt;properties&gt; &lt;flink.version&gt;1.13.0&lt;/flink.version&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;scala.binary.version&gt;2.12&lt;/scala.binary.version&gt; &lt;slf4j.version&gt;1.7.30&lt;/slf4j.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- 引入 Flink 相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-java&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-streaming-java_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-clients_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 引入日志管理相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-to-slf4j&lt;/artifactId&gt; &lt;version&gt;2.14.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 在属性中，我们定义了&lt;scala.binary.version&gt;，这指代的是所依赖的 Scala 版本。这有一点奇怪：Flink 底层是 Java，而且我们也只用 Java API，为什么还会依赖 Scala 呢？这是因为 Flink的架构中使用了 Akka 来实现底层的分布式通信，而 Akka 是用 Scala 开发的 2、配置日志管理在目录 src/main/resources 下添加文件:log4j.properties，内容配置如下： log4j.rootLogger=error, stdout log4j.appender.stdout=org.apache.log4j.ConsoleAppender log4j.appender.stdout.layout=org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern=%-4r [%t] %-5p %c %x - %m%n 2、编写代码搭好项目框架，接下来就是我们的核心工作——往里面填充代码。我们会用一个最简单的示例来说明 Flink 代码怎样编写：统计一段文字中，每个单词出现的频次。这就是传说中的 WordCount 程序——它是大数据领域非常经典的入门案例，地位等同于初学编程语言时的Hello World。 1、批处理 1、根目录下创建一个 txt文件，内容如下 hello world hello flink hello java 2、思路 先逐行读入文件数据，然后将每一行文字拆分成单词；接着按照单词分组，统计每组数据的个数，就是对应单词的频次。 3、Java 类 BatchWordCount package com.kk.wc; import org.apache.flink.api.common.typeinfo.Types; import org.apache.flink.api.java.ExecutionEnvironment; import org.apache.flink.api.java.operators.AggregateOperator; import org.apache.flink.api.java.operators.DataSource; import org.apache.flink.api.java.operators.FlatMapOperator; import org.apache.flink.api.java.operators.UnsortedGrouping; import org.apache.flink.api.java.tuple.Tuple2; import org.apache.flink.util.Collector; public class BatchWordCount { public static void main(String[] args) throws Exception { // 1. 创建执行环境 ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment ( ); // 2. 从文件读取数据 按行读取(存储的元素就是每行的文本) DataSource&lt;String&gt; listDateSource = env.readTextFile (\"input/words.txt\"); // 3. 将每行数据进行分词，转换成二元组类型 // Collector: flink 定义的收集器 // Tuple: 二元组类型 &lt;String,Long&gt;,K 就是具体的单词，V 就是个数 FlatMapOperator&lt;String, Tuple2&lt;String, Long&gt;&gt; wordAndOneTuple = listDateSource.flatMap ((String line, Collector&lt;Tuple2&lt;String, Long&gt;&gt; out) -&gt; { // 每行根据空格分隔出，单词 String[] words = line.split (\" \"); // out.collect 就是输出的意思 for (String word : words) { // Tuple2.of 构建二元组实例 out.collect (Tuple2.of (word, 1L)); } }) // returns 解决 scala 泛型擦除问题 .returns (Types.TUPLE (Types.STRING, Types.LONG)); // 根据转换得到的运算子 wordAndOneTuple // 4. 按照 word 进行分组, 0 表示第 1 个字段索引，就是上面泛型&lt;k,v&gt; 中的 k 为 word 字段 UnsortedGrouping&lt;Tuple2&lt;String, Long&gt;&gt; wordAndOneGroup = wordAndOneTuple.groupBy (0); // 5. 分组进行聚合(求和)统计，1 表示第 2 个字段索引，就是上面泛型&lt;k,v&gt; 中的 v 为 1L 数值的字段 AggregateOperator&lt;Tuple2&lt;String, Long&gt;&gt; sum = wordAndOneGroup.sum (1); // 6. 打印 sum.print ( ); } } 2、流处理（有界）package com.kk.wc; import org.apache.flink.api.common.typeinfo.Types; import org.apache.flink.api.java.tuple.Tuple2; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.datastream.KeyedStream; import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; import org.apache.flink.util.Collector; /* * @Description: 流处理有界流 * @Author: 阿K * @CreateDate: 2022/5/19 21:14 * @Param: * @Return: **/ public class BoundedStreamWordCount { public static void main(String[] args) throws Exception{ // 1. 创建流式执行环境 StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); // 2. 从文件读取数据 按行读取(存储的元素就是每行的文本) DataStreamSource&lt;String&gt; listDateSource = env.readTextFile (\"input/words.txt\"); // 3. 将每行数据进行分词，转换成二元组类型 SingleOutputStreamOperator&lt;Tuple2&lt;String, Long&gt;&gt; wordAndOne = listDateSource.flatMap ((String line, Collector&lt;Tuple2&lt;String,Long&gt;&gt; out) -&gt; { String[] words = line.split (\" \"); for (String word : words) { out.collect (Tuple2.of (word,1L)); } }).returns (Types.TUPLE (Types.STRING, Types.LONG)); // 4. 分组(keyBy 按照 key 分组 KeyedStream&lt;Tuple2&lt;String, Long&gt;, String&gt; wordAndOneKS = wordAndOne.keyBy (data -&gt; data.f0); // 5. 求和 SingleOutputStreamOperator&lt;Tuple2&lt;String, Long&gt;&gt; result = wordAndOneKS.sum (1); // 6. 打印 result.print (); // 7. 执行 env.execute (); } } 3、流处理（无界）利用 nc 模拟实时推送，可以参考底下 【5】 package com.kk.wc; import org.apache.flink.api.common.typeinfo.Types; import org.apache.flink.api.java.tuple.Tuple2; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.datastream.KeyedStream; import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; import org.apache.flink.util.Collector; /* * @Description: 流式计算（nc 测试无界流） * @Author: 阿K * @CreateDate: 2022/5/19 22:43 * @Param: * @Return: **/ public class StreamWordCount { public static void main(String[] args) throws Exception{ // 1. 创建流式执行环境 StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); // 2. 读取文本流(远程机) DataStreamSource&lt;String&gt; lineDataStream = env.socketTextStream (\"101.34.180.133\", 7777); // 3. 将每行数据进行分词，转换成二元组类型 SingleOutputStreamOperator&lt;Tuple2&lt;String, Long&gt;&gt; wordAndOne = lineDataStream.flatMap ((String line, Collector&lt;Tuple2&lt;String,Long&gt;&gt; out) -&gt; { String[] words = line.split (\" \"); for (String word : words) { out.collect (Tuple2.of (word,1L)); } }).returns (Types.TUPLE (Types.STRING, Types.LONG)); // 4. 分组(keyBy 按照 key 分组 KeyedStream&lt;Tuple2&lt;String, Long&gt;, String&gt; wordAndOneKS = wordAndOne.keyBy (data -&gt; data.f0); // 5. 求和 SingleOutputStreamOperator&lt;Tuple2&lt;String, Long&gt;&gt; result = wordAndOneKS.sum (1); // 6. 打印 result.print (); // 7. 执行 env.execute (); } } 测试上面可以用 nc 测试（实时模拟数据发送） 二、作业部署1、搭建FlinkFlink 是一个分布式的流处理框架，所以实际应用一般都需要搭建集群环境。作者初学就搭建单机好了 有条件就用 docker 快速占用小，可以参考下面第六 1.官网下载flink-1.13.0-bin-scala_2.12.tgz 2.解压mkdir /opt/module/ tar -zxvf flink-1.13.0-bin-scala_2.12.tgz -C /opt/module/ 3.启动cd flink-1.13.0/ # 启动 bin/start-cluster.sh # 停止 bin/stop-cluster.sh 2、打包&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;FlinkTutorial&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;flink.version&gt;1.13.0&lt;/flink.version&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;scala.binary.version&gt;2.12&lt;/scala.binary.version&gt; &lt;slf4j.version&gt;1.7.30&lt;/slf4j.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- 引入Flink相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-java&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-streaming-java_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-clients_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-kafka_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.bahir&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-redis_2.11&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-elasticsearch6_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-jdbc_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-statebackend-rocksdb_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;1.13.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-table-api-java-bridge_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-table-planner-blink_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-streaming-scala_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-csv&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-cep_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 引入日志管理相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;${slf4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-to-slf4j&lt;/artifactId&gt; &lt;version&gt;2.14.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt; &lt;version&gt;2.7.5&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;${java.version}&lt;/source&gt; &lt;target&gt;${java.version}&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 会生成两个 jar ，一个有 flink依赖的比较大，一个没有依赖的比较小 3、提交作业1、选择一个 jar 小的那个没有依赖的 2、上传，登录UI面板：http://101.34.180.133:8081/ 3、配置启动类 一个节点选择 1，两个节点选择 2 4、启动 nc 模拟 5、任务提交成功之后，可点击左侧导航栏的“Running Jobs”查看程序运行列表情况 三、搭建kafkadocker版本搭建 zookeeper and kafka 1、zookeeperdocker run -d --name zookeeper -p 2181:2181 -v /etc/localtime:/etc/localtime wurstmeister/zookeeper 2、kafka这边需要注意网段，192.168.16.4 ifconfig 查看下，如果用127.0.0.1 可能会闪退 docker run -d --name kafka -p 9092:9092 -e KAFKA_BROKER_ID=0 -e KAFKA_ZOOKEEPER_CONNECT=192.168.16.4:2181 -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://106.12.159.22:9092 -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 -t wurstmeister/kafka -e KAFKA_BROKER_ID=0 在kafka集群中，每个kafka都有一个BROKER_ID来区分自己 -e KAFKA_ZOOKEEPER_CONNECT=192.168.16.4:2181/kafka 配置zookeeper管理kafka的路径10.9.44.11:2181/kafka -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.16.4:9092 把kafka的地址端口注册给zookeeper -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 配置kafka的监听端口 -v /etc/localtime:/etc/localtime 容器时间同步虚拟机的时间 公网配置映射参数：才能让你的kafka被远程访问，底下配置只有 KAFKA_ADVERTISED_LISTENERS 必须是公网映射 docker run -d –restart=always –name kafka -p 9092:9092 -e KAFKA_BROKER_ID=1 -e KAFKA_auto_create_topics_enable=true \\-e KAFKA_HEAP_OPTS=”-Xmx256M -Xms128M” -e KAFKA_ZOOKEEPER_CONNECT=公网ip:2181 -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://公网ip:9092 -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 \\ 3、检验kafka1、进入容器docker exec -it kafka /bin/sh 2、切换到路径cd /opt/kafka/bin 3、运行kafka生产者命令./kafka-console-producer.sh --broker-list localhost:9092 --topic clicks 4、运行消费者命令注意：topic 主题要一致，方能消费到 ./kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic clicks 5、发送数据aaa bbb 6、效果图 Ⅲ、DataStream API一、概念DataStream（数据流）本身是 Flink 中一个用来表示数据集合的类，这套核心 API 可以做流处理以及批处理,这套API 主要做的是数据的转换 一个 Flink 程序，其实就是对 DataStream 的各种转换。具体来说，代码基本上都由以下几部分构成 获取执行环境 读取数据源 定义基于数据的转换操作 定义计算结果的输出位置 触发程序执行 二、执行环境运行环境：本地 JVM 中执行程序，也可以提交到远程集群上运行。 1、创建执行环境我 们 要 获 取 的 执 行 环 境 ， 是 StreamExecutionEnvironment 类的对象，这是所有 Flink 程序的基础。 创建执行环境的方式，就是调用这个类的静态方法，具体有以下三种： getExecutionEnvironment StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); - 智能判断：如果当前程序是独立运行，则返回一个本地环境；如果是集群环境，则返回集群环境 - **createLocalEnvironment** - ```java StreamExecutionEnvironment localEnv = StreamExecutionEnvironment.createLocalEnvironment ( ); 这个方法返回一个本地执行环境。可以在调用时传入一个参数，指定默认的并行度；如果不传入，则默认并行度就是本地的 CPU 核心数。 createRemoteEnvironment StreamExecutionEnvironment remoteEnv = StreamExecutionEnvironment .createRemoteEnvironment ( \"host\", // JobManager 主机名 1234, // JobManager 进程端口号 \"path/to/jarFile.jar\" // 提交给 JobManager 的 JAR 包 ); - 在获取到程序执行环境后，还可以对执行环境进行灵活的设置。比如可以全局设置程序的并行度、禁用算子链，还可以定义程序的时间语义、配置容错机制。关于时间语义和容错机制 #### 2、执行模式 ```java // 批处理环境 ExecutionEnvironment batchEnv = ExecutionEnvironment.getExecutionEnvironment ( ); // 流处理环境 StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); 3、触发程序执行1、当 main()方法被调用时，其实只是定义了作业的每个执行操作，然后添加到数据流图中；这时并没有真正处理数据【因为数据可能还没来】 2、只有等到数据到来，才会触发真正的计算，这也被称为“延迟执行”或“懒执行” 3、所以我们需要显式地调用执行环境的 execute()方法，来触发程序执行。execute()方法将一直等待作业完成，然后返回一个执行结果 env.execute(); 三、源算子1、准备工作为了更好地理解，我们先构建一个实际应用场景。比如网站的访问操作，可以抽象成一个三元组（用户名，用户访问的 urrl，用户访问 url 的时间戳），所以在这里，我们可以创建一个类 Event，将用户行为包装成它的一个对象。Event 包含了以下一些字段 字段名 数据类型 说明 user String 用户名 url String 用户访问的url timeStamp Long 用户访问url的时间戳 package com.kk.model2.pojo; import lombok.AllArgsConstructor; import lombok.NoArgsConstructor; import lombok.ToString; @NoArgsConstructor @AllArgsConstructor @ToString public class Event { public String user; public String url; public Long timestamp; } 这里需要注意，我们定义的 Event，有这样几个特点： 类是公有（public）的 有一个无参的构造方法 所有属性都是公有（public）的 所有属性的类型都是可以序列化的 Flink 会把这样的类作为一种特殊的 POJO 数据类型来对待，方便数据的解析和序列化。 2、常规读数据集合读数据-文件读数据-Socket 读数据 package com.kk.model2; import com.kk.model2.pojo.Event; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; import java.util.ArrayList; /* * @Description: 集合中读取数据 * @Author: 阿K * @CreateDate: 2022/5/24 22:04 * @Param: * @Return: **/ public class SourceTest1 { public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); // 设置并行度为 1 ，保证有序运行 env.setParallelism (1); // 1.从文件中读取数据 DataStreamSource&lt;String&gt; stream1 = env.readTextFile (\"input/clicks.csv\"); // 2.从集合中读取数据 ArrayList&lt;Integer&gt; nums = new ArrayList&lt;&gt; ( ); nums.add (2); nums.add (5); DataStreamSource&lt;Integer&gt; numStream = env.fromCollection (nums); ArrayList&lt;Event&gt; events = new ArrayList&lt;&gt; ( ); events.add (new Event (\"Mary\", \"./home\", 1000L)); events.add (new Event (\"Bob\", \"./cart\", 2000L)); DataStreamSource&lt;Event&gt; stream2 = env.fromCollection (events); // 3.从元素读取数据 DataStreamSource&lt;Event&gt; stream3 = env.fromElements ( new Event (\"Mary\", \"./home\", 1000L), new Event (\"Bob\", \"./cart\", 2000L) ); // 从Socket文本流读取 DataStreamSource&lt;String&gt; stream4 = env.socketTextStream (\"localhost\", 7777); // stream1.print(\"1\"); // numStream.print(\"nums\"); // stream2.print(\"2\"); // stream3.print(\"3\"); stream4.print (\"4\"); env.execute ( ); } } 3、Kafka 读数据 ★Flink 官方提供的是一个通用的 Kafka 连接器，它会自动跟踪最新版本的 Kafka 客户端 &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-kafka_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; 然后调用 env.addSource()，传入 FlinkKafkaConsumer 的对象实例就可以了 package com.kk.model2; import org.apache.flink.api.common.serialization.SimpleStringSchema; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer; import java.util.Properties; public class SourceKafkaTest { public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.setParallelism (1); Properties properties = new Properties ( ); properties.setProperty (\"bootstrap.servers\", \"106.12.159.22:9092\"); // properties.setProperty(\"group.id\", \"consumer-group\"); // properties.setProperty(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); // properties.setProperty(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\"); // properties.setProperty(\"auto.offset.reset\", \"latest\"); DataStreamSource&lt;String&gt; stream = env.addSource (new FlinkKafkaConsumer&lt;String&gt; ( \"sun\", new SimpleStringSchema ( ), properties )); stream.print ( ); env.execute ( ); } } 创建 FlinkKafkaConsumer 时需要传入三个参数： ⚫ 第一个参数 topic，定义了从哪些主题中读取数据。可以是一个 topic，也可以是 topic列表，还可以是匹配所有想要读取的 topic 的正则表达式。当从多个 topic 中读取数据时，Kafka 连接器将会处理所有 topic 的分区，将这些分区的数据放到一条流中去。 ⚫ 第二个参数是一个 DeserializationSchema 或者 KeyedDeserializationSchema。Kafka 消息被存储为原始的字节数据，所以需要反序列化成 Java 或者 Scala 对象。上面代码中使用的 SimpleStringSchema，是一个内置的 DeserializationSchema，它只是将字节数组简单地反序列化成字符串。DeserializationSchema 和 KeyedDeserializationSchema 是公共接口，所以我们也可以自定义反序列化逻辑。 ⚫ 第三个参数是一个 Properties 对象，设置了 Kafka 客户端的一些属性。 结果： 4、自定义 Source想要读取的数据源来自某个外部系统，而 flink 既没有预实现的方法、也没有提供连接器， 我们创建一个自定义的数据源，实现 SourceFunction 接口 ⚫ run()方法：使用运行时上下文对象（SourceContext）向下游发送数据； ⚫ cancel()方法：通过标识位控制退出循环，来达到中断数据源的效果。 package com.kk.model2; import com.kk.model2.pojo.Event; import org.apache.flink.streaming.api.functions.source.SourceFunction; import java.util.Calendar; import java.util.Random; public class ClickSource implements SourceFunction&lt;Event&gt; { // 声明一个布尔变量，作为控制数据生成的标识位 private Boolean running = true; @Override public void run(SourceContext&lt;Event&gt; ctx) throws Exception { // 在指定的数据集中随机选取数据 Random random = new Random ( ); String[] users = {\"Mary\", \"Alice\", \"Bob\", \"Cary\"}; String[] urls = {\"./home\", \"./cart\", \"./fav\", \"./prod?id=1\", \"./prod?id=2\"}; while (running) { ctx.collect (new Event ( users[random.nextInt (users.length)], urls[random.nextInt (urls.length)], Calendar.getInstance ( ).getTimeInMillis ( ) )); // 隔 1 秒生成一个点击事件，方便观测 Thread.sleep (1000); } } @Override public void cancel() { running = false; } } 这个数据源，我们后面会频繁使用，所以在后面的代码中涉及到 ClickSource()数据源，使用上面的代码就可以了。 下面的代码我们来读取一下自定义的数据源。有了自定义的 source function，接下来只要调用 addSource()就可以了 public static void main(String[] args) throws Exception{ StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.setParallelism (1); // 有了自定义的 source function，调用 addSource 方法 DataStreamSource&lt;Event&gt; stream = env.addSource(new ClickSource()); stream.print(\"SourceCustom\"); env.execute(); } 所以如果我们想要自定义并行的数据源的话，需要使用 ParallelSourceFunction public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.addSource (new CustomSource ( )).setParallelism (2).print ( ); env.execute ( ); } public static class CustomSource implements ParallelSourceFunction&lt;Integer&gt; { private boolean running = true; private Random random = new Random ( ); @Override public void run(SourceContext&lt;Integer&gt; sourceContext) throws Exception { while (running) { sourceContext.collect (random.nextInt ( )); } } @Override public void cancel() { running = false; } } 5、Flink 支持的数据类型1. Flink 的类型系统Flink 有自己一整套类型系统。Flink 使用“类型信息” （TypeInformation）来统一表示数据类型。TypeInformation 类是 Flink 中所有类型描述符的基类。 它涵盖了类型的一些基本属性，并为每个数据类型生成特定的序列化器、反序列化器和比较器。 2. Flink 支持的数据类型（1）基本类型 所有 Java 基本类型及其包装类，再加上 Void、String、Date、BigDecimal 和 BigInteger。 （2）数组类型 包括基本类型数组（PRIMITIVE_ARRAY）和对象数组(OBJECT_ARRAY) （3）复合数据类型 ⚫ Java 元组类型（TUPLE）：这是 Flink 内置的元组类型，是 Java API 的一部分。最多 25 个字段，也就是从 Tuple0~Tuple25，不支持空字段 ⚫ Scala 样例类及 Scala 元组：不支持空字段 ⚫ 行类型（ROW）：可以认为是具有任意个字段的元组,并支持空字段 ⚫ POJO：Flink 自定义的类似于 Java bean 模式的类 （4）辅助类型 Option、Either、List、Map 等 （5）泛型类型（GENERIC） Flink 支持所有的 Java 类和 Scala 类。不过如果没有按照上面 POJO 类型的要求来定义，就会被 Flink 当作泛型类来处理。Flink 会把泛型类型当作黑盒，无法获取它们内部的属性；它们也不是由 Flink 本身序列化的，而是由 Kryo 序列化的。在这些类型中，元组类型和 POJO 类型最为灵活，因为它们支持创建复杂类型。而相比之下，POJO 还支持在键（key）的定义中直接使用字段名，这会让我们的代码可读性大大增加。所以，在项目实践中，往往会将流处理程序中的元素类型定为 Flink 的 POJO 类型。 Flink 对 POJO 类型的要求如下： ⚫ 类是公共的（public）和独立的（standalone，也就是说没有非静态的内部类）； ⚫ 类有一个公共的无参构造方法； ⚫ 类中的所有字段是 public 且非 final 的；或者有一个公共的 getter 和 setter 方法，这些方法需要符合 Java bean 的命名规范。 所以我们看到，之前的 UserBehavior，就是我们创建的符合 Flink POJO 定义的数据类型。 3. 类型提示（Type Hints）由于 Java 中泛型擦除的存在，在某些特殊情况下（比如 Lambda 表达式中），为了解决这类问题，Java API 提供了专门的“类型提示”（type hints） .map(word -&gt; Tuple2.of(word, 1L)) .returns(Types.TUPLE(Types.STRING, Types.LONG)); --------------------------------------------------------------------------- returns(new TypeHint&lt;Tuple2&lt;Integer, SomeType&gt;&gt;(){}) 四、转换算子 1、基本转换算子1. 映射（map）主要用于将数据流中的数据进行转换，形成新的数据流。简单来说，消费一个元素就产出一个元素 我们只需要基于 DataStrema 调用 map()方法就可以进行转换处理。方法需要传入的参数是接口 MapFunction 的实现；返回值类型还是 DataStream eg：提取 Event 中的 user 字段的功能 package com.kk.model2; import com.kk.model2.pojo.Event; import org.apache.flink.api.common.functions.MapFunction; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; public class TransMapTest { public static void main(String[] args) throws Exception { // 创造执行环境 // 并行为 1 StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.setParallelism (1); // 构建数据 DataStreamSource&lt;Event&gt; stream = env.fromElements ( new Event (\"Mary\", \"./home\", 1000L), new Event (\"Bob\", \"./cart\", 2000L) ); // 写法一：传入匿名类，实现 MapFunction stream.map (new MapFunction&lt;Event, String&gt; ( ) { @Override public String map(Event e) throws Exception { return e.user; } }).print ( ); // 写法二： 传入 MapFunction 的实现类 //stream.map (new UserExtractor ()).print (); env.execute ( ); } public static class UserExtractor implements MapFunction&lt;Event, String&gt; { @Override public String map(Event e) throws Exception { return e.user; } } } 上面代码中，MapFunction 实现类的泛型类型，与输入数据类型和输出数据的类型有关。在实现 MapFunction 接口的时候，需要指定两个泛型，分别是输入事件和输出事件的类型，还需要重写一个 map()方法，定义从一个输入事件转换为另一个输出事件的具体逻辑。 2. 过滤（filter）filter 转换操作，顾名思义是对数据流执行一个过滤，通过一个布尔条件表达式设置过滤条件，对于每一个流内元素进行判断，若为 true 则元素正常输出，若为 false 则元素被过滤掉 package com.kk.model2; import com.kk.model2.pojo.Event; import org.apache.flink.api.common.functions.FilterFunction; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; public class TransFilterTest { public static void main(String[] args) throws Exception { // 创造执行环境 // 并行为 1 StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.setParallelism (1); // 构建数据 DataStreamSource&lt;Event&gt; stream = env.fromElements ( new Event (\"Mary\", \"./home\", 1000L), new Event (\"Bob\", \"./cart\", 2000L) ); // 写法一：传入匿名类实现 FilterFunction stream.filter (new FilterFunction&lt;Event&gt; ( ) { @Override public boolean filter(Event e) throws Exception { return e.user.equals (\"Bob\"); } }).print ( ); // 写法二：传入 FilterFunction 实现类 stream.filter (new UserFilter ( )).print ( ); env.execute ( ); } public static class UserFilter implements FilterFunction&lt;Event&gt; { @Override public boolean filter(Event e) throws Exception { return e.user.equals (\"Mary\"); } } } 进行 filter 转换之后的新数据流的数据类型与原数据流是相同的。filter 转换需要传入的参数需要实现 FilterFunction 接口，而 FilterFunction 内要实现 filter()方法，就相当于一个返回布尔类型的条件表达式。 3、扁平映射（flatMap）flatMap 操作又称为扁平映射，主要是将数据流中的整体（一般是集合类型）拆分成一个一个的个体使用。消费一个元素，可以产生 0 到多个元素,也就是先按照某种规则对数据进行打散拆分，再对拆分后的元素做转换处理 package com.kk.model2; import com.kk.model2.pojo.Event; import org.apache.flink.api.common.functions.FlatMapFunction; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; import org.apache.flink.util.Collector; public class TransFlatmapTest { public static void main(String[] args) throws Exception { // 创造执行环境 // 并行为 1 StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.setParallelism (1); // 构建数据 DataStreamSource&lt;Event&gt; stream = env.fromElements ( new Event (\"Mary\", \"./home\", 1000L), new Event (\"Bob\", \"./cart\", 2000L) ); stream.flatMap (new FlatMapFunction&lt;Event, String&gt; ( ) { @Override public void flatMap(Event e, Collector&lt;String&gt; collector) throws Exception { if (e.user.equals (\"Mary\")) { collector.collect (e.user); } else if (e.user.equals (\"Bob\")) { collector.collect (e.user); collector.collect (e.url); } } }).print ( );// print () 打印 // 执行 env.execute ( ); } } flatMap 操作会应用在每一个输入事件上面，FlatMapFunction 接口中定义了 flatMap 方法， 用户可以重写这个方法，在这个方法中对输入数据进行处理，并决定是返回 0 个、1 个或多个结果数据。因此 flatMap 并没有直接定义返回值类型，而是通过一个“收集器”（Collector）来指定输出。希望输出结果时，只要调用收集器的.collect()方法就可以了；这个方法可以多次调用，也可以不调用。所以 flatMap 方法也可以实现 map 方法和 filter 方法的功能，当返回结果是 0 个的时候，就相当于对数据进行了过滤，当返回结果是 1 个的时候，相当于对数据进行了简单的转换操作。 2、聚合算子1. 按键分区keyBy 是聚合前必须要用到的一个算子。keyBy 通过指定键（key），可以将一条流从逻辑上划分成不同的分区（partitions）。这里所说的分区，其实就是并行处理的子任务，也就对应着任务槽 package com.kk.model2; import com.kk.model2.pojo.Event; import org.apache.flink.streaming.api.datastream.DataStreamSink; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; public class TransKeyByTest { public static void main(String[] args) throws Exception { // 创造执行环境 // 并行为 1 StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.setParallelism (1); // 构建数据 DataStreamSource&lt;Event&gt; stream = env.fromElements ( new Event (\"Mary\", \"./home\", 1000L), new Event (\"Bob\", \"./cart\", 2000L) ); // lambda DataStreamSink&lt;Event&gt; byKeyStream = stream.keyBy (e -&gt; e.user).print ( ); env.execute ( ); } } 2. 简单聚合⚫ sum()：在输入流上，对指定的字段做叠加求和的操作。 ⚫ min()：在输入流上，对指定的字段求最小值。 ⚫ max()：在输入流上，对指定的字段求最大值。 ⚫ minBy()：与 min()类似，在输入流上针对指定字段求最小值。不同的是，min()只计算指定字段的最小值，其他字段会保留最初第一个数据的值；而 minBy()则会返回包 含字段最小值的整条数据。 ⚫ maxBy()：与 max()类似，在输入流上针对指定字段求最大值。两者区别与 min()/minBy()完全一致。 package com.kk.model2; import org.apache.flink.api.java.tuple.Tuple2; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; public class TransTupleAggreationTest { public static void main(String[] args) throws Exception { // 创造执行环境 // 并行为 1 StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.setParallelism (1); // 构建数据 DataStreamSource&lt;Tuple2&lt;String, Integer&gt;&gt; stream = env.fromElements ( Tuple2.of (\"a\", 1), Tuple2.of (\"a\", 5), Tuple2.of (\"a\", 3), Tuple2.of (\"b\", 4), Tuple2.of (\"b\", 5), Tuple2.of (\"b\", 2) ); // stream.keyBy(r -&gt; r.f0).sum(1).print(\"SUM:\"); // stream.keyBy(r -&gt; r.f0).sum(\"f1\").print(); stream.keyBy(r -&gt; r.f0).max(1).print(\"MAX\"); // stream.keyBy(r -&gt; r.f0).max(\"f1\").print(); // stream.keyBy(r -&gt; r.f0).min(1).print(); // stream.keyBy(r -&gt; r.f0).min(\"f1\").print(); // stream.keyBy(r -&gt; r.f0).maxBy(1).print(); // stream.keyBy(r -&gt; r.f0).maxBy(\"f1\").print(); // stream.keyBy(r -&gt; r.f0).minBy(1).print(); // stream.keyBy(r -&gt; r.f0).minBy(\"f1\").print(); env.execute (); } } 而如果数据流的类型是 POJO 类，那么就只能通过字段名称来指定，不能通过位置来指定了 package com.kk.model3; import com.kk.model2.pojo.Event; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; public class TransformSimpleaggTest { public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.setParallelism (1); DataStreamSource&lt;Event&gt; stream = env.fromElements ( new Event (\"Mary\", \"/home\", 1000L), new Event (\"Bob\", \"/cart\", 2000L), new Event (\"Alice\", \"/prod?id=100\", 3000L), new Event (\"Bob\", \"/prod?id=1\", 3300L), new Event (\"Bob\", \"/home?id=2\", 3800L), new Event (\"Alice\", \"/prod?id=200\", 3200L), new Event (\"Bob\", \"/home?id=3\", 4000L) ); // 按键分组之后进行聚合，提取当前用户最近一次访问数据（最大时间数值） /*stream.keyBy (new KeySelector&lt;Event, String&gt; ( ) { @Override public String getKey(Event val) { return val.user; } });*/ // 以后 user 作为 key,timestamp 作为排序值 stream.keyBy (val -&gt;val.user).max (\"timestamp\").print (\"max:\"); stream.keyBy (val -&gt;val.user).maxBy (\"timestamp\").print (\"maxBy:\"); env.execute (); // 总结：同样，max和maxBy的区别在于，max算子对某字段求最大值，maxBy返回具有最大值的元素。 } } 总结：同样，max和maxBy的区别在于，max算子对某字段求最大值，maxBy返回具有最大值的元素。 3. 归约聚合（reduce）需求：统计出用户访问频率最高的 package com.kk.model3; import com.kk.model2.pojo.Event; import org.apache.flink.api.common.functions.MapFunction; import org.apache.flink.api.common.functions.ReduceFunction; import org.apache.flink.api.java.tuple.Tuple2; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; public class TransformReduceTest { public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.setParallelism (1); DataStreamSource&lt;Event&gt; stream = env.fromElements ( new Event (\"Mary\", \"/home\", 1000L), new Event (\"Bob\", \"/cart\", 2000L), new Event (\"Alice\", \"/prod?id=100\", 3000L), new Event (\"Bob\", \"/prod?id=1\", 3300L), new Event (\"Alice\", \"/prod?id=200\", 3200L), new Event (\"Bob\", \"/home?id=2\", 3800L), new Event (\"Bob\", \"/home?id=3\", 4000L) ); // 1、统计每个用户的访问频率 // 依然是一个DataStream SingleOutputStreamOperator&lt;Tuple2&lt;String, Long&gt;&gt; clicksByUser = stream.map (new MapFunction&lt;Event, Tuple2&lt;String, Long&gt;&gt; ( ) { @Override public Tuple2&lt;String, Long&gt; map(Event val) { return Tuple2.of (val.user, 1L);// 将pojo转成二元组，每次用户+1次,相当于赋值List中的元素 } }).keyBy (data -&gt; data.f0)// 按键分区(组 .reduce (new ReduceFunction&lt;Tuple2&lt;String, Long&gt;&gt; ( ) { @Override public Tuple2&lt;String, Long&gt; reduce(Tuple2&lt;String, Long&gt; val1, Tuple2&lt;String, Long&gt; val2) throws Exception { // 新二元组 参1为key,参2为每次的叠加 return Tuple2.of (val1.f0, val1.f1 + val2.f1); } }); // 2、获取当前最活跃的用户 // 所有的数据都有相同的key，都会分配到同一个分区（生产慎用，同一个分区则为串行（单线程）） SingleOutputStreamOperator&lt;Tuple2&lt;String, Long&gt;&gt; result = clicksByUser.keyBy (data -&gt; \"key\") .reduce (new ReduceFunction&lt;Tuple2&lt;String, Long&gt;&gt; ( ) { @Override public Tuple2&lt;String, Long&gt; reduce(Tuple2&lt;String, Long&gt; val1, Tuple2&lt;String, Long&gt; val2) throws Exception { // 判断谁的数值大，输出完整实体 return val1.f1 &gt; val2.f1 ? val1 : val2; } }); result.print ( );// 输出 env.execute ( ); } } 3、自定义函数（UDF）1、函数类其实上面已经介绍过 2、匿名类其实上面已经介绍过 https://v1.mykkto.cn/image/blog/2022/Interview/202303252125554.png 3、富函数生命周期： open()方法，是 Rich Function 的初始化方法，也就是会开启一个算子的生命周期。当一个算子的实际工作方法例如 map()或者 filter()方法被调用之前， close()方法，是生命周期中的最后一个调用的方法，类似于解构方法。一般用来做一些清理工作。 需要注意的是，对于一个并行子任务来说只会调用一次；而对应的， 实际工作方法，在每个线程都会触发一次调用。 StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.setParallelism (1); 比如1是串行，就一个线程，那么开关方法就调用一次，如果 setParallelism 为2就是两次开关生命周期 上案例： package com.kk.model3; import com.kk.model2.pojo.Event; import org.apache.flink.api.common.functions.RichMapFunction; import org.apache.flink.configuration.Configuration; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; public class TransformRichFunctionTest { public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); // 注意：这边线程1个生命周期开关一次，2个便有2遍 env.setParallelism (1); DataStreamSource&lt;Event&gt; stream = env.fromElements ( new Event (\"Mary\", \"./home\", 1000L), new Event (\"Tom\", \"./cart\", 3000L), new Event (\"Bob\", \"./cart?id=1\", 2000L) ); // 设置并行度=生命周期次数 stream.map (new MyRichMapper ( )).setParallelism (2).print ( ); env.execute ( ); } public static class MyRichMapper extends RichMapFunction&lt;Event, Integer&gt; { @Override public void open(Configuration parameters) throws Exception { super.open (parameters); // 获取当前索引号 System.out.println (\"open生命周期被调用：\" + getRuntimeContext ( ).getIndexOfThisSubtask ( ) + \"号任务启动\"); } @Override public Integer map(Event value) { return value.url.length ( ); } @Override public void close() throws Exception { super.close ( ); System.out.println (\"close生命周期被调用：\" + getRuntimeContext ( ).getIndexOfThisSubtask ( ) + \"号任务启动\"); } } } open生命周期被调用：1号任务启动 open生命周期被调用：0号任务启动 close生命周期被调用：0号任务启动 close生命周期被调用：1号任务启动 6 11 6 一个常见的应用场景就是，如果我们希望连接到一个外部数据库进行读写操作，那么将连接操作放在 map()中显然不是个好选择——因为每来一条数据就会重新连接一次数据库；所以 我们可以在 open()中建立连接，在 map()中读写数据，而在 close()中关闭连接。所以我们推荐的最佳实践如下： public class MyFlatMap extends RichFlatMapFunction&lt;IN, OUT&gt;&gt; { @Override public void open(Configuration configuration) { // 做一些初始化工作 // 例如建立一个和 MySQL 的连接 } @Override public void flatMap(IN in, Collector&lt;OUT out) { // 对数据库进行读写 } @Override public void close() { // 清理工作，关闭和 MySQL 数据库的连接。 } } 4、物理分区1、随机分区2、轮训分区（默认）3、rescale 重缩放分区4、广播（发给每个线程）5、全局分区（强行设置成 1 串行）6、自定义重分区（有点像4）package com.kk.model3; import com.kk.model2.pojo.Event; import org.apache.flink.api.common.functions.Partitioner; import org.apache.flink.api.java.functions.KeySelector; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction; public class TransformPartitionTest { public static void main(String[] args)throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.setParallelism (1); DataStreamSource&lt;Event&gt; stream = env.fromElements ( new Event (\"Mary\", \"/home\", 1000L), new Event (\"Bob\", \"/cart\", 2000L), new Event (\"Alice\", \"/prod?id=100\", 3000L), new Event (\"Bob\", \"/prod?id=1\", 3300L), new Event (\"Alice\", \"/prod?id=200\", 3200L), new Event (\"Bob\", \"/home?id=2\", 3800L), new Event (\"Bob\", \"/home?id=3\", 4000L) ); m6 (env); env.execute (); } public static void m1(DataStreamSource stream){ // 1、随机分区 stream.shuffle ().print ().setParallelism (4); } public static void m2(DataStreamSource stream){ // 2、轮训分区 stream.print ().setParallelism (4); // stream.rebalance ().print ().setParallelism (3); } public static void m3(StreamExecutionEnvironment env){ // 3、rescale 重缩放分区(使用合理的话效率更高 // RichParallelSourceFunction 抽象父函数的子实现 env.addSource (new RichParallelSourceFunction&lt;String&gt; ( ) { @Override public void run(SourceContext&lt;String&gt; ctx)throws Exception { for (int i = 1; i &lt;= 8; i++) { // 将奇偶数分别发送到0号或1号分区 if (i%2==getRuntimeContext ().getIndexOfThisSubtask ()) ctx.collect (i+\",\"+getRuntimeContext ().getIndexOfThisSubtask ()); } } @Override public void cancel() { } }).setParallelism (2).rescale ().print ().setParallelism (4); } public static void m4(DataStreamSource stream){ // 4、广播（发给每个线程） stream.broadcast ().print ().setParallelism (4); } public static void m5(DataStreamSource stream){ // 5、全局分区（强行设置成 1 串行） stream.global ().print ().setParallelism (4); } public static void m6(StreamExecutionEnvironment env){ // 6、自定义重分区（自定义分区器，数据长什么样，就分配到哪里） env.fromElements (1,2,3,4,5,6,7,8) .partitionCustom (new Partitioner&lt;Integer&gt; ( ) { @Override public int partition(Integer key, int num) { // 指定分区策略 return key % 2; } }, new KeySelector&lt;Integer, Integer&gt; ( ) { @Override public Integer getKey(Integer value) throws Exception { return value; } }) .print ().setParallelism (4); } } 五、输出算子1、输出到文件比如我们经常用的日志文件，就是类似于这种滚动输出 package com.kk.model4; import com.kk.BaseUtil; import org.apache.flink.api.common.serialization.SimpleStringEncoder; import org.apache.flink.core.fs.Path; import org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink; import org.apache.flink.streaming.api.functions.sink.filesystem.rollingpolicies.DefaultRollingPolicy; import java.util.concurrent.TimeUnit; public class SinkToFileTest { public static void main(String[] args) throws Exception { // 1、定义String类型方便输出 StreamingFileSink&lt;String&gt; streamingFileSink = StreamingFileSink.&lt;String&gt;forRowFormat ( new Path (\"./output\"),// 输出路径 new SimpleStringEncoder&lt;&gt; (\"UTF-8\"))//字符集 // 指定滚动策略： // 比如日志文件不停写入，文件不停增大，那么需要一个策略设置一个文件多大停止写入， // 开启一个新的文件继续写入 .withRollingPolicy ( DefaultRollingPolicy.builder ( ) .withMaxPartSize (1024 * 1024 * 1024)// 滚动大小：1G // 滚动时间，15分钟开启一个新的 .withRolloverInterval (TimeUnit.MINUTES.toMinutes (15)) // 滚动周期（如果5分钟没有数据写入，则开启一个新的文件） .withInactivityInterval (TimeUnit.MINUTES.toMinutes (5)) .build ( ) ) .build ( );// 构建返回对象 BaseUtil.stream.map (data -&gt; data.toString ( )) .addSink (streamingFileSink); BaseUtil.env.setParallelism (4); BaseUtil.env.execute (); } } 2、输出到kafka（1）创建生产者 1、进入容器 docker exec -it kafka /bin/sh 2、进入驱动文件路径 cd opt/kafka/bin 3、创建生产者 ./kafka-console-producer.sh --broker-list localhost:9092 --topic clicks （2）创建消费者 ./kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic events （3）编码 package com.kk.model4; import com.kk.BaseUtil; import com.kk.model2.pojo.Event; import org.apache.flink.api.common.functions.MapFunction; import org.apache.flink.api.common.serialization.SimpleStringSchema; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer; import org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer; import java.util.Properties; public class SinkToKafka { public static void main(String[] args)throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.setParallelism (1); Properties properties = new Properties ( ); properties.setProperty (\"bootstrap.servers\", BaseUtil.KAFKAURL); // 1、从kafka中读取数据 DataStreamSource&lt;String&gt; kafkaStream = env.addSource (new FlinkKafkaConsumer&lt;String&gt; ( \"clicks\", new SimpleStringSchema ( ), properties )); kafkaStream.print ( ); // 2、用flink进行转换处理 SingleOutputStreamOperator&lt;String&gt; result = kafkaStream.map (new MapFunction&lt;String, String&gt; ( ) { @Override public String map(String value) { String[] fields = value.split (\",\"); return new Event (fields[0].trim ( ), fields[1].trim ( ), Long.valueOf (fields[2])).toString ( ); } }); // 3、结果数据写入 kafka result.addSink (new FlinkKafkaProducer&lt;String&gt; (BaseUtil.KAFKAURL,\"events\",new SimpleStringSchema ())); env.execute (); } } (4)流程 生产者发送 -》 flink 接收处理 -》 kafka 消费者消费 （X）补充：kafka 对外远程映射 docker 启动需要指定公网配置，如果没有配置的话，需要在配置文件配置(重启有自动重刷回原始的问题) 配置路径：opt/kafka/conf/services.properties 3、输出到Redis&lt;dependency&gt; &lt;groupId&gt;org.apache.bahir&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-redis_2.11&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/dependency&gt; 需要实现一个子类实现接口 RedisMapper，这边使用匿名类，主要是 RedisCommandDescription 的两个参数，以及其他两个函数key，value的重写 package com.kk.model4; import com.kk.model2.ClickSource; import com.kk.model2.pojo.Event; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; import org.apache.flink.streaming.connectors.redis.RedisSink; import org.apache.flink.streaming.connectors.redis.common.config.FlinkJedisPoolConfig; import org.apache.flink.streaming.connectors.redis.common.mapper.RedisCommand; import org.apache.flink.streaming.connectors.redis.common.mapper.RedisCommandDescription; import org.apache.flink.streaming.connectors.redis.common.mapper.RedisMapper; public class SinkToRedis { public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment ( ); env.setParallelism (1); // Event 是我们封装的类实体 FlinkJedisPoolConfig conf = new FlinkJedisPoolConfig.Builder ( ).setHost (IpUtil.IPREDIS).build ( ); env.addSource (new ClickSource ( )) // 匿名内部类实现 RedisMapper接口 .addSink (new RedisSink&lt;Event&gt; (conf, new RedisMapper&lt;Event&gt; ( ) { @Override public String getKeyFromData(Event e) { return e.user; } @Override public String getValueFromData(Event event) { return event.url; } @Override public RedisCommandDescription getCommandDescription() { // 参数1：redis 存储的数据结构类型 hset 散列函数 // 参数2：redis 的 key clicks return new RedisCommandDescription (RedisCommand.HSET, \"clicks\"); } })); env.execute ( ); } // 自定义实现RedisMapper接口 //public static class MyRedisMapper implements RedisMapper&lt;Event&gt; } 4、输出到ElasticecSearch&lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-connector-elasticsearch7_${scala.binary.version}&lt;/artifactId&gt; &lt;version&gt;${flink.version}&lt;/version&gt; &lt;/dependency&gt; package com.kk.model4; import com.kk.model2.pojo.Event; import org.apache.flink.api.common.functions.RuntimeContext; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; import org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkFunction; import org.apache.flink.streaming.connectors.elasticsearch.RequestIndexer; import org.apache.flink.streaming.connectors.elasticsearch6.ElasticsearchSink; import org.apache.http.HttpHost; import org.elasticsearch.action.index.IndexRequest; import org.elasticsearch.client.Requests; import java.util.ArrayList; import java.util.HashMap; public class SinkToElasticSearch { public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment .getExecutionEnvironment ( ); env.setParallelism (1); Event[] events = { new Event (\"Mary\", \"./home\", 1000L), new Event (\"Bob\", \"./cart\", 2000L), new Event (\"Alice\", \"./prod?id=100\", 3000L), new Event (\"Alice\", \"./prod?id=200\", 3500L), new Event (\"Bob\", \"./prod?id=2\", 2500L), new Event (\"Alice\", \"./prod?id=300\", 3600L), new Event (\"Bob\", \"./home\", 3000L), new Event (\"Bob\", \"./prod?id=1\", 2300L), new Event (\"Bob\", \"./prod?id=3\", 3300L) }; // 参数是个可变数组 DataStreamSource&lt;Event&gt; stream = env.fromElements (events); ArrayList&lt;HttpHost&gt; httpHosts = new ArrayList&lt;&gt; ( ); httpHosts.add (new HttpHost (IpUtil.IPES, 9200, \"http\")); // 创建一个 ElasticsearchSinkFunction ElasticsearchSinkFunction&lt;Event&gt; elasticsearchSinkFunction = new ElasticsearchSinkFunction&lt;Event&gt; ( ) { @Override public void process(Event event, RuntimeContext ctx, RequestIndexer indexer) { HashMap&lt;String, String&gt; data = new HashMap&lt;&gt; ( ); data.put (event.user, event.url); IndexRequest request = Requests.indexRequest ( ) .index (\"clicks\") // key名 .type (\"type\")// Es 6 必须定义 type .source (data); indexer.add (request); } }; stream.addSink (new ElasticsearchSink.Builder&lt;Event&gt; (httpHosts, elasticsearchSinkFunction).build ( )); env.execute ( ); } } es支持 rest风格，所以直接访问查看是否有数据了 5、输出到MySQL(JDBC)create table clicks( user varchar(20) not null, url varchar(100) not null); package com.kk.model4; import com.kk.model2.pojo.Event; import org.apache.flink.connector.jdbc.JdbcConnectionOptions; import org.apache.flink.connector.jdbc.JdbcExecutionOptions; import org.apache.flink.connector.jdbc.JdbcSink; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; public class SinkToMySQL { public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment .getExecutionEnvironment ( ); DataStreamSource&lt;Event&gt; stream = env.fromElements ( new Event (\"Mary\", \"./home\", 1000L), new Event (\"Bob\", \"./cart\", 2000L), new Event (\"Alice\", \"./prod?id=100\", 3000L), new Event (\"Alice\", \"./prod?id=200\", 3500L), new Event (\"Bob\", \"./prod?id=2\", 2500L), new Event (\"Alice\", \"./prod?id=300\", 3600L), new Event (\"Bob\", \"./home\", 3000L), new Event (\"Bob\", \"./prod?id=1\", 2300L), new Event (\"Bob\", \"./prod?id=3\", 3300L)); stream.addSink ( JdbcSink.sink ( \"INSERT INTO clicks (user, url) VALUES (?, ?)\", (statement, r) -&gt; { statement.setString (1, r.user); statement.setString (2, r.url); }, JdbcExecutionOptions.builder ( ) .withBatchSize (1000) .withBatchIntervalMs (200) .withMaxRetries (5) .build ( ), new JdbcConnectionOptions.JdbcConnectionOptionsBuilder ( ) .withUrl (\"jdbc:mysql://localhost:3306/book\") // 对于 MySQL 5.7，用\"com.mysql.jdbc.Driver\" .withDriverName (\"com.mysql.jdbc.Driver\") .withUsername (\"root\") .withPassword (\"a1b2c3\") .build ( ) ) ); env.execute ( ); } } 6、自定义Sink输出Flink 为我们提供了通用的 SinkFunction 接口和对应的 RichSinkDunction 抽象类，只要实现它，通过简单地调用 DataStream 的.addSink()方法就可以自定义写入任何外部存储。 例如，Flink 并没有提供 HBase 的连接器，所以需要我们自己写 在实现 SinkFunction 的时候，需要重写的一个关键方法 invoke(), 创建 HBase 的连接以及关闭 HBase 的连接需要分别放在 open()方法和 close()方法中。 docker run -itd -h hbase.dev.xhyun.vip --name hbase2.1 -p 2181:2181 -p 8080:8080 -p 8085:8085 -p 9090:9090 -p 9095:9095 -p 16000:16000 -p 16010:16010 -p 16201:16201 -p 16301:16301 harisekhon/hbase:2.1 访问地址：http://mykkto.cn:16010/master-status Ⅳ、Flink 时间和窗口一、时间语义二、水位线三、窗口四、迟到数据的处理五、总结Ⅴ、处理函数Ⅵ、多流转换Ⅶ、状态编程Ⅷ、容错机制Ⅸ、Table API and SQLⅩ、Flink CEP参考地址 ↓1、docker 加速（博主简书）url：https://www.jianshu.com/p/f554c85b25c1 2、Hadoop 单机安装url：https://blog.51cto.com/u_15187242/4760802 docker run -i -t --network host -p 50070:50070 -p 9000:9000 -p 8088:8088 -p 8040:8040 -p 8042:8042 -p 49707:49707 -p 50010:50010 -p 50075:50075 -p 50090:50090 sequenceiq/hadoop-docker:2.7.0 /etc/bootstrap.sh -bash 3、Hadoop集群url：https://dhcp.cn/k8s/docker/deploy_hadoop.html#reference 4、Hadoop常用端口url：https://blog.csdn.net/qq_36816848/article/details/113106441 5、nc -lk 模拟实时数据url：https://www.csdn.net/tags/MtzakgwsODA4NjktYmxvZwO0O0OO0O0O.html 6、Flink（docker）快速搭建url：https://blog.csdn.net/weixin_42357472/article/details/118223101 7、Zookeeper(docker)快速搭建拉取url：https://blog.csdn.net/u010416101/article/details/122803105 启动url：https://www.cnblogs.com/shanfeng1000/p/14488665.html 8、kafka(docker)快速搭建搭建url：https://www.cnblogs.com/shanfeng1000/p/14638455.html 使用url：https://blog.csdn.net/qq_22041375/article/details/106180415 9、ES（docker）快速搭建url：https://www.cnblogs.com/nesn/p/15898123.html 10、Hbase(docker)搭建和测试url：https://www.cnblogs.com/user-sunli/p/16362500.html","categories":[{"name":"大数据","slug":"大数据","permalink":"https://mykkto.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"Flink","slug":"Flink","permalink":"https://mykkto.github.io/tags/Flink/"},{"name":"hadoop","slug":"hadoop","permalink":"https://mykkto.github.io/tags/hadoop/"},{"name":"kafka","slug":"kafka","permalink":"https://mykkto.github.io/tags/kafka/"}],"author":"mykk"},{"title":"项目-金融背景及其后端搭建","slug":"08-项目/01尚融宝/01_金融项目说明和搭建","date":"2022-04-26T15:11:33.000Z","updated":"2023-02-26T14:08:44.233Z","comments":true,"path":"posts/a6407b24.html","link":"","permalink":"https://mykkto.github.io/posts/a6407b24.html","excerpt":"","text":"〇、主目录总纲Ⅰ、项目概念一、项目简介1、项目说明尚融宝是一个网络借贷信息中介服务平台，为个人投资者、个人融资用户和小微企业提供专业的线上信贷及出借撮合服务。 行业案例：人人贷 https://www.renrendai.com/、拍拍贷 https://www.paipaidai.com/ 2、项目架构图 3、业务流程图 二、开发环境和技术栈1、技术栈-后端 SpringBoot 2.3.4.RELEASE SpringCloud Hoxton.SR8：微服务基础设施 - 服务注册、服务发现、服务熔断、微服务网关、配置中心等 SpringCloud Alibaba 2.2.2.RELEASE MyBatis Plus：持久层框架和代码生成器 Lombok：简化实体类开发 Swagger2：Api接口文档生成工具 Logback：日志系统 alibaba-easyexcel：Excel读写 Spring Data Redis：Spring项目中访问Redis缓存 HTTPClient: 基于Http协议的客户端，用来实现远程调用 Spring Task：定时任务 2、技术栈-前端 Node.js： JavaScript 运行环境 ES6：JavaScript的模块化版本 axios：一个发送Ajax请求的工具 Vue.js：web 界面的渐进式框架 Element-UI：前端组件库 模块化开发：解决javascript变量全局空间污染的问题 NPM：模块资源管理器 vue-element-admin：基于Vue.js的后台管理系统UI集成方案 NuxtJS：基于Vue.js构建的服务器端渲染应用的轻量级框架 3、中间件 MySQL 5.7：关系型数据库 Redis 5.0：缓存技术 RabbitMQ 3.8：消息中间件 4、第三方接口 阿里云短信：短信网关 阿里云OSS：分布式文件存储 资金托管平台API对接：汇付宝 5、开发环境 jdk 1.8 maven 3.6 ideaIU-2020.2.3： 插件：lombok、MyBatisX 三、金融知识普及1、信用贷款平台的类别1、银行系 优势： 第一，资金雄厚，流动性充足； 第二，项目源质地优良，大多来自于银行原有中小型客户； 第三，风险控制能力强。如恒丰银行、招商银行等旗下都有信用贷款平台。 劣势：收益率偏低，预期年化收益率处于5.5%-8.6%之间，略高于银行其他理财产品，对投资人吸引力有限。 2、国资系 优势： 拥有国有背景股东的隐性背书，兑付能力有保障，业务模式较为规范，从业人员金融专业素养较高。 劣势： 缺乏互联网基因；项目标的较大，起投门槛较高；且产品种类有限，多为企业信用贷； 较为谨慎，层层审核的机制严重影响了平台运营效率；收益率不具有吸引力。 3、民营系民营系平台数量最多，起步最早，但鱼龙混杂，不胜枚举。 优势： 普惠金融，手续便捷；门槛极低，投资起点低最低起投门槛甚至50元； 强大的互联网思维，产品创新能力高，市场化程度高；收益率高，投资收益率具有吸引力。 劣势： 风险偏高，资本实力及风控能力偏弱，跑路及倒闭的高发区。 2、业务流程 1、投资人希望在平台上找到合适的投资项目，获取利润回报的用户 2、借款人需要资金周转的用户 3、资金池风险 资金池：一个大池子放钱，一边存进来（入水管），一边贷出去（出水管）。不管是张三的钱、李四的钱、还是王五的钱，只要进到池子里，就都叫池子的钱了。银行就是典型的资金池。 资金池风险： 第一种情况：投资入水管流量过大，池子里全是水。这种情况，平台亏钱，干不长。原因很简单，池子里的钱是有成本的，只进不出，没有利差，拿什么钱付投资人的利息，时间长了，就只能用投资人的本金还投资人的利息，借新还旧，庞氏骗局。这个过程就直接背离了平台信息中介的身份，而成了与银行类似的金融机构。 第二种情况：突然来了这么多钱，怎么办？只能把放贷出水管的流量调大。放贷的这条出水管上有两个阀门，一个叫找项目，一个叫做风控。遇到这种情况，经常就是两个阀门一块儿放，钱是贷出去了，但由于放松了对风险的把控，能不能再流回来，就不好说了，危险。 第三种情况：提款的出水管流量变大。比如，一个黑天鹅事件，一个负面新闻，一个平台垮了，都可能诱发这种情况，这就是挤兑。比如说某租宝事件后，不只这一家平台，很多其他平台的用户，也在疯狂的提现，有可能一直提到关门为止。 第四种情况最极端：平台把池子里的钱都提出来，走人。这个就不用解释了，就是 跑路。 以上四种情况就是资金池最主要的几个风险——经营不善，风险失控，挤兑和跑路。银监会发布的《网络借贷信息中介机构业务活动管理暂行办法》让资金存管成为网贷平台的硬性要求，同时降低了平台建立资金池、挪用用户资金的风险。 4、资金托管平台 第三方存管模式：“第三方存管”的全称是“客户交易结算资金第三方存管”。这里的第三方存管机构，目前是指具备第三方存管资格的商业银行。银行的流入资金成本低，风控体系较完善，资金池子足够大，而且是国家背书，不会跑路。 说明：由于我们是教学使用，无法申请到正式的资金托管平台的支持，所以我们根据资金托管平台API接口文档，自行开发模拟一套API接口来满足业务需要，业务过程与实际开发基本一致。 Ⅱ、后端架构搭建一、接口工程创建1、创建父工程 BackEndCode1、创建 maven 项目Group：com.kk Artifact：BackEndCode 2、删除src目录3、配置SpringBoot版本&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.3.4.RELEASE&lt;/version&gt; &lt;/parent&gt; 4、配置pom依赖版本号&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud-alibaba.version&gt;2.2.2.RELEASE&lt;/spring-cloud-alibaba.version&gt; &lt;spring-cloud.version&gt;Hoxton.SR8&lt;/spring-cloud.version&gt; &lt;mybatis-plus.version&gt;3.4.1&lt;/mybatis-plus.version&gt; &lt;velocity.version&gt;2.0&lt;/velocity.version&gt; &lt;swagger.version&gt;2.9.2&lt;/swagger.version&gt; &lt;swagger-bootstrap-ui.version&gt;1.9.2&lt;/swagger-bootstrap-ui.version&gt; &lt;commons-lang3.version&gt;3.9&lt;/commons-lang3.version&gt; &lt;commons-fileupload.version&gt;1.3.1&lt;/commons-fileupload.version&gt; &lt;commons-io.version&gt;2.6&lt;/commons-io.version&gt; &lt;alibaba.easyexcel.version&gt;2.1.1&lt;/alibaba.easyexcel.version&gt; &lt;apache.xmlbeans.version&gt;3.1.0&lt;/apache.xmlbeans.version&gt; &lt;fastjson.version&gt;1.2.28&lt;/fastjson.version&gt; &lt;gson.version&gt;2.8.2&lt;/gson.version&gt; &lt;json.version&gt;20170516&lt;/json.version&gt; &lt;aliyun-java-sdk-core.version&gt;4.3.3&lt;/aliyun-java-sdk-core.version&gt; &lt;aliyun-sdk-oss.version&gt;3.10.2&lt;/aliyun-sdk-oss.version&gt; &lt;jodatime.version&gt;2.10.1&lt;/jodatime.version&gt; &lt;jwt.version&gt;0.7.0&lt;/jwt.version&gt; &lt;httpclient.version&gt;4.5.1&lt;/httpclient.version&gt; &lt;/properties&gt; 5、配置pom依赖&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--Spring Cloud--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--Spring Cloud Alibaba--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;${spring-cloud-alibaba.version}&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--mybatis-plus--&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;${mybatis-plus.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--mybatis-plus 代码生成器--&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;version&gt;${mybatis-plus.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Mybatis Plus 代码生成器模板引擎, --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-engine-core&lt;/artifactId&gt; &lt;version&gt;${velocity.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--swagger--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;${swagger.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--swagger ui--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;${swagger.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--swagger-bootstrap-ui--&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt; &lt;version&gt;${swagger-bootstrap-ui.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--commons-lang3--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt; &lt;version&gt;${commons-lang3.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--文件上传--&gt; &lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;${commons-fileupload.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--commons-io--&gt; &lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;${commons-io.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--excel解析--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;easyexcel&lt;/artifactId&gt; &lt;version&gt;${alibaba.easyexcel.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--excel解析依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.xmlbeans&lt;/groupId&gt; &lt;artifactId&gt;xmlbeans&lt;/artifactId&gt; &lt;version&gt;${apache.xmlbeans.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--json--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;${fastjson.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.json&lt;/groupId&gt; &lt;artifactId&gt;json&lt;/artifactId&gt; &lt;version&gt;${json.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;version&gt;${gson.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--阿里云SDK远程调用--&gt; &lt;dependency&gt; &lt;groupId&gt;com.aliyun&lt;/groupId&gt; &lt;artifactId&gt;aliyun-java-sdk-core&lt;/artifactId&gt; &lt;version&gt;${aliyun-java-sdk-core.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--阿里云文件管理--&gt; &lt;dependency&gt; &lt;groupId&gt;com.aliyun.oss&lt;/groupId&gt; &lt;artifactId&gt;aliyun-sdk-oss&lt;/artifactId&gt; &lt;version&gt;${aliyun-sdk-oss.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--日期时间工具--&gt; &lt;dependency&gt; &lt;groupId&gt;joda-time&lt;/groupId&gt; &lt;artifactId&gt;joda-time&lt;/artifactId&gt; &lt;version&gt;${jodatime.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--jwt工具--&gt; &lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;${jwt.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--httpclient--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;${httpclient.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 2、创建模块kk-common1、创建Maven模块在 父工程 下创建普通maven模块 Group：com.kk Artifact：kk-common 2、配置pom&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--lombok用来简化实体类：需要安装lombok插件--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 3、创建模块service-base1、创建Maven模块在 父工程 下创建普通maven模块 Group：com.kk Artifact：service-base 2、配置pom注意：依赖kk-common &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;service-base&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--swagger--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--swagger ui--&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 4、创建模块service-core1、创建Maven模块在 父工程 下创建普通maven模块 Group：com.kk Artifact：service-core 2、配置pom注意：依赖kk-common &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;service-base&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mybatis-plus--&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mybatis-plus 代码生成器--&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Mybatis Plus 代码生成器模板引擎, --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-engine-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 5、代码生成器1、创建数据库创建数据库srb_core 并执行sql脚本初始化数据结构和数据 2、创建代码生成器在test目录中创建测试用例，并执行 package com.kk.srb.core; import com.baomidou.mybatisplus.annotation.DbType; import com.baomidou.mybatisplus.annotation.IdType; import com.baomidou.mybatisplus.generator.AutoGenerator; import com.baomidou.mybatisplus.generator.config.DataSourceConfig; import com.baomidou.mybatisplus.generator.config.GlobalConfig; import com.baomidou.mybatisplus.generator.config.PackageConfig; import com.baomidou.mybatisplus.generator.config.StrategyConfig; import com.baomidou.mybatisplus.generator.config.rules.NamingStrategy; import org.junit.Test; public class CodeGenerator { @Test public void genCode() { // 1、创建代码生成器 AutoGenerator mpg = new AutoGenerator ( ); // 2、全局配置 GlobalConfig gc = new GlobalConfig ( ); String projectPath = System.getProperty (\"user.dir\"); gc.setOutputDir (projectPath + \"/src/main/java\"); gc.setAuthor (\"mykk\"); gc.setOpen (false); //生成后是否打开资源管理器 gc.setServiceName (\"%sService\"); //去掉Service接口的首字母I gc.setIdType (IdType.AUTO); //主键策略 gc.setSwagger2 (true);//开启Swagger2模式 mpg.setGlobalConfig (gc); // 3、数据源配置 DataSourceConfig dsc = new DataSourceConfig ( ); dsc.setUrl (\"jdbc:mysql://121.4.120.62:3306/srb_core?serverTimezone=GMT%2B8&amp;characterEncoding=utf-8\"); dsc.setDriverName (\"com.mysql.cj.jdbc.Driver\"); dsc.setUsername (\"root\"); dsc.setPassword (\"root\"); dsc.setDbType (DbType.MYSQL); mpg.setDataSource (dsc); // 4、包配置 PackageConfig pc = new PackageConfig ( ); pc.setParent (\"com.kk.srb.core\"); pc.setEntity (\"pojo.entity\"); //此对象与数据库表结构一一对应，通过 DAO 层向上传输数据源对象。 mpg.setPackageInfo (pc); // 5、策略配置 StrategyConfig strategy = new StrategyConfig ( ); strategy.setNaming (NamingStrategy.underline_to_camel);//数据库表映射到实体的命名策略 strategy.setColumnNaming (NamingStrategy.underline_to_camel);//数据库表字段映射到实体的命名策略 strategy.setEntityLombokModel (true); // lombok strategy.setLogicDeleteFieldName (\"is_deleted\");//逻辑删除字段名 strategy.setEntityBooleanColumnRemoveIsPrefix (true);//去掉布尔值的is_前缀（确保tinyint(1)） strategy.setRestControllerStyle (true); //restful api风格控制器 mpg.setStrategy (strategy); // 6、执行 mpg.execute ( ); } } 6、启动应用程序1、创建application.ymlserver: port: 8110 # 服务端口 spring: profiles: active: dev # 环境设置 application: name: service-core # 服务名 datasource: # mysql数据库连接 type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://121.4.120.62:3306/srb_core?serverTimezone=GMT%2B8&amp;characterEncoding=utf-8 username: root password: root mybatis-plus: #mybatis configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl mapper-locations: classpath:com/kk/srb/core/mapper/xml/*.xml 2、创建SpringBoot配置文件在service-core中创建config包，创建MybatisPlusConfig类 package com.kk.srb.core.config; import com.baomidou.mybatisplus.annotation.DbType; import com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor; import com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor; import org.mybatis.spring.annotation.MapperScan; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.transaction.annotation.EnableTransactionManagement; @Configuration @MapperScan(\"com.kk.srb.core.mapper\") @EnableTransactionManagement //事务处理 public class MybatisPlusConfig { @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() { MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor ( ); interceptor.addInnerInterceptor (new PaginationInnerInterceptor (DbType.MYSQL));//分页 return interceptor; } } 3、创建SpringBoot启动类注意：扫描com.kk.srb package com.kk.srb.core; import org.mybatis.spring.annotation.MapperScan; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication @MapperScan({\"com.kk.srb\"}) public class ServiceCoreApplication { public static void main(String[] args) { SpringApplication.run (ServiceCoreApplication.class, args); } } 4、运行启动类查看控制台8110端口是否成功启动 7、整体代码结构图 二、积分等级CRUD1、积分等级列表接口1、编写积分等级管理接口在controller中添加admin包，添加AdminIntegralGradeController类 package com.kk.srb.core.controller.admin; import com.kk.srb.core.pojo.entity.IntegralGrade; import com.kk.srb.core.service.IntegralGradeService; import org.springframework.web.bind.annotation.CrossOrigin; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; import java.util.List; @CrossOrigin//允许可访问的域列表 @RestController @RequestMapping(\"/admin/core/integralGrade\") public class AdminIntegralGradeController { @Resource private IntegralGradeService integralGradeService; @GetMapping(\"/list\") public List&lt;IntegralGrade&gt; listAll() { return integralGradeService.list ( ); } } 2、测试重启服务，访问： http://localhost:8110/admin/core/integralGrade/list 查看结果json数据 2、逻辑删除接口1、添加删除方法AdminIntegralGradeController添加removeById方法 @DeleteMapping(\"/remove/{id}\") public boolean removeById(@PathVariable Long id){ return integralGradeService.removeById(id); } 2、使用postman测试删除 3、配置Swagger21、Swagger2配置文件在service-base中创建Swagger2Config package com.kk.srb.core.config; import com.google.common.base.Predicates; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import springfox.documentation.builders.ApiInfoBuilder; import springfox.documentation.builders.PathSelectors; import springfox.documentation.service.ApiInfo; import springfox.documentation.service.Contact; import springfox.documentation.spi.DocumentationType; import springfox.documentation.spring.web.plugins.Docket; import springfox.documentation.swagger2.annotations.EnableSwagger2; @Configuration @EnableSwagger2 public class Swagger2Config { @Bean public Docket adminApiConfig() { return new Docket (DocumentationType.SWAGGER_2) .groupName (\"adminApi\") .apiInfo (adminApiInfo ( )) .select ( ) //只显示admin路径下的页面 .paths (Predicates.and (PathSelectors.regex (\"/admin/.*\"))) .build ( ); } private ApiInfo adminApiInfo() { return new ApiInfoBuilder ( ) .title (\"尚融宝后台管理系统-API文档\") .description (\"本文档描述了尚融宝后台管理系统接口\") .version (\"1.0\") .contact (new Contact (\"Helen\", \"http://mykkto.cn\", \"763856958@qq.com\")) .build ( ); } } 2、查看Swagger文档重启服务器查看接口文档：http://localhost:8110/swagger-ui.html 3、常见注解实体类注解：entity的实体类中可以添加一些自定义设置，例如： @ApiModelProperty(value = \"创建时间\", example = \"2019-01-01 8:00:00\") private LocalDateTime createTime; @ApiModelProperty(value = \"更新时间\", example = \"2019-01-01 8:00:00\") private LocalDateTime updateTime; controller注解： 定义在类上 @Api(tags = \"积分等级管理\") 定义在方法上 @ApiOperation(\"积分等级列表\") @ApiOperation(value = \"根据id删除积分等级\", notes = \"逻辑删除\") 定义在参数上 @ApiParam(value = \"数据id\", required = true, example = \"100\") 三、统一返回结果1、数据格式的定义项目中我们会将响应封装成json返回，一般我们会将所有接口的数据格式统一， 使前端对数据的操作更一致、轻松。 一般情况下，统一返回数据格式没有固定的格式，只要能描述清楚返回的数据状态以及要返回的具体数据就可以。但是一般会包含状态码、返回消息、数据这几部分内容 例如，我们的系统要求返回的基本数据格式如下： 成功： { \"code\": 0, \"message\": \"成功\", \"data\": 数据 } 失败： { \"code\": -1, \"message\": \"失败\", \"data\": null } 因此，我们定义统一结果 { \"code\": 数字, //业务响应码 \"message\": 字符串, //返回消息 \"data\": 对象 //返回数据 } 2、创建枚举在kk-common中创建result包，创建枚举 ResponseEnum package com.kk.common.result; import lombok.AllArgsConstructor; import lombok.Getter; import lombok.ToString; @Getter @AllArgsConstructor @ToString public enum ResponseEnum { SUCCESS (0, \"成功\"), ERROR (-1, \"服务器内部错误\"); // 响应状态码 private Integer code; // 响应信息 private String message; } 3、定义同统一结果类package com.kk.common.result; import lombok.Data; import java.util.HashMap; import java.util.Map; @Data public class R { private Integer code; private String message; private Map&lt;String, Object&gt; data = new HashMap ( ); /** * 构造器私有 */ private R() { } /** * 返回成功 */ public static R ok() { R r = new R ( ); r.setCode (ResponseEnum.SUCCESS.getCode ( )); r.setMessage (ResponseEnum.SUCCESS.getMessage ( )); return r; } /** * 返回失败 */ public static R error() { R r = new R ( ); r.setCode (ResponseEnum.ERROR.getCode ( )); r.setMessage (ResponseEnum.ERROR.getMessage ( )); return r; } /** * 设置特定结果 */ public static R setResult(ResponseEnum responseEnum) { R r = new R ( ); r.setCode (responseEnum.getCode ( )); r.setMessage (responseEnum.getMessage ( )); return r; } public R message(String message) { this.setMessage (message); return this; } public R code(Integer code) { this.setCode (code); return this; } public R data(String key, Object value) { this.data.put (key, value); return this; } public R data(Map&lt;String, Object&gt; map) { this.setData (map); return this; } } 4、使用统一返回结果1、修改listAll@GetMapping(\"/list\") @ApiOperation(\"积分等级列表\") public List&lt;IntegralGrade&gt; listAll() { return integralGradeService.list ( ); } 2、修改removeById@ApiOperation(value = \"根据id删除积分等级\", notes = \"逻辑删除\") @DeleteMapping(\"/remove/{id}\") public R removeById( @ApiParam(value = \"数据id\", required = true, example = \"1\") @PathVariable Long id) { boolean result = integralGradeService.removeById (id); if (result) { //return R.setResult(ResponseEnum.UPLOAD_ERROR); return R.ok ( ).message (\"删除成功\"); } else { return R.error ( ).message (\"删除失败\"); } } 3、新增数据@ApiOperation(\"新增积分等级\") @PostMapping(\"/save\") public R save( @ApiParam(value = \"积分等级对象\", required = true) @RequestBody IntegralGrade integralGrade) { boolean result = integralGradeService.save (integralGrade); if (result) { return R.ok ( ).message (\"保存成功\"); } else { return R.error ( ).message (\"保存失败\"); } } 4、根据id查询@ApiOperation(\"根据id获取积分等级\") @GetMapping(\"/get/{id}\") public R getById( @ApiParam(value = \"数据id\", required = true, example = \"1\") @PathVariable Long id ) { IntegralGrade integralGrade = integralGradeService.getById (id); if (integralGrade != null) { return R.ok ( ).data (\"record\", integralGrade); } else { return R.error ( ).message (\"数据不存在\"); } } 5、根据id修改@ApiOperation(\"更新积分等级\") @PutMapping(\"/update\") public R updateById( @ApiParam(value = \"积分等级对象\", required = true) @RequestBody IntegralGrade integralGrade) { boolean result = integralGradeService.updateById (integralGrade); if (result) { return R.ok ( ).message (\"修改成功\"); } else { return R.error ( ).message (\"修改失败\"); } } 四、统一异常处理1、项目中的异常1、制造异常屏蔽 IntegralGrade 中的 @TableField注解 @ApiModelProperty(value = \"逻辑删除(1:已删除，0:未删除)\") //@TableField(\"is_deleted\") @TableLogic private Boolean deleted; 2、Swagger中测试测试列表查询功能，查看结果，发生错误，显示响应失败 2、统一异常处理目标：我们想让异常结果也显示为统一的返回结果对象，并且统一处理系统的异常信息，那么需要进行统一异常处理。 1、创建统一异常处理器kk-common中创建exception包，创建统一异常处理器类UnifiedExceptionHandler package com.kk.common.exception; import com.kk.common.result.R; import lombok.extern.slf4j.Slf4j; import org.springframework.stereotype.Component; import org.springframework.web.bind.annotation.ExceptionHandler; import org.springframework.web.bind.annotation.RestControllerAdvice; @Slf4j @Component //Spring容易自动管理 @RestControllerAdvice //在controller层添加通知。如果使用@ControllerAdvice，则方法上需要添加@ResponseBody public class UnifiedExceptionHandler { /** * 未定义异常 */ @ExceptionHandler(value = Exception.class) //当controller中抛出Exception，则捕获 public R handleException(Exception e) { log.error (e.getMessage ( ), e); return R.error ( ); } } 2、service-core添加扫描添加 “com.kk.common” @SpringBootApplication //@MapperScan({\"com.kk.srb\"})// 需要指定指定路径 @ComponentScan({\"com.kk.srb\",\"com.kk.common\"}) public class ServiceCoreApplication { 3、测试返回统一错误结果 3、处理特定异常如果我们不想显示统一的“服务器内部错误”，需要个性化的显示异常信息，那么需要针对特定的异常做处理 1、添加依赖在kk-common中添加jdbc依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; 2、添加异常处理方法在 UnifiedExceptionHandler 中添加 /** * 特定异常 */ @ExceptionHandler(BadSqlGrammarException.class) public R handleBadSqlGrammarException(BadSqlGrammarException e){ log.error(e.getMessage(), e); return R.setResult(ResponseEnum.BAD_SQL_GRAMMAR_ERROR); } 完整枚举 package com.kk.common.result; import lombok.AllArgsConstructor; import lombok.Getter; import lombok.ToString; @Getter @AllArgsConstructor @ToString public enum ResponseEnum { SUCCESS (0, \"成功\"), ERROR (-1, \"服务器内部错误\"), //-1xx 服务器错误 BAD_SQL_GRAMMAR_ERROR (-101, \"sql语法错误\"), SERVLET_ERROR (-102, \"servlet请求异常\"), //-2xx 参数校验 UPLOAD_ERROR (-103, \"文件上传错误\"), EXPORT_DATA_ERROR (104, \"数据导出失败\"), //-2xx 参数校验 BORROW_AMOUNT_NULL_ERROR (-201, \"借款额度不能为空\"), MOBILE_NULL_ERROR (-202, \"手机号码不能为空\"), MOBILE_ERROR (-203, \"手机号码不正确\"), PASSWORD_NULL_ERROR (204, \"密码不能为空\"), CODE_NULL_ERROR (205, \"验证码不能为空\"), CODE_ERROR (206, \"验证码错误\"), MOBILE_EXIST_ERROR (207, \"手机号已被注册\"), LOGIN_MOBILE_ERROR (208, \"用户不存在\"), LOGIN_PASSWORD_ERROR (209, \"密码错误\"), LOGIN_LOKED_ERROR (210, \"用户被锁定\"), LOGIN_AUTH_ERROR (-211, \"未登录\"), USER_BIND_IDCARD_EXIST_ERROR (-301, \"身份证号码已绑定\"), USER_NO_BIND_ERROR (302, \"用户未绑定\"), USER_NO_AMOUNT_ERROR (303, \"用户信息未审核\"), USER_AMOUNT_LESS_ERROR (304, \"您的借款额度不足\"), LEND_INVEST_ERROR (305, \"当前状态无法投标\"), LEND_FULL_SCALE_ERROR (306, \"已满标，无法投标\"), NOT_SUFFICIENT_FUNDS_ERROR (307, \"余额不足，请充值\"), PAY_UNIFIEDORDER_ERROR (401, \"统一下单错误\"), ALIYUN_SMS_LIMIT_CONTROL_ERROR (-502, \"短信发送过于频繁\"),//业务限流 ALIYUN_SMS_ERROR (-503, \"短信发送失败\"),//其他失败 WEIXIN_CALLBACK_PARAM_ERROR (-601, \"回调参数不正确\"), WEIXIN_FETCH_ACCESSTOKEN_ERROR (-602, \"获取access_token失败\"), WEIXIN_FETCH_USERINFO_ERROR (-603, \"获取用户信息失败\"); // 响应状态码 private Integer code; // 响应信息 private String message; } 3、恢复制造的异常@TableField(value = \"is_deleted\") 4、自定义异常目标：使用一个或较少的异常类，可以捕获和显示所有的异常信息。 方案：因此，我们可以创建一个自定义异常类（必须是运行时异常），在程序中抛出这个自定义异常对象，并在统一异常处理器中捕获自定义异常对象 1、创建自定义异常类完整查看github源码 package com.kk.common.exception; import lombok.Data; import lombok.NoArgsConstructor; @Data @NoArgsConstructor public class BusinessException extends RuntimeException { //状态码 private Integer code; //错误消息 private String message; } 2、添加异常处理方法UnifiedExceptionHandler类中添加 /** * 自定义异常 */ @ExceptionHandler(BusinessException.class) public R handleBusinessException(BusinessException e){ log.error(e.getMessage(), e); return R.error().message(e.getMessage()).code(e.getCode()); } 3、修改Controller在AdminIntegralGradeController的方法中添加异常处理，业务中需要的位置抛出BusinessException自定义异常。 @ApiOperation(\"新增积分等级\") @PostMapping(\"/save\") public R save( @ApiParam(value = \"积分等级对象\", required = true) @RequestBody IntegralGrade integralGrade){ //如果借款额度为空就手动抛出一个自定义的异常！ if(integralGrade.getBorrowAmount() == null){ //BORROW_AMOUNT_NULL_ERROR(-201, \"借款额度不能为空\"), throw new BusinessException(ResponseEnum.BORROW_AMOUNT_NULL_ERROR); } boolean result = integrationService.save(integralGrade); if (result) { return R.ok().message(\"保存成功\"); } else { return R.error().message(\"保存失败\"); } } 4、测试 5、异常处理优化目标：以优雅的 Assert(断言) 方式来校验业务的异常情况，消除 if else 1、什么是断言用断言的方式封装异常的抛出 package com.kk.srb.core; import org.junit.Test; import org.springframework.util.Assert; public class AssertTests { //if else的用法 @Test public void test1() { Object o = null; if (o == null) { throw new IllegalArgumentException (\"用户不存在.\"); } } //断言的用法：更为简洁 @Test public void test2() { // 另一种写法 Object o = null; Assert.notNull (o, \"用户不存在.\"); } } 2、自定义断言引入自定义断言，类路径：com.kk.common.exception.Assert @Slf4j public class Assert { /** * 断言对象不为空 * obj 为空则抛异常 * * @param obj * @param responseEnum */ public static void notNull(Object obj, ResponseEnum responseEnum) { if (obj == null) { log.info (\"obj is null.....................\"); throw new BusinessException (responseEnum); } } ........... } 完整的源代码：Assert.java 3、修改controller在controller中用断言替换if else Assert.notNull(integralGrade.getBorrowAmount(), ResponseEnum.BORROW_AMOUNT_NULL_ERROR); 6、Controller上层异常1、异常分类对异常按阶段进行分类，大体可以分成：进入Controller前的异常 和 业务层异常，具体可以参考下图： 2、处理Controller上层异常UnifiedExceptionHandler中添加 /** * Controller上一层相关异常 */ @ExceptionHandler({ NoHandlerFoundException.class, HttpRequestMethodNotSupportedException.class, HttpMediaTypeNotSupportedException.class, MissingPathVariableException.class, MissingServletRequestParameterException.class, TypeMismatchException.class, HttpMessageNotReadableException.class, HttpMessageNotWritableException.class, MethodArgumentNotValidException.class, HttpMediaTypeNotAcceptableException.class, ServletRequestBindingException.class, ConversionNotSupportedException.class, MissingServletRequestPartException.class, AsyncRequestTimeoutException.class }) public R handleServletException(Exception e) { log.error(e.getMessage(), e); //SERVLET_ERROR(-102, \"servlet请求异常\"), return R.error().message(ResponseEnum.SERVLET_ERROR.getMessage()).code(ResponseEnum.SERVLET_ERROR.getCode()); } 3、测试在save测试用例中输入非法的json参数，则得到下面的结果。我们可以在控制台日志中查看具体的错误原因。前端只需要返回相对简单友好的提示即可。 五、统一日志处理1、Logback日志1.什么是日志通过日志查看程序的运行过程，运行信息，异常信息等 2.日志级别日志记录器（Logger）的行为是分等级的。如下表所示： 分为：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF 默认情况下，spring boot从控制台打印出来的日志级别只有INFO及以上级别，可以配置日志级别 # 设置日志级别 logging: level: root: ERROR 这种方式能将ERROR级别以及以上级别的日志输出到控制台上，其他级别将不会输出 3.创建日志文件spring boot内部使用Logback作为日志实现的框架。 先删除前面在application.yml中的日志级别配置 resources 中创建 logback-spring.xml （默认日志文件的名字） &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;configuration&gt; &lt;/configuration&gt; 4、创建测试日志输出将以下日志输出到任意controller的方法中即可，例如list方法中 前提：类上记得加 @Slf4j，注入 log.info @GetMapping(\"/list\") @ApiOperation(\"积分等级列表\") public R listAll() { log.info (\"hi i'm helen\"); log.warn (\"warning!!!\"); log.error (\"it's a error\"); List&lt;IntegralGrade&gt; list = integralGradeService.list ( ); return R.ok ( ).data (\"list\", list); } 2、基本配置说明1.configuration日志配置的根节点 &lt;configuration&gt;&lt;/configuration&gt; 2.contextName是 的子节点。 每个logger都关联到logger上下文，默认上下文名称为“default”。但可以使用设置成其他名字，用于区分不同的应用程序。 &lt;contextName&gt;kkSrb&lt;/contextName&gt; 3.property是 的子节点，用来定义变量。 有两个属性，name和value：name的值是变量的名称，value是变量的值。 通过 定义的值会被插入到logger上下文中。定义变量后，可以使“${}”来使用变量。 &lt;!-- 日志的输出目录 --&gt; &lt;property name=\"log.path\" value=\"D:/project/finance/srb_log/core\" /&gt; &lt;!--控制台日志格式：彩色日志--&gt; &lt;!-- magenta:洋红 --&gt; &lt;!-- boldMagenta:粗红--&gt; &lt;!-- cyan:青色 --&gt; &lt;!-- white:白色 --&gt; &lt;!-- magenta:洋红 --&gt; &lt;property name=\"CONSOLE_LOG_PATTERN\" value=\"%yellow(%date{yyyy-MM-dd HH:mm:ss}) %highlight([%-5level]) %green(%logger) %msg%n\"/&gt; &lt;!--文件日志格式--&gt; &lt;property name=\"FILE_LOG_PATTERN\" value=\"%date{yyyy-MM-dd HH:mm:ss} [%-5level] %thread %file:%line %logger %msg%n\" /&gt; &lt;!--编码--&gt; &lt;property name=\"ENCODING\" value=\"UTF-8\" /&gt; 4、appender 是的子节点，是负责写日志的组件 有两个必要属性name和class：name指定appender名称，class指定appender的全限定名 对日志进行格式化 定义日志的具体输出格式 编码方式 4.1控制台日志配置 &lt;!-- 控制台日志 --&gt; &lt;appender name=\"CONSOLE\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder&gt; &lt;pattern&gt;${CONSOLE_LOG_PATTERN}&lt;/pattern&gt; &lt;charset&gt;${ENCODING}&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; 4.2文件日志配置 表示日志文件的位置，如果上级目录不存在会自动创建，没有默认值。 默认 true，日志被追加到文件结尾，如果是 false，服务重启后清空现存文件。 &lt;!-- 文件日志 --&gt; &lt;appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"&gt; &lt;file&gt;${log.path}/log.log&lt;/file&gt; &lt;append&gt;true&lt;/append&gt; &lt;encoder&gt; &lt;pattern&gt;${FILE_LOG_PATTERN}&lt;/pattern&gt; &lt;charset&gt;${ENCODING}&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; 5、logger可以是 的子节点，用来设置某一个包或具体某一个类的日志打印级别、指定 name： 用来指定受此logger约束的某一个包或者具体的某一个类 level： 用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF。默认继承上级的级别 可以包含零个或多个元素，标识这个appender将会添加到这个logger &lt;!-- 日志记录器 --&gt; &lt;logger name=\"com.kk\" level=\"INFO\"&gt; &lt;appender-ref ref=\"CONSOLE\" /&gt; &lt;appender-ref ref=\"FILE\" /&gt; &lt;/logger&gt; 6、测试测试日志记录的控制台输出、文件输出、以及日志级别 3、多环境配置springProfile在一个基于Spring boot开发的项目里，常常需要有多套环境的配置：开发，测试以及产品。 使用springProfile 可以分别配置开发（dev），测试（test）以及生产（prod）等不同的环境 &lt;!-- 开发环境和测试环境 --&gt; &lt;springProfile name=\"dev,test\"&gt; &lt;logger name=\"com.kk\" level=\"INFO\"&gt; &lt;appender-ref ref=\"CONSOLE\" /&gt; &lt;/logger&gt; &lt;/springProfile&gt; &lt;!-- 生产环境 --&gt; &lt;springProfile name=\"prod\"&gt; &lt;logger name=\"com.kk\" level=\"ERROR\"&gt; &lt;appender-ref ref=\"CONSOLE\" /&gt; &lt;appender-ref ref=\"FILE\" /&gt; &lt;/logger&gt; &lt;/springProfile&gt; 注意：需要注释原始配置 &lt;!-- 日志记录器 --&gt; &lt;!--&lt;logger name=\"com.kk\" level=\"INFO\"&gt;--&gt; &lt;!--&lt;appender-ref ref=\"CONSOLE\"/&gt;--&gt; &lt;!--&lt;appender-ref ref=\"FILE\"/&gt;--&gt; &lt;!--&lt;/logger&gt;--&gt; 4、滚动日志 ★问题：生产环境下，如果系统长时间运行，那么日志文件会变得越来越大，系统读取和写入日志的时间会越来越慢，严重的情况会耗尽系统内存，导致系统宕机。 解决方案：可以设置滚动日志。 1.设置时间滚动策略RollingFileAppender是 Appender的另一个实现，表示滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将旧日志备份到其他文件 是 的子节点，用来定义滚动策略。 TimeBasedRollingPolicy： 最常用的滚动策略，根据时间来制定滚动策略。 ： 包含文件名及转换符， “%d”可以包含指定的时间格式，如：%d{yyyy-MM-dd}。如果直接使用 %d，默认格式是 yyyy-MM-dd。 ： 可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件。假设设置每个月滚动，且是6，则只保存最近6个月的文件，删除之前的旧文件。注意，删除旧文件是，那些为了归档而创建的目录也会被删除。 &lt;appender name=\"ROLLING_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 要区别于其他的appender中的文件名字 --&gt; &lt;file&gt;${log.path}/log-rolling.log&lt;/file&gt; &lt;encoder&gt; &lt;pattern&gt;${FILE_LOG_PATTERN}&lt;/pattern&gt; &lt;charset&gt;${ENCODING}&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 设置滚动日志记录的滚动策略 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- 日志归档路径以及格式 --&gt; &lt;fileNamePattern&gt;${log.path}/info/log-rolling-%d{yyyy-MM-dd}.log&lt;/fileNamePattern&gt; &lt;!--归档日志文件保留的最大数量--&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; 2.设置触发滚动时机放在的子节点的位置里面，基于实践策略的触发滚动策略 设置触发滚动条件：单个文件大于100M时生成新的文件 注意：修改日志文件名 此时 ${log.path}/info/log-rolling-%d{yyyy-MM-dd}.%i.log &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;1KB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; 5、完整的日志配置文件&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;configuration&gt; &lt;contextName&gt;kkSrb&lt;/contextName&gt; &lt;!-- 日志的输出目录 --&gt; &lt;property name=\"log.path\" value=\"D:/project/test/srb_log/core\"/&gt; &lt;!--控制台日志格式：彩色日志--&gt; &lt;!-- magenta:洋红 --&gt; &lt;!-- boldMagenta:粗红--&gt; &lt;!-- cyan:青色 --&gt; &lt;!-- white:白色 --&gt; &lt;!-- magenta:洋红 --&gt; &lt;property name=\"CONSOLE_LOG_PATTERN\" value=\"%yellow(%date{yyyy-MM-dd HH:mm:ss}) %highlight([%-5level]) %green(%logger) %msg%n\"/&gt; &lt;!--文件日志格式--&gt; &lt;property name=\"FILE_LOG_PATTERN\" value=\"%date{yyyy-MM-dd HH:mm:ss} [%-5level] %thread %file:%line %logger %msg%n\"/&gt; &lt;!--编码--&gt; &lt;property name=\"ENCODING\" value=\"UTF-8\"/&gt; &lt;!-- 控制台日志 --&gt; &lt;appender name=\"CONSOLE\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder&gt; &lt;pattern&gt;${CONSOLE_LOG_PATTERN}&lt;/pattern&gt; &lt;charset&gt;${ENCODING}&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 文件日志 --&gt; &lt;appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"&gt; &lt;file&gt;${log.path}/log.log&lt;/file&gt; &lt;append&gt;true&lt;/append&gt; &lt;encoder&gt; &lt;pattern&gt;${FILE_LOG_PATTERN}&lt;/pattern&gt; &lt;charset&gt;${ENCODING}&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name=\"ROLLING_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!-- 要区别于其他的appender中的文件名字 --&gt; &lt;file&gt;${log.path}/log-rolling.log&lt;/file&gt; &lt;encoder&gt; &lt;pattern&gt;${FILE_LOG_PATTERN}&lt;/pattern&gt; &lt;charset&gt;${ENCODING}&lt;/charset&gt; &lt;/encoder&gt; &lt;!-- 设置滚动日志记录的滚动策略 --&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- 日志归档路径以及格式 --&gt; &lt;fileNamePattern&gt;${log.path}/info/log-rolling-%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt; &lt;!--归档日志文件保留的最大数量--&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"&gt; &lt;maxFileSize&gt;1KB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;!-- &lt;logger name=\"com.kk\" level=\"INFO\"&gt;--&gt; &lt;!-- &lt;appender-ref ref=\"CONSOLE\" /&gt;--&gt; &lt;!-- &lt;appender-ref ref=\"FILE\" /&gt;--&gt; &lt;!-- &lt;/logger&gt;--&gt; &lt;!-- 开发环境和测试环境 --&gt; &lt;springProfile name=\"dev,test\"&gt; &lt;logger name=\"com.kk\" level=\"INFO\"&gt; &lt;appender-ref ref=\"CONSOLE\"/&gt; &lt;/logger&gt; &lt;/springProfile&gt; &lt;!-- 生产环境 --&gt; &lt;springProfile name=\"prod\"&gt; &lt;logger name=\"com.kk\" level=\"ERROR\"&gt; &lt;appender-ref ref=\"CONSOLE\"/&gt; &lt;appender-ref ref=\"ROLLING_FILE\"/&gt; &lt;/logger&gt; &lt;/springProfile&gt; &lt;/configuration&gt; Ⅲ、前端架构搭建一、搭建前端平台1、vue-element-adminvue-element-admin是基于element-ui 的一套后台管理系统集成方案。 GitHub地址：https://github.com/PanJiaChen/vue-element-admin 项目在线预览：https://panjiachen.gitee.io/vue-element-admin 2、vue-admin-template1、简介vueAdmin-template是基于vue-element-admin的一套后台管理系统基础模板（最少精简版），可作为模板进行二次开发。 GitHub地址：https://github.com/PanJiaChen/vue-admin-template 根据用户角色来动态生成侧边栏的分支：https://github.com/PanJiaChen/vue-admin-template/tree/permission-control 2、安装和运行# clone 项目 git clone https...... # 重命名,删掉自带的 .git文件夹 # 进入目录 cd FrontEndCode # 安装依赖 npm install # 启动。执行后，浏览器自动弹出并访问http://localhost:9528/ npm run dev 3、前端配置1、禁用ESLint语法检查vue.config.js 第30行处禁用ESLint语法检查 lintOnSave: false, 2、添加prettier格式化配置在vue项目根目录下新建一个文件.prettierrc { \"semi\": false, \"singleQuote\": true, \"htmlWhitespaceSensitivity\": \"ignore\" } 3、修改页面标题src/settings.js 第3行处修改页面标题 4、国际化设置src/main.js 第7行处修改语言 import locale from 'element-ui/lib/locale/lang/zh-CN' // lang i18n 测试平台语言的修改 5、下拉菜单修改 6、登录页修改src/views/login/index.vue 修改页面标题、登录按钮等 二、系统路由配置1、组件定义1、创建vue组件在src/views文件夹下创建以下文件夹和文件 2、list.vuecore/integral-grade/list.vue 注意，最底下保留一行，不然vscode报错 &lt;template&gt; &lt;div class=\"app-container\"&gt;积分等级列表&lt;/div&gt; &lt;/template&gt; 3、form.vuecore/integral-grade/orm.vue &lt;template&gt; &lt;div class=\"app-container\"&gt; 积分等级表单 &lt;/div&gt; &lt;/template&gt; 2、路由定义修改 src/router/index.js 文件，重新定义constantRoutes，拷贝到 dashboard路由节点 下面 注意：每个路由的name不能相同 { path: '/core/integral-grade', component: Layout, redirect: '/core/integral-grade/list', name: 'coreIntegralGrade', meta: { title: '积分等级管理', icon: 'el-icon-s-marketing' }, alwaysShow: true, children: [ { path: 'list', name: 'coreIntegralGradeList', component: () =&gt; import('@/views/core/integral-grade/list'), meta: { title: '积分等级列表' } }, { path: 'create', name: 'coreIntegralGradeCreate', component: () =&gt; import('@/views/core/integral-grade/form'), meta: { title: '新增积分等级' } }, { path: 'edit/:id', name: 'coreIntegralGradeEdit', component: () =&gt; import('@/views/core/integral-grade/form'), meta: { title: '编辑积分等级' }, hidden: true } ] }, 三、前端开发流程1、全栈开发流程1、前端调用流程下图是开发过程中涉及到和几个核心的模块，我们已经完成了路由的配置和页面组件的创建，接下来我们需要进一步完善页面组件的模板 &lt;template&gt;部分，以及脚本&lt;script&gt;等部分的开发，然后创建前后端对接需要的api模块，最后通过api模块向后端接口发起调用。 2、nginx反向代理配置目前，应用程序的前后端基本架构如下：srb-admin是前端程序，直接调用后端的srb-core微服务 为了能够让前端程序能够同时对接多个后端服务，我们可以使用多种解决方案，例如nginx反向代理、微服务网关等。这里我们先使用nginx作为前后端中间的反向代理层，架构如下 nginx的配置 server { listen 80; server_name localhost; location ~ /core/ { proxy_pass http://localhost:8110; } location ~ /sms/ { proxy_pass http://localhost:8120; } location ~ /oss/ { proxy_pass http://localhost:8130; } } nginx的命令 start nginx #启动 nginx -s stop #停止 nginx -s reload #重新加载配置 前端的配置： .env.development # base api：连接到nginx VUE_APP_BASE_API = 'http://localhost' 3、mock-serverVUE_APP_BASE_API 的 修改会影响到平台模拟登录功能的mock数据，因此需要修改mock-server的地址 修改 mock/mock-server.js 文件 第37行 url: new RegExp(`/dev-api${url}`), 修改 src/api/user.js中的接口调用，为每一个远程调用添加配置 baseURL: '/dev-api', 2、前端组件开发1、定义api模块创建文件 src/api/core/integral-grade.js // @ 符号在vue.config.js 中配置， 表示 'src' 路径的别名 import request from '@/utils/request' export default { list() { return request({ url: '/admin/core/integralGrade/list', method: 'get' }) } } 2、定义页面组件脚本src/views/core/integral-grade/list.vue &lt;script&gt; import integralGradeApi from '@/api/core/integral-grade' export default { // 定义数据模型 data() { return { list: [] // 数据列表 } }, // 页面渲染成功后获取数据 created() { this.fetchData() }, // 定义方法 methods: { fetchData() { // 调用api integralGradeApi.list().then(response =&gt; { this.list = response.data.list }) } } } &lt;/script&gt; 3、定义页面组件模板src/views/core/integral-grade/list.vue &lt;template&gt; &lt;div class=\"app-container\"&gt; &lt;!-- 表格 --&gt; &lt;el-table :data=\"list\" border stripe&gt; &lt;el-table-column type=\"index\" width=\"50\" /&gt; &lt;el-table-column prop=\"borrowAmount\" label=\"借款额度\" /&gt; &lt;el-table-column prop=\"integralStart\" label=\"积分区间开始\" /&gt; &lt;el-table-column prop=\"integralEnd\" label=\"积分区间结束\" /&gt; &lt;/el-table&gt; &lt;/div&gt; &lt;/template&gt; 4、axios响应拦截器修改src/utils/request.js 中 将第49行的 if (res.code !== 20000) { 修改成 if (res.code !== 0 &amp;&amp; res.code !== 20000) { 因为我们的后端接口统一结果判断0为成功的响应结果，而mock数据判断20000位正确的结果 四、完善积分模块1、删除数据1.定义api src/api/core/integral-grade.js removeById(id) { return request({ url: `/admin/core/integralGrade/remove/${id}`, method: 'delete' }) } 2.页面组件模板src/views/core/integral-grade/list.vue，在table组件中添加删除列 &lt;el-table-column label=\"操作\" width=\"200\" align=\"center\"&gt; &lt;template slot-scope=\"scope\"&gt; &lt;el-button type=\"danger\" size=\"mini\" icon=\"el-icon-delete\" @click=\"removeById(scope.row.id)\" &gt; 删除 &lt;/el-button&gt; &lt;/template&gt; &lt;/el-table-column&gt; 3.删除数据脚本// 根据id删除数据 removeById(id) { // debugger console.log('id', id) this.$confirm('此操作将永久删除该记录, 是否继续?', '提示', { confirmButtonText: '确定', cancelButtonText: '取消', type: 'warning' }) .then(() =&gt; { return integralGradeApi.removeById(id) }) .then(response =&gt; { this.$message({ message: response.message, type: 'success' }) this.fetchData() }) .catch(error =&gt; { console.log('catch的error', error) if (error === 'cancel') { this.$message({ type: 'info', message: '已取消删除' }) } }) } 2、新增数据1.定义api src/api/core/integral-grade.js save(integralGrade) { return request({ url: '/admin/core/integralGrade/save', method: 'post', data: integralGrade }) } 2.定义页面datasrc/views/core/integral-grade/form.vue，完善data定义 &lt;script&gt; export default { data() { return { integralGrade: {}, // 初始化数据 saveBtnDisabled: false // 保存按钮是否禁用，防止表单重复提交 } } } &lt;/script&gt; 3.页面组件模板src/views/core/integral-grade/form.vue，完善template &lt;template&gt; &lt;div class=\"app-container\"&gt; &lt;!-- 输入表单 --&gt; &lt;el-form label-width=\"120px\"&gt; &lt;el-form-item label=\"借款额度\"&gt; &lt;el-input-number v-model=\"integralGrade.borrowAmount\" :min=\"0\" /&gt; &lt;/el-form-item&gt; &lt;el-form-item label=\"积分区间开始\"&gt; &lt;el-input-number v-model=\"integralGrade.integralStart\" :min=\"0\" /&gt; &lt;/el-form-item&gt; &lt;el-form-item label=\"积分区间结束\"&gt; &lt;el-input-number v-model=\"integralGrade.integralEnd\" :min=\"0\" /&gt; &lt;/el-form-item&gt; &lt;el-form-item&gt; &lt;el-button :disabled=\"saveBtnDisabled\" type=\"primary\" @click=\"saveOrUpdate()\"&gt; 保存 &lt;/el-button&gt; &lt;/el-form-item&gt; &lt;/el-form&gt; &lt;/div&gt; &lt;/template&gt; 4.新增数据脚本src/views/core/integral-grade/form.vue，引入api import integralGradeApi from '@/api/core/integral-grade' 定义保存方法 methods: { saveOrUpdate() { // 禁用保存按钮 this.saveBtnDisabled = true this.saveData() }, // 新增数据 saveData() { // debugger integralGradeApi.save(this.integralGrade).then(response =&gt; { this.$message({ type: 'success', message: response.message }) this.$router.push('/core/integral-grade/list') }) } } 3、回显数据1.列表页编辑按钮src/views/core/integral-grade/list.vue，表格“操作”列中增加“修改”按钮 &lt;router-link :to=\"'/core/integral-grade/edit/' + scope.row.id\" style=\"margin-right:5px;\" &gt; &lt;el-button type=\"primary\" size=\"mini\" icon=\"el-icon-edit\"&gt; 修改 &lt;/el-button&gt; &lt;/router-link&gt; 2.定义apisrc/api/core/integral-grade.js getById(id) { return request({ url: `/admin/core/integralGrade/get/${id}`, method: 'get' }) } 3.获取数据脚本src/views/core/integral-grade/form.vue，methods中定义回显方法 // 根据id查询记录 fetchDataById(id) { integralGradeApi.getById(id).then(response =&gt; { this.integralGrade = response.data.record }) } 页面渲染成功后获取数据 因为已在路由中定义如下内容：path: ‘edit/:id’/，因此可以使用 this.$route.params.id 获取路由中的id //页面渲染成功 created() { if (this.$route.params.id) { this.fetchDataById(this.$route.params.id) } }, 4、更新数据1.定义apisrc/api/core/integral-grade.js updateById(integralGrade) { return request({ url: '/admin/core/integralGrade/update', method: 'put', data: integralGrade }) } 2.更新数据脚本src/views/core/integral-grade/form.vue，methods中定义updateData // 根据id更新记录 updateData() { // 数据的获取 integralGradeApi.updateById(this.integralGrade).then(response =&gt; { this.$message({ type: 'success', message: response.message }) this.$router.push('/core/integral-grade/list') }) } 完善saveOrUpdate方法 saveOrUpdate() { // 禁用保存按钮 this.saveBtnDisabled = true if (!this.integralGrade.id) { this.saveData() } else { this.updateData() } }, 参考地址 ↓1、Springboot 启动注解扫描：https://blog.csdn.net/m0_50932526/article/details/122936434 2、异常：org.apache.ibatis.binding.BindingException: Invalid bound statement (not fou 需要指定扫描包路径为具体路径，之前是 @MapperScan({“com.kk.srb”}),现在是**@MapperScan({“com.kk.srb.core.mapper”})** https://www.freesion.com/article/7476436940/ 3、vue项目 出现 Failed to compile. 编译错误，可能是指定的路径和文件不匹配 4、 &lt; 标签开头如果不是成对存在，需用 \\ 转义","categories":[{"name":"项目-金融","slug":"项目-金融","permalink":"https://mykkto.github.io/categories/%E9%A1%B9%E7%9B%AE-%E9%87%91%E8%9E%8D/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://mykkto.github.io/tags/nginx/"},{"name":"springboot","slug":"springboot","permalink":"https://mykkto.github.io/tags/springboot/"},{"name":"vue","slug":"vue","permalink":"https://mykkto.github.io/tags/vue/"}],"author":"mykk"},{"title":"JVM-01-字节码","slug":"07-内力/03-jvm/01_jvm_Byte","date":"2022-04-16T13:00:12.000Z","updated":"2022-11-12T15:07:08.023Z","comments":true,"path":"posts/6ae84987.html","link":"","permalink":"https://mykkto.github.io/posts/6ae84987.html","excerpt":"","text":"一、JVM概述1、Java的生态1、Oracle JDK与Open JDK 关系Oracle与OpenJDK之间的主要区别： Oracle JDK版本将每三年发布一次LTS版本，而OpenJDK版本每三个月发布一次。 Oracle JDK将更多地关注稳定性，它重视更多的企业级用户，而OpenJDK经常发布以支持其他性能，这可能会导致不稳定。 Oracle JDK支持长期发布的更改，而Open JDK仅支持计划和完成下一个发行版。 Oracle JDK根据二进制代码许可协议获得许可，而OpenJDK根据GPL v2许可获得许可。 使用Oracle平台时会产生一些许可影响。如Oracle 宣布的那样，在没有商业许可的情况下，在2019年1月之后发布的Oracle Java SE 8的公开更新将无法用于商业，商业或生产用途。但是，OpenJDK是完全开源的，可以自由使用。 Oracle JDK的构建过程基于OpenJDK，因此OpenJDK与Oracle JDK之间没有技术差异。 顶级公司正在使用Oracle JDK，例如Android Studio，Minecraft和IntelliJ IDEA开发工具，其中Open JDK不太受欢迎。 Oracle JDK具有Flight Recorder，Java Mission Control和Application Class-Data Sharing功能，Open JDK具有Font Renderer功能，这是OpenJDK与Oracle JDK之间的显着差异。 Oracle JDK具有良好的GC选项和更好的渲染器，而OpenJDK具有更少的GC选项，并且由于其包含自己的渲染器的分布，因此具有较慢的图形渲染器选项。 在响应性和JVM性能方面，Oracle JDK与OpenJDK相比提供了更好的性能。 与OpenJDK相比，Oracle JDK的开源社区较少，OpenJDK社区用户的表现优于Oracle JDK发布的功能，以提高性能。 如果使用Oracle JDK会产生许可影响，而OpenJDK没有这样的问题，并且可以以任何方式使用，以满足完全开源和免费使用。 Oracle JDK在运行JDK时不会产生任何问题，而OpenJDK在为某些用户运行JDK时会产生一些问题。 根据使用方的使用和许可协议，现有应用程序可以从Oracle JDK迁移到Open JDK，反之亦然。 Oracle JDK将从其10.0.X版本将收费，用户必须付费或必须依赖OpenJDK才能使用其免费版本。 Oracle JDK不会为即将发布的版本提供长期支持，用户每次都必须通过更新到最新版本获得支持来获取最新版本。 Oracle JDK以前的1.0版以前的版本是由Sun开发的，后来被Oracle收购并为其他版本维护，而OpenJDK最初只基于Java SDK或JDK版本7。 Oracle JDK发布时大多数功能都是开源的，其中一些功能免于开源，并且根据Sun的许可授权，而OpenJDK发布了所有功能，如开源和免费。 Oracle JDK完全由Oracle公司开发，而Open JDK项目由IBM，Apple，SAP AG，Redhat等顶级公司加入和合作。 2、JDK与JVM是什么关系 1、如何理解Java是跨平台的语言 当Java源代码成功编译成字节码后，如果想在不同的平台上面运行，则无须再次编译这个优势不再那么吸引人了。Python、PHP、Perl、Ruby、Lisp等有强大的解释器。跨平台似乎已经快成为一门语言必选的特性。 2、如何理解JVM跨语言的平台 Java虚拟机根本不关心运行在其内部的程序到底是使用何种编程语言编写的，它只关心“字节码”文件。 Java不是最强大的语言，但是JVM是最强大的虚拟机。 3、Java发展的几个重大事件2000年，JDK 1.3发布，Java HotSpot Virtual Machine正式发布，成为Java的默认虚拟机。2002年，JDK 1.4发布，古老的Classic虚拟机退出历史舞台。2003年年底，Java平台的Scala正式发布，同年Groovy也加入了 Java阵营。2006年，JDK 6发布。同年，Java开源并建立了 OpenJDK。顺理成章，Hotspot虚拟机也成为了 OpenJDK中的默认虚拟机。2007年，Java平台迎来了新伙伴Clojure。2008 年，Oracle 收购了 BEA,得到了 JRockit 虚拟机。2009年，Twitter宣布把后台大部分程序从Ruby迁移到Scala，这是Java平台的又一次大规模应用。2010年，Oracle收购了Sun，获得Java商标和最具价值的HotSpot虚拟机。此时，Oracle拥有市场占用率最高的两款虚拟机HotSpot和JRockit，并计划在未来对它们进行整合：HotRockit. JCP组织管理：Java语言2011年，JDK7发布。在JDK 1.7u4中，正式启用了新的垃圾回收器G1。2017年，JDK9发布。将G1设置为默认GC，替代CMS (被标记为Deprecated)同年，IBM的J9开源，形成了现在的Open J9社区2018年，Android的Java侵权案判决，Google赔偿Oracle计88亿美元同年，JDK11发布，LTS版本的JDK,发布革命性的ZGC,调整JDK授权许可2019年，JDK12发布，加入RedHat领导开发的Shenandoah GC 2、JVM的架构1、JVM架构图 这个架构可以分成三层看： 最上层：javac编译器将编译好的字节码class文件，通过java 类装载器执行机制，把对象或class文件存放在 jvm划分内存区域。中间层：称为Runtime Data Area，主要是在Java代码运行时用于存放数据的，从左至右为方法区(永久代、元数据区)、堆(共享,GC回收对象区域)、栈、程序计数器、寄存器、本地方法栈(私有)。最下层：解释器、JIT(just in time)编译器和 GC（Garbage Collection，垃圾回收器） 2、JVM脉络 二、字节码文件概述1、字节码文件跨平台Class文件结构不仅仅是Java虚拟机的执行入口，更是Java生态圈的基础和核心。 1、class文件里是什么字节码文件里是什么？ 源代码经过编译器编译之后便会生成一个字节码文件，字节码是一种二进制的类文件，它的内容是JVM的指令，而不像C、C++经由编译器直接生成机器码。 随着Java平台的不断发展，在将来，Class文件的内容也一定会做进一步的扩充，但是其基本的格式和结构不会做重大调整。 2、☆ class文件的编译器1、从位置上理解 2、前端编译器的种类Java源代码的编译结果是字节码，那么肯定需要有一种编译器能够将Java源码编译为字节码，承担这个重要责任的就是配置在path环境变量中的javac编译器。javac是一种能够将Java源码编译为字节码的前端编译器。 HotSpot VM并没有强制要求前端编译器只能使用javac来编译字节码，其实只要编译结果符合JVM规范都可以被JVM所识别即可。在Java的前端编译器领域，除了javac之外，还有一种被大家经常用到的前端编译器，那就是内置在Eclipse中的ECJ (Eclipse Compiler for Java)编译器。和Javac的全量式编译不同，ECJ是一种增量式编译器。 默认情况下，IntelliJ IDEA 使用 javac 编译器。(还可以自己设置为AspectJ编译器 ajc) 3、前端编译器的任务前端编译器的主要任务就是负责将符合Java语法规范的Java代码转换为符合JVM规范的字节码文件。 3、前端编译器的局限性前端编译器并不会直接涉及编译优化等方面的技术，而是将这些具体优化细节移交给HotSpot的JIT编译器负责。 复习：AOT(静态提前编译器，Ahead Of Time Compiler) jdk9引入了AOT编译器(静态提前编译器，Ahead Of Time Compiler) Java 9 引入了实验性 AOT 编译工具jaotc。它借助了 Graal 编译器，将所输入的 Java 类文件转换为机器码，并存放至生成的动态共享库之中。 所谓 AOT 编译，是与即时编译相对立的一个概念。我们知道，即时编译指的是在程序的运行过程中，将字节码转换为可在硬件上直接运行的机器码，并部署至托管环境中的过程。而 AOT 编译指的则是，在程序运行之前，便将字节码转换为机器码的过程。.java -&gt; .class -&gt; .so 最大好处：Java虚拟机加载已经预编译成二进制库，可以直接执行。不必等待即时编译器的预热，减少Java应用给人带来“第一次运行慢”的不良体验。 缺点：破坏了java“一次编译，到处运行”，必须为每个不同硬件、OS编译对应的发行包。降低了Java链接过程的动态性，加载的代码在编译期就必须全部已知。 还需要继续优化中，最初只支持Linux x64 java base 2、Class对象对应类型 （1）class：外部类，成员(成员内部类，静态内部类)，局部内部类，匿名内部类（2）interface：接口（3）[]：数组（4）enum：枚举（5）annotation：注解@interface（6）primitive type：基本数据类型（7）void @Test public void test(){ Class c1 = Object.class; Class c2 = Comparable.class; Class c3 = String[].class; Class c4 = int[][].class; Class c5 = ElementType.class; Class c6 = Override.class; Class c7 = int.class; Class c8 = void.class; Class c9 = Class.class; int[] a = new int[10]; int[] b = new int[100]; Class c10 = a.getClass(); Class c11 = b.getClass(); // 只要元素类型与维度一样，就是同一个Class System.out.println(c10 == c11); } 3、字节码指令1、什么是字节码指令Java虚拟机的指令由一个字节长度的、代表着某种特定操作含义的操作码（opcode）以及跟随其后的零至多个代表此操作所需参数的操作数（operand）所构成。虚拟机中许多指令并不包含操作数，只有一个操作码。 2、☆ 面试题i++和++i有什么区别 public class ByteCodeInterview { //面试题： i++和++i有什么区别？ @Test public void test1(){ int i = 10; i++; //++i; System.out.println(i); } @Test public void test2(){ int i = 10; i = i++; System.out.println(i); } @Test public void test3(){ int i = 2; i *= i++; System.out.println(i); } @Test public void test4(){ int k = 10; k = k + (k++) + (++k); System.out.println(k); } //包装类对象的缓存问题 @Test public void test5(){ // Integer x = 5; // int y = 5; Integer i1 = 10; Integer i2 = 10; System.out.println(i1 == i2); Integer i3 = 128; Integer i4 = 128; System.out.println(i3 == i4); Boolean b1 = true; Boolean b2 = true; System.out.println(b1 == b2); } @Test public void test6(){ String str = new String(\"hello\") + new String(\"world\"); String str1 = \"helloworld\"; System.out.println(str == str1); } } class Father { int x = 10; public Father() { this.print(); x = 20; } public void print() { System.out.println(\"Father.x = \" + x); } } class Son extends Father { int x = 30; public Son() { this.print(); x = 40; } public void print() { System.out.println(\"Son.x = \" + x); } } public class SonTest { public static void main(String[] args) { Father f = new Son(); System.out.println(f.x); } } 4、如何解读class文件方式一：一个一个二进制的看。这里用到的是Notepad++,需要安装一个HEX-Editor插件，或者使用Binary Viewer 方式二：使用javap指令：jdk自带的反解析工具方式三：使用IDEA插件：jclasslib 或jclasslib bytecode viewer客户端工具。（可视化更好） 三、Class文件结构细节1、概述1、class文件结构概述Class文件的结构并不是一成不变的，随着Java虚拟机的不断发展，总是不可避免地会对Class文件结构做出一些调整，但是其基本结构和框架是非常稳定的。Class文件的总体结构如下： 魔数 Class文件版本 常量池 访问标识(或标志) 类索引，父类索引，接口索引集合 字段表集合 方法表集合 属性表集合 2、结构图表 这是一张Java字节码总的结构表，我们按照上面的顺序逐一进行解读就可以了。 2、魔数Magic Number（魔数）：class文件的标志 每个 Class 文件开头的4个字节的无符号整数称为魔数（Magic Number） 它的唯一作用是确定这个文件是否为一个能被虚拟机接受的有效合法的Class文件。即：魔数是Class文件的标识符。 魔数值固定为0xCAFEBABE。不会改变。 如果一个Class文件不以0xCAFEBABE开头，虚拟机在进行文件校验的时候就会直接抛出以下错误： Error: A JNI error has occurred, please check your installation and try againException in thread “main” java.lang.ClassFormatError: Incompatible magic value 1885430635 in class file StringTest 使用魔数而不是扩展名来进行识别主要是基于安全方面的考虑，因为文件扩展名可以随意地改动。 3、高版本执行低版本Class不同版本的Java编译器编译的Class文件对应的版本是不一样的。目前，高版本的Java虚拟机可以执行由低版本编译器生成的Class文件,但是低版本的Java虚拟机不能执行由高版本编译器生成的Class文件。否则JVM会抛出java.lang.UnsupportedClassVersionError异常。 （向下兼容） 在实际应用中，由于开发环境和生产环境的不同，可能会导致该问题的发生。因此，需要我们在开发时，特别注意开发编译的JDK版本和生产环境中的JDK版本是否一致。 class文件版本号 紧接着魔数的 4 个字节存储的是 Class 文件的版本号。同样也是4个字节。第5个和第6个字节所代表的含义就是编译的副版本号minor_version，而第7个和第8个字节就是编译的主版本号major_version。 它们共同构成了class文件的格式版本号。譬如某个 Class 文件的主版本号为 M，副版本号为 m，那么这个Class 文件的格式版本号就确定为 M.m。 版本号和Java编译器的对应关系如下表： Java 的版本号是从45开始的，JDK 1.1之后的每个JDK大版本发布主版本号向上加1。 虚拟机JDK版本为1.k （k &gt;= 2）时，对应的class文件格式版本号的范围为45.0 - 44+k.0 （含两端）。 4、☆ 常量池常量池：class文件的基石？作用是？ 1、为什么需要常量池计数器constant_pool_count （常量池计数器） 由于常量池的数量不固定，时长时短，所以需要放置两个字节来表示常量池容量计数值。 常量池容量计数值（u2类型）：从1开始，表示常量池中有多少项常量。即constant_pool_count=1表示常量池中有0个常量项。 Demo的值为： 其值为0x0016,掐指一算，也就是22。需要注意的是，这实际上只有21项常量。索引为范围是1-21。为什么呢？通常我们写代码时都是从0开始的，但是这里的常量池却是从1开始，因为它把第0项常量空出来了。这是为了满足后面某些指向常量池的索引值的数据在特定情况下需要表达“不引用任何一个常量池项目”的含义，这种情况可用索引值0来表示。 int[] arr = new int[10]; arr[0]; arr[1]; ar[10 - 1]; #### 2、常量池表 **constant_pool []（常量池）** - constant_pool是一种表结构，以 1 ~ constant_pool_count - 1为索引。表明了后面有多少个常量项。 - 常量池主要存放两大类常量：`字面量（Literal）`和`符号引用（Symbolic References）` - 它包含了class文件结构及其子结构中引用的所有字符串常量、类或接口名、字段名和其他常量。常量池中的每一项都具备相同的特征。第1个字节作为类型标记，用于确定该项的格式，这个字节称为tag byte （标记字节、标签字节）。 ![](https://v1.mykkto.cn/image/blog/2022/jvm/20220417163310.png) ##### 1、字面量和符号引用 1、字面量和符号引用 在对这些常量解读前，我们需要搞清楚几个概念。 常量池主要存放两大类常量：字面量（Literal）和符号引用（Symbolic References）。如下表： ![](https://v1.mykkto.cn/image/blog/2022/jvm/20220417164111.png) ```java String str = \"mykk\"; final int NUM = 10; 2、全限定名com/kk/test/Demo这个就是类的全限定名，仅仅是把包名的”.”替换成”/“，为了使连续的多个全限定名之间不产生混淆，在使用时最后一般会加入一个“;”表示全限定名结束。 3、简单名称简单名称是指没有类型和参数修饰的方法或者字段名称，上面例子中的类的add()方法和num字段的简单名称分别是add和num。 4、描述符描述符的作用是用来描述字段的数据类型、方法的参数列表（包括数量、类型以及顺序）和返回值。根据描述符规则，基本数据类型（byte、char、double、float、int、long、short、boolean）以及代表无返回值的void类型都用一个大写字符来表示，而对象类型则用字符L加对象的全限定名来表示，详见下表: （数据类型：基本数据类型 、 引用数据类型） 用描述符来描述方法时，按照先参数列表，后返回值的顺序描述，参数列表按照参数的严格顺序放在一组小括号“()”之内。如：方法java.lang.String toString()的描述符为() Ljava/lang/String;，方法int abc(int[] x, int y)的描述符为([II) I。 2、谈谈你对符号引用、直接引用的理解？这里说明下符号引用和直接引用的区别与关联：符号引用：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。符号引用与虚拟机实现的内存布局无关，引用的目标并不一定已经加载到了内存中。直接引用：直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是与虚拟机实现的内存布局相关的，同一个符号引用在不同虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那说明引用的目标必定已经存在于内存之中了。 3、常量类型和结构常量池中每一项常量都是一个表，JDK1.7之后共有14种不同的表结构数据。如下表格所示： 这14种表（或者常量项结构）的共同点是：表开始的第一位是一个u1类型的标志位（tag），代表当前这个常量项使用的是哪种表结构，即哪种常量类型。 在常量池列表中，CONSTANT_Utf8_info常量项是一种使用改进过的UTF-8编码格式来存储诸如文字字符串、类或者接口的全限定名、字段或者方法的简单名称以及描述符等常量字符串信息。 这14种常量项结构还有一个特点是，其中13个常量项占用的字节固定，只有CONSTANT_Utf8_info占用字节不固定，其大小由length决定。为什么呢？因为从常量池存放的内容可知，其存放的是字面量和符号引用，最终这些内容都会是一个字符串，这些字符串的大小是在编写程序时才确定，比如你定义一个类，类名可以取长取短，所以在没编译前，大小不固定，编译后，通过utf-8编码，就可以知道其长度。 3、访问标识访问标识(access_flag、访问标志、访问标记) 在常量池后，紧跟着访问标记。该标记使用两个字节表示，用于识别一些类或者接口层次的访问信息，包括：这个 Class 是类还是接口；是否定义为 public 类型；是否定义为 abstract 类型；如果是类的话，是否被声明为 final 等。各种访问标记如下所示： 类的访问权限通常为 ACC_ 开头的常量。 每一种类型的表示都是通过设置访问标记的32位中的特定位来实现的。比如，若是public final的类，则该标记为ACC_PUBLIC | ACC_FINAL。 使用ACC_SUPER可以让类更准确地定位到父类的方法super.method(),现代编译器都会设置并且使用这个标记。 4、类索引、父类索引、接口索引集合 在访问标记后，会指定该类的类别、父类类别以及实现的接口，格式如下： 这三项数据来确定这个类的继承关系。 类索引用于确定这个类的全限定名 父类索引用于确定这个类的父类的全限定名。由于 Java语言不允许多重继承，所以父类索引只有一个，除了java.lang.Object 之外，所有的Java类都有父类，因此除了java.lang.Object 外，所有Java类的父类索引都不为 0。 接口索引集合就用来描述这个类实现了哪些接口，这些被实现的接口将按 implements 语句（如果这个类本身是一个接口，则应当是 extends 语句）后的接口顺序从左到右排列在接口索引集合中。 this_class（类索引） 字节无符号整数，指向常量池的索引。它提供了类的全限定名,如com/kk/java1/Demo。this_class的值必须是对常量池表中某项的一个有效索引值。常量池在这个索引处的成员必须为CONSTANT_Class_info类型结构体，该结构体表示这个class文件所定义的类或接口。 super_class （父类索引） 2字节无符号整数，指向常量池的索引。它提供了当前类的父类的全限定名。如果我们没有继承任何类，其默认继承的是java/lang/Object类。同时，由于Java不支持多继承，所以其父类只有一个。 superclass指向的父类不能是final。 interfaces 指向常量池索引集合，它提供了一个符号引用到所有已实现的接口 由于一个类可以实现多个接口，因此需要以数组形式保存多个接口的索引，表示接口的每个索引也是一个指向常量池的CONSTANT_Class (当然这里就必须是接口，而不是类)。 interfaces_count (接口计数器) interfaces_count项的值表示当前类或接口的直接超接口数量。 interfaces [](接口索引集合) interfaces []中每个成员的值必须是对常量池表中某项的有效索引值，它的长度为 interfaces_count。 每个成员 interfaces[i]必须为 CONSTANT_Class_info结构，其中 0 &lt;= i &lt; interfaces_count。在 interfaces[]中，各成员所表示的接口顺序和对应的源代码中给定的接口顺序（从左至右）一样，即 interfaces[0]对应的是源代码中最左边的接口。 5、字段表集合1、字段计数器 fields_count的值表示当前class文件fields表的成员个数。使用两个字节来表示。 fields表中每个成员都是一个field_info结构，用于表示该类或接口所声明的所有类字段或者实例字段，不包括方法内部声明的变量，也不包括从父类或父接口继承的那些字段 2、字段表，fields [] fields表中的每个成员都必须是一个fields_info结构的数据项，用于表示当前类或接口中某个字段的完整描述。 一个字段的信息包括如下这些信息。这些信息中，各个修饰符都是布尔值，要么有，要么没有。 作用域（public、private、protected修饰符） 是实例变量还是类变量（static修饰符） 可变性（final） 并发可见性（volatile修饰符，是否强制从主内存读写） 可否序列化（transient修饰符） 字段数据类型（基本数据类型、对象、数组） 字段名称 字段表结构 6、方法表集合1、方法计数器 methods_count的值表示当前class文件methods表的成员个数。使用两个字节来表示。 methods 表中每个成员都是一个method_info结构。 2、方法表 methods表中的每个成员都必须是一个method_info结构，用于表示当前类或接口中某个方法的完整描述。如果某个method_info结构的access_flags项既没有设置 ACC_NATIVE 标志也没有设置ACC_ABSTRACT标志，那么该结构中也应包含实现这个方法所用的Java虚拟机指令。 method_info结构可以表示类和接口中定义的所有方法，包括实例方法、类方法、实例初始化方法和类或接口初始化方法 方法表的结构实际跟字段表是一样的，方法表结构如下： 7、属性表集合1、属性计数器attributes_count的值表示当前class文件属性表的成员个数。属性表中每一项都是一个attribute_info结构。 2、属性表 ConstantValue 属性 ConstantValue 属性表示一个常量字段的值。位于 field_info结构的属性表中。 ConstantValue_attribute { u2 attribute_name_index; u4 attribute_length; u2 constantvalue_index;//字段值在常量池中的索引，常量池在该索引处的项给出该属性表示的常量值。（例如，值是long型的，在常量池中便是CONSTANT_Long） } - Deprecated 属性 - Deprecated 属性是在 JDK 1.1 为了支持注释中的关键词@deprecated 而引入的。 ```java Deprecated_attribute { u2 attribute_name_index; u4 attribute_length; } Code 属性 Code属性就是存放方法体里面的代码。但是，并非所有方法表都有Code属性。像接口或者抽象方法，他们没有具体的方法体，因此也就不会有Code属性了。Code属性表的结构,如下图： 可以看到：Code属性表的前两项跟属性表是一致的，即Code属性表遵循属性表的结构，后面那些则是他自定义的结构。 InnerClasses 属性 为了方便说明特别定义一个表示类或接口的 Class 格式为 C。如果 C 的常量池中包含某个CONSTANT_Class_info 成员，且这个成员所表示的类或接口不属于任何一个包，那么 C 的ClassFile 结构的属性表中就必须含有对应的 InnerClasses 属性。InnerClasses 属性是在 JDK 1.1 中为了支持内部类和内部接口而引入的,位于 ClassFile结构的属性表。 LineNumberTable 属性 LineNumberTable 属性是可选变长属性，位于 Code结构的属性表。 LineNumberTable属性是用来描述Java源码行号与字节码行号之间的对应关系。这个属性可以用来在调试的时候定位代码执行的行数。 start_pc,即字节码行号;line_number，即Java源代码行号。 在 Code 属性的属性表中,LineNumberTable 属性可以按照任意顺序出现，此外，多个 LineNumberTable属性可以共同表示一个行号在源文件中表示的内容，即 LineNumberTable 属性不需要与源文件的行一一对应。 LocalVariableTable 属性 LocalVariableTable 是可选变长属性，位于 Code属性的属性表中。它被调试器用于确定方法在执行过程中局部变量的信息。在 Code 属性的属性表中，LocalVariableTable 属性可以按照任意顺序出现。 Code 属性中的每个局部变量最多只能有一个 LocalVariableTable 属性。 start pc + length表示这个变量在字节码中的生命周期起始和结束的偏移位置（this生命周期从头0到结尾） index就是这个变量在局部变量表中的槽位（槽位可复用） name就是变量名称 Descriptor表示局部变量类型描述 Signature 属性 Signature 属性是可选的定长属性，位于 ClassFile， field_info或 method_info结构的属性表中。在 Java 语言中，任何类、 接口、 初始化方法或成员的泛型签名如果包含了类型变量（ Type Variables） 或参数化类型（ Parameterized Types），则 Signature 属性会为它记录泛型签名信息。 SourceFile属性 其他属性 Java虚拟机中预定义的属性有20多个，这里就不一一介绍了，通过上面几个属性的介绍，只要领会其精髓，其他属性的解读也是易如反掌。 5、四、javaporacle官方的反解析工具：javap 1、解析字节码的作用通过反编译生成的字节码文件，我们可以深入的了解java代码的工作机制。但是，自己分析类文件结构太麻烦了！除了使用第三方的jclasslib工具之外，oracle官方也提供了工具：javap。 javap是jdk自带的反解析工具。它的作用就是根据class字节码文件，反解析出当前类对应的code区（字节码指令）、局部变量表、异常表和代码行偏移量映射表、常量池等信息。 通过局部变量表，我们可以查看局部变量的作用域范围、所在槽位等信息，甚至可以看到槽位复用等信息。 2、javac -g操作解析字节码文件得到的信息中，有些信息（如局部变量表、指令和代码行偏移量映射表、常量池中方法的参数名称等等）需要在使用javac编译成class文件时，指定参数才能输出。 比如，你直接javac xx.java，就不会在生成对应的局部变量表等信息，如果你使用javac -g xx.java就可以生成所有相关信息了。如果你使用的eclipse或IDEA，则默认情况下，eclipse、IDEA在编译时会帮你生成局部变量表、指令和代码行偏移量映射表等信息的。 3、javap的用法javap的用法格式：javap 其中，classes就是你要反编译的class文件。 在命令行中直接输入javap或javap -help可以看到javap的options有如下选项： -help –help -? 输出此用法消息 -version 版本信息，其实是当前javap所在jdk的版本信息，不是class在哪个jdk下生成的。 -public 仅显示公共类和成员 -protected 显示受保护的/公共类和成员 -p -private 显示所有类和成员 -package 显示程序包/受保护的/公共类 和成员 (默认) -sysinfo 显示正在处理的类的系统信息 (路径, 大小, 日期, MD5 散列,源文件名) -constants 显示静态最终常量 -s 输出内部类型签名 -l 输出行号和本地变量表 -c 对代码进行反汇编 -v -verbose 输出附加信息（包括行号、本地变量表，反汇编等详细信息） -classpath 指定查找用户类文件的位置 -cp 指定查找用户类文件的位置 -bootclasspath 覆盖引导类文件的位置 一般常用的是-v -l -c三个选项。 javap -l 会输出行号和本地变量表信息。javap -c 会对当前class字节码进行反编译生成汇编代码。javap -v classxx 除了包含-c内容外，还会输出行号、局部变量表信息、常量池等信息。 4、使用举例package com.kk.test; public class JavapTest { private int num; boolean flag; protected char gender; public String info; public static final int COUNTS = 1; static{ String url = \"www.mykkto.com\"; } { info = \"java\"; } public JavapTest(){ } private JavapTest(boolean flag){ this.flag = flag; } private void methodPrivate(){ } int getNum(int i){ return num + i; } protected char showGender(){ return gender; } public void showInfo(){ int i = 10; System.out.println(info + i); } } 希望输出的信息比较完整的话，使用如下操作： javac JavapTest.java javap -v -p JavapTest.class J:\\0 大厂素材\\jvm\\00Test&gt;javac JavapTest.java J:\\0 大厂素材\\jvm\\00Test&gt;javap -v -p JavapTest.class Classfile /J:/0 大厂素材/jvm/00Test/JavapTest.class Last modified 2022-4-17; size 1141 bytes MD5 checksum 16833cad2e0187d03ccf1baecaa23808 Compiled from \"JavapTest.java\" public class com.kk.test.JavapTest minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPER Constant pool: #1 = Methodref #16.#42 // java/lang/Object.\"&lt;init&gt;\":()V #2 = String #43 // java #3 = Fieldref #15.#44 // com/kk/test/JavapTest.info:Ljava/lang/String; #4 = Fieldref #15.#45 // com/kk/test/JavapTest.flag:Z #5 = Fieldref #15.#46 // com/kk/test/JavapTest.num:I #6 = Fieldref #15.#47 // com/kk/test/JavapTest.gender:C #7 = Fieldref #48.#49 // java/lang/System.out:Ljava/io/PrintStream; #8 = Class #50 // java/lang/StringBuilder #9 = Methodref #8.#42 // java/lang/StringBuilder.\"&lt;init&gt;\":()V #10 = Methodref #8.#51 // java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; #11 = Methodref #8.#52 // java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder; #12 = Methodref #8.#53 // java/lang/StringBuilder.toString:()Ljava/lang/String; #13 = Methodref #54.#55 // java/io/PrintStream.println:(Ljava/lang/String;)V #14 = String #56 // www.mykkto.com #15 = Class #57 // com/kk/test/JavapTest #16 = Class #58 // java/lang/Object #17 = Utf8 num #18 = Utf8 I #19 = Utf8 flag #20 = Utf8 Z #21 = Utf8 gender #22 = Utf8 C #23 = Utf8 info #24 = Utf8 Ljava/lang/String; #25 = Utf8 COUNTS #26 = Utf8 ConstantValue #27 = Integer 1 #28 = Utf8 &lt;init&gt; #29 = Utf8 ()V #30 = Utf8 Code #31 = Utf8 LineNumberTable #32 = Utf8 (Z)V #33 = Utf8 methodPrivate #34 = Utf8 getNum #35 = Utf8 (I)I #36 = Utf8 showGender #37 = Utf8 ()C #38 = Utf8 showInfo #39 = Utf8 &lt;clinit&gt; #40 = Utf8 SourceFile #41 = Utf8 JavapTest.java #42 = NameAndType #28:#29 // \"&lt;init&gt;\":()V #43 = Utf8 java #44 = NameAndType #23:#24 // info:Ljava/lang/String; #45 = NameAndType #19:#20 // flag:Z #46 = NameAndType #17:#18 // num:I #47 = NameAndType #21:#22 // gender:C #48 = Class #59 // java/lang/System #49 = NameAndType #60:#61 // out:Ljava/io/PrintStream; #50 = Utf8 java/lang/StringBuilder #51 = NameAndType #62:#63 // append:(Ljava/lang/String;)Ljava/lang/StringBuilder; #52 = NameAndType #62:#64 // append:(I)Ljava/lang/StringBuilder; #53 = NameAndType #65:#66 // toString:()Ljava/lang/String; #54 = Class #67 // java/io/PrintStream #55 = NameAndType #68:#69 // println:(Ljava/lang/String;)V #56 = Utf8 www.mykkto.com #57 = Utf8 com/kk/test/JavapTest #58 = Utf8 java/lang/Object #59 = Utf8 java/lang/System #60 = Utf8 out #61 = Utf8 Ljava/io/PrintStream; #62 = Utf8 append #63 = Utf8 (Ljava/lang/String;)Ljava/lang/StringBuilder; #64 = Utf8 (I)Ljava/lang/StringBuilder; #65 = Utf8 toString #66 = Utf8 ()Ljava/lang/String; #67 = Utf8 java/io/PrintStream #68 = Utf8 println #69 = Utf8 (Ljava/lang/String;)V { private int num; descriptor: I flags: ACC_PRIVATE boolean flag; descriptor: Z flags: protected char gender; descriptor: C flags: ACC_PROTECTED public java.lang.String info; descriptor: Ljava/lang/String; flags: ACC_PUBLIC public static final int COUNTS; descriptor: I flags: ACC_PUBLIC, ACC_STATIC, ACC_FINAL ConstantValue: int 1 public com.kk.test.JavapTest(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: aload_0 5: ldc #2 // String java 7: putfield #3 // Field info:Ljava/lang/String; 10: return LineNumberTable: line 16: 0 line 14: 4 line 18: 10 private com.kk.test.JavapTest(boolean); descriptor: (Z)V flags: ACC_PRIVATE Code: stack=2, locals=2, args_size=2 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: aload_0 5: ldc #2 // String java 7: putfield #3 // Field info:Ljava/lang/String; 10: aload_0 11: iload_1 12: putfield #4 // Field flag:Z 15: return LineNumberTable: line 19: 0 line 14: 4 line 20: 10 line 21: 15 private void methodPrivate(); descriptor: ()V flags: ACC_PRIVATE Code: stack=0, locals=1, args_size=1 0: return LineNumberTable: line 24: 0 int getNum(int); descriptor: (I)I flags: Code: stack=2, locals=2, args_size=2 0: aload_0 1: getfield #5 // Field num:I 4: iload_1 5: iadd 6: ireturn LineNumberTable: line 26: 0 protected char showGender(); descriptor: ()C flags: ACC_PROTECTED Code: stack=1, locals=1, args_size=1 0: aload_0 1: getfield #6 // Field gender:C 4: ireturn LineNumberTable: line 29: 0 public void showInfo(); descriptor: ()V flags: ACC_PUBLIC Code: stack=3, locals=2, args_size=1 0: bipush 10 2: istore_1 3: getstatic #7 // Field java/lang/System.out:Ljava/io/PrintStream; 6: new #8 // class java/lang/StringBuilder 9: dup 10: invokespecial #9 // Method java/lang/StringBuilder.\"&lt;init&gt;\":()V 13: aload_0 14: getfield #3 // Field info:Ljava/lang/String; 17: invokevirtual #10 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 20: iload_1 21: invokevirtual #11 // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder; 24: invokevirtual #12 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 27: invokevirtual #13 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 30: return LineNumberTable: line 32: 0 line 33: 3 line 34: 30 static {}; descriptor: ()V flags: ACC_STATIC Code: stack=1, locals=1, args_size=0 0: ldc #14 // String www.mykkto.com 2: astore_0 3: return LineNumberTable: line 11: 0 line 12: 3 } SourceFile: \"JavapTest.java\" J:\\0 大厂素材\\jvm\\00Test&gt; 5、总结1、通过javap命令可以查看一个java类反汇编得到的Class文件版本号、常量池、访问标识、变量表、指令代码行号表等等信息。不显示类索引、父类索引、接口索引集合、()、()等结构 2、通过对前面例子代码反汇编文件的简单分析，可以发现，一个方法的执行通常会涉及下面几块内存的操作：（1）java栈中：局部变量表、操作数栈。（2）java堆。通过对象的地址引用去操作。（3）常量池。（4）其他如帧数据区、方法区的剩余部分等情况，测试中没有显示出来，这里说明一下。 3、平常，我们比较关注的是java类中每个方法的反汇编中的指令操作过程，这些指令都是顺序执行的，可以参考官方文档查看每个指令的含义，很简单：https://docs.oracle.com/javase/specs/jvms/se7/html/jvms-6.html 五、字节码指令集与解析概述Java字节码对于虚拟机，就好像汇编语言对于计算机，属于基本执行指令。 Java 虚拟机的指令由一个字节长度的、代表着某种特定操作含义的数字（称为操作码，Opcode）以及跟随其后的零至多个代表此操作所需参数（称为操作数，Operands）而构成。由于 Java 虚拟机采用面向操作数栈而不是寄存器的结构，所以大多数的指令都不包含操作数，只有一个操作码。 由于限制了 Java 虚拟机操作码的长度为一个字节（即 0～255），这意味着指令集的操作码总数不可能超过 256 条。 官方文档：https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-6.html 熟悉虚拟机的指令对于动态字节码生成、反编译Class文件、Class文件修补都有着非常重要的价值。因此，阅读字节码作为了解 Java 虚拟机的基础技能，需要熟练掌握常见指令。 1、字节码与数据类型在Java虚拟机的指令集中，大多数的指令都包含了其操作所对应的数据类型信息。例如，iload指令用于从局部变量表中加载int型的数据到操作数栈中，而fload指令加载的则是float类型的数据。 对于大部分与数据类型相关的字节码指令，它们的操作码助记符中都有特殊的字符来表明专门为哪种数据类型服务： i代表对int类型的数据操作 l代表long类型的数据操作 s代表short类型的数据操作 b代表byte类型的数据操作 c代表char类型的数据操作 f代表float类型的数据操作 d代表double类型的数据操作 也有一些指令的助记符中没有明确地指明操作类型的字母，如arraylength指令，它没有代表数据类型的特殊字符，但操作数永远只能是一个数组类型的对象。 还有另外一些指令，如无条件跳转指令goto则是与数据类型无关的。 大部分的指令都没有支持整数类型byte、char和short，甚至没有任何指令支持boolean类型。编译器会在编译期或运行期将byte和short类型的数据带符号扩展（Sign-Extend）为相应的int类型数据，将boolean和char类型数据零位扩展（Zero-Extend）为相应的int类型数据。与之类似，在处理boolean、byte、short和char类型的数组时，也会转换为使用对应的int类型的字节码指令来处理。因此，大多数对于boolean、byte、short和char类型数据的操作，实际上都是使用相应的int类型作为运算类型。 byte b1 = 12; short s1 = 10; int i = b1 + s1; 2、指令分类由于完全介绍和学习这些指令需要花费大量时间。为了让大家能够更快地熟悉和了解这些基本指令，这里将JVM中的字节码指令集按用途大致分成 9 类。 加载与存储指令 算术指令 类型转换指令 对象的创建与访问指令 方法调用与返回指令 操作数栈管理指令 控制转移指令 异常处理指令 同步控制指令 (说在前面)在做值相关操作时： 一个指令，可以从局部变量表、常量池、堆中对象、方法调用、系统调用中等取得数据，这些数据（可能是值，可能是对象的引用）被压入操作数栈。 一个指令，也可以从操作数栈中取出一到多个值（pop多次），完成赋值、加减乘除、方法传参、系统调用等等操作。 六、★ 字节码指令1、加载与存储指令2、算术指令3、类型转换指令4、对象的创建与访问指令5、方法调用与返回指令6、操作数栈管理指令7、控制转移指令8、异常处理指令9、同步控制指令","categories":[{"name":"高阶篇","slug":"高阶篇","permalink":"https://mykkto.github.io/categories/%E9%AB%98%E9%98%B6%E7%AF%87/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"https://mykkto.github.io/tags/jvm/"},{"name":"字节码","slug":"字节码","permalink":"https://mykkto.github.io/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"}],"author":"mykk"},{"title":"历来面基题【长期】","slug":"05-面试题/00-面基/01_Always_Interview","date":"2022-04-09T03:06:12.000Z","updated":"2022-11-12T15:07:08.031Z","comments":true,"path":"posts/c1193e28.html","link":"","permalink":"https://mykkto.github.io/posts/c1193e28.html","excerpt":"","text":"一、前言1、说明初稿没想好怎么定义，把最近遇到的面试题大概梳理下（可能比较潦草，暂时没花时间排版） 二、题目一些题目会贴出问题方案，部分暂时没有归纳，不过在此站都能搜索得到，提下 本站采用全文搜索，可以方便的检索到问题以及方案。 数据库三范式（收集需求和怎么设计数据库的） Spring、SpringBoot、SpringCloud区别，展开 Spring特性用法，事务，jdbc模板之类 SpringBoot零配置……可以的话自定义配置聊下 SpringCloud分两部分说（netfix,alibaba），每个组件用法说下，可以的话原理展开下 Seata ID(1)+组件(3)扩展说明，用法及区别 这边ID用到的雪花算法，懂的话可以展开，如果会写的话，说出实现算法的原理最佳，以及雪花的缺陷（时钟问题），解决方案 三个组件原理本站也有写 数据库优化，索引失效哪些情况 数据库，物化视图 物化视图与普通的视图相比的区别是物化视图是建立的副本，它类似于一张表，需要占用存储空间。而对一个物化视图查询的执行效率与查询一个表是一样的。 其实就是存在物理内存的副本表，但是性能和视图一样 最近项目描述及其展开说明（这个不用多说了吧） 同步集合用过哪些，说明，以及分布式锁说明 这边之前想展开AQS说明但是讲了很多了口干舌燥的，水也不够喝了 一方面对底层也是大概了解，FIFO内的Node深入API的话未必答的全面 分布锁可以分为三个实现展开（lua、redission、zookeeper），lua又分为单体和集群都可以展开说明 lua 集群实现分布式锁，可以聊下redlock，redission底层就是….. redission 底层自旋的看门口狗(watchdog)机制可以说下 es用过说下，倒排索引机制原理说下 多线程扩展聊了CAS 基本介绍下CAS，优缺点，缺点方案解决 几种原子类说明，跟volatile可见性比较 可以的话原子类原理展开，LongAdder快的原因 Synchronized用过吗 可以的话说明下用法，然后展开下锁升级（无锁-偏锁-轻锁-重锁） 可以提下JUC中的读写锁（ReentrantReadWriteLock），大概说下读写四种情况以及锁降级 自述完读写锁，可以提下更高效的邮戳锁（StampedLock），优缺点说下，特点说下（名字就可以看出是不重入锁） redis击穿、穿透、雪崩 说下是什么，解决方案 布隆过滤器实现原理 参考文档 ↓物化视图：https://baijiahao.baidu.com/s?id=1709212821591222829&amp;wfr=spider&amp;for=pc","categories":[{"name":"面试题","slug":"面试题","permalink":"https://mykkto.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"原理","slug":"原理","permalink":"https://mykkto.github.io/tags/%E5%8E%9F%E7%90%86/"},{"name":"java","slug":"java","permalink":"https://mykkto.github.io/tags/java/"},{"name":"分布式","slug":"分布式","permalink":"https://mykkto.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"数据库","slug":"数据库","permalink":"https://mykkto.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"author":"mykk"},{"title":"ShardingSphere分库分表【作废】","slug":"03-java分布式/05-jdbc/01_ShardingSphere","date":"2022-04-09T01:01:02.000Z","updated":"2022-11-12T15:07:08.042Z","comments":true,"path":"posts/97bfaea3.html","link":"","permalink":"https://mykkto.github.io/posts/97bfaea3.html","excerpt":"","text":"一、概述1、学英语博主是个二流子，英语不会但又格外喜欢 ShardingSphere(塞腚-菲儿)【分片-球】、Proxy(普拉克谁)【代理】 2、分库分表1、什么是分库分表分库分表就是为了解决由于数据量过大而导致数据库性能降低的问题，将原来独立的数据库拆分成若干数据库组成，将数据大表拆分成若干数据表组成，使得单一数据库、单一数据表的数据量变小，从而达到提升数据库性能的目的。 2、分库分表方式分库分表 分库分表包括分库和分表两个部分： 在生产中通常包括：垂直分库、水平分库、垂直分表、水平分表四种方式。 水平拆分：根据表中数据的逻辑关系，将表中的数据按照某种条件拆分到多台数据库上。 垂直拆分：把单一的表拆分成多个表，并分散到不同的数据库（主机）上 2.1 垂直分库 2.2 垂直分表 2.3 水平分表 2.4 水平分库 3、为什么要分库分表一般的机器（4核16G），单库的MySQL并发（QPS+TPS）超过了2k，系统基本就宕机了。最好是并发量控制在1k左右。 QPS：每秒并发量 TPS：每秒吞吐量 分库分表目的：解决高并发，和数据量大的问题。 4、分库分表的场景（1）在数据库设计时候考虑垂直分库和垂直分表 （2）随着数据库数据量增加，不要马上考虑做水平切分，首先考虑缓存处理，读写分离，使用索引等等方式，如果这些方式不能根本解决问题了， 再考虑做水平分库和水平分表 5、分库分表带来的问题• 事务一致性问题 • 跨节点关联查询的问题 ( Join )。 • 跨节点分页、分组、排序问题。 • 存在多数据源管理的问题 二、Sharding-JDBC快速入门官网http://shardingsphere.apache.org/index_zh.html 1、基本介绍Sharding-JDBC是当当网研发的开源分布式数据库中间件，从3.0 开始Sharding-JDBC 被包含在Sharding-Sphere中， 之后该项目进入进入Apache孵化器，4.版本之后的版本为Apache版本。 定位为轻量级 Java 框架，在 Java 的 JDBC 层提供的额外服务。 它使用客户端直连数据库，以 jar 包形式提供服务，无需额外部署和依赖，可理解为增强版的 JDBC 驱动，完全兼容 JDBC 和各种 ORM 框架。 Sharding-JDBC架构图： Sharding-Proxy架构图： Sharding-Jdbc混合架构： ShardingSphere-JDBC 采用无中心化架构，适用于 Java 开发的高性能的轻量级 OLTP（连接事务处理） 应用；ShardingSphere-Proxy 提供静态入口以及异构语言的支持，适用于 OLAP（连接数据分析） 应用以及对分片数据库进行管理和运维的场景。 Apache ShardingSphere 是多接入端共同组成的生态圈。 通过混合使用 ShardingSphere-JDBC 和 ShardingSphere-Proxy，并采用同一注册中心统一配置分片策略，能够灵活的搭建适用于各种场景的应用系统，使得架构师更加自由地调整适合与当前业务的最佳系统架构。 与jdbc性能对比 2、需求说明1、案例一：水平分表手动创建两张表，t_order_1和t_order_2，这两张表是订单表，拆分后的表，通过Sharding-Jdbc向课程表插入数据，按照一定的分片规则，主键为偶数的进入t_order_1，另一部分数据进入t_order_2，通过Sharding-Jdbc 查询数据，根据 SQL语句的内容从t_order_1或t_order_2查询数据。 2、案例二、水平分库在案例一的基础上，扩展出两个数据库，根据 user_id 偶数入库，sharding_jdbc1 奇数入库，sharding_jdbc2 3、案例三、垂直分库按照业余去区分库 3、项目搭建1、技术选型springboot2.2.1+MybatisPlus+Sharding-JDBC+Druid连接池 阿里镜像：比较快 https://start.aliyun.com/ 建表 两张结构一样 DROP TABLE IF EXISTS `course_1`; CREATE TABLE `course_1` ( `cid` bigint(20) NOT NULL COMMENT '课程id', `cname` VARCHAR(50) NOT NULL COMMENT '课程名', `user_id` bigint(20) NOT NULL COMMENT '课程老师', `cstatus` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '课程状态', PRIMARY KEY (`cid`) USING BTREE ) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic; DROP TABLE IF EXISTS `course_2`; CREATE TABLE `course_2` ( `cid` bigint(20) NOT NULL COMMENT '课程id', `cname` VARCHAR(50) NOT NULL COMMENT '课程名', `user_id` bigint(20) NOT NULL COMMENT '课程老师', `cstatus` varchar(10) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '课程状态', PRIMARY KEY (`cid`) USING BTREE ) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic; 2、建model 3、导pom&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.20&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;4.0.0-RC1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 4、基础业务代码1、entirypackage com.kk.shardingjdbc.entiry; import lombok.Data; @Data public class Course { private Long cid; private String cname; private Long userId; private String cstatus; } 2、mapperpackage com.kk.shardingjdbc.mapper; import com.baomidou.mybatisplus.core.mapper.BaseMapper; import org.springframework.stereotype.Repository; @Repository public interface CourseMapper extends BaseMapper&lt;CourseMapper&gt; { } 3、扫描配置package com.kk.shardingjdbc; import org.mybatis.spring.annotation.MapperScan; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication @MapperScan(\"com.kk.shardingjdbc.entiry.mapper\") public class ShardingjdbcApplication { public static void main(String[] args) { SpringApplication.run (ShardingjdbcApplication.class, args); } } 5、写 application.propertiesmysql 数据源 8.0的话驱动包路径要加 cj，com.mysql.cj.jdbc.Driver url要加**时区[?serverTimezone=GMT%2B8]**，jdbc:mysql://localhost:3306/sharding_jdbc1?serverTimezone=GMT%2B8 # sharding分片策略 # 配置数据源，给数据源起别名 spring.shardingsphere.datasource.names=s1 # 配置数据源具体内容，包含连接池，驱动，地址，用户名和密码 spring.shardingsphere.datasource.s1.type=com.alibaba.druid.pool.DruidDataSource spring.shardingsphere.datasource.s1.driver-class-name=com.mysql.jdbc.Driver spring.shardingsphere.datasource.s1.url=jdbc:mysql://localhost:3306/sharding_jdbc1 spring.shardingsphere.datasource.s1.username=root spring.shardingsphere.datasource.s1.password=a1b2c3 # 指定 course 表分布情况，配置表在哪个数据库里面，表名称都是什么 s1.course_1 , s1.course_2 #course 是表的前缀， {1,2}是表的后缀，表示有course1 和 course2 spring.shardingsphere.sharding.tables.course.actual-data-nodes=s1.course_$-&gt;{1..2} # 指定 以course为前缀的表里面主键 cid 。生成策略 SNOWFLAKE（雪花算法） spring.shardingsphere.sharding.tables.course.key-generator.column=cid spring.shardingsphere.sharding.tables.course.key-generator.type=SNOWFLAKE # 指定分片策略，约定 cid值为偶数添加到表 course_1, 奇数到 course_2 #course 是表的前缀 #第二行的取模后，+1 操作防止取模后为 0 spring.shardingsphere.sharding.tables.course.table-strategy.inline.sharding-column=cid spring.shardingsphere.sharding.tables.course.table-strategy.inline.algorithm-expression=course_$-&gt;{cid % 2 + 1} # 打开sql 输出日志 spring.shardingsphere.props.sql.show=true # 解决一个实体对应两个表问题 spring.main.allow-bean-definition-overriding=true 6、测试类package com.kk.shardingjdbc; import com.kk.shardingjdbc.entiry.Course; import com.kk.shardingjdbc.mapper.CourseMapper; import org.junit.jupiter.api.Test; import org.junit.runner.RunWith; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; @RunWith(SpringRunner.class) @SpringBootTest class ShardingjdbcApplicationTests { @Autowired private CourseMapper courseMapper; @Test public void addCourse() { for (int i = 0; i &lt; 10; i++) { Course course = new Course ( ); course.setCname (\"java\"+i); course.setUserId (100L); course.setCstatus (\"Normal\"+i); courseMapper.insert (course); } } @Test public void searchCourse() { QueryWrapper&lt;Course&gt; wrapper = new QueryWrapper&lt;&gt; ( ); wrapper.eq (\"cid\",721132131354411008L); Course course = courseMapper.selectOne (wrapper); System.out.println (course ); } } 4、案例二基于案例一扩展 1、当前库结构 2、application.properties# sharding分片策略 # 配置数据源，给数据源起别名 spring.shardingsphere.datasource.names=s1,s2 # 配置数据源具体内容，包含连接池，驱动，地址，用户名和密码 spring.shardingsphere.datasource.s1.type=com.alibaba.druid.pool.DruidDataSource spring.shardingsphere.datasource.s1.driver-class-name=com.mysql.cj.jdbc.Driver spring.shardingsphere.datasource.s1.url=jdbc:mysql://localhost:3306/sharding_jdbc1?serverTimezone=GMT%2B8 spring.shardingsphere.datasource.s1.username=root spring.shardingsphere.datasource.s1.password=a1b2c3 # 配置数据源具体内容，包含连接池，驱动，地址，用户名和密码 spring.shardingsphere.datasource.s2.type=com.alibaba.druid.pool.DruidDataSource spring.shardingsphere.datasource.s2.driver-class-name=com.mysql.cj.jdbc.Driver spring.shardingsphere.datasource.s2.url=jdbc:mysql://localhost:3306/sharding_jdbc2?serverTimezone=GMT%2B8 spring.shardingsphere.datasource.s2.username=root spring.shardingsphere.datasource.s2.password=a1b2c3 #--------------------------------------------------------------------------------------------------- # 指定 course 表分布情况，配置表在哪个数据库里面，表名称都是什么 s1.course_1 , s1.course_2 #course 是表的前缀， {1,2}是表的后缀，表示有course1 和 course2 #spring.shardingsphere.sharding.tables.course.actual-data-nodes=s1.course_$-&gt;{1..2} # 配置两个数据库 spring.shardingsphere.sharding.tables.course.actual-data-nodes=s$-&gt;{1..2}.course_$-&gt;{1..2} # 指定 以course为前缀的表里面主键 cid 。生成策略 SNOWFLAKE（雪花算法） spring.shardingsphere.sharding.tables.course.key-generator.column=cid spring.shardingsphere.sharding.tables.course.key-generator.type=SNOWFLAKE # 指定分片策略，约定 cid值为偶数添加到表 course_1, 奇数到 course_2 #course 是表的前缀 #第二行的取模后，+1 操作防止取模后为 0 spring.shardingsphere.sharding.tables.course.table-strategy.inline.sharding-column=cid spring.shardingsphere.sharding.tables.course.table-strategy.inline.algorithm-expression=course_$-&gt;{cid % 2 + 1} # 指定数据库分片策略 #约定user_id是偶数添加m1，是奇数添加m2 spring.shardingsphere.sharding.tables.course.database-strategy.inline.sharding-column=user_id spring.shardingsphere.sharding.tables.course.database-strategy.inline.algorithm-expression=s$-&gt;{user_id % 2 + 1} # 打开sql 输出日志 spring.shardingsphere.props.sql.show=true # 解决一个实体对应两个表问题 spring.main.allow-bean-definition-overriding=true 3、测试package com.kk.shardingjdbc; import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper; import com.kk.shardingjdbc.entiry.Course; import com.kk.shardingjdbc.mapper.CourseMapper; import org.junit.jupiter.api.Test; import org.junit.runner.RunWith; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; @RunWith(SpringRunner.class) @SpringBootTest class ShardingjdbcApplicationTests { @Autowired private CourseMapper courseMapper; //----------------以下是水平分库测试 @Test public void add() { for (int i = 0; i &lt; 20; i++) { Course course = new Course ( ); course.setUserId (0L + i); course.setCname (\"java\" + i); course.setCstatus (\"Normal\" + i); courseMapper.insert (course); } } @Test public void delete() { QueryWrapper&lt;Course&gt; wrapper = new QueryWrapper&lt;&gt; ( ); wrapper.isNotNull (\"cid\"); courseMapper.delete (wrapper); } //----------------以下是水平分表测试 @Test public void addCourse() { for (int i = 0; i &lt; 10; i++) { Course course = new Course ( ); course.setCname (\"java\" + i); course.setUserId (100L); course.setCstatus (\"Normal\" + i); courseMapper.insert (course); } } @Test public void searchCourse() { QueryWrapper&lt;Course&gt; wrapper = new QueryWrapper&lt;&gt; ( ); wrapper.eq (\"cid\", 721132131354411008L); Course course = courseMapper.selectOne (wrapper); System.out.println (course); } } 5、案例三1、建表2、三、Sharding-JDBC执行原理1、2、3、4、5、四、分库分表分类1、2、3、4、5、五、Mysql主从搭建路由：nacos高可用搭建 六、读写分离1、2、3、4、5、参考文档 ↓https://blog.csdn.net/unique_perfect/article/details/116134490 https://www.kuangstudy.com/zl/sharding#1369532356595126274","categories":[{"name":"中间件","slug":"中间件","permalink":"https://mykkto.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"ShardingSphere","slug":"ShardingSphere","permalink":"https://mykkto.github.io/tags/ShardingSphere/"},{"name":"分库分表","slug":"分库分表","permalink":"https://mykkto.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"},{"name":"jdbc","slug":"jdbc","permalink":"https://mykkto.github.io/tags/jdbc/"}],"author":"mykk"},{"title":"Lua脚本语言基础","slug":"06-编程语言基/01-lua/01_lua","date":"2022-04-03T15:17:13.000Z","updated":"2022-11-12T15:07:08.042Z","comments":true,"path":"posts/fafe363a.html","link":"","permalink":"https://mykkto.github.io/posts/fafe363a.html","excerpt":"","text":"一、概述1、概念Lua是一种轻量、小巧的脚本语言，用标准C语言编写并以源代码形式开发。设计的目的是为了嵌入到其他应用程序中，从而为应用程序提供灵活的扩展和定制功能。 2、特性跟其他语言进行比较，Lua有其自身的特点： （1）轻量级 Lua用标准C语言编写并以源代码形式开发，编译后仅仅一百余千字节，可以很方便的嵌入到其他程序中。 （2）可扩展 Lua提供非常丰富易于使用的扩展接口和机制，由宿主语言(通常是C或C++)提供功能，Lua可以使用它们，就像内置的功能一样。 （3）支持面向过程编程和函数式编程 3、应用场景Lua在不同的系统中得到大量应用，场景的应用场景如下: 游戏开发、独立应用脚本、web应用脚本、扩展和数据库插件、系统安全上。 二、安装1、官网在linux上安装Lua非常简单，只需要下载源码包并在终端解压、编译即可使用。 Lua的官网地址为:https://www.lua.org 2、下载并且解压1、下载wget https://www.lua.org/ftp/lua-5.4.1.tar.gz 2、安装依赖libreadline-dev依赖包，需要通过命令来进行安装 yum install -y readline-devel 3、解压tar zxvf lua-5.4.1.tar.gz 4、编译安装cd lua-5.4.1 make linux make install 5、验证lua -v 三、Lua的语法1、第一个程序1、进入控制台操作1、用 lua进入 2、编写输出语句，print(“xxxx”) 3、ctrl+D 退出控制台 2、lua 文件运行1、创建 test.lua 2、编写语句，保存 3、运行 3、lua直接运行 1、创建 test2.lua 2、编写语句的时候前缀加上声明，可以直接运行 #!/usr/local/bin/lua 3、文件赋权限，运行 chmod 755 test2.lua ./test2.lua 2、注释1、单行注释的语法为：--注释内容 2、多行注释的语法为:--[[ 注释内容 注释内容 --]] 3、取消多行如果想取消多行注释，只需要在第一个–之前在加一个-即可，如： ---[[ 注释内容 注释内容 --]] 3、标识符换句话说标识符就是我们的变量名，Lua定义变量名以一个字母 A 到 Z 或 a 到 z 或下划线 _ 开头后加上0个或多个字母，下划线，数字（0到9）。这块建议大家最好不要使用下划线加大写字母的标识符，因为Lua的保留字也是这样定义的，容易发生冲突。注意Lua是区分大小写字母的。 简单来说参考java规范就好 4、关键字下列是Lua的关键字，大家在定义常量、变量或其他用户自定义标识符都要避免使用以下这些关键字： and break do else elseif end false for function if in local nil not or repeat return then true until while goto 一般约定，以下划线开头连接一串大写字母的名字（比如 _VERSION）被保留用于 Lua 内部全局变量。这个也是上面我们不建议这么定义标识符的原因。 5、运算符Lua中支持的运算符有算术运算符、关系运算符、逻辑运算符、其他运算符。 算术运算符: + 加法 - 减法 * 乘法 / 除法 % 取余 ^ 乘幂 - 负号 例如: 10+20 --&gt;30 20-10 --&gt;10 10*20 --&gt;200 20/10 --&gt;2 3%2 --&gt;1 10^2 --&gt;100 -10 --&gt;-10 关系运算符 == 等于 ~= 不等于 &gt; 大于 &lt; 小于 &gt;= 大于等于 &lt;= 小于等于 例如: 10==10 --&gt;true 10~=10 --&gt;false 20&gt;10 --&gt;true 20&lt;10 --&gt;false 20&gt;=10 --&gt;true 20&lt;=10 --&gt;false 逻辑运算符 and 逻辑与 A and B &amp;&amp; or 逻辑或 A or B || not 逻辑非 取反，如果为true,则返回false ! 逻辑运算符可以作为if的判断条件，返回的结果如下: A = true B = true A and B --&gt;true A or B --&gt;true not A --&gt;false ------------------------------------------------------------------------------------------------ A = true B = false A and B --&gt;false A or B --&gt;true not A --&gt;false ------------------------------------------------------------------------------------------------ A = false B = true A and B --&gt;false A or B --&gt;true not A --&gt;true 其他运算符 .. 连接两个字符串 # 一元预算法，返回字符串或表的长度 例如: &gt; \"HELLO \"..\"WORLD\" --&gt;HELLO WORLD &gt; #\"HELLO\" --&gt;5 6、全局变量&amp;局部变量在Lua语言中，全局变量无须声明即可使用。在默认情况下，变量总是认为是全局的，如果未提前赋值，默认为nil: 要想声明一个局部变量，需要使用local来声明 7、Lua数据类型Lua有8个数据类型 nil(空，无效值) boolean(布尔，true/false) number(数值) string(字符串) function(函数) table（表） thread(线程) userdata（用户数据） 可以使用type函数测试给定变量或者的类型： print(type(nil)) --&gt;nil print(type(true)) --&gt; boolean print(type(1.1*1.1)) --&gt; number print(type(\"Hello world\")) --&gt; string print(type(type(X))) --&gt; string ，type函数返回的也是字符串类型 print(type(print)) --&gt; function print(type(type)) --&gt;function print(type{}) --&gt;table print(type(io.stdin)) --&gt;userdata nilnil是一种只有一个nil值的类型，它的作用可以用来与其他所有值进行区分，也可以当想要移除一个变量时，只需要将该变量名赋值为nil,垃圾回收就会会释放该变量所占用的内存。 booleanboolean类型具有两个值，true和false。boolean类型一般被用来做条件判断的真与假。在Lua语言中，只会将false和nil视为假，其他的都视为真，特别是在条件检测中0和空字符串都会认为是真，这个和我们熟悉的大多数语言不太一样。 number在Lua5.3版本开始，Lua语言为数值格式提供了两种选择:integer(整型)和float(双精度浮点型)[和其他语言不太一样，float不代表单精度类型]。 数值常量的表示方式: &gt;4 --&gt;4 &gt;0.4 --&gt;0.4 &gt;4.75e-3 --&gt;0.00475 &gt;4.75e3 --&gt;4750 不管是整型还是双精度浮点型，使用type()函数来取其类型，都会返回的是number &gt;type(3) --&gt;number &gt;type(3.3) --&gt;number 所以它们之间是可以相互转换的，同时，具有相同算术值的整型值和浮点型值在Lua语言中是相等的 stringLua语言中的字符串即可以表示单个字符，也可以表示一整本书籍。在Lua语言中，操作100K或者1M个字母组成的字符串的程序很常见。 可以使用单引号或双引号来声明字符串 &gt;a = \"hello\" &gt;b = 'world' &gt;print(a) --&gt;hello &gt;print(b) --&gt;world 如果声明的字符串比较长或者有多行，则可以使用如下方式进行声明 html = [[ &lt;html&gt; &lt;head&gt; &lt;title&gt;Lua-string&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;a href=\"http://www.lua.org\"&gt;Lua&lt;/a&gt; &lt;/body&gt; &lt;/html&gt; ]] table​ table是Lua语言中最主要和强大的数据结构。使用表， Lua 语言可以以一种简单、统一且高效的方式表示数组、集合、记录和其他很多数据结构。 Lua语言中的表本质上是一种辅助数组。这种数组比Java中的数组更加灵活，可以使用数值做索引，也可以使用字符串或其他任意类型的值作索引(除nil外)。 创建表的最简单方式: &gt; a = {} 创建数组: ​ 我们都知道数组就是相同数据类型的元素按照一定顺序排列的集合，那么使用table如何创建一个数组呢? &gt;arr = {\"TOM\",\"JERRY\",\"ROSE\"} ​ 要想获取数组中的值，我们可以通过如下内容来获取: print(arr[0]) nil print(arr[1]) TOM print(arr[2]) JERRY print(arr[3]) ROSE ​ 从上面的结果可以看出来，数组的下标默认是从1开始的。所以上述创建数组，也可以通过如下方式来创建 &gt;arr = {} &gt;arr[1] = \"TOM\" &gt;arr[2] = \"JERRY\" &gt;arr[3] = \"ROSE\" 上面我们说过了，表的索引即可以是数字，也可以是字符串等其他的内容，所以我们也可以将索引更改为字符串来创建 &gt;arr = {} &gt;arr[\"X\"] = 10 &gt;arr[\"Y\"] = 20 &gt;arr[\"Z\"] = 30 当然，如果想要获取这些数组中的值，可以使用下面的方式 方式一 &gt;print(arr[\"X\"]) &gt;print(arr[\"Y\"]) &gt;print(arr[\"Z\"]) 方式二 &gt;print(arr.X) &gt;print(arr.Y) &gt;print(arr.Z) 当前table的灵活不进于此，还有更灵活的声明方式 &gt;arr = {\"TOM\",X=10,\"JERRY\",Y=20,\"ROSE\",Z=30} 如何获取上面的值? TOM : arr[1] 10 : arr[\"X\"] | arr.X JERRY: arr[2] 20 : arr[\"Y\"] | arr.Y ROESE? function在 Lua语言中，函数（ Function ）是对语句和表达式进行抽象的主要方式。 定义函数的语法为: function functionName(params) end 函数被调用的时候，传入的参数个数与定义函数时使用的参数个数不一致的时候，Lua 语言会通过 抛弃多余参数和将不足的参数设为 nil 的方式来调整参数的个数。 function f(a,b) print(a,b) end f() --&gt; nil nil f(2) --&gt; 2 nil f(2,6) --&gt; 2 6 f(2.6.8) --&gt; 2 6 (8被丢弃) 可变长参数函数 function add(...) a,b,c=... print(a) print(b) print(c) end add(1,2,3) --&gt; 1 2 3 函数返回值可以有多个，这点和Java不太一样 function f(a,b) return a,b end x,y=f(11,22) --&gt; x=11,y=22 threadthread翻译过来是线程的意思，在Lua中，thread用来表示执行的独立线路，用来执行协同程序。 userdatauserdata是一种用户自定义数据，用于表示一种由应用程序或C/C++语言库所创建的类型。 8、Lua控制结构Lua 语言提供了一组精简且常用的控制结构，包括用于条件执行的证 以及用于循环的 while、 repeat 和 for。 所有的控制结构语法上都有一个显式的终结符： end 用于终结 if、 for 及 while 结构， until 用于终结 repeat 结构。 if then elseif elseif语句先测试其条件，并根据条件是否满足执行相应的 then 部分或 else 部分。 else 部分 是可选的。 function testif(a) if a&gt;0 then print(\"a是正数\") end end function testif(a) if a&gt;0 then print(\"a是正数\") else print(\"a是负数\") end end 如果要编写嵌套的 if 语句，可以使用 elseif。 它类似于在 else 后面紧跟一个if。根据传入的年龄返回不同的结果，如 age&lt;=18 青少年， age&gt;18 , age &lt;=45 青年 age&gt;45 , age&lt;=60 中年人 age&gt;60 老年人 function show(age) if age&lt;=18 then return \"青少年\" elseif age&gt;18 and age&lt;=45 then return \"青年\" elseif age&gt;45 and age&lt;=60 then return \"中年人\" elseif age&gt;60 then return \"老年人\" end end while循环顾名思义，当条件为真时 while 循环会重复执行其循环体。 Lua 语言先测试 while 语句 的条件，若条件为假则循环结束；否则， Lua 会执行循环体并不断地重复这个过程。 语法： while 条件 do 循环体 end 例子:实现数组的循环 function testWhile() local i = 1 while i&lt;=10 do print(i) i=i+1 end end repeat循环顾名思义， repeat-until语句会重复执行其循环体直到条件为真时结束。 由于条件测试在循环体之后执行，所以循环体至少会执行一次。 语法 repeat 循环体 until 条件 function testRepeat() local i = 10 repeat print(i) i=i-1 until i &lt; 1 end for循环数值型for循环 语法 for param=exp1,exp2,exp3 do 循环体 end param的值从exp1变化到exp2之前的每次循环会执行 循环体，并在每次循环结束后将步长(step)exp3增加到param上。exp3可选，如果不设置默认为1 人话：从输出1开始，每次 +10，小于100（1，11，21，…,91） for i = 1,100,10 do print(i) end 泛型for循环 泛型for循环通过一个迭代器函数来遍历所有值，类似于java中的foreach语句。 语法 for i,v in ipairs(x) do 循环体 end i是数组索引值，v是对应索引的数组元素值，ipairs是Lua提供的一个迭代器函数，用来迭代数组，x是要遍历的数组。 例如: arr = {\"TOME\",\"JERRY\",\"ROWS\",\"LUCY\"} for i,v in ipairs(arr) do print(i,v) end 上述实例输出的结果为 1 TOM 2 JERRY 3 ROWS 4 LUCY 但是如果将arr的值进行修改为 arr = {\"TOME\",\"JERRY\",\"ROWS\",x=\"JACK\",\"LUCY\"} 同样的代码在执行的时候，就只能看到和之前一样的结果，而其中的x为JACK就无法遍历出来，缺失了数据，如果解决呢? 我们可以将迭代器函数变成pairs,如 for i,v in pairs(arr) do print(i,v) end 上述实例就输出的结果为 1 TOM 2 JERRY 3 ROWS 4 LUCY x JACK 四、OpenResty1、基本操作1、是什么OpenResty是一个基于Nginx与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。所以本身OpenResty内部就已经集成了Nginx和Lua，所以我们使用起来会更加方便。 2、安装详情可见【OpenResty】 1、拉取docker pull openresty/openresty 2、挂载并启动说明下： 完全基于上面的nginx配置的三个部分，唯一修改的是 nginx.conf配置文件，这边挂载改成了 nginx2.conf，用于保留之前的（自己懒而已） 新增了，lua文件挂载 修改了容器内的挂载位置，因为 openresty容器位置不一样了(外部还是不变，容器内的位置变了) docker run -d -p 443:443 -p 80:80 --name openresty -v /root/nginx/www:/usr/local/openresty/nginx/html -v /root/nginx/conf/nginx2.conf:/usr/local/openresty/nginx/conf/nginx.conf -v /root/nginx/logs:/usr/local/openresty/nginx/logs -v /root/nginx/lls/:/usr/local/openresty/nginx/ssl -v /root/nginx/lua/:/usr/local/openresty/nginx/lua openresty/openresty 2、ngx_lua的使用使用Lua编写Nginx脚本的基本构建块是指令。指令用于指定何时运行用户Lua代码以及如何使用结果。下图显示了执行指令的顺序。 先来解释下*的作用 *：无 ， 即 xxx_by_lua ,指令后面跟的是 lua指令 *:_file，即 xxx_by_lua_file 指令后面跟的是 lua文件 *:_block,即 xxx_by_lua_block 在0.9.17版后替换init_by_lua_file init_by_lua*该指令在每次Nginx重新加载配置时执行，可以用来完成一些耗时模块的加载，或者初始化一些全局配置。 init_worker_by_lua*该指令用于启动一些定时任务，如心跳检查、定时拉取服务器配置等。 set_by_lua*该指令只要用来做变量赋值，这个指令一次只能返回一个值，并将结果赋值给Nginx中指定的变量。 rewrite_by_lua*该指令用于执行内部URL重写或者外部重定向，典型的如伪静态化URL重写，本阶段在rewrite处理阶段的最后默认执行。 access_by_lua*该指令用于访问控制。例如，如果只允许内网IP访问。 content_by_lua*该指令是应用最多的指令，大部分任务是在这个阶段完成的，其他的过程往往为这个阶段准备数据，正式处理基本都在本阶段。 header_filter_by_lua*该指令用于设置应答消息的头部信息。 body_filter_by_lua*该指令是对响应数据进行过滤，如截断、替换。 log_by_lua*该指令用于在log请求处理阶段，用Lua代码处理日志，但并不替换原有log处理。 balancer_by_lua*该指令主要的作用是用来实现上游服务器的负载均衡器算法 ssl_certificate_by_*该指令作用在Nginx和下游服务开始一个SSL握手操作时将允许本配置项的Lua代码。 需求:http://192.168.200.133?name=张三&amp;gender=1 Nginx接收到请求后，根据gender传入的值，如果gender传入的是1，则在页面上展示 张三先生,如果gender传入的是0，则在页面上展示张三女士,如果未传或者传入的不是1和2则在页面上展示张三。 实现代码 注意：加入配置文件的时候 #内容要去掉 location /getByGender { default_type 'text/html'; set_by_lua $name \" #获取请求url上的值 name，gender local uri_args = ngx.req.get_uri_args() gender = uri_args['gender'] name = uri_args['name'] if gender=='1' then return name..'先生' elseif gender=='0' then return name..'女士' else return name end \"; #解决乱码问题 charset utf-8; return 200 $name; } 3、ngx_lua操作Redis1、Api及其语句说明lua-resty-redis提供了访问Redis的详细API，包括创建对接、连接、操作、数据处理等。这些API基本上与Redis的操作一一对应。 （1）redis = require \"resty.redis\" （2）new 语法: redis,err = redis:new(),创建一个Redis对象。 （3）connect 语法:ok,err=redis:connect(host,port[,options_table]),设置连接Redis的连接信息。 ok:连接成功返回 1，连接失败返回nil err:返回对应的错误信息 （4）set_timeout 语法: redis:set_timeout(time) ，设置请求操作Redis的超时时间。 （5）close 语法: ok,err = redis:close(),关闭当前连接，成功返回1，失败返回nil和错误信息 （6）redis命令对应的方法 在lua-resty-redis中，所有的Redis命令都有自己的方法，方法名字和命令名字相同，只是全部为小写。 2、实现location /testRedis { default_type \"text/html\"; content_by_lua_block{ local redis = require \"resty.redis\" -- 引入Redis local redisObj = redis:new() --创建Redis对象 redisObj:set_timeout(1000) --设置超时数据为1s local ok,err = redisObj:connect(\"10.0.4.7\",6379) --设置redis连接信息，这边不要用127.0.0.1 if not ok then --判断是否连接成功 ngx.say(\"failed to connection redis\",err) return end ok,err = redisObj:set(\"username\",\"TOM\")--存入数据 if not ok then --判断是否存入成功 ngx.say(\"failed to set username\",err) return end local res,err = redisObj:get(\"username\") --从redis中获取数据 ngx.say(res) --将数据写会消息体中 redisObj:close() } } 4、ngx_lua操作Mysql1、查询1、准备driverClass=com.mysql.jdbc.Driver url=jdbc:mysql://10.0.4.7:3306/nginx_db username=root password=root 2、建库 create table users( id int primary key auto_increment, username varchar(30), birthday date, salary double ); insert into users(id,username,birthday,salary) values(null,\"TOM\",\"1988-11-11\",10000.0); insert into users(id,username,birthday,salary) values(null,\"JERRY\",\"1989-11-11\",20000.0); insert into users(id,username,birthday,salary) values(null,\"ROWS\",\"1990-11-11\",30000.0); insert into users(id,username,birthday,salary) values(null,\"LUCY\",\"1991-11-11\",40000.0); insert into users(id,username,birthday,salary) values(null,\"JACK\",\"1992-11-11\",50000.0); 3、Api详解（1）引入\"resty.mysql\"模块 local mysql = require \"resty.mysql\" （2）new 创建一个MySQL连接对象，遇到错误时，db为nil，err为错误描述信息 语法: db,err = mysql:new() （3）connect 尝试连接到一个MySQL服务器 语法:ok,err=db:connect(options),options是一个参数的Lua表结构，里面包含数据库连接的相关信息 host:服务器主机名或IP地址 port:服务器监听端口，默认为3306 user:登录的用户名 password:登录密码 database:使用的数据库名 （4）set_timeout 设置子请求的超时时间(ms)，包括connect方法 语法:db:set_timeout(time) （5）close 关闭当前MySQL连接并返回状态。如果成功，则返回1；如果出现任何错误，则将返回nil和错误描述。 语法:db:close() （6）send_query 异步向远程MySQL发送一个查询。如果成功则返回成功发送的字节数；如果错误，则返回nil和错误描述 语法:bytes,err=db:send_query(sql) （7）read_result 从MySQL服务器返回结果中读取一行数据。res返回一个描述OK包或结果集包的Lua表,语法: res, err, errcode, sqlstate = db:read_result() res, err, errcode, sqlstate = db:read_result(rows) :rows指定返回结果集的最大值，默认为4 如果是查询，则返回一个容纳多行的数组。每行是一个数据列的key-value对，如 { {id=1,username=\"TOM\",birthday=\"1988-11-11\",salary=10000.0}, {id=2,username=\"JERRY\",birthday=\"1989-11-11\",salary=20000.0} } 如果是增删改，则返回类上如下数据 { insert_id = 0, server_status=2, warning_count=1, affected_rows=2, message=nil } 返回值: res:操作的结果集 err:错误信息 errcode:MySQL的错误码，比如1064 sqlstate:返回由5个字符组成的标准SQL错误码，比如42000 4、实现location /mysqlSearch{ default_type 'text/html'; content_by_lua_block{ local mysql = require \"resty.mysql\" local db = mysql:new() local ok,err = db:connect{ host=\"10.0.4.7\", #不要用127.0.0.1 port=3306, user=\"root\", password=\"root\", database=\"lua_db\" } db:set_timeout(1000) db:send_query(\"select * from users where id =1\") local res,err,errcode,sqlstate = db:read_result() ngx.say(res[1].id..\",\"..res[1].username..\",\"..res[1].birthday..\",\"..res[1].salary) db:close() } } 5、🐤优化:location /mysqlSearch { default_type 'text/html'; content_by_lua_block{ local mysql = require \"resty.mysql\" local db = mysql:new() local ok,err = db:connect{ host=\"10.0.4.7\", port=3306, user=\"root\", password=\"root\", database=\"lua_db\" } db:set_timeout(1000) local uri_args = ngx.req.get_uri_args() local reqId = uri_args['id'] db:send_query(\"select * from users where id =\"..reqId) local res,err,errcode,sqlstate = db:read_result() ngx.say(res[1].id..\",\"..res[1].username..\",\"..res[1].birthday..\",\"..res[1].salary) db:close() } } 6、🛰lua-cjsonread_result()得到的结果res都是table类型，要想在页面上展示，就必须知道table的具体数据结构才能进行遍历获取。处理起来比较麻烦，接下来我们介绍一种简单方式cjson，使用它就可以将table类型的数据转换成json字符串，把json字符串展示在页面上即可。 步骤一：引入cjson local cjson = require \"cjson\" 步骤二：调用cjson的encode方法进行类型转换 cjson.encode(res) 优化代码： location /mysqlSearch { default_type 'text/html'; content_by_lua_block{ local mysql = require \"resty.mysql\" local db = mysql:new() local cjson = require \"cjson\" local ok,err = db:connect{ host=\"10.0.4.7\", port=3306, user=\"root\", password=\"root\", database=\"lua_db\" } db:set_timeout(1000) local uri_args = ngx.req.get_uri_args() local reqId = uri_args['id'] db:send_query(\"select * from users where id =\"..reqId) local res,err,errcode,sqlstate = db:read_result() ngx.say(cjson.encode(res)) for i,v in ipairs(res) do ngx.say(v.id..\",\"..v.username..\",\"..v.birthday..\",\"..v.salary) end db:close() } } 2、增删改location /mysql { default_type 'text/html'; content_by_lua_block{ local mysql = require \"resty.mysql\" local db = mysql:new() local cjson = require \"cjson\" local ok,err = db:connect{ host=\"10.0.4.7\", port=3306, user=\"root\", password=\"root\", database=\"lua_db\" } db:set_timeout(1000) local uri_args = ngx.req.get_uri_args() local reqId = uri_args['id'] local reqType = uri_args['reqType'] db:send_query(\"select * from users where id =\"..reqId) if reqType == 'search' then local res,err,errcode,sqlstate = db:read_result() ngx.say(cjson.encode(res)) for i,v in ipairs(res) do ngx.say(v.id..\",\"..v.username..\",\"..v.birthday..\",\"..v.salary) end elseif reqType == 'add' then local res,err,errcode,sqlstate = db:query(\"insert into users(id,username,birthday,salary) values(6,'zhangsan','2023-11-11',32222.0)\") elseif reqType == 'update' then local res,err,errcode,sqlstate = db:query(\"update users set username='lisi' where id = 6\") elseif reqType == 'delete' then local res,err,errcode,sqlstate = db:query(\"delete from users where id = 6\") end db:close() } } 5、Rdis缓存预热使用ngx_lua模块完成Redis缓存预热。 步骤: （1）先得有一张表(users) （2）浏览器输入如下地址 http://10.0.4.7?username=TOM （3）从表中查询出符合条件的记录，此时获取的结果为table类型 （4）使用cjson将table数据转换成json字符串 （5）将查询的结果数据存入Redis中 init_by_lua_block{ redis = require \"resty.redis\" mysql = require \"resty.mysql\" cjson = require \"cjson\" } location /redisPreheat{ default_type \"text/html\"; content_by_lua_block{ --获取请求的参数username local param = ngx.req.get_uri_args()[\"username\"] --建立mysql数据库的连接 local db = mysql:new() local ok,err = db:connect{ host=\"10.0.4.7\", port=3306, user=\"root\", password=\"root\", database=\"lua_db\" } if not ok then ngx.say(\"failed connect to mysql:\",err) return end --设置连接超时时间 db:set_timeout(1000) --查询数据 local sql = \"\"; if not param then sql=\"select * from users\" else sql=\"select * from users where username=\"..\"'\"..param..\"'\" end local res,err,errcode,sqlstate=db:query(sql) if not res then ngx.say(\"failed to query from mysql:\",err) return end --连接redis local rd = redis:new() ok,err = rd:connect(\"10.0.4.7\",6379) if not ok then ngx.say(\"failed to connect to redis:\",err) return end rd:set_timeout(1000) --循环遍历数据 for i,v in ipairs(res) do rd:set(\"user_\"..v.username,cjson.encode(v)) end ngx.say(\"success\") rd:close() db:close() } } 发现: + 英文字母有小图标 :c —&gt; ⏰🐤 关于撤回，vim","categories":[{"name":"计算机语言","slug":"计算机语言","permalink":"https://mykkto.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://mykkto.github.io/tags/nginx/"},{"name":"lua","slug":"lua","permalink":"https://mykkto.github.io/tags/lua/"},{"name":"openresty","slug":"openresty","permalink":"https://mykkto.github.io/tags/openresty/"}],"author":"mykk"},{"title":"SpringCloud-Alibaba-Seata 处理分布式事务","slug":"03-java分布式/01-springcloud/16_SpringCloudAlibaba-Seata","date":"2022-03-25T12:11:33.000Z","updated":"2022-11-12T15:07:08.072Z","comments":true,"path":"posts/e1138fa5.html","link":"","permalink":"https://mykkto.github.io/posts/e1138fa5.html","excerpt":"","text":"一、分布式事务问题1、分布式前 单机单库没这个问题 从1：1 -&gt; 1：N -&gt; N：N 2、分布式之后单体应用被拆分成微服务应用，原来的三个模块被拆分成三个独立的应用，分别使用三个独立的数据源，业务操作需要调用三个服务来完成。此时每个服务内部的数据一致性由本地**事务来保证，但是全局**的数据一致性问题没法保证。 3、一句话一次业务操作需要跨多个数据源或需要跨多个系统进行远程调用，就会产生分布式事务问题 二、Seata简介1、是什么Seata是一款开源的分布式事务解决方案，致力于在微服务架构下提供高性能和简单易用的分布式事务服务。 2、能干嘛（★）1、ID(1)+组件(3)1、ID全局唯一的事务ID：Transaction ID XID 2、组件Transaction Coordinator (TC)【打工人】 事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚； Transaction Manager (TM)【老板】 控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议； Resource Manager (RM)【任务】 控制分支事务，负责分支注册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚 2、处理过程1、TM 向 TC 申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的 XID； 2、XID 在微服务调用链路的上下文中传播； 3、RM 向 TC 注册分支事务，将其纳入 XID 对应全局事务的管辖； 4、TM 向 TC 发起针对 XID 的全局提交或回滚决议； 5、TC 调度 XID 下管辖的全部分支事务完成提交或回滚请求。 3、怎么用1、本地单体架构上，本地使用spring：@Transactional 2、全局分布式上，全局使用Seata：@GlobalTransactional 三、Seata-Server安装1、官网1、地址http://seata.io/zh-cn/ 2、下载地址https://github.com/seata/seata/releases 选择 1.0.0 GA 稳定版 2、配置seata-server-1.0.0.zip 解压到指定目录并修改conf目录下的file.conf配置文件 1、file.conf（service模块）vgroup_mapping.my_test_tx_group = \"fsp_tx_group\" 2、file.conf（store模块）mode = \"db\" url = \"jdbc:mysql://127.0.0.1:3306/seata\" user = \"root\" password = \"你自己密码\" 3、导入建表sql-- -------------------------------- The script used when storeMode is 'db' -------------------------------- -- the table to store GlobalSession data CREATE TABLE IF NOT EXISTS `global_table` ( `xid` VARCHAR(128) NOT NULL, `transaction_id` BIGINT, `status` TINYINT NOT NULL, `application_id` VARCHAR(32), `transaction_service_group` VARCHAR(32), `transaction_name` VARCHAR(128), `timeout` INT, `begin_time` BIGINT, `application_data` VARCHAR(2000), `gmt_create` DATETIME, `gmt_modified` DATETIME, PRIMARY KEY (`xid`), KEY `idx_gmt_modified_status` (`gmt_modified`, `status`), KEY `idx_transaction_id` (`transaction_id`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8; -- the table to store BranchSession data CREATE TABLE IF NOT EXISTS `branch_table` ( `branch_id` BIGINT NOT NULL, `xid` VARCHAR(128) NOT NULL, `transaction_id` BIGINT, `resource_group_id` VARCHAR(32), `resource_id` VARCHAR(256), `branch_type` VARCHAR(8), `status` TINYINT, `client_id` VARCHAR(64), `application_data` VARCHAR(2000), `gmt_create` DATETIME(6), `gmt_modified` DATETIME(6), PRIMARY KEY (`branch_id`), KEY `idx_xid` (`xid`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8; -- the table to store lock data CREATE TABLE IF NOT EXISTS `lock_table` ( `row_key` VARCHAR(128) NOT NULL, `xid` VARCHAR(96), `transaction_id` BIGINT, `branch_id` BIGINT NOT NULL, `resource_id` VARCHAR(256), `table_name` VARCHAR(32), `pk` VARCHAR(36), `gmt_create` DATETIME, `gmt_modified` DATETIME, PRIMARY KEY (`row_key`), KEY `idx_branch_id` (`branch_id`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8; 4、启动1、启动cacos，seate 2、查看 nacos 控制台 四、订单/库存/账户业务数据库准备1、实战业务说明1、详细这里我们会创建三个服务，一个订单服务，一个库存服务，一个账户服务。 当用户下单时，会在订单服务中创建一个订单，然后通过远程调用库存服务来扣减下单商品的库存，再通过远程调用账户服务来扣减用户账户里面的余额，最后在订单服务中修改订单状态为已完成。 该操作跨越三个数据库，有两次远程调用，很明显会有分布式事务问题。 2、调用流程下订单—&gt;扣库存—&gt;减账户(余额) 2、建库建表0、建库CREATE DATABASE seata_order; CREATE DATABASE seata_storage; CREATE DATABASE seata_account; 1、订单seata_order：存储订单的数据库； 表语句： CREATE TABLE t_order ( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY, `user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id', `product_id` BIGINT(11) DEFAULT NULL COMMENT '产品id', `count` INT(11) DEFAULT NULL COMMENT '数量', `money` DECIMAL(11,0) DEFAULT NULL COMMENT '金额', `status` INT(1) DEFAULT NULL COMMENT '订单状态：0：创建中；1：已完结' ) ENGINE=INNODB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8; SELECT * FROM t_order; 2、库存seata_storage：存储库存的数据库； 表语句： CREATE TABLE t_storage ( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY, `product_id` BIGINT(11) DEFAULT NULL COMMENT '产品id', `total` INT(11) DEFAULT NULL COMMENT '总库存', `used` INT(11) DEFAULT NULL COMMENT '已用库存', `residue` INT(11) DEFAULT NULL COMMENT '剩余库存' ) ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; INSERT INTO seata_storage.t_storage(`id`, `product_id`, `total`, `used`, `residue`) VALUES ('1', '1', '100', '0', '100'); SELECT * FROM t_storage; 3、账户信息seata_account：存储账户信息的数据库。 表语句： CREATE TABLE t_account ( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'id', `user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id', `total` DECIMAL(10,0) DEFAULT NULL COMMENT '总额度', `used` DECIMAL(10,0) DEFAULT NULL COMMENT '已用余额', `residue` DECIMAL(10,0) DEFAULT '0' COMMENT '剩余可用额度' ) ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; INSERT INTO seata_account.t_account(`id`, `user_id`, `total`, `used`, `residue`) VALUES ('1', '1', '1000', '0', '1000'); SELECT * FROM t_account; 4、回滚日志表按照上述3库分别建对应的回滚日志表 -- the table to store seata xid data -- 0.7.0+ add context -- you must to init this sql for you business databese. the seata server not need it. -- 此脚本必须初始化在你当前的业务数据库中，用于AT 模式XID记录。与server端无关（注：业务数据库） -- 注意此处0.3.0+ 增加唯一索引 ux_undo_log DROP TABLE `undo_log`; CREATE TABLE `undo_log` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT, `branch_id` BIGINT(20) NOT NULL, `xid` VARCHAR(100) NOT NULL, `context` VARCHAR(128) NOT NULL, `rollback_info` LONGBLOB NOT NULL, `log_status` INT(11) NOT NULL, `log_created` DATETIME NOT NULL, `log_modified` DATETIME NOT NULL, `ext` VARCHAR(100) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`) ) ENGINE=INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; 5、效果 五、订单/库存/账户业务微服务准备1、业务需求下订单-&gt;减库存-&gt;扣余额-&gt;改(订单)状态 2、新建订单Order-Module1、modelseata-order-service2001 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;seata-order-service2001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--nacos--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--seata--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--feign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web-actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mysql-druid--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.37&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 2001 spring: application: name: seata-order-service cloud: alibaba: seata: #自定义事务组名称需要与seata-server中的对应 tx-service-group: fsp_tx_group nacos: discovery: server-addr: 106.52.23.202:8848 datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://106.52.23.202:3306/seata_order username: root password: root feign: hystrix: enabled: false logging: level: io: seata: info mybatis: mapperLocations: classpath:mapper/*.xml 4、file.confyml 同层目录下 需要修改的是 mysql url,username,password transport { # tcp udt unix-domain-socket type = \"TCP\" #NIO NATIVE server = \"NIO\" #enable heartbeat heartbeat = true #thread factory for netty thread-factory { boss-thread-prefix = \"NettyBoss\" worker-thread-prefix = \"NettyServerNIOWorker\" server-executor-thread-prefix = \"NettyServerBizHandler\" share-boss-worker = false client-selector-thread-prefix = \"NettyClientSelector\" client-selector-thread-size = 1 client-worker-thread-prefix = \"NettyClientWorkerThread\" # netty boss thread size,will not be used for UDT boss-thread-size = 1 #auto default pin or 8 worker-thread-size = 8 } shutdown { # when destroy server, wait seconds wait = 3 } serialization = \"seata\" compressor = \"none\" } service { vgroup_mapping.fsp_tx_group = \"default\" #修改自定义事务组名称 default.grouplist = \"127.0.0.1:8091\" enableDegrade = false disable = false max.commit.retry.timeout = \"-1\" max.rollback.retry.timeout = \"-1\" disableGlobalTransaction = false } client { async.commit.buffer.limit = 10000 lock { retry.internal = 10 retry.times = 30 } report.retry.count = 5 tm.commit.retry.count = 1 tm.rollback.retry.count = 1 } ## transaction log store store { ## store mode: file、db mode = \"db\" ## file store file { dir = \"sessionStore\" # branch session size , if exceeded first try compress lockkey, still exceeded throws exceptions max-branch-session-size = 16384 # globe session size , if exceeded throws exceptions max-global-session-size = 512 # file buffer size , if exceeded allocate new buffer file-write-buffer-cache-size = 16384 # when recover batch read size session.reload.read_size = 100 # async, sync flush-disk-mode = async } ## database store db { ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp) etc. datasource = \"dbcp\" ## mysql/oracle/h2/oceanbase etc. db-type = \"mysql\" driver-class-name = \"com.mysql.jdbc.Driver\" url = \"jdbc:mysql://106.52.23.202:3306/seata\" user = \"root\" password = \"root\" min-conn = 1 max-conn = 3 global.table = \"global_table\" branch.table = \"branch_table\" lock-table = \"lock_table\" query-limit = 100 } } lock { ## the lock store mode: local、remote mode = \"remote\" local { ## store locks in user's database } remote { ## store locks in the seata's server } } recovery { #schedule committing retry period in milliseconds committing-retry-period = 1000 #schedule asyn committing retry period in milliseconds asyn-committing-retry-period = 1000 #schedule rollbacking retry period in milliseconds rollbacking-retry-period = 1000 #schedule timeout retry period in milliseconds timeout-retry-period = 1000 } transaction { undo.data.validation = true undo.log.serialization = \"jackson\" undo.log.save.days = 7 #schedule delete expired undo_log in milliseconds undo.log.delete.period = 86400000 undo.log.table = \"undo_log\" } ## metrics settings metrics { enabled = false registry-type = \"compact\" # multi exporters use comma divided exporter-list = \"prometheus\" exporter-prometheus-port = 9898 } support { ## spring spring { # auto proxy the DataSource bean datasource.autoproxy = false } } 5、registry.confregistry { # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = \"nacos\" nacos { serverAddr = \"106.52.23.202:8848\" namespace = \"\" cluster = \"default\" } eureka { serviceUrl = \"http://localhost:8761/eureka\" application = \"default\" weight = \"1\" } redis { serverAddr = \"localhost:6379\" db = \"0\" } zk { cluster = \"default\" serverAddr = \"127.0.0.1:2181\" session.timeout = 6000 connect.timeout = 2000 } consul { cluster = \"default\" serverAddr = \"127.0.0.1:8500\" } etcd3 { cluster = \"default\" serverAddr = \"http://localhost:2379\" } sofa { serverAddr = \"127.0.0.1:9603\" application = \"default\" region = \"DEFAULT_ZONE\" datacenter = \"DefaultDataCenter\" cluster = \"default\" group = \"SEATA_GROUP\" addressWaitTime = \"3000\" } file { name = \"file.conf\" } } config { # file、nacos 、apollo、zk、consul、etcd3 type = \"file\" nacos { serverAddr = \"localhost\" namespace = \"\" } consul { serverAddr = \"127.0.0.1:8500\" } apollo { app.id = \"seata-server\" apollo.meta = \"http://192.168.1.204:8801\" } zk { serverAddr = \"127.0.0.1:2181\" session.timeout = 6000 connect.timeout = 2000 } etcd3 { serverAddr = \"http://localhost:2379\" } file { name = \"file.conf\" } } 6、业务类1、domainpackage com.kk.springcloud.domain; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @Data @AllArgsConstructor @NoArgsConstructor public class CommonResult&lt;T&gt; { private Integer code; private String message; private T data; public CommonResult(Integer code, String message) { this (code, message, null); } } package com.kk.springcloud.domain; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; import java.math.BigDecimal; @Data @AllArgsConstructor @NoArgsConstructor public class Order { private Long id; private Long userId; private Long productId; private Integer count; private BigDecimal money; /** * 订单状态：0：创建中；1：已完结 */ private Integer status; } 2、daopackage com.kk.springcloud.dao; import com.kk.springcloud.domain.Order; import org.apache.ibatis.annotations.Mapper; import org.apache.ibatis.annotations.Param; @Mapper public interface OrderDao { /** * 创建订单 */ void create(Order order); /** * 修改订单金额 */ void update(@Param(\"userId\") Long userId, @Param(\"status\") Integer status); } OrderMapper.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt; &lt;mapper namespace=\"com.kk.springcloud.dao.OrderDao\"&gt; &lt;resultMap id=\"BaseResultMap\" type=\"com.kk.springcloud.domain.Order\"&gt; &lt;id column=\"id\" property=\"id\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"user_id\" property=\"userId\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"product_id\" property=\"productId\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"count\" property=\"count\" jdbcType=\"INTEGER\"/&gt; &lt;result column=\"money\" property=\"money\" jdbcType=\"DECIMAL\"/&gt; &lt;result column=\"status\" property=\"status\" jdbcType=\"INTEGER\"/&gt; &lt;/resultMap&gt; &lt;insert id=\"create\"&gt; INSERT INTO `t_order` (`id`, `user_id`, `product_id`, `count`, `money`, `status`) VALUES (NULL, #{userId}, #{productId}, #{count}, #{money}, 0); &lt;/insert&gt; &lt;update id=\"update\"&gt; UPDATE `t_order` SET status = 1 WHERE user_id = #{userId} AND status = #{status}; &lt;/update&gt; &lt;/mapper&gt; 3、serivce OrderService OrderServiceImpl package com.kk.springcloud.service; import com.kk.springcloud.domain.Order; public interface OrderService { /** * 创建订单 */ void create(Order order); } package com.kk.springcloud.service; import com.kk.springcloud.dao.OrderDao; import com.kk.springcloud.domain.Order; import io.seata.spring.annotation.GlobalTransactional; import lombok.extern.slf4j.Slf4j; import org.springframework.stereotype.Service; import javax.annotation.Resource; @Service @Slf4j public class OrderServiceImpl implements OrderService { @Resource private OrderDao orderDao; @Resource private StorageService storageService; @Resource private AccountService accountService; /** * 创建订单-&gt;调用库存服务扣减库存-&gt;调用账户服务扣减账户余额-&gt;修改订单状态 * 简单说： * 下订单-&gt;减库存-&gt;减余额-&gt;改状态 * rollbackFor = Exception.class ,任何异常都回滚 */ @Override @GlobalTransactional(name = \"fsp-create-order\", rollbackFor = Exception.class) public void create(Order order) { log.info (\"===开始下单===\"); //本应用创建订单 orderDao.create (order); //远程调用库存服务扣减库存 log.info (\"-------&gt;order-service中扣减库存开始\"); storageService.decrease (order.getProductId ( ), order.getCount ( )); log.info (\"-------&gt;order-service中扣减库存结束\"); //远程调用账户服务扣减余额 log.info (\"-------&gt;order-service中扣减余额开始\"); accountService.decrease (order.getUserId ( ), order.getMoney ( )); log.info (\"-------&gt;order-service中扣减余额结束\"); //修改订单状态为已完成 log.info (\"-------&gt;order-service中修改订单状态开始\"); orderDao.update (order.getUserId ( ), 0); log.info (\"-------&gt;order-service中修改订单状态结束\"); log.info (\"-------&gt;下单结束\"); } } AccountService package com.kk.springcloud.service; import com.kk.springcloud.domain.CommonResult; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestParam; import java.math.BigDecimal; @FeignClient(value = \"seata-account-service\") public interface AccountService { /** * 扣减账户余额 */ //@RequestMapping(value = \"/account/decrease\", method = RequestMethod.POST, produces = \"application/json; charset=UTF-8\") @PostMapping(\"/account/decrease\") CommonResult decrease(@RequestParam(\"userId\") Long userId, @RequestParam(\"money\") BigDecimal money); } StorageService package com.kk.springcloud.service; import com.kk.springcloud.domain.CommonResult; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestParam; @FeignClient(value = \"seata-storage-service\") public interface StorageService { /** * 扣减库存 */ @PostMapping(value = \"/storage/decrease\") CommonResult decrease(@RequestParam(\"productId\") Long productId, @RequestParam(\"count\") Integer count); } 4、controllerpackage com.kk.springcloud.controller; import com.kk.springcloud.domain.CommonResult; import com.kk.springcloud.domain.Order; import com.kk.springcloud.service.OrderService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class OrderController { @Autowired private OrderService orderService; /** * 创建订单 */ @GetMapping(\"/order/create\") public CommonResult create(Order order) { orderService.create(order); return new CommonResult(200, \"订单创建成功!\"); } } 7、Config配置 MybatisConfig package com.kk.springcloud.config; import org.mybatis.spring.annotation.MapperScan; import org.springframework.context.annotation.Configuration; @Configuration @MapperScan({\"com.kk.springcloud.dao\"}) public class MyBatisConfig { } DataSourceProxyConfig package com.kk.springcloud.config; import com.alibaba.druid.pool.DruidDataSource; import io.seata.rm.datasource.DataSourceProxy; import org.apache.ibatis.session.SqlSessionFactory; import org.mybatis.spring.SqlSessionFactoryBean; import org.mybatis.spring.transaction.SpringManagedTransactionFactory; import org.springframework.beans.factory.annotation.Value; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.core.io.support.PathMatchingResourcePatternResolver; import javax.sql.DataSource; /* * @Description: 使用Seata对数据源进行代理 * @Author: 阿K * @CreateDate: 2022/3/27 13:31 * @Param: * @Return: **/ @Configuration public class DataSourceProxyConfig { @Value(\"${mybatis.mapperLocations}\") private String mapperLocations; @Bean @ConfigurationProperties(prefix = \"spring.datasource\") public DataSource druidDataSource() { return new DruidDataSource ( ); } @Bean public DataSourceProxy dataSourceProxy(DataSource dataSource) { return new DataSourceProxy (dataSource); } @Bean public SqlSessionFactory sqlSessionFactoryBean(DataSourceProxy dataSourceProxy) throws Exception { SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean ( ); sqlSessionFactoryBean.setDataSource (dataSourceProxy); sqlSessionFactoryBean.setMapperLocations (new PathMatchingResourcePatternResolver ( ).getResources (mapperLocations)); sqlSessionFactoryBean.setTransactionFactory (new SpringManagedTransactionFactory ( )); return sqlSessionFactoryBean.getObject ( ); } } 8、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; import org.springframework.cloud.openfeign.EnableFeignClients; @EnableDiscoveryClient @EnableFeignClients @SpringBootApplication(exclude = DataSourceAutoConfiguration.class)//取消数据源的自动创建 public class SeataOrderMainApp2001 { public static void main(String[] args) { SpringApplication.run (SeataOrderMainApp2001.class, args); } } 3、新建库存Storage-Module1、modelseata-storage-service2002 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;seata-order-service2001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--nacos--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--seata--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--feign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web-actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--mysql-druid--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.37&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 2002 spring: application: name: seata-storage-service cloud: alibaba: seata: tx-service-group: fsp_tx_group nacos: discovery: server-addr: 106.52.23.202:8848 datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://106.52.23.202:3306/seata_storage username: root password: root logging: level: io: seata: info mybatis: mapperLocations: classpath:mapper/*.xml 4、file.confvgroup_mapping.fsp_tx_group = \"default\" transport { # tcp udt unix-domain-socket type = \"TCP\" #NIO NATIVE server = \"NIO\" #enable heartbeat heartbeat = true #thread factory for netty thread-factory { boss-thread-prefix = \"NettyBoss\" worker-thread-prefix = \"NettyServerNIOWorker\" server-executor-thread-prefix = \"NettyServerBizHandler\" share-boss-worker = false client-selector-thread-prefix = \"NettyClientSelector\" client-selector-thread-size = 1 client-worker-thread-prefix = \"NettyClientWorkerThread\" # netty boss thread size,will not be used for UDT boss-thread-size = 1 #auto default pin or 8 worker-thread-size = 8 } shutdown { # when destroy server, wait seconds wait = 3 } serialization = \"seata\" compressor = \"none\" } service { #vgroup-&gt;rgroup vgroup_mapping.fsp_tx_group = \"default\" #only support single node default.grouplist = \"127.0.0.1:8091\" #degrade current not support enableDegrade = false #disable disable = false #unit ms,s,m,h,d represents milliseconds, seconds, minutes, hours, days, default permanent max.commit.retry.timeout = \"-1\" max.rollback.retry.timeout = \"-1\" disableGlobalTransaction = false } client { async.commit.buffer.limit = 10000 lock { retry.internal = 10 retry.times = 30 } report.retry.count = 5 tm.commit.retry.count = 1 tm.rollback.retry.count = 1 } transaction { undo.data.validation = true undo.log.serialization = \"jackson\" undo.log.save.days = 7 #schedule delete expired undo_log in milliseconds undo.log.delete.period = 86400000 undo.log.table = \"undo_log\" } support { ## spring spring { # auto proxy the DataSource bean datasource.autoproxy = false } } 5、registry.confregistry { # file 、nacos 、eureka、redis、zk type = \"nacos\" nacos { serverAddr = \"106.52.23.202:8848\" namespace = \"\" cluster = \"default\" } eureka { serviceUrl = \"http://localhost:8761/eureka\" application = \"default\" weight = \"1\" } redis { serverAddr = \"localhost:6381\" db = \"0\" } zk { cluster = \"default\" serverAddr = \"127.0.0.1:2181\" session.timeout = 6000 connect.timeout = 2000 } file { name = \"file.conf\" } } config { # file、nacos 、apollo、zk type = \"file\" nacos { serverAddr = \"localhost\" namespace = \"\" cluster = \"default\" } apollo { app.id = \"fescar-server\" apollo.meta = \"http://192.168.1.204:8801\" } zk { serverAddr = \"127.0.0.1:2181\" session.timeout = 6000 connect.timeout = 2000 } file { name = \"file.conf\" } } 6、业务类1、domainpackage com.kk.springcloud.domain; import lombok.Data; @Data public class Storage { private Long id; /** * 产品id */ private Long productId; /** * 总库存 */ private Integer total; /** * 已用库存 */ private Integer used; /** * 剩余库存 */ private Integer residue; } 2、daopackage com.kk.springcloud.dao; import org.apache.ibatis.annotations.Mapper; import org.apache.ibatis.annotations.Param; @Mapper public interface StorageDao { /** * 扣减库存 */ void decrease(@Param(\"productId\") Long productId, @Param(\"count\") Integer count); } &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt; &lt;mapper namespace=\"com.kk.springcloud.dao.StorageDao\"&gt; &lt;resultMap id=\"BaseResultMap\" type=\"com.kk.springcloud.domain.Storage\"&gt; &lt;id column=\"id\" property=\"id\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"product_id\" property=\"productId\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"total\" property=\"total\" jdbcType=\"INTEGER\"/&gt; &lt;result column=\"used\" property=\"used\" jdbcType=\"INTEGER\"/&gt; &lt;result column=\"residue\" property=\"residue\" jdbcType=\"INTEGER\"/&gt; &lt;/resultMap&gt; &lt;update id=\"decrease\"&gt; UPDATE t_storage SET used = used + #{count}, residue = residue - #{count} WHERE product_id = #{productId} &lt;/update&gt; &lt;/mapper&gt; 3、serivcepackage com.kk.springcloud.service; public interface StorageService { /** * 扣减库存 */ void decrease(Long productId, Integer count); } package com.kk.springcloud.service; import com.kk.springcloud.dao.StorageDao; import lombok.extern.slf4j.Slf4j; import org.springframework.stereotype.Service; import javax.annotation.Resource; @Service @Slf4j public class StorageServiceImpl implements StorageService { @Resource private StorageDao storageDao; /** * 扣减库存 */ @Override public void decrease(Long productId, Integer count) { log.info (\"-------&gt;storage-service中扣减库存开始\"); storageDao.decrease (productId, count); log.info (\"-------&gt;storage-service中扣减库存结束\"); } } 4、controllerpackage com.kk.springcloud.controller; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.service.StorageService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class StorageController { @Autowired private StorageService storageService; /** * 扣减库存 */ @RequestMapping(\"/storage/decrease\") public CommonResult decrease(Long productId, Integer count) { storageService.decrease (productId, count); return new CommonResult (200, \"扣减库存成功！\"); } } 7、Config配置 MybatisConfig package com.kk.springcloud.config; import org.mybatis.spring.annotation.MapperScan; import org.springframework.context.annotation.Configuration; @Configuration @MapperScan({\"com.kk.springcloud.dao\"}) public class MyBatisConfig { } DataSourceProxyConfig package com.kk.springcloud.config; import com.alibaba.druid.pool.DruidDataSource; import io.seata.rm.datasource.DataSourceProxy; import org.apache.ibatis.session.SqlSessionFactory; import org.mybatis.spring.SqlSessionFactoryBean; import org.mybatis.spring.transaction.SpringManagedTransactionFactory; import org.springframework.beans.factory.annotation.Value; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.core.io.support.PathMatchingResourcePatternResolver; import javax.sql.DataSource; /* * @Description: 使用Seata对数据源进行代理 * @Author: 阿K * @CreateDate: 2022/3/27 13:31 * @Param: * @Return: **/ @Configuration public class DataSourceProxyConfig { @Value(\"${mybatis.mapperLocations}\") private String mapperLocations; @Bean @ConfigurationProperties(prefix = \"spring.datasource\") public DataSource druidDataSource() { return new DruidDataSource ( ); } @Bean public DataSourceProxy dataSourceProxy(DataSource dataSource) { return new DataSourceProxy (dataSource); } @Bean public SqlSessionFactory sqlSessionFactoryBean(DataSourceProxy dataSourceProxy) throws Exception { SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean ( ); sqlSessionFactoryBean.setDataSource (dataSourceProxy); sqlSessionFactoryBean.setMapperLocations (new PathMatchingResourcePatternResolver ( ).getResources (mapperLocations)); sqlSessionFactoryBean.setTransactionFactory (new SpringManagedTransactionFactory ( )); return sqlSessionFactoryBean.getObject ( ); } } 8、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; import org.springframework.cloud.openfeign.EnableFeignClients; @SpringBootApplication(exclude = DataSourceAutoConfiguration.class) @EnableDiscoveryClient @EnableFeignClients public class SeataStorageServiceApplication2002 { public static void main(String[] args) { SpringApplication.run (SeataStorageServiceApplication2002.class, args); } } 4、新建账户Account-Module1、modelseata-account-service2003 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;seata-account-service2003&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--nacos--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--seata--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--feign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.37&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 2003 spring: application: name: seata-account-service cloud: alibaba: seata: tx-service-group: fsp_tx_group nacos: discovery: server-addr: 106.52.23.202:8848 datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://106.52.23.202:3306/seata_account username: root password: root feign: hystrix: enabled: false logging: level: io: seata: info mybatis: mapperLocations: classpath:mapper/*.xml 4、file.conftransport { # tcp udt unix-domain-socket type = \"TCP\" #NIO NATIVE server = \"NIO\" #enable heartbeat heartbeat = true #thread factory for netty thread-factory { boss-thread-prefix = \"NettyBoss\" worker-thread-prefix = \"NettyServerNIOWorker\" server-executor-thread-prefix = \"NettyServerBizHandler\" share-boss-worker = false client-selector-thread-prefix = \"NettyClientSelector\" client-selector-thread-size = 1 client-worker-thread-prefix = \"NettyClientWorkerThread\" # netty boss thread size,will not be used for UDT boss-thread-size = 1 #auto default pin or 8 worker-thread-size = 8 } shutdown { # when destroy server, wait seconds wait = 3 } serialization = \"seata\" compressor = \"none\" } service { vgroup_mapping.fsp_tx_group = \"default\" #修改自定义事务组名称 default.grouplist = \"127.0.0.1:8091\" enableDegrade = false disable = false max.commit.retry.timeout = \"-1\" max.rollback.retry.timeout = \"-1\" disableGlobalTransaction = false } client { async.commit.buffer.limit = 10000 lock { retry.internal = 10 retry.times = 30 } report.retry.count = 5 tm.commit.retry.count = 1 tm.rollback.retry.count = 1 } ## transaction log store store { ## store mode: file、db mode = \"db\" ## file store file { dir = \"sessionStore\" # branch session size , if exceeded first try compress lockkey, still exceeded throws exceptions max-branch-session-size = 16384 # globe session size , if exceeded throws exceptions max-global-session-size = 512 # file buffer size , if exceeded allocate new buffer file-write-buffer-cache-size = 16384 # when recover batch read size session.reload.read_size = 100 # async, sync flush-disk-mode = async } ## database store db { ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp) etc. datasource = \"dbcp\" ## mysql/oracle/h2/oceanbase etc. db-type = \"mysql\" driver-class-name = \"com.mysql.jdbc.Driver\" url = \"jdbc:mysql://106.52.23.202:3306/seata\" user = \"root\" password = \"root\" min-conn = 1 max-conn = 3 global.table = \"global_table\" branch.table = \"branch_table\" lock-table = \"lock_table\" query-limit = 100 } } lock { ## the lock store mode: local、remote mode = \"remote\" local { ## store locks in user's database } remote { ## store locks in the seata's server } } recovery { #schedule committing retry period in milliseconds committing-retry-period = 1000 #schedule asyn committing retry period in milliseconds asyn-committing-retry-period = 1000 #schedule rollbacking retry period in milliseconds rollbacking-retry-period = 1000 #schedule timeout retry period in milliseconds timeout-retry-period = 1000 } transaction { undo.data.validation = true undo.log.serialization = \"jackson\" undo.log.save.days = 7 #schedule delete expired undo_log in milliseconds undo.log.delete.period = 86400000 undo.log.table = \"undo_log\" } ## metrics settings metrics { enabled = false registry-type = \"compact\" # multi exporters use comma divided exporter-list = \"prometheus\" exporter-prometheus-port = 9898 } support { ## spring spring { # auto proxy the DataSource bean datasource.autoproxy = false } } 5、registry.confregistry { # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = \"nacos\" nacos { serverAddr = \"106.52.23.202:8848\" namespace = \"\" cluster = \"default\" } eureka { serviceUrl = \"http://localhost:8761/eureka\" application = \"default\" weight = \"1\" } redis { serverAddr = \"localhost:6379\" db = \"0\" } zk { cluster = \"default\" serverAddr = \"127.0.0.1:2181\" session.timeout = 6000 connect.timeout = 2000 } consul { cluster = \"default\" serverAddr = \"127.0.0.1:8500\" } etcd3 { cluster = \"default\" serverAddr = \"http://localhost:2379\" } sofa { serverAddr = \"127.0.0.1:9603\" application = \"default\" region = \"DEFAULT_ZONE\" datacenter = \"DefaultDataCenter\" cluster = \"default\" group = \"SEATA_GROUP\" addressWaitTime = \"3000\" } file { name = \"file.conf\" } } config { # file、nacos 、apollo、zk、consul、etcd3 type = \"file\" nacos { serverAddr = \"localhost\" namespace = \"\" } consul { serverAddr = \"127.0.0.1:8500\" } apollo { app.id = \"seata-server\" apollo.meta = \"http://192.168.1.204:8801\" } zk { serverAddr = \"127.0.0.1:2181\" session.timeout = 6000 connect.timeout = 2000 } etcd3 { serverAddr = \"http://localhost:2379\" } file { name = \"file.conf\" } } 6、业务类1、domainpackage com.kk.springclpid.domain; import lombok.Data; import java.math.BigDecimal; @Data public class Account { private Long id; /** * 用户id */ private Long userId; /** * 总额度 */ private BigDecimal total; /** * 已用额度 */ private BigDecimal used; /** * 剩余额度 */ private BigDecimal residue; } 2、daopackage com.kk.springcloud.dao; import org.apache.ibatis.annotations.Mapper; import org.apache.ibatis.annotations.Param; import java.math.BigDecimal; @Mapper public interface AccountDao { /** * 扣减账户余额 */ void decrease(@Param(\"userId\") Long userId, @Param(\"money\") BigDecimal money); } &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt; &lt;mapper namespace=\"com.kk.springcloud.dao.AccountDao\"&gt; &lt;resultMap id=\"BaseResultMap\" type=\"com.kk.springcloud.domain.Account\"&gt; &lt;id column=\"id\" property=\"id\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"user_id\" property=\"userId\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"total\" property=\"total\" jdbcType=\"DECIMAL\"/&gt; &lt;result column=\"used\" property=\"used\" jdbcType=\"DECIMAL\"/&gt; &lt;result column=\"residue\" property=\"residue\" jdbcType=\"DECIMAL\"/&gt; &lt;/resultMap&gt; &lt;update id=\"decrease\"&gt; UPDATE t_account SET residue = residue - #{money},used = used + #{money} WHERE user_id = #{userId}; &lt;/update&gt; &lt;/mapper&gt; 3、serivcepackage com.kk.springcloud.service; import org.springframework.web.bind.annotation.RequestParam; import java.math.BigDecimal; public interface AccountService { /** * 扣减账户余额 * * @param userId 用户id * @param money 金额 */ void decrease(@RequestParam(\"userId\") Long userId, @RequestParam(\"money\") BigDecimal money); } package com.kk.springcloud.service; import com.kk.springcloud.dao.AccountDao; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.stereotype.Service; import javax.annotation.Resource; import java.math.BigDecimal; import java.util.concurrent.TimeUnit; @Service public class AccountServiceImpl implements AccountService { private static final Logger LOGGER = LoggerFactory.getLogger (AccountServiceImpl.class); @Resource AccountDao accountDao; /** * 扣减账户余额 */ @Override public void decrease(Long userId, BigDecimal money) { LOGGER.info (\"-------&gt;account-service中扣减账户余额开始\"); //模拟超时异常，全局事务回滚 //暂停几秒钟线程 try { TimeUnit.SECONDS.sleep (30); } catch (InterruptedException e) { e.printStackTrace ( ); } accountDao.decrease (userId, money); LOGGER.info (\"-------&gt;account-service中扣减账户余额结束\"); } } 4、controllerpackage com.kk.springcloud.controller; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.service.AccountService; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; import java.math.BigDecimal; @RestController public class AccountController { @Resource AccountService accountService; /** * 扣减账户余额 */ @RequestMapping(\"/account/decrease\") public CommonResult decrease(@RequestParam(\"userId\") Long userId, @RequestParam(\"money\") BigDecimal money) { accountService.decrease (userId, money); return new CommonResult (200, \"扣减账户余额成功！\"); } } 7、Config配置 MybatisConfig package com.kk.springcloud.config; import org.mybatis.spring.annotation.MapperScan; import org.springframework.context.annotation.Configuration; @Configuration @MapperScan({\"com.kk.springcloud.dao\"}) public class MyBatisConfig { } DataSourceProxyConfig package com.kk.springcloud.config; import com.alibaba.druid.pool.DruidDataSource; import io.seata.rm.datasource.DataSourceProxy; import org.apache.ibatis.session.SqlSessionFactory; import org.mybatis.spring.SqlSessionFactoryBean; import org.mybatis.spring.transaction.SpringManagedTransactionFactory; import org.springframework.beans.factory.annotation.Value; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.core.io.support.PathMatchingResourcePatternResolver; import javax.sql.DataSource; /* * @Description: 使用Seata对数据源进行代理 * @Author: 阿K * @CreateDate: 2022/3/27 13:31 * @Param: * @Return: **/ @Configuration public class DataSourceProxyConfig { @Value(\"${mybatis.mapperLocations}\") private String mapperLocations; @Bean @ConfigurationProperties(prefix = \"spring.datasource\") public DataSource druidDataSource() { return new DruidDataSource ( ); } @Bean public DataSourceProxy dataSourceProxy(DataSource dataSource) { return new DataSourceProxy (dataSource); } @Bean public SqlSessionFactory sqlSessionFactoryBean(DataSourceProxy dataSourceProxy) throws Exception { SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean ( ); sqlSessionFactoryBean.setDataSource (dataSourceProxy); sqlSessionFactoryBean.setMapperLocations (new PathMatchingResourcePatternResolver ( ).getResources (mapperLocations)); sqlSessionFactoryBean.setTransactionFactory (new SpringManagedTransactionFactory ( )); return sqlSessionFactoryBean.getObject ( ); } } 8、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; import org.springframework.cloud.openfeign.EnableFeignClients; @SpringBootApplication(exclude = DataSourceAutoConfiguration.class) @EnableDiscoveryClient @EnableFeignClients public class SeataAccountMainApp2003 { public static void main(String[] args) { SpringApplication.run (SeataAccountMainApp2003.class, args); } } 六、Test1、初始情况 2、正常下单1、请求http://localhost:2001/order/create?userId=1&amp;productId=1&amp;count=10&amp;money=100 2、数据库情况 3、无注解超时异常，没加@GlobalTransactional 1、AccountServiceImpl添加超时 2、数据库情况 3、故障情况 当库存和账户金额扣减后，订单状态并没有设置为已经完成，没有从零改为1 而且由于feign的重试机制，账户余额还有可能被多次扣减 4、有注解超时异常，添加@GlobalTransactional 1、AccountServiceImpl添加超时 2、OrderServiceImpl@GlobalTransactional @GlobalTransactional(name = \"fsp-create-order\",rollbackFor = Exception.class) public void create(Order order) { 。。。。。。 } 3、结果 下单后数据库数据并没有任何改变 记录都添加不进来 七、一部分补充1、再看TC/TM/RM三大组件分布式事务的执行流程 1、TM 开启分布式事务（TM 向 TC 注册全局事务记录）； 2、按业务场景，编排数据库、服务等事务内资源（RM 向 TC 汇报资源准备状态 ）； 3、TM 结束分布式事务，事务一阶段结束（TM 通知 TC 提交/回滚分布式事务）； 4、TC 汇总事务信息，决定分布式事务是提交还是回滚； 5、TC 通知所有 RM 提交/回滚 资源，事务二阶段结束。 2、AT模式如何做到对业务的无侵入1、是什么 2、一阶段加载在一阶段，Seata 会拦截“业务 SQL”，1 解析 SQL 语义，找到“业务 SQL”要更新的业务数据，在业务数据被更新前，将其保存成“before image”，2 执行“业务 SQL”更新业务数据，在业务数据更新之后，3 其保存成“after image”，最后生成行锁。以上操作全部在一个数据库事务内完成，这样保证了一阶段操作的原子性。 3、二阶段提交二阶段如是顺利提交的话，因为“业务 SQL”在一阶段已经提交至数据库，所以Seata框架只需将一阶段保存的快照数据和行锁删掉，完成数据清理即可。 3、二阶段回滚二阶段回滚：二阶段如果是回滚的话，Seata 就需要回滚一阶段已经执行的“业务 SQL”，还原业务数据。回滚方式便是用“before image”还原业务数据；但在还原前要首先要校验脏写，对比“数据库当前业务数据”和 “after image”，如果两份数据完全一致就说明没有脏写，可以还原业务数据，如果不一致就说明有脏写，出现脏写就需要转人工处理。 3、补充 参考文档 ↓docker 安装问题：https://www.cnblogs.com/youngyajun/p/14002547.html docker 网络问题：https://blog.csdn.net/tilyp/article/details/103371360 docker 运行问题：https://www.manongdao.com/article-2421258.html","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud-alibaba","slug":"springcloud-alibaba","permalink":"https://mykkto.github.io/tags/springcloud-alibaba/"},{"name":"seata","slug":"seata","permalink":"https://mykkto.github.io/tags/seata/"},{"name":"分布式事务","slug":"分布式事务","permalink":"https://mykkto.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"}],"author":"mykk"},{"title":"云主机部署并同步更新二级域名","slug":"00-blog/01_blogSynGithub","date":"2022-03-20T08:17:13.000Z","updated":"2022-11-22T15:05:04.625Z","comments":true,"path":"posts/829b453d.html","link":"","permalink":"https://mykkto.github.io/posts/829b453d.html","excerpt":"","text":"一、本地拉取配置1、创建并启动1、拉取docker pull nginx 2、启动docker run --name nginx-test -p 80:80 -d nginx – name 容器命名 -v 映射目录 -d 设置容器后台运行 -p 本机端口映射 将容器的80端口映射到本机的80端口 2、映射到本地1、创建首先在本机创建nginx的一些文件存储目录 mkdir -p /root/nginx/www /root/nginx/logs /root/nginx/conf www: nginx存储网站网页的目录 logs: nginx日志目录 conf: nginx配置文件目录 2、映射（1）先查看容器 docker ps -a （2）映射 docker cp 481e121fb29f:/etc/nginx/nginx.conf /root/nginx/conf 3、启动容器需要说明下，ngxin-test 容器是为了获得容器的配置文件，最终使用的是 nginx-web 目前已经启动 nginx-test 80端口，若是 nginx-web指定的也是 80，就需要关闭 nginx-test了 docker stop nginx-test 1、新容器映射创建新nginx容器nginx-web,并将www,logs,conf目录映射到本地 docker run -d -p 80:80 --name nginx-web -v /root/nginx/www:/usr/share/nginx/html -v /root/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v /root/nginx/logs:/var/log/nginx nginx 2、启动docker start nginx-web 二、下载git1、下载yum install git 2、配置github 代理git config --global url.\"https://ghproxy.com/https://github.com\".insteadOf \"https://github.com\" 3、拉取git clone https://github.com/mykkTo/mykkTo.github.io.git 4、剪切文件mv /root/nginx/www/mykkTo.github.io/* /root/nginx/www 三、定时任务1、编写shell脚本#!/bin/bash #删除原始静态页面数据以及拉取的文件夹 rm -rf /root/nginx/www/* rm -rf /root/nginx/mykkTo.github.iopwd #拉取，剪切到80映射下 cd /root/nginx/ git clone https://github.com/mykkTo/mykkTo.github.io.git mv /root/nginx/mykkTo.github.io/* /root/nginx/www #复制令牌用户百度站长验证使用 cp /root/nginx/baidu_verify_code-Os7hLX61vV.html /root/nginx/www/baidu_verify_code-Os7hLX61vV.html #替换文本，用于百度站长seo映射 sed 's/github.io/cn/g' /root/nginx/www/baidu_urls.txt&gt;/root/nginx/www/baidu_urls1.txt sed 's/https/http/g' /root/nginx/www/baidu_urls1.txt&gt;/root/nginx/www/baidu_urls2.txt echo \"============成功=========\" 2、创建定时任务crontab -e 补充： linux 黑洞，防止资源占用 /dev/null 2&gt;&amp;1 #后缀加上 /root/nginx/synblog.sh /dev/null 2&gt;&amp;1 启动： 这边设置没一个小时更新一次（需要注意centos7.6写法启动） service crond start 四、SSL证书1、是什么数据加密：开启 HTTPS 绿色加密通道，网站数据的加密传输，防止网站核心数据被窃取或篡改。 简单来说，就是把 http 访问的变成 https，并且浏览器显示安全，不在是不安全了 2、获取证书1、下载 2、上传到服务器并解压 3、重挂载1、删掉之前的容器docker rm -f nginx-web 2、重新挂载1、新增了 443端口映射，目录挂载 2、容器外，在nginx底下，创建新目录 mkdir lls 3、创建容器 多加了两个配置 docker run -d -p 443:443 -p 80:80 --name nginx-web -v /root/nginx/www:/usr/share/nginx/html -v /root/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v /root/nginx/logs:/var/log/nginx -v /root/nginx/lls/:/etc/nginx/ssl nginx 4、修改配置nginx.conf user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { limit_req_zone $binary_remote_addr zone=mylimit:10m rate=2r/s; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; server{ listen 443 ssl; #对应的域名，把mykkto.cn改成你们自己的域名就可以了 server_name mykkto.cn; #证书的两个配置文件 ssl_certificate /etc/nginx/ssl/7526194_www.mykkto.cn.pem; ssl_certificate_key /etc/nginx/ssl/7526194_www.mykkto.cn.key; #以下都是一些加密规则 ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; #这是我的主页访问地址，因为使用的是静态的html网页，所以直接使用location就可以完成了。 location / { #文件夹（这个其实挂载的就是外部的www目录下的静态资源） root //usr/share/nginx/html; #主页文件 index index.html; } } server { listen 80; #这边空格隔开，配置了两个，因为加了www也要配置 server_name mykkto.cn www.mykkto.cn; rewrite ^/(.*)$ https://mykkto.cn:443/$1 permanent; # location / { # limit_req zone=mylimit; #} } } 5、重启并测试1、重启docker restart nginx-web 2、测试1、访问，www.mykkto.cnm，自动跳转 2、访问，mykkto.cn，自动跳转 五、IP黑名单限制1、前言1、用到什么技术栈首先，基本架构是 docker+nginx+lua+mysql这是最初的想法，但是作者用了docker搭建的nginx，lua模块集成不是很方便，所以替换成了，OpenResty。 2、什么是 OpenResty简单来说就是 lua + nginx，当然还有更多功能，自己百度吧 3、遇到的问题简单描述下，上面用到的 nginx.conf写法，前缀 user nginx; 会导致无法运行，因为openresty没有这个用户，可以自己新建，我采用的是改写配置。 2、搭建 OpenResty1、拉取docker pull openresty/openresty 2、挂载并启动说明下： 完全基于上面的nginx配置的三个部分，唯一修改的是 nginx.conf配置文件，这边挂载改成了 nginx2.conf，用于保留之前的（自己懒而已） 新增了，lua文件挂载 修改了容器内的挂载位置，因为 openresty容器位置不一样了(外部还是不变，容器内的位置变了) docker run -d -p 443:443 -p 80:80 --name openresty -v /root/nginx/www:/usr/local/openresty/nginx/html -v /root/nginx/conf/nginx2.conf:/usr/local/openresty/nginx/conf/nginx.conf -v /root/nginx/logs:/usr/local/openresty/nginx/logs -v /root/nginx/lls/:/usr/local/openresty/nginx/ssl -v /root/nginx/lua/:/usr/local/openresty/nginx/lua openresty/openresty 3、配置文件修改1、初始化这是自带的，可以自己 DIY # nginx.conf -- docker-openresty # # This file is installed to: # `/usr/local/openresty/nginx/conf/nginx.conf` # and is the file loaded by nginx at startup, # unless the user specifies otherwise. # # It tracks the upstream OpenResty's `nginx.conf`, but removes the `server` # section and adds this directive: # `include /etc/nginx/conf.d/*.conf;` # # The `docker-openresty` file `nginx.vh.default.conf` is copied to # `/etc/nginx/conf.d/default.conf`. It contains the `server section # of the upstream `nginx.conf`. # # See https://github.com/openresty/docker-openresty/blob/master/README.md#nginx-config-files # #user nobody; #worker_processes 1; # Enables the use of JIT for regular expressions to speed-up their processing. pcre_jit on; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; # Enables or disables the use of underscores in client request header fields. # When the use of underscores is disabled, request header fields whose names contain underscores are marked as invalid and become subject to the ignore_invalid_headers directive. # underscores_in_headers off; #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #access_log logs/access.log main; # Log in JSON Format # log_format nginxlog_json escape=json '{ \"timestamp\": \"$time_iso8601\", ' # '\"remote_addr\": \"$remote_addr\", ' # '\"body_bytes_sent\": $body_bytes_sent, ' # '\"request_time\": $request_time, ' # '\"response_status\": $status, ' # '\"request\": \"$request\", ' # '\"request_method\": \"$request_method\", ' # '\"host\": \"$host\",' # '\"upstream_addr\": \"$upstream_addr\",' # '\"http_x_forwarded_for\": \"$http_x_forwarded_for\",' # '\"http_referrer\": \"$http_referer\", ' # '\"http_user_agent\": \"$http_user_agent\", ' # '\"http_version\": \"$server_protocol\", ' # '\"nginx_access\": true }'; # access_log /dev/stdout nginxlog_json; # See Move default writable paths to a dedicated directory (#119) # https://github.com/openresty/docker-openresty/issues/119 client_body_temp_path /var/run/openresty/nginx-client-body; proxy_temp_path /var/run/openresty/nginx-proxy; fastcgi_temp_path /var/run/openresty/nginx-fastcgi; uwsgi_temp_path /var/run/openresty/nginx-uwsgi; scgi_temp_path /var/run/openresty/nginx-scgi; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; # Don't reveal OpenResty version to clients. # server_tokens off; } 2、引入之前的配置在初始的基础上加上，两个之前写好的 server 块，以及lua脚本用于测试 # nginx.conf -- docker-openresty # # This file is installed to: # `/usr/local/openresty/nginx/conf/nginx.conf` # and is the file loaded by nginx at startup, # unless the user specifies otherwise. # # It tracks the upstream OpenResty's `nginx.conf`, but removes the `server` # section and adds this directive: # `include /etc/nginx/conf.d/*.conf;` # # The `docker-openresty` file `nginx.vh.default.conf` is copied to # `/etc/nginx/conf.d/default.conf`. It contains the `server section # of the upstream `nginx.conf`. # # See https://github.com/openresty/docker-openresty/blob/master/README.md#nginx-config-files # #user nobody; #worker_processes 1; # Enables the use of JIT for regular expressions to speed-up their processing. pcre_jit on; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; # Enables or disables the use of underscores in client request header fields. # When the use of underscores is disabled, request header fields whose names contain underscores are marked as invalid and become subject to the ignore_invalid_headers directive. # underscores_in_headers off; #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #access_log logs/access.log main; # Log in JSON Format # log_format nginxlog_json escape=json '{ \"timestamp\": \"$time_iso8601\", ' # '\"remote_addr\": \"$remote_addr\", ' # '\"body_bytes_sent\": $body_bytes_sent, ' # '\"request_time\": $request_time, ' # '\"response_status\": $status, ' # '\"request\": \"$request\", ' # '\"request_method\": \"$request_method\", ' # '\"host\": \"$host\",' # '\"upstream_addr\": \"$upstream_addr\",' # '\"http_x_forwarded_for\": \"$http_x_forwarded_for\",' # '\"http_referrer\": \"$http_referer\", ' # '\"http_user_agent\": \"$http_user_agent\", ' # '\"http_version\": \"$server_protocol\", ' # '\"nginx_access\": true }'; # access_log /dev/stdout nginxlog_json; # See Move default writable paths to a dedicated directory (#119) # https://github.com/openresty/docker-openresty/issues/119 client_body_temp_path /var/run/openresty/nginx-client-body; proxy_temp_path /var/run/openresty/nginx-proxy; fastcgi_temp_path /var/run/openresty/nginx-fastcgi; uwsgi_temp_path /var/run/openresty/nginx-uwsgi; scgi_temp_path /var/run/openresty/nginx-scgi; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; server{ listen 443 ssl; #对应的域名，把mykkto.cn改成你们自己的域名就可以了 server_name mykkto.cn; #证书的两个配置文件 ssl_certificate /usr/local/openresty/nginx/ssl/7526194_www.mykkto.cn.pem; ssl_certificate_key /usr/local/openresty/nginx/ssl/7526194_www.mykkto.cn.key; #以下都是一些加密规则 ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; #这是我的主页访问地址，因为使用的是静态的html网页，所以直接使用location就可以完成了。 location / { #文件夹（这个其实挂载的就是外部的www目录下的静态资源） root /usr/local/openresty/nginx/html; #主页文件 index index.html; } #lua脚本用于测试 location /lua { default_type 'text/html'; content_by_lua 'ngx.say(\"&lt;h1&gt; hello,openrestry&lt;/h1&gt;\")'; } } server { listen 80; #这边空格隔开，配置了两个，因为加了www也要配置 server_name mykkto.cn www.mykkto.cn; rewrite ^/(.*)$ https://mykkto.cn:443/$1 permanent; # location / { # limit_req zone=mylimit; #} } # Don't reveal OpenResty version to clients. # server_tokens off; } 3、测试lua脚本 六、限流1、配置http { limit_req_zone $binary_remote_addr zone=one:10m rate=5r/s; server { location /search/ { limit_req zone=one burst=5 nodelay; } } limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; 第一个参数：$binary_remote_addr 表示通过remote_addr这个标识来做限制，“binary_”的目的是缩写内存占用量，是限制同一客户端ip地址。 第二个参数：zone=one:10m表示生成一个大小为10M，名字为one的内存区域，用来存储访问的频次信息。 第三个参数：rate=5r/s表示允许相同标识的客户端的访问频次，这里限制的是每秒 5 次，还可以有比如30r/m的。 limit_req zone=one burst=5 nodelay; 第一个参数：zone=one 设置使用哪个配置区域来做限制，与上面limit_req_zone 里的name对应。 第二个参数：burst=5，重点说明一下这个配置，burst爆发的意思，这个配置的意思是设置一个大小为5的缓冲区当有大量请求（爆发）过来时，超过了访问频次限制的请求可以先放到这个缓冲区内。 第三个参数：nodelay，如果设置，超过访问频次而且缓冲区也满了的时候就会直接返回503，如果没有设置，则所有请求会等待排队。 2、网站配置源码#user nobody; #worker_processes 1; # Enables the use of JIT for regular expressions to speed-up their processing. pcre_jit on; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; server_tokens off; #引入lib包 lua_package_path \"/usr/local/openresty/lualib/?.lua;;\"; #开辟一块内存区域 lua_shared_dict ip_blacklist 4m; # Enables or disables the use of underscores in client request header fields. # When the use of underscores is disabled, request header fields whose names contain underscores are marked as invalid and become subject to the ignore_invalid_headers directive. # underscores_in_headers off; #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #access_log logs/access.log main; # Log in JSON Format # log_format nginxlog_json escape=json '{ \"timestamp\": \"$time_iso8601\", ' # '\"remote_addr\": \"$remote_addr\", ' # '\"body_bytes_sent\": $body_bytes_sent, ' # '\"request_time\": $request_time, ' # '\"response_status\": $status, ' # '\"request\": \"$request\", ' # '\"request_method\": \"$request_method\", ' # '\"host\": \"$host\",' # '\"upstream_addr\": \"$upstream_addr\",' # '\"http_x_forwarded_for\": \"$http_x_forwarded_for\",' # '\"http_referrer\": \"$http_referer\", ' # '\"http_user_agent\": \"$http_user_agent\", ' # '\"http_version\": \"$server_protocol\", ' # '\"nginx_access\": true }'; # access_log /dev/stdout nginxlog_json; # See Move default writable paths to a dedicated directory (#119) # https://github.com/openresty/docker-openresty/issues/119 client_body_temp_path /var/run/openresty/nginx-client-body; proxy_temp_path /var/run/openresty/nginx-proxy; fastcgi_temp_path /var/run/openresty/nginx-fastcgi; uwsgi_temp_path /var/run/openresty/nginx-uwsgi; scgi_temp_path /var/run/openresty/nginx-scgi; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; #限流设置 limit_req_zone $binary_remote_addr zone=one:30m rate=10r/s; server{ listen 443 ssl; #对应的域名，把mykkto.cn改成你们自己的域名就可以了 server_name mykkto.cn; #证书的两个配置文件 ssl_certificate /usr/local/openresty/nginx/ssl/7526194_www.mykkto.cn.pem; ssl_certificate_key /usr/local/openresty/nginx/ssl/7526194_www.mykkto.cn.key; #以下都是一些加密规则 ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; #这是我的主页访问地址，因为使用的是静态的html网页，所以直接使用location就可以完成了。 set $real_ip $remote_addr; if ( $http_x_forwarded_for ~ \"^(\\d+\\.\\d+\\.\\d+\\.\\d+)\" ) { set $real_ip $1; } # 管理信息，访问该URL可以查看nginx中的IP黑名单信息 location /get-ipblacklist-info { access_by_lua_file /usr/local/openresty/nginx/lua/get_ipblacklist_info.lua; } # 同步URL，通过定时任务调用该URL,实现IP黑名单从mysql到nginx的定时刷新 location /sync-ipblacklist { access_by_lua_file /usr/local/openresty/nginx/lua/sync_ipblacklist.lua; } location / { #限流 limit_req zone=one burst=10 nodelay; # 所有IP进来都要校验 access_by_lua_file /usr/local/openresty/nginx/lua/check_realip.lua; # proxy_read_timeout 60s; # proxy_set_header Host $http_host; # proxy_set_header X-Real_IP $remote_addr; # proxy_set_header X-Forwarded-for $remote_addr; # proxy_http_version 1.1; #文件夹（这个其实挂载的就是外部的www目录下的静态资源） root /usr/local/openresty/nginx/html; #主页文件 index index.html; } } server { listen 80; #这边空格隔开，配置了两个，因为加了www也要配置 server_name mykkto.cn www.mykkto.cn; rewrite ^/(.*)$ https://mykkto.cn:443/$1 permanent; # location / { # limit_req zone=mylimit; #} } # Don't reveal OpenResty version to clients. # server_tokens off; } 3、测试QPS：3000压测 5次 压测的IP为 A，通过，同网段的机器访问（手机模拟），503异常，结论被限流成功 切换网段B ，非压测IP 不限流，测试成功 七、DNS解析+Github Pages（无服务器化）前提：先买个DNS解析，博主目前域名和DNS解析都是买阿里云的 1、DNS解析域名这个是初版1.0，错误的，因为 主机记录解析 * 可能覆盖后面床图指向的 v1 配置 正确配置：最新版！！！ 2、Github Pages进入自己二级静态网站仓库，配置（如果有配SSL证书的打勾，没有不需要打勾 HTTPS） 关于证书：后面搭建床图也需要指向，不然无法加载图片（小坑） 八、Nginx搭建床图基于dns解析 + Github pages 映射适配 传统搭建方式（http）,会导致在 img 上渲染图片的时候无法显示（谷歌浏览器，IE浏览器会，360极速不会–具体不清楚）， 因为 pages 开启了 https 所以，自己搭建的床图也要是 https （我是这么想的，然后实现，确实可以了） 分析：一开始看到 console 控制台， 一堆图片报错 ，于是拿连接去请求，发现不可以访问（带http，无 s） 1、配置域名解析初版1.0，废弃，最好不要用 _ 为前缀，因为后面要是有配置SSL证书，就无法通过 最新2.0配置，完美解决了所有问题 2、配置SSL证书购买证书，这边作者用的是免费的 然后下载部署，具体配置信息 4 nginx.conf 3、搭建具体参考 一、四用了docker 4、补充1、nginx 配置user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { limit_req_zone $binary_remote_addr zone=mylimit:10m rate=2r/s; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; server{ listen 443 ssl; #对应的域名，把mykkto.cn改成你们自己的域名就可以了 server_name mykkto.cn; #证书的两个配置文件 ssl_certificate /etc/nginx/ssl/8799443_v1.mykkto.cn.pem; ssl_certificate_key /etc/nginx/ssl/8799443_v1.mykkto.cn.key; #以下都是一些加密规则 ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; #这是我的主页访问地址，因为使用的是静态的html网页，所以直接使用location就可以完成了。 location / { #文件夹（这个其实挂载的就是外部的www目录下的静态资源） root //usr/share/nginx/html; #主页文件 index index.html; } } server { listen 80; #这边空格隔开，配置了两个，因为加了www也要配置 server_name mykkto.cn; rewrite ^/(.*)$ https://mykkto.cn:443/$1 permanent; # location / { # limit_req zone=mylimit; #} } } 2、更新床图脚本 3、PICGO 配置 参考 ↓—— 【一到三】参考———– https://www.cnblogs.com/zltech/p/13517231.html https://www.cnblogs.com/thepoy/p/14848080.html https://www.cnblogs.com/jianqingwang/p/6726589.html —— 【一到三】参考———– SSL证书参考&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; https://www.cnblogs.com/zeussbook/p/11231820.html https://www.cnblogs.com/yuyeblog/p/13582127.html https://www.cnblogs.com/makalochen/p/14241052.html#%E5%A4%9A%E7%9B%AE%E5%BD%95%E6%8C%82%E8%BD%BD IP黑名单参考&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; https://www.jb51.net/article/168907.htm https://blog.csdn.net/weixin_33971205/article/details/89861486 https://www.csdn.net/tags/MtTaIgzsNDYzNDUtYmxvZwO0O0OO0O0O.html 限流&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; https://www.cnblogs.com/biglittleant/p/8979915.html DNS解析+Github Pages（无服务器） https://cloud.tencent.com/developer/article/2019284","categories":[{"name":"博客","slug":"博客","permalink":"https://mykkto.github.io/categories/%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"blog","slug":"blog","permalink":"https://mykkto.github.io/tags/blog/"},{"name":"部署","slug":"部署","permalink":"https://mykkto.github.io/tags/%E9%83%A8%E7%BD%B2/"},{"name":"小姿势","slug":"小姿势","permalink":"https://mykkto.github.io/tags/%E5%B0%8F%E5%A7%BF%E5%8A%BF/"}],"author":"mykk"},{"title":"SpringCloud-Alibaba-Sentinel 实现熔断与限流","slug":"03-java分布式/01-springcloud/15_SpringCloudAlibaba-Sentinel","date":"2022-03-13T07:17:13.000Z","updated":"2022-11-12T15:07:08.061Z","comments":true,"path":"posts/32724da3.html","link":"","permalink":"https://mykkto.github.io/posts/32724da3.html","excerpt":"","text":"一、概述1、官网https://github.com/alibaba/Sentinel https://github.com/alibaba/Sentinel/wiki/%E4%BB%8B%E7%BB%8D 2、是什么一句话解释，就是类似于 Hystrix 3、去哪下https://github.com/alibaba/Sentinel/releases 4、能干嘛 服务使用中的各种问题 服务雪崩 服务降级 服务熔断 服务限流 二、安装控制台1、sentinel组件由两部分构成 后台 前台8080 2、安装步骤1、拉取镜像docker pull bladex/sentinel-dashboard:1.7.0 2、启动并创建容器docker run --name sentinel -d -p 8858:8858 bladex/sentinel-dashboard:1.7.0 3、访问ip:8858 登录账号密码均为sentinel 三、初始化工程1、启动准备工作启动 sentinel （8858），nacos（8848） 2、model1、建modelcloudalibaba-sentinel-service8401 2、pom&lt;!--SpringCloud ailibaba nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--SpringCloud ailibaba sentinel-datasource-nacos 后续做持久化用到--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--SpringCloud ailibaba sentinel --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloudalibaba-sentinel-service8401&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--SpringCloud ailibaba nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--SpringCloud ailibaba sentinel-datasource-nacos 后续做持久化用到--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--SpringCloud ailibaba sentinel --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- SpringBoot整合Web组件+actuator --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--日常通用jar包配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.6.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: #Nacos服务注册中心地址 server-addr: 101.34.180.133:8848 sentinel: transport: #配置Sentinel dashboard地址 # dashboard: 101.34.180.133:8858 # dashboard: 106.52.23.202:8080 # 项目和 sentinel 不在同一台机器无法查看实时监控 dashboard: localhost:8080 #默认8719端口，假如被占用会自动从8719开始依次+1扫描,直至找到未被占用的端口 port: 8719 # 本地机器ip(docker容器必须加上) # client-ip: 169.254.135.77 management: endpoints: web: exposure: include: '*' 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @SpringBootApplication @EnableDiscoveryClient public class SpringCloudSentinelMain8401 { public static void main(String[] args) { SpringApplication.run (SpringCloudSentinelMain8401.class,args); } } 5、业务类package com.kk.springcloud.controller; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class FlowLimitController { @GetMapping(\"/testA\") public String testA() { return \"------testA\"; } @GetMapping(\"/testB\") public String testB() { return \"------testB\"; } } 3、操作 sentinel控制台1、刚进来空空如也，啥都没有 2、懒加载说明 Sentinel采用的懒加载说明 需要执行一次 http://localhost:8401/testA http://localhost:8401/testB 这边需要注意一点：如果你的实时监控没有数据，可能是因为 sentinel 和项目不再同一个 机器或者 sentinel访问不到 项目就监控不到了 四、流控制规则1、基本介绍 2、流控模式1、直接(默认)表示：1秒钟内查询1次就是OK，若超过次数1，就直接-快速失败，报默认错误 1、配置内容 2、测试效果访问：http://localhost:8401/testA 3、结论思考直接调用默认报错信息，技术方面OK， 但是否应该有我们自己的后续处理，类似有个fallback的兜底方法 2、关联1、是什么 当关联的资源达到阈值时，就限流自己 当与A关联的资源B达到阀值后，就限流A自己 B惹事，A挂了 2、配置A当关联资源 /testB 的 qps 阀值超过1时，就限流 /testA 的Rest访问地址，当关联资源到阈值后限制配置好的资源名 3、postman模拟并发密集访问testB创建一个集合并发测试文件夹 将测试的url放进文件夹 4、测试启动并发对 /testB run，再次过程中访问 /testB 发现出错 3、链路 多个请求调用了同一个微服务 2X（流控模式总结） 直接：对当前资源限流 关联：高优先级资源触发阈值，对低优先级资源限流。 链路：阈值统计时，只统计从指定资源进入当前资源的请求，是对请求来源的限流 3、流控效果1、快速失败达到峰值，直接失败，抛出异常（Blocked by Sentinel (flow limiting)） 源码（修改扩展位置）：com.alibaba.csp.sentinel.slots.block.flow.controller.DefaultController 2、WarmUp（预热）1、公式阈值除以coldFactor(默认值为3),经过预热时长后才会达到阈值 2、官网 默认coldFactor为3，即请求 QPS 从 threshold / 3 开始，经预热时长逐渐升至设定的 QPS 阈值。 限流，冷启动 https://github.com/alibaba/Sentinel/wiki/%E9%99%90%E6%B5%81---%E5%86%B7%E5%90%AF%E5%8A%A8 3、源码com.alibaba.csp.sentinel.slots.block.flow.controller.WarmUpController 4、WarmUp配置 默认 coldFactor 为 3，即请求QPS从(threshold / 3) 开始，经多少预热时长才逐渐升至设定的 QPS 阈值。 案例，阀值为10+预热时长设置5秒。系统初始化的阀值为10 / 3 约等于3,即阀值刚开始为3；然后过了5秒后阀值才慢慢升高恢复到10 5、点击测试多次点击http://localhost:8401/testB 刚开始不行，后续慢慢OK 6、应用场景如：秒杀系统在开启的瞬间，会有很多流量上来，很有可能把系统打死，预热方式就是把为了保护系统，可慢慢的把流量放进来，慢慢的把阀值增长到设置的阀值。 3、排队等待1、说明匀速排队，阈值必须设置为QPS 2、官网https://github.com/alibaba/Sentinel/wiki/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6 3、源码com.alibaba.csp.sentinel.slots.block.flow.controller.RateLimiterController 4、配置 匀速排队，让请求以均匀的速度通过，阀值类型必须设成QPS，否则无效。 设置含义： /testB 每秒1次请求，超过的话就排队等待，等待的超时时间为20000毫秒。 5、测试 五、降级规则1、官网https://github.com/alibaba/Sentinel/wiki/%E7%86%94%E6%96%AD%E9%99%8D%E7%BA%A7 2、基本介绍1、说明 Sentinel 熔断降级会在调用链路中某个资源出现不稳定状态时（例如调用超时或异常比例升高），对这个资源的调用进行限制，让请求快速失败，避免影响到其它的资源而导致级联错误。 当资源被降级后，在接下来的降级时间窗口之内，对该资源的调用都自动熔断（默认行为是抛出 DegradeException） 2、hystrix比较Sentinel的断路器是没有半开状态的 半开的状态系统自动去检测是否请求有异常，没有异常就关闭断路器恢复使用，有异常则继续打开断路器不可用。具体可以参考Hystrix 以下是hystrix断路器结构图 3、降级策略实战1、RT 1、代码@GetMapping(\"/testD\") public String testD() { //暂停几秒钟线程 try { TimeUnit.SECONDS.sleep (1); } catch (InterruptedException e) { e.printStackTrace ( ); } log.info (\"testD 测试RT\"); return \"------testD\"; } 2、配置 3、jmeter压测 4、结果 2、异常比例1、是什么 2、代码@GetMapping(\"/testD\") public String testD() { log.info (\"testD 测试异常比例\"); int age = 10 / 0; return \"------testD\"; } 3、配置 4、jmeter 5、结论 3、异常数1、是什么 2、需知异常数是按照分钟统计的 3、代码@GetMapping(\"/testE\") public String testE() { log.info (\"testE 测试异常比例\"); int age = 10 / 0; return \"------testE 测试异常比例\"; } 4、配置 5、jmeter 六、热点key限流1、基本介绍1、是什么何为热点 热点即经常访问的数据，很多时候我们希望统计或者限制某个热点数据中访问频次最高的TopN数据，并对其访问进行限流或者其它操作 2、官网https://github.com/alibaba/Sentinel/wiki/%E7%83%AD%E7%82%B9%E5%8F%82%E6%95%B0%E9%99%90%E6%B5%81 3、兜底方法sentinel系统默认的提示：Blocked by Sentinel (flow limiting) 可以指定，自定义兜底方法 从HystrixCommand 到@SentinelResource 2、案例1、代码@GetMapping(\"/testHotKey\") @SentinelResource(value = \"testHotKey\", blockHandler = \"dealHandler_testHotKey\") public String testHotKey(@RequestParam(value = \"p1\", required = false) String p1, @RequestParam(value = \"p2\", required = false) String p2) { return \"------testHotKey\"; } public String dealHandler_testHotKey(String p1, String p2, BlockException exception) { return \"-----dealHandler_testHotKey\"; } 2、配置说明 限流模式只支持QPS模式，固定写死了。（这才叫热点）@SentinelResource注解的方法参数索引，0代表第一个参数，1代表第二个参数，以此类推单机阀值以及统计窗口时长表示在此窗口时间超过阀值就限流。上面的抓图就是第一个参数有值的话，1秒的QPS为1，超过就限流，限流后调用 dealHandler_testHotKey支持方法。 3、配置 @SentinelResource(value = \"testHotKey\",blockHandler = \"dealHandler_testHotKey\") 方法testHotKey里面第一个参数只要QPS超过每秒1次，马上降级处理 4、测试http://localhost:8401/testHotKey?p1=abc http://localhost:8401/testHotKey?p1=abc&amp;p2=33 http://localhost:8401/testHotKey?p2=33 3、参数高级选项1、作用上述案例，第一个参数p1，当QPS超过1秒1次点击后马上被限流 若是我们有一个需求，p1特例为5 ，QPS 阈值为 200就可以通过 这个实现 2、配置 3、测试http://localhost:8401/testHotKey?p1=5 http://localhost:8401/testHotKey?p1=3 4、结论当p1等于5的时候，阈值变为 200 当p1不等于5的时候，阈值为平常的 1 热点参数的注意点，参数必须是基本类型或者String 七、@SentinelResource1、按资源名称限流+后续处理1、代码1、代码 package com.kk.springcloud.controller; import com.alibaba.csp.sentinel.annotation.SentinelResource; import com.alibaba.csp.sentinel.slots.block.BlockException; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class RateLimitController { @GetMapping(\"/byResource\") @SentinelResource(value = \"byResource\",blockHandler = \"handleException\") public CommonResult byResource() { return new CommonResult (200,\"按资源名称限流测试OK\",new Payment (2020L,\"serial001\")); } public CommonResult handleException(BlockException exception) { return new CommonResult(444,exception.getClass().getCanonicalName()+\"\\t 服务不可用\"); } } 2、pom &lt;dependency&gt; &lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; 2、配置流控规则1、步骤 2、图形配置和代码关系 3、配置说明表示1秒钟内查询次数大于1，就跑到我们自定义的处流，限流 3、测试1秒钟点击1下，OK 超过上述，疯狂点击，返回了自己定义的限流处理信息，限流发生 2、按照Url地址限流+后续处理1、作用通过访问的URL来限流，会返回Sentinel自带默认的限流处理信息 2、代码@GetMapping(\"/rateLimit/byUrl\") @SentinelResource(value = \"byUrl\") public CommonResult byUrl() { return new CommonResult (200, \"按url限流测试OK\", new Payment (2020L, \"serial002\")); } 3、访问（1次）为了刷新实时配置，线上就没必要这个操作了 http://localhost:8401//rateLimit/byUrl 4、配置 5、访问（狂点） 3、兜底方案面临的问题1 系统默认的，没有体现我们自己的业务要求。 2 依照现有条件，我们自定义的处理方法又和业务代码耦合在一块，不直观。 3 每个业务方法都添加一个兜底的，那代码膨胀加剧。 4 全局统一的处理方法没有体现 4、用户自定义限流处理逻辑1、自定义限流处理类创建CustomerBlockHandler类用于自定义限流处理逻辑 package com.kk.springcloud.handler; import com.alibaba.csp.sentinel.slots.block.BlockException; import com.kk.springcloud.entities.CommonResult; public class CustomerBlockHandler { public static CommonResult handleException(BlockException exception) { return new CommonResult (2020, \"自定义的限流处理信息......CustomerBlockHandler\"); } } 2、使用/** * 自定义通用的限流处理逻辑， blockHandlerClass = CustomerBlockHandler.class blockHandler = handleException 上述配置：找CustomerBlockHandler类里的handleException2方法进行兜底处理 */ /** * 自定义通用的限流处理逻辑 */ @GetMapping(\"/rateLimit/customerBlockHandler\") @SentinelResource(value = \"customerBlockHandler\", blockHandlerClass = CustomerBlockHandler.class, blockHandler = \"handleException\") public CommonResult customerBlockHandler() { return new CommonResult (200, \"按客户自定义限流处理逻辑\"); } 3、配置 4、配置说明 5、测试 5、更多注解属性说明 八、服务熔断功能1、整合sentinel整合ribbon+openFeign+fallback 2、Ribbon1、生产者1、建modelcloudalibaba-provider-payment9003 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloudalibaba-provider-payment9003&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--SpringCloud ailibaba nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- SpringBoot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--日常通用jar包配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 9003 spring: application: name: nacos-payment-provider cloud: nacos: discovery: server-addr: localhost:8848 #配置Nacos地址 management: endpoints: web: exposure: include: '*' 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @EnableDiscoveryClient @SpringBootApplication public class PaymentMain9003 { public static void main(String[] args) { SpringApplication.run (PaymentMain9003.class,args); } } 5、业务类package com.kk.springcloud.controller; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import java.util.HashMap; @RestController public class PaymentController { @Value(\"${server.port}\") private String serverPort; public static HashMap&lt;Long, Payment&gt; hashMap = new HashMap&lt;&gt; ( ); static { hashMap.put (1L, new Payment (1L, \"28a8c1e3bc2742d8848569891fb42181\")); hashMap.put (2L, new Payment (2L, \"bba8c1e3bc2742d8848569891ac32182\")); hashMap.put (3L, new Payment (3L, \"6ua8c1e3bc2742d8848569891xt92183\")); } @GetMapping(value = \"/paymentSQL/{id}\") public CommonResult&lt;Payment&gt; paymentSQL(@PathVariable(\"id\") Long id) { Payment payment = hashMap.get (id); CommonResult&lt;Payment&gt; result = new CommonResult (200, \"from mysql,serverPort: \" + serverPort, payment); return result; } } 6、启动同一个服务，启动9003，9004 -Dserver.port=9004 7、测试http://localhost:9003/paymentSQL/1 http://localhost:9004/paymentSQL/1 2、消费者1、model新建cloudalibaba-consumer-nacos-order84 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloudalibaba-consumer-nacos-order84&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--SpringCloud ailibaba nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--SpringCloud ailibaba sentinel --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- SpringBoot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--日常通用jar包配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 84 spring: application: name: nacos-order-consumer cloud: nacos: discovery: server-addr: localhost:8848 sentinel: transport: #配置Sentinel dashboard地址 dashboard: localhost:8080 #默认8719端口，假如被占用会自动从8719开始依次+1扫描,直至找到未被占用的端口 port: 8719 #消费者将要去访问的微服务名称(注册成功进nacos的微服务提供者) service-url: nacos-user-service: http://nacos-payment-provider 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @EnableDiscoveryClient @SpringBootApplication public class OrderNacosMain84 { public static void main(String[] args) { SpringApplication.run (OrderNacosMain84.class,args); } } 5、配置类1、rabbion 负载配置 package com.kk.springcloud.config; import org.springframework.cloud.client.loadbalancer.LoadBalanced; import org.springframework.context.annotation.Bean; import org.springframework.stereotype.Component; import org.springframework.web.client.RestTemplate; @Component public class ApplicationContextConfig { @Bean @LoadBalanced public RestTemplate getRestTemplate() { return new RestTemplate ( ); } } 6、业务类1、只配置fallback（本例sentinel无配置） 2、只配置blockHandler package com.kk.springcloud.controller; import com.alibaba.csp.sentinel.annotation.SentinelResource; import com.alibaba.csp.sentinel.slots.block.BlockException; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import lombok.extern.slf4j.Slf4j; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import javax.annotation.Resource; @RestController @Slf4j public class CircleBreakerController { public static final String SERVICE_URL = \"http://nacos-payment-provider\"; @Resource private RestTemplate restTemplate; @RequestMapping(\"/consumer/fallback/{id}\") @SentinelResource(value = \"fallback\", blockHandler = \"blockHandler\") //blockHandler负责在sentinel里面配置的降级限流 public CommonResult&lt;Payment&gt; fallback(@PathVariable Long id) { CommonResult&lt;Payment&gt; result = restTemplate.getForObject (SERVICE_URL + \"/paymentSQL/\" + id, CommonResult.class, id); if (id == 4) { throw new IllegalArgumentException (\"非法参数异常....\"); } else if (result.getData ( ) == null) { throw new NullPointerException (\"NullPointerException,该ID没有对应记录\"); } return result; } // 兜底 public CommonResult handlerFallback(@PathVariable Long id, Throwable e) { Payment payment = new Payment (id, \"null\"); return new CommonResult&lt;&gt; (444, \"兜底异常handlerFallback,exception内容 \" + e.getMessage ( ), payment); } // 降级 public CommonResult blockHandler(@PathVariable Long id, BlockException blockException) { Payment payment = new Payment (id, \"null\"); return new CommonResult&lt;&gt; (445, \"blockHandler-sentinel限流,无此流水: blockException \" + blockException.getMessage ( ), payment); } } 3、fallback和blockHandler都配置 package com.kk.springcloud.controller; import com.alibaba.csp.sentinel.annotation.SentinelResource; import com.alibaba.csp.sentinel.slots.block.BlockException; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import lombok.extern.slf4j.Slf4j; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import javax.annotation.Resource; @RestController @Slf4j public class CircleBreakerController { public static final String SERVICE_URL = \"http://nacos-payment-provider\"; @Resource private RestTemplate restTemplate; @RequestMapping(\"/consumer/fallback/{id}\") @SentinelResource(value = \"fallback\", fallback = \"handlerFallback\", blockHandler = \"blockHandler\") public CommonResult&lt;Payment&gt; fallback(@PathVariable Long id) { CommonResult&lt;Payment&gt; result = restTemplate.getForObject (SERVICE_URL + \"/paymentSQL/\" + id, CommonResult.class, id); if (id == 4) { throw new IllegalArgumentException (\"非法参数异常....\"); } else if (result.getData ( ) == null) { throw new NullPointerException (\"NullPointerException,该ID没有对应记录\"); } return result; } // 兜底 public CommonResult handlerFallback(@PathVariable Long id, Throwable e) { Payment payment = new Payment (id, \"null\"); return new CommonResult&lt;&gt; (444, \"fallback,无此流水,exception \" + e.getMessage ( ), payment); } // 降级 public CommonResult blockHandler(@PathVariable Long id, BlockException blockException) { Payment payment = new Payment (id, \"null\"); return new CommonResult&lt;&gt; (445, \"blockHandler-sentinel限流,无此流水: blockException \" + blockException.getMessage ( ), payment); } } 降级优先于限流：若 blockHandler 和 fallback 都进行了配置，则被限流降级而抛出 BlockException 时只会进入 blockHandler 处理逻辑。 4、属性忽略 直接抛到前台对用户体验不好，细节注意 3、Feign1、model修改84模块 2、pom&lt;!--SpringCloud openfeign --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; 3、yml# 激活Sentinel对Feign的支持 feign: sentinel: enabled: true 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; import org.springframework.cloud.openfeign.EnableFeignClients; @EnableDiscoveryClient @SpringBootApplication @EnableFeignClients public class OrderNacosMain84 { public static void main(String[] args) { SpringApplication.run (OrderNacosMain84.class,args); } } 5、业务类1、远程调服务接口package com.kk.springcloud.serivice; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; /** * @auther mykk * @create 2022年3月24日 21:45:49 * 使用 fallback 方式是无法获取异常信息的， * 如果想要获取异常信息，可以使用 fallbackFactory参数 */ @FeignClient(value = \"nacos-payment-provider\", fallback = PaymentFallbackService.class)//调用中关闭9003服务提供者 public interface PaymentService { @GetMapping(value = \"/paymentSQL/{id}\") CommonResult&lt;Payment&gt; paymentSQL(@PathVariable(\"id\") Long id); } 2、兜底实现package com.kk.springcloud.serivice; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import org.springframework.stereotype.Component; @Component public class PaymentFallbackService implements PaymentService { @Override public CommonResult&lt;Payment&gt; paymentSQL(Long id) { return new CommonResult&lt;&gt; (444, \"服务降级返回,没有该流水信息\", new Payment (id, \"errorSerial......\")); } } 3、Controller//==================OpenFeign @Resource private PaymentService paymentService; @GetMapping(value = \"/consumer/openfeign/{id}\") public CommonResult&lt;Payment&gt; paymentSQL(@PathVariable(\"id\") Long id) { if (id == 4) { throw new RuntimeException (\"没有该id\"); } return paymentService.paymentSQL (id); } 6、测试测试84调用9003，此时故意关闭9003/9004微服务提供者，看84消费侧自动降级，不会被耗死 4、熔断框架比较 九、持久化规则1、是什么一旦我们重启应用，sentinel规则将消失，生产环境需要将配置规则进行持久化 2、怎么玩将限流配置规则持久化进Nacos保存，只要刷新8401某个rest地址，sentinel控制台的流控规则就能看到，只要Nacos里面的配置不删除，针对8401上sentinel上的流控规则持续有效 3、实战1、model修改cloudalibaba-sentinel-service8401 2、pom &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloudalibaba-sentinel-service8401&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--SpringCloud ailibaba sentinel-datasource-nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--SpringCloud ailibaba nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--SpringCloud ailibaba sentinel-datasource-nacos 后续做持久化用到--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--SpringCloud ailibaba sentinel --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- SpringBoot整合Web组件+actuator --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--日常通用jar包配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;4.6.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、yml server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: #Nacos服务注册中心地址 server-addr: 101.34.180.133:8848 sentinel: transport: #配置Sentinel dashboard地址 # dashboard: 101.34.180.133:8858 # dashboard: 106.52.23.202:8080 # 项目和 sentinel 不在同一台机器无法查看实时监控 dashboard: localhost:8080 #默认8719端口，假如被占用会自动从8719开始依次+1扫描,直至找到未被占用的端口 port: 8719 datasource: ds1: nacos: server-addr: 101.34.180.133:8848 dataId: cloudalibaba-sentinel-service groupId: DEFAULT_GROUP data-type: json rule-type: flow # 本地机器ip(docker容器必须加上) # client-ip: 169.254.135.77 feign: sentinel: enabled: true # 激活Sentinel对Feign的支持 management: endpoints: web: exposure: include: '*' 4、添加Nacos业务规则配置[ { \"resource\": \"/rateLimit/byUrl\", \"limitApp\": \"default\", \"grade\": 1, \"count\": 1, \"strategy\": 0, \"controlBehavior\": 0, \"clusterMode\": false } ] 5、启动启动8401后刷新sentinel发现业务规则有了 6、测试（访问）快速访问测试接口 http://localhost:8401/rateLimit/byUrl 十二、参考文档 ↓https://www.cnblogs.com/linjiqin/p/15369091.html https://www.jianshu.com/p/373eb512ec48 https://m.imooc.com/article/details?article_id=289384 https://www.cnblogs.com/yunqing/p/11406225.html","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud-alibaba","slug":"springcloud-alibaba","permalink":"https://mykkto.github.io/tags/springcloud-alibaba/"},{"name":"熔断器","slug":"熔断器","permalink":"https://mykkto.github.io/tags/%E7%86%94%E6%96%AD%E5%99%A8/"},{"name":"sentinel","slug":"sentinel","permalink":"https://mykkto.github.io/tags/sentinel/"},{"name":"限流","slug":"限流","permalink":"https://mykkto.github.io/tags/%E9%99%90%E6%B5%81/"}],"author":"mykk"},{"title":"Nacos 高可用集群（docker-compose）","slug":"03-java分布式/02-容器/01_docker(nacos)","date":"2022-03-12T03:17:13.000Z","updated":"2022-11-12T15:07:08.072Z","comments":true,"path":"posts/d9c3bea0.html","link":"","permalink":"https://mykkto.github.io/posts/d9c3bea0.html","excerpt":"","text":"一、架构1、前言本来这部分是要在 Spring-nacos 手册中 ，但是后面搭建遇到很多坑找了很多资料，就单独整理后写出这篇。 2、架构图 一个ngxin 负载 三个 nacos节点，mysql 主从两个节点 二、搭建 mysql 主从1、拉取和创建# 1、拉取 [root@VM_0_17_centos ~]docker pull mysql:5.7.13 # 2、启动 [root@VM_0_17_centos ~]docker run --name master -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root -d mysql:5.7.13 # 参数说明 --name 为容器指定名称，这里是master -p 将容器的指定端口映射到主机的指定端口，这里是将容器的3306端口映射到主机的3306端口 -e 设置环境变量，这里是指定root账号的密码为root -d 后台运行容器，并返回容器ID mysql:5.7.13 指定运行的mysql版 # 3、查看是否启动,以有容器 [root@VM_0_17_centos ~]# docker ps -a 2、开放端口firewall-cmd --zone=public --add-port=3306/tcp --permanent firewall-cmd --reload # 说明 --permanent 永久开启，避免下次开机需要再次手动开启端口 3、创建[主容器]的复制账号使用Navicat友好的图像化界面执行SQL GRANT REPLICATION SLAVE ON *.* to 'backup'@'%' identified by 'backup'; show grants for 'backup'@'%'; 4、修改MySQL[主容器]配置环境1、创建配置文件目录，目录结构如下：/usr/local/mysql/master/usr/local/mysql/slave1/usr/local/mysql/slave2 [root@VM_0_17_centos ~]# mkdir -p /usr/local/mysql/master /usr/local/mysql/slave1 /usr/local/mysql/slave2 2、拷贝一份MySQL配置文件[root@VM_0_17_centos local]# docker cp master:/etc/mysql/my.cnf /usr/local/mysql/master/my.cnf 3、进到master目录下，已存在拷贝的my.cnf[root@VM_0_17_centos master]# ll total 4 -rw-r--r-- 1 root root 1801 May 10 10:27 my.cnf 4、修改my.cnf，在 [mysqld] 节点最后加上后保存log-bin=mysql-bin server-id=1 log-bin=mysql-bin 使用binary logging，mysql-bin是log文件名的前缀 server-id=1 唯一服务器ID，非0整数，不能和其他服务器的server-id重复 5、将修改后的文件覆盖Docker中MySQL中的配置文件docker cp /usr/local/mysql/master/my.cnf master:/etc/mysql/my.cnf 6、重启 mysql 的docker , 让配置生效[root@VM_0_17_centos master]# docker restart master 5、运行MySQL [从]容器1、首先运行从容器[root@VM_0_17_centos ~]# docker run --name slave1 -p 3307:3306 -e MYSQL_ROOT_PASSWORD=root -d mysql:5.7.13 2、与主容器相似，拷贝配置文件至slave1目录修改后覆盖回Docker中log-bin=mysql-bin server-id=2 3、别忘记，重启slave1容器，使配置生效[root@VM_0_17_centos master]# docker slave1 master 6、配置主从复制1、使用Navicat连接 [slave1]后新建查询，执行以下SQLCHANGE MASTER TO MASTER_HOST='连接Navicat的ip', MASTER_PORT=3306, MASTER_USER='backup', MASTER_PASSWORD='backup'; START SLAVE; MASTER_HOST 填Navicat连接配置中的ip应该就可以 MASTER_PORT 主容器的端口 MASTER_USER 同步账号的用户名 MASTER_PASSWORD 同步账号的密码 2、检查是否配置成功show slave status; 7、检查主从 三、搭建 nacos 集群1、前言docker-compose配置的源码，已经上传到 github,可直接clone ： https://github.com/mykkTo/nacos-cluster-docker.git 2、配置文件说明1、Nacos共用的init.d/custom.properties，与官方保持一致，按需使用 2、docker-compose-nacos1.yml 以 1为例， 带个都大同小异 3、启动 nacos 集群1、将源代码配置修改后，分别上传到三台主机 101.34.180.133 对应 nacos-1 106.52.23.202 对应 nacos-2 119.45.122.161 对应 nacos-3 2、启动容器分别在各主机上进入各自对应的nacos目录中，启动容器，命令如下： 133服务器： $ cd nacos-cluster-docker/nacos-1 $ docker-compose -f docker-compose-nacos1.yml up -d 202服务器： $ cd nacos-cluster-docker/nacos-2 $ docker-compose -f docker-compose-nacos2.yml up -d 161服务器： $ cd nacos-cluster-docker/nacos-3 $ docker-compose -f docker-compose-nacos3.yml up -d 3、查看日志查看日志分别在对应的nacos-*目录下，执行 tail -f cluster-logs/nacos*/nacos.log 4、停止容器$ docker-compose -f docker-compose-nacos1.yml stop 5、访问Nacos UI界面 这里我们看到Nacos集群各节点已经正常了，LEADER与FOLLOWER已经选出，一切正常了 四、nginx 负载1、创建并启动1、拉取docker pull nginx 2、启动docker run --name nginx-test -p 80:80 -d nginx – name 容器命名 -v 映射目录 -d 设置容器后台运行 -p 本机端口映射 将容器的80端口映射到本机的80端口 2、映射到本地1、创建首先在本机创建nginx的一些文件存储目录 mkdir -p /root/nginx/www /root/nginx/logs /root/nginx/conf www: nginx存储网站网页的目录 logs: nginx日志目录 conf: nginx配置文件目录 2、映射（1）先查看容器 docker ps -a （2）映射 docker cp 481e121fb29f:/etc/nginx/nginx.conf /root/nginx/conf 3、启动容器需要说明下，ngxin-test 容器是为了获得容器的配置文件，最终使用的是 nginx-web 目前已经启动 nginx-test 80端口，若是 nginx-web指定的也是 80，就需要关闭 nginx-test了 docker stop nginx-test 1、新容器映射创建新nginx容器nginx-web,并将www,logs,conf目录映射到本地 docker run -d -p 80:80 --name nginx-web -v /root/nginx/www:/usr/share/nginx/html -v /root/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v /root/nginx/logs:/var/log/nginx nginx 2、启动docker start nginx-web 4、配置负载均衡1、进入 配置在 root 底下 2、配置源码user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { #gzip on; upstream nacos-cluster { server 101.34.180.133:8848; server 106.52.23.202:8848; server 119.45.122.161:8848; } server { listen 80; location /{ proxy_pass http://nacos-cluster; } } } 主要的是这块 说明下： 新手可能不太会nginx，listen 为 80 是因为你容器启动时候是 80，当访问 80的时候转到 以上三个 ip 负载轮训，还可以设置权重可以去看文档 3、重启docker restart nginx-web 五、Spring-boot连接1、yml配置 2、查看客户端 六、问题汇总1、关于 503异常信息：java.lang.IllegalStateException: failed to req API:/nacos/v1/ns/instance after all servers([101.34.180.133:8848]) tried: failed to req API:101.34.180.133:8848/nacos/v1/ns/instance. code:503 msg: server is DOWN now, please try again later! 个人见解：这个问题博主认为是集群节点少于3个出现的，因为服务器过期了一台剩下了 两台，所以报这个错误，三台没有这个问题。 七、参考文档 ↓https://www.cnblogs.com/hellxz/p/nacos-cluster-docker.html https://docs.docker.com/compose/install/ https://www.cnblogs.com/bigband/p/13515219.html https://my.oschina.net/u/3773384/blog/1810111 https://www.jianshu.com/p/658911a8cff3 https://www.yht7.com/news/92162 https://blog.csdn.net/weixin_40461281/article/details/92586378 https://www.cnblogs.com/ilinuxer/p/6916969.html https://blog.csdn.net/weixin_40461281/article/details/92586378","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud-alibaba","slug":"springcloud-alibaba","permalink":"https://mykkto.github.io/tags/springcloud-alibaba/"},{"name":"nacos","slug":"nacos","permalink":"https://mykkto.github.io/tags/nacos/"},{"name":"集群","slug":"集群","permalink":"https://mykkto.github.io/tags/%E9%9B%86%E7%BE%A4/"},{"name":"docker-compose","slug":"docker-compose","permalink":"https://mykkto.github.io/tags/docker-compose/"}],"author":"mykk"},{"title":"高阶面试题：JUC-AQS","slug":"05-面试题/01-多线程/01_Interview-JUC-AQS","date":"2022-03-09T13:32:10.000Z","updated":"2022-11-12T15:07:08.031Z","comments":true,"path":"posts/3fb37166.html","link":"","permalink":"https://mykkto.github.io/posts/3fb37166.html","excerpt":"","text":"一、是什么1、字面意思抽象的队列同步器 结构关系图： 2、技术解释 用来构建锁或者其它同步器组件的重量级基础框架及整个JUC体系的基石。 通过内置的FIFO1队列来完成资源获取线程的排队工作，并通过一个int类变量表示持有锁的状态 CLH：Craig、Landin and Hagersten 队列，是一个单向链表，AQS中的队列是CLH变体的虚拟双向队列FIFO 二、AQS=JUC（基石）AQS为什么是JUC内容中最重要的基石 1、AQS有关的锁 ReentrantLock CountDownLatch ReentrantReadWriteLock Semaphore ……………等等 2、进一步理解锁和同步器的关系 锁，面向锁的使用者： 定义了程序员和锁交互的使用层API，隐藏了实现细节，你调用即可。 同步器，面向锁的实现者 比如Java并发大神DougLee，提出统一规范并简化了锁的实现，屏蔽了同步状态管理、阻塞线程排队和通知、唤醒机制等。 三、能干嘛1、加锁会导致阻塞有阻塞就需要排队，实现排队必然需要队列 2、说明解释抢到资源的线程直接使用处理业务，抢不到资源的必然涉及一种排队等候机制。抢占资源失败的线程继续去等待(类似银行业务办理窗口都满了，暂时没有受理窗口的顾客只能去候客区排队等候)，但等候线程仍然保留获取锁的可能且获取锁流程仍在继续(候客区的顾客也在等着叫号，轮到了再去受理窗口办理业务)。 既然说到了排队等候机制，那么就一定会有某种队列形成，这样的队列是什么数据结构呢？ 如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中，这个队列就是AQS的抽象表现。它将请求共享资源的线程封装成队列的结点（Node），通过CAS、自旋以及LockSupport.park()的方式，维护state变量的状态，使并发达到同步的效果。 LockSupport.park()：阻塞当前线程的执行，且都不会释放当前线程占有的锁资源； 四、AQS 解读1、AQS概述1、官网解释 2、阻塞-&gt;队列有阻塞就需要排队，实现排队必然需要队列 AQS使用一个volatile的int类型的成员变量来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作将每条要去抢占资源的线程封装成一个Node节点来实现锁的分配，通过CAS完成对State值的修改。 2、AQS内部体系架构 1、AQS自身1、AQS的int变量 ★1、AQS的同步状态State成员变量 2、银行办理业务的受理窗口状态（通俗理解） 零就是没人（自由状态），可以办理 大于等于1，有人占用窗口，等着去 2、AQS的CLH队列1、CLH队列(三个大牛的名字组成)，为一个双向队列 2、银行候客区的等待顾客（通俗理解） 3、小总结 有阻塞就需要排队，实现排队必然需要队列 state变量+CLH双端队列 2、内部类Node内部类Node(Node类在AQS类内部) 1、Node的int变量 ★1、Node的等待状态waitState成员变量 2、说明 等候区其它顾客(其它线程)的等待状态 队列中每个排队的个体就是一个 Node 2、Node此类详解1、内部结构 2、属性说明 3、AQS同步队列的基本结构 CLH：Craig、Landin and Hagersten 队列，是个单向链表，AQS中的队列是CLH变体的虚拟双向队列（FIFO） FIFO：队列中用到了哨兵节点（傀儡节点）既，头节点（好处就是不用去判空，因为有头节点） 五、从ReentrantLock开始解读AQS1、说明Lock接口的实现类，基本都是通过【聚合】了一个【队列同步器】的子类完成线程访问控制的 1、可以看出内部子类 Sync，继承了 AQS 2、看下类 UML图，Sync 底下又有两个子类（分别为公平和非公平） 2、公平锁和非公平锁1、先从创建入手 2、追溯1、默认构造方法，默认不传参构造 2、带参传入，此时判断是非公平还是公平 3、很明显这是两个类，分别继承与Sync，上面有提到 3、看源码1、看差异1、可以明显看出公平锁与非公平锁的lock()方法唯一的区别就在于公平锁在获取同步状态时多了一个限制条件 hasQueuedPredecessors() hasQueuedPredecessors是公平锁加锁时判断等待队列中是否存在有效节点的方法 2、对比公平锁：公平锁讲究先来先到，线程在获取锁时，如果这个锁的等待队列中已经有线程在等待，那么当前线程就会进入等待队列中； 非公平锁：不管是否有等待队列，如果可以获取锁，则立刻占有锁对象。也就是说队列的第一个排队线程在unpark()，之后还是需要竞争锁（存在线程竞争的情况下） 3、必调 lock()在创建完公平/非公平锁，调用lock方法进行加锁，最终都会调用 acquire 方法 3、源码Api解读1、lock() 2、acquire() 三个走向 1、tryAcquire() -&gt; tryAcquire () 由于子类 FairSync 实现 2、调用 addWaiter() -&gt; enq() 入队操作 3、acquireQueued() -&gt; cancelAcquire() 参考文档https://www.cnblogs.com/tong-yuan/p/11768904.html https://baijiahao.baidu.com/s?id=1718317852417206951&amp;wfr=spider&amp;for=pc https://blog.csdn.net/hengyunabc/article/details/28126139 哨兵节点解读：https://www.cnblogs.com/litexy/p/9749544.html","categories":[{"name":"面试题","slug":"面试题","permalink":"https://mykkto.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"}],"tags":[{"name":"AQS","slug":"AQS","permalink":"https://mykkto.github.io/tags/AQS/"},{"name":"多线程","slug":"多线程","permalink":"https://mykkto.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"JUC","slug":"JUC","permalink":"https://mykkto.github.io/tags/JUC/"}],"author":"mykk"},{"title":"Oracle11g(docker版)","slug":"04-基础/04oracle/01_oracle11g-docker","date":"2022-02-28T04:49:31.000Z","updated":"2022-11-12T15:07:08.042Z","comments":true,"path":"posts/42dbeac3.html","link":"","permalink":"https://mykkto.github.io/posts/42dbeac3.html","excerpt":"","text":"一、Docker安装和配置1、镜像拉取（第三方）docker pull registry.cn-hangzhou.aliyuncs.com/helowin/oracle_11g 2、下载完后，查看docker images 3、创建容器docker run -d -p 1521:1521 --name oracle11g registry.cn-hangzhou.aliyuncs.com/helowin/oracle_11g 4、启动容器，操作1、启动docker start oracle11g 2、进入容器docker exec -it oracle11g bash 3、切换root用户su root 密码：helowin 注意：现在还不能退出，继续操作 5、编辑profile文件配置ORACLE环境变量在docker中查找并编辑profile文件 vi /etc/profile export ORACLE_HOME=/home/oracle/app/oracle/product/11.2.0/dbhome_2 export ORACLE_SID=helowin export PATH=$ORACLE_HOME/bin:$PATH 在最后上加： 保存并退出 ：wq 6、oracle的配置1. 创建软连接ln -s $ORACLE_HOME/bin/sqlplus /usr/bin 2.切换到oracle 用户这里还要说一下，一定要写中间的 - 必须要，否则软连接无效 su - oracle 7、oracle数据库的操作1. 登录sqlplus并修改sys、system用户密码sqlplus /nolog conn /as sysdba 2. 修改和创建用户alter user system identified by system; alter user sys identified by sys; 也可以创建用户 create user test identified by test; 并给用户赋予权限 grant connect,resource,dba to test; 3. scott用户的开启--解锁scott用户（安装时若使用默认情况没有解锁和设置密码进行下列操作，要超级管理员操作） alter user scott account unlock; --解锁scott用户的密码【此句也可以用来重置密码】 alter user scott identified by tiger; 二、客户端连接1、navicat连接打开navicat后（navicat12不用配置oci.dll文件了） 2、pl/sql 连接101.xx.xxx.133:1521/helowinXDB密码：tiger 三、其他功能1、scott赋予最高权限分两条运行 CONN / AS SYSDBA; GRANT DBA TO SCOTT; 参考https://www.cnblogs.com/laoluoits/p/13942119.html https://www.cnblogs.com/flyingsand/p/9463460.html","categories":[{"name":"数据库","slug":"数据库","permalink":"https://mykkto.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"oracle","slug":"oracle","permalink":"https://mykkto.github.io/tags/oracle/"},{"name":"docker","slug":"docker","permalink":"https://mykkto.github.io/tags/docker/"},{"name":"安装","slug":"安装","permalink":"https://mykkto.github.io/tags/%E5%AE%89%E8%A3%85/"}],"author":"mykk"},{"title":"SpringCloud-Alibaba-Nacos 服务注册+配置中心","slug":"03-java分布式/01-springcloud/14_SpringCloudAlibaba-Nacos","date":"2022-02-23T13:12:31.000Z","updated":"2023-02-15T13:42:01.977Z","comments":true,"path":"posts/af0a257d.html","link":"","permalink":"https://mykkto.github.io/posts/af0a257d.html","excerpt":"","text":"友情链接-早期Nacos文章一、Nacos简介1、是什么项目文档：https://github.com/alibaba/Nacos 使用文档：https://nacos.io/zh-cn/index.html 一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 Nacos = Eureka+Config +Bus 2、能干嘛 替代Eureka做服务注册中心 替代Config做服务配置中心 3、注册中心比较 二、安装（docker）1、pull镜像推荐稳定版版本(官方推荐1.3.1),如果不指定版本的话则就是latest版本(对应nacos的1.4版本) docker pull nacos/nacos-server:1.3.1 2、运行并创建容器docker run --name nacosName -e MODE=standalone -d -v /mnt/logs/nacos:/home/logs/nacos -p 8848:8848 nacos/nacos-server:1.1.4 -d 后台运行 -p 外部访问端口:内部被映射端口 Docker相对于虚拟机 外部访问端口就是 外网访问的端口 内部被映射端口就是 该镜像在docker里面的端口 –name 容器的名称 镜像名称：版本号 nacos/nacos-server:1.3.1 （运行该镜像） -e 环境变量设置 -e MODE=standalone -v 映射到centos上的某个目录:配置某个容器的目录 -v /mnt/logs/nacos:/home/logs/nacos 3、查看启动日志 #查看已经启动的容器 获取容器ID docker ps #查看指定容器的输出日志 docker logs --since 10m nacos的容器id #查看指定容器的输出日志 4、访问http://lhttp://localhost:8848/nacos 登录账号 登录密码 nacos nacos 三、Nacos（注册中心）1、基于Nacos生产者1、建modelcloudalibaba-provider-payment9001 2、pom1、父pom &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; 2、本模块pom &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloudalibaba-provider-payment9001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--SpringCloud ailibaba nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- SpringBoot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--日常通用jar包配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 9001 spring: application: name: nacos-payment-provider cloud: nacos: discovery: server-addr: 101.34.180.133:8848 #配置Nacos地址 management: endpoints: web: exposure: include: '*' 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @EnableDiscoveryClient @SpringBootApplication public class PaymentMain9001 { public static void main(String[] args) { SpringApplication.run (PaymentMain9001.class, args); } } 5、业务类package com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; @RestController public class PaymentController { @Value(\"${server.port}\") private String serverPort; @GetMapping(value = \"/payment/nacos/{id}\") public String getPayment(@PathVariable(\"id\") Integer id) { return \"nacos registry, serverPort: \" + serverPort + \"\\t id\" + id; } } 6、测试1、访问：http://localhost:9001/payment/nacos/1 2、nacos客户端 7、映射出一模一样的9002，测试负载1、复制配置 2、编写配置 -DServer.port=9002 3、查看是否成功启动 2、基于Nacos消费者1、建modelcloudalibaba-consumer-nacos-order83 2、pom为什么nacos支持负载均衡 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloudalibaba-consumer-nacos-order83&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--SpringCloud ailibaba nacos --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- SpringBoot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--日常通用jar包配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 83 spring: application: name: nacos-order-consumer cloud: nacos: discovery: server-addr: 101.34.180.133:8848 #配置Nacos地址 #消费者将要去访问的微服务名称(注册成功进nacos的微服务提供者) service-url: nacos-user-service: http://nacos-payment-provider 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @EnableDiscoveryClient @SpringBootApplication public class OrderNacosMain83 { public static void main(String[] args) { SpringApplication.run(OrderNacosMain83.class,args); } } 5、业务类ApplicationContextBean： package com.kk.springcloud.config; import org.springframework.cloud.client.loadbalancer.LoadBalanced; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.web.client.RestTemplate; @Configuration public class ApplicationContextBean { @Bean @LoadBalanced public RestTemplate getRestTempe() { return new RestTemplate ( ); } } OrderNacosController： package com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import javax.annotation.Resource; @RestController public class OrderNacosController { @Resource private RestTemplate restTemplate; @Value(\"${service-url.nacos-user-service}\") private String serverURL; @GetMapping(\"/consumer/payment/nacos/{id}\") public String paymentInfo(@PathVariable(\"id\") Long id) { return restTemplate.getForObject (serverURL + \"/payment/nacos/\" + id, String.class); } } 6、测试1、客户端注册 2、访问：http://localhost:83/consumer/payment/nacos/13 1,2,1,2,1,2 切换效果存在 3、服务注册中心对比1、nacos全景图 2、Nacos和CAP 3、Nacos 支持AP和CP模式的切换C是所有节点在同一时间看到的数据是一致的；而A的定义是所有的请求都会收到响应。 何时选择使用何种模式？一般来说，如果不需要存储服务级别的信息且服务实例是通过nacos-client注册，并能够保持心跳上报，那么就可以选择AP模式。当前主流的服务如 Spring cloud 和 Dubbo 服务，都适用于AP模式，AP模式为了服务的可能性而减弱了一致性，因此AP模式下只支持注册临时实例。 如果需要在服务级别编辑或者存储配置信息，那么 CP 是必须，K8S服务和DNS服务则适用于CP模式。CP模式下则支持注册持久化实例，此时则是以 Raft 协议为集群运行模式，该模式下注册实例之前必须先注册服务，如果服务不存在，则会返回错误。 curl -X PUT ‘$NACOS_SERVER:8848/nacos/v1/ns/operator/switches?entry=serverMode&amp;value=CP’ 四、Nacos（配置中心）1、建model1、建modelcloudalibaba-config-nacos-client3377 2、pom&lt;!--nacos-config--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloudalibaba-config-nacos-client3377&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--nacos-config--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--nacos-discovery--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web + actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--一般基础配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、yml1、why配置两个springboot中配置文件的加载是存在优先级顺序的，bootstrap优先级高于application 2、bootstrap.ymlfile-extension: yaml #指定yaml格式的配置 # nacos配置 server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 #Nacos服务注册中心地址 config: server-addr: localhost:8848 #Nacos作为配置中心地址 file-extension: yaml #指定yaml格式的配置 3、application.ymlspring: profiles: active: dev # 表示开发环境 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @EnableDiscoveryClient @SpringBootApplication public class NacosConfigClientMain3377 { public static void main(String[] args) { SpringApplication.run (NacosConfigClientMain3377.class, args); } } 5、业务类@RefreshScope package com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Value; import org.springframework.cloud.context.config.annotation.RefreshScope; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController @RefreshScope //在控制器类加入@RefreshScope注解使当前类下的配置支持Nacos的动态刷新功能。 public class ConfigClientController { @Value(\"${config.info}\") private String configInfo; @GetMapping(\"/config/info\") public String getConfigInfo() { return configInfo; } } 2、配置中心基础1、规则${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension} 2、新增配置文件 nacos-config-client-dev.yaml config: info: nacos to info 3、对应配置说明 prefix 默认为 spring.application.name 的值 spring.profile.active 即为当前环境对应的 profile，可以通过配置项 spring.profile.active 来配置。 file-exetension 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置 4、历史配置（回滚）Nacos会记录配置文件的历史版本默认保留30天，此外还有一键回滚功能，回滚操作将会触发配置更新 nacos-config-client-dev.yaml DEFAULT_GROUP 3、测试 启动 3377 访问：http://localhost:3377/config/info 测试自带刷新功能 修改下Nacos中的yaml配置文件，再次调用查看配置的接口，就会发现配置已经刷新 4、配置中心分类1、Nacos的图形化管理界面1、配置管理 2、名称空间 3、三种方案加载配置1、DataID方案（1）说明 指定spring.profile.active和配置文件的DataID来使不同环境下读取不同的配置 （2）新建两个配置 （3）配置是什么就加载什么 2、Group方案（1）说明 通过Group实现环境区分 （2）新建组 （3）控制台上的效果 （4）Springboot上的配置 在config下增加一条group的配置即可。可配置为DEV_GROUP或TEST_GROUP 3、Namespace方案（1）新建dev/test的Namespace （2）回到服务管理-服务列表查看 （3）按照域名配置填写 （4）yml配置文件 application.yml bootstrap.yml 五、★ Nacos（集群和持久化）1、基本说明1、架构图 2、官方信息 2、Nacos持久化配置解释1、Nacos默认自带的是嵌入式数据库derby2、derby切换到mysql 步骤（1）进入容器，找到对应的配置文件 （2）在数据库执行以上 sql schema.sql CREATE DATABASE nacos_config; USE nacos_config; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_info */ /******************************************/ CREATE TABLE `config_info` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT 'id', `data_id` VARCHAR(255) NOT NULL COMMENT 'data_id', `group_id` VARCHAR(255) DEFAULT NULL, `content` LONGTEXT NOT NULL COMMENT 'content', `md5` VARCHAR(32) DEFAULT NULL COMMENT 'md5', `gmt_create` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '创建时间', `gmt_modified` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '修改时间', `src_user` TEXT COMMENT 'source user', `src_ip` VARCHAR(20) DEFAULT NULL COMMENT 'source ip', `app_name` VARCHAR(128) DEFAULT NULL, `tenant_id` VARCHAR(128) DEFAULT '' COMMENT '租户字段', `c_desc` VARCHAR(256) DEFAULT NULL, `c_use` VARCHAR(64) DEFAULT NULL, `effect` VARCHAR(64) DEFAULT NULL, `type` VARCHAR(64) DEFAULT NULL, `c_schema` TEXT, PRIMARY KEY (`id`), UNIQUE KEY `uk_configinfo_datagrouptenant` (`data_id`,`group_id`,`tenant_id`) ) ENGINE=INNODB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_info'; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_info_aggr */ /******************************************/ CREATE TABLE `config_info_aggr` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT 'id', `data_id` VARCHAR(255) NOT NULL COMMENT 'data_id', `group_id` VARCHAR(255) NOT NULL COMMENT 'group_id', `datum_id` VARCHAR(255) NOT NULL COMMENT 'datum_id', `content` LONGTEXT NOT NULL COMMENT '内容', `gmt_modified` DATETIME NOT NULL COMMENT '修改时间', `app_name` VARCHAR(128) DEFAULT NULL, `tenant_id` VARCHAR(128) DEFAULT '' COMMENT '租户字段', PRIMARY KEY (`id`), UNIQUE KEY `uk_configinfoaggr_datagrouptenantdatum` (`data_id`,`group_id`,`tenant_id`,`datum_id`) ) ENGINE=INNODB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='增加租户字段'; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_info_beta */ /******************************************/ CREATE TABLE `config_info_beta` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT 'id', `data_id` VARCHAR(255) NOT NULL COMMENT 'data_id', `group_id` VARCHAR(128) NOT NULL COMMENT 'group_id', `app_name` VARCHAR(128) DEFAULT NULL COMMENT 'app_name', `content` LONGTEXT NOT NULL COMMENT 'content', `beta_ips` VARCHAR(1024) DEFAULT NULL COMMENT 'betaIps', `md5` VARCHAR(32) DEFAULT NULL COMMENT 'md5', `gmt_create` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '创建时间', `gmt_modified` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '修改时间', `src_user` TEXT COMMENT 'source user', `src_ip` VARCHAR(20) DEFAULT NULL COMMENT 'source ip', `tenant_id` VARCHAR(128) DEFAULT '' COMMENT '租户字段', PRIMARY KEY (`id`), UNIQUE KEY `uk_configinfobeta_datagrouptenant` (`data_id`,`group_id`,`tenant_id`) ) ENGINE=INNODB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_info_beta'; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_info_tag */ /******************************************/ CREATE TABLE `config_info_tag` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT 'id', `data_id` VARCHAR(255) NOT NULL COMMENT 'data_id', `group_id` VARCHAR(128) NOT NULL COMMENT 'group_id', `tenant_id` VARCHAR(128) DEFAULT '' COMMENT 'tenant_id', `tag_id` VARCHAR(128) NOT NULL COMMENT 'tag_id', `app_name` VARCHAR(128) DEFAULT NULL COMMENT 'app_name', `content` LONGTEXT NOT NULL COMMENT 'content', `md5` VARCHAR(32) DEFAULT NULL COMMENT 'md5', `gmt_create` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '创建时间', `gmt_modified` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '修改时间', `src_user` TEXT COMMENT 'source user', `src_ip` VARCHAR(20) DEFAULT NULL COMMENT 'source ip', PRIMARY KEY (`id`), UNIQUE KEY `uk_configinfotag_datagrouptenanttag` (`data_id`,`group_id`,`tenant_id`,`tag_id`) ) ENGINE=INNODB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_info_tag'; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = config_tags_relation */ /******************************************/ CREATE TABLE `config_tags_relation` ( `id` BIGINT(20) NOT NULL COMMENT 'id', `tag_name` VARCHAR(128) NOT NULL COMMENT 'tag_name', `tag_type` VARCHAR(64) DEFAULT NULL COMMENT 'tag_type', `data_id` VARCHAR(255) NOT NULL COMMENT 'data_id', `group_id` VARCHAR(128) NOT NULL COMMENT 'group_id', `tenant_id` VARCHAR(128) DEFAULT '' COMMENT 'tenant_id', `nid` BIGINT(20) NOT NULL AUTO_INCREMENT, PRIMARY KEY (`nid`), UNIQUE KEY `uk_configtagrelation_configidtag` (`id`,`tag_name`,`tag_type`), KEY `idx_tenant_id` (`tenant_id`) ) ENGINE=INNODB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_tag_relation'; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = group_capacity */ /******************************************/ CREATE TABLE `group_capacity` ( `id` BIGINT(20) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '主键ID', `group_id` VARCHAR(128) NOT NULL DEFAULT '' COMMENT 'Group ID，空字符表示整个集群', `quota` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '配额，0表示使用默认值', `usage` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '使用量', `max_size` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '单个配置大小上限，单位为字节，0表示使用默认值', `max_aggr_count` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '聚合子配置最大个数，，0表示使用默认值', `max_aggr_size` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值', `max_history_count` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '最大变更历史数量', `gmt_create` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '创建时间', `gmt_modified` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '修改时间', PRIMARY KEY (`id`), UNIQUE KEY `uk_group_id` (`group_id`) ) ENGINE=INNODB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='集群、各Group容量信息表'; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = his_config_info */ /******************************************/ CREATE TABLE `his_config_info` ( `id` BIGINT(64) UNSIGNED NOT NULL, `nid` BIGINT(20) UNSIGNED NOT NULL AUTO_INCREMENT, `data_id` VARCHAR(255) NOT NULL, `group_id` VARCHAR(128) NOT NULL, `app_name` VARCHAR(128) DEFAULT NULL COMMENT 'app_name', `content` LONGTEXT NOT NULL, `md5` VARCHAR(32) DEFAULT NULL, `gmt_create` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00', `gmt_modified` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00', `src_user` TEXT, `src_ip` VARCHAR(20) DEFAULT NULL, `op_type` CHAR(10) DEFAULT NULL, `tenant_id` VARCHAR(128) DEFAULT '' COMMENT '租户字段', PRIMARY KEY (`nid`), KEY `idx_gmt_create` (`gmt_create`), KEY `idx_gmt_modified` (`gmt_modified`), KEY `idx_did` (`data_id`) ) ENGINE=INNODB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='多租户改造'; /******************************************/ /* 数据库全名 = nacos_config */ /* 表名称 = tenant_capacity */ /******************************************/ CREATE TABLE `tenant_capacity` ( `id` BIGINT(20) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT '主键ID', `tenant_id` VARCHAR(128) NOT NULL DEFAULT '' COMMENT 'Tenant ID', `quota` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '配额，0表示使用默认值', `usage` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '使用量', `max_size` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '单个配置大小上限，单位为字节，0表示使用默认值', `max_aggr_count` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '聚合子配置最大个数', `max_aggr_size` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值', `max_history_count` INT(10) UNSIGNED NOT NULL DEFAULT '0' COMMENT '最大变更历史数量', `gmt_create` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '创建时间', `gmt_modified` DATETIME NOT NULL DEFAULT '2010-05-05 00:00:00' COMMENT '修改时间', PRIMARY KEY (`id`), UNIQUE KEY `uk_tenant_id` (`tenant_id`) ) ENGINE=INNODB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='租户容量信息表'; CREATE TABLE `tenant_info` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT 'id', `kp` VARCHAR(128) NOT NULL COMMENT 'kp', `tenant_id` VARCHAR(128) DEFAULT '' COMMENT 'tenant_id', `tenant_name` VARCHAR(128) DEFAULT '' COMMENT 'tenant_name', `tenant_desc` VARCHAR(256) DEFAULT NULL COMMENT 'tenant_desc', `create_source` VARCHAR(32) DEFAULT NULL COMMENT 'create_source', `gmt_create` BIGINT(20) NOT NULL COMMENT '创建时间', `gmt_modified` BIGINT(20) NOT NULL COMMENT '修改时间', PRIMARY KEY (`id`), UNIQUE KEY `uk_tenant_info_kptenantid` (`kp`,`tenant_id`), KEY `idx_tenant_id` (`tenant_id`) ) ENGINE=INNODB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='tenant_info'; CREATE TABLE users ( username VARCHAR(50) NOT NULL PRIMARY KEY, PASSWORD VARCHAR(500) NOT NULL, enabled BOOLEAN NOT NULL ); CREATE TABLE roles ( username VARCHAR(50) NOT NULL, role VARCHAR(50) NOT NULL ); INSERT INTO users (username, PASSWORD, enabled) VALUES ('nacos', '$2a$10$EuWPZHzz32dJN7jexM34MOeYirDdFAZm2kuWj7VEOJhhZkDrxfvUu', TRUE); INSERT INTO roles (username, role) VALUES ('nacos', 'ROLE_ADMIN'); （3）在 application.properties修改配置 以上 五个配置均要修改 （4）改完之后重启 （5）重新登录客户端，发现以前的数据没有了，说明切换成功 3、高可用集群搭建1、架构图 最终落地：Nacos 高可用集群（docker-compose）参考文章https://www.jianshu.com/p/d2c81d647323 https://blog.csdn.net/wwwwwww31311/article/details/113066637 https://www.cnblogs.com/hellxz/p/nacos-cluster-docker.html","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud-alibaba","slug":"springcloud-alibaba","permalink":"https://mykkto.github.io/tags/springcloud-alibaba/"},{"name":"服务注册与发现","slug":"服务注册与发现","permalink":"https://mykkto.github.io/tags/%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0/"},{"name":"配置中心","slug":"配置中心","permalink":"https://mykkto.github.io/tags/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"},{"name":"nacos","slug":"nacos","permalink":"https://mykkto.github.io/tags/nacos/"}],"author":"mykk"},{"title":"SpringCloud-Sleuth分布式请求链路跟踪","slug":"03-java分布式/01-springcloud/13_SpringCloud-Sleuth","date":"2022-02-21T18:22:22.000Z","updated":"2022-11-12T15:07:08.072Z","comments":true,"path":"posts/35c50dd0.html","link":"","permalink":"https://mykkto.github.io/posts/35c50dd0.html","excerpt":"","text":"1、概述1、为什么出现​ 在微服务框架中，一个由客户端发起的请求在后端系统中会经过多个不同的的服务节点调用来协同产生最后的请求结果，每一个前段请求都会形成一条复杂的分布式服务调用链路，链路中的任何一环出现高延时或错误都会引起整个请求最后的失败。 2、是什么1、官网https://github.com/spring-cloud/spring-cloud-sleuth 2、说明Spring Cloud Sleuth提供了一套完整的服务跟踪的解决方案 在分布式系统中提供追踪解决方案并且兼容支持了zipkin 2、搭建链路监控步骤1、zipkin1、下载 SpringCloud从F版起已不需要自己构建Zipkin Server了，只需调用jar包即可 https://repo1.maven.org/maven2/io/zipkin/java/zipkin-server/ zipkin-server-2.12.9-exec.jar 2、运行 jarjava -jar zipkin-server-2.12.9-exec.jar 3、运行控制台 3、服务生产者1、建modelcloud-provider-sleuth8001 2、pom&lt;!--包含了sleuth+zipkin--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-provider-sleuth8001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--包含了sleuth+zipkin--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--eureka-client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;!--mysql-connector-java--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--jdbc--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、yml server: port: 8001 spring: application: name: cloud-payment-service zipkin: base-url: http://106.52.23.202:9411 sleuth: sampler: #采样率值介于 0 到 1 之间，1 则表示全部采集 probability: 1 datasource: type: com.alibaba.druid.pool.DruidDataSource # 当前数据源操作类型 driver-class-name: org.gjt.mm.mysql.Driver # mysql驱动包 url: jdbc:mysql://101.34.180.133:3306/spring_cloud?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: a1b2c3 eureka: client: #表示是否将自己注册进EurekaServer默认为true。 register-with-eureka: true #是否从EurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetchRegistry: true service-url: #defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka # 集群版 defaultZone: http://localhost:7001/eureka # 单机版 instance: instance-id: payment8001 #访问路径可以显示IP地址 prefer-ip-address: true #Eureka客户端向服务端发送心跳的时间间隔，单位为秒(默认是30秒) lease-renewal-interval-in-seconds: 1 #Eureka服务端在收到最后一次心跳后等待时间上限，单位为秒(默认是90秒)，超时将剔除服务 lease-expiration-duration-in-seconds: 2 mybatis: mapperLocations: classpath:mapper/*.xml type-aliases-package: com.kk.springcloud.entities # 所有Entity别名类所在包 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication @EnableEurekaClient public class SleuthZipkinMain8001 { public static void main(String[] args) { SpringApplication.run (SleuthZipkinMain8001.class,args); } } 5、业务类package com.kk.springcloud.controller; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class PromentController { @GetMapping(\"/payment/zipkin\") public String paymentZipkin() { return \"hi ,i'am paymentzipkin server fall back，welcome to kk demo ，O(∩_∩)O哈哈~\"; } } 4、服务消费者1、建modelcloud-consumer-order81 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-consumer-sleuth80&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--包含了sleuth+zipkin--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 81 spring: application: name: cloud-order-service zipkin: base-url: http://106.52.23.202:9411 sleuth: sampler: probability: 1 eureka: client: #表示是否将自己注册进EurekaServer默认为true。 register-with-eureka: true #是否从EurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetchRegistry: true service-url: #defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ defaultZone: http://eureka7001.com:7001/eureka 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; import org.springframework.context.annotation.Bean; import org.springframework.web.client.RestTemplate; @SpringBootApplication @EnableEurekaClient public class ConsumerSleuthMain81 { public static void main(String[] args) { SpringApplication.run (ConsumerSleuthMain80.class,args); } @Bean public RestTemplate restTemplate() { return new RestTemplate(); } } 5、业务类package com.kk.springcloud.controller; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import javax.annotation.Resource; @RestController public class ConsumerController { public static final String PAYMENT_URL = \"http://CLOUD-PAYMENT-SERVICE\"; @Resource private RestTemplate restTemplate; // ====================&gt; zipkin+sleuth @GetMapping(\"/consumer/payment/zipkin\") public String paymentZipkin() { String result = restTemplate.getForObject (PAYMENT_URL + \"/payment/zipkin/\", String.class); return result; } } 5、测试1、访问 http://localhost:81/consumer/payment/zipkin 2、打开 zipkin客户端 http://106.52.23.202:9411/","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"服务跟踪","slug":"服务跟踪","permalink":"https://mykkto.github.io/tags/%E6%9C%8D%E5%8A%A1%E8%B7%9F%E8%B8%AA/"},{"name":"sleuth","slug":"sleuth","permalink":"https://mykkto.github.io/tags/sleuth/"}],"author":"mykk"},{"title":"SpringCloud-Stream消息驱动","slug":"03-java分布式/01-springcloud/12_SpringCloud-Stream","date":"2022-02-19T14:52:16.000Z","updated":"2023-02-15T14:24:03.328Z","comments":true,"path":"posts/e867710e.html","link":"","permalink":"https://mykkto.github.io/posts/e867710e.html","excerpt":"","text":"友情链接rabitMQ安装（docker） 1、消息驱动概述1、是什么屏蔽底层消息中间件的差异,降低切换成本，统一消息的编程模型 官网：https://m.wang1314.com/doc/webapp/topic/20971999.html 2、设计思想1、标准MQ Message：生产者/消费者之间靠消息媒介传递信息内容 MessageChannel（消息通道）：消息必须走特定的通道 消息通道里的消息如何被消费呢，谁负责收发处理 消息通道MessageChannel的子接口SubscribableChannel，由MessageHandler消息处理器所订阅 2、为什么用Cloud Stream1、概念比方说我们用到了RabbitMQ和Kafka，由于这两个消息中间件的架构上的不同，像RabbitMQ有exchange，kafka有Topic和Partitions分区， 这些中间件的差异性导致我们实际项目开发给我们造成了一定的困扰，我们如果用了两个消息队列的其中一种，后面的业务需求，我想往另外一种消息队列进行迁移，这时候无疑就是一个灾难性的，一大堆东西都要重新推倒重新做，因为它跟我们的系统耦合了，这时候springcloud Stream给我们提供了一种解耦合的方式。 2、Stream中的消息通信方式遵循了发布-订阅模式Topic主题进行广播： 在RabbitMQ就是Exchange 在Kakfa中就是Topic 3、Spring Cloud Stream标准流程套路 Binder： 很方便的连接中间件，屏蔽差异 Channel： 通道，是队列Queue的一种抽象，在消息通讯系统中就是实现存储和转发的媒介，通过Channel对队列进行配置 Source和Sink： 简单的可理解为参照对象是Spring Cloud Stream自身，从Stream发布消息就是输出，接受消息就是输入 4、编码API和常用注解 2、案例说明工程中新建三个子模块 cloud-stream-rabbitmq-provider8801， 作为生产者进行发消息模块 cloud-stream-rabbitmq-consumer8802，作为消息接收模块 cloud-stream-rabbitmq-consumer8803 作为消息接收模块 3、消息驱动之生产者1、新建Modulecloud-stream-rabbitmq-provider8801 2、pom&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-stream-rabbitmq-provider8801&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--基础配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlbindings: # 服务的整合处理 output: # 这个名字是一个通道的名称 destination: studyExchange # 表示要使用的Exchange名称定义 content-type: application/json # 设置消息类型，本次为json，文本则设置“text/plain” binder: defaultRabbit # 设置要绑定的消息服务的具体设置 server: port: 8801 spring: application: name: cloud-stream-provider cloud: stream: binders: # 在此处配置要绑定的rabbitmq的服务信息； defaultRabbit: # 表示定义的名称，用于于binding整合 type: rabbit # 消息组件类型 environment: # 设置rabbitmq的相关的环境配置 spring: rabbitmq: host: 101.34.180.133 port: 5672 username: guest password: guest bindings: # 服务的整合处理 output: # 这个名字是一个通道的名称 destination: studyExchange # 表示要使用的Exchange名称定义 content-type: application/json # 设置消息类型，本次为json，文本则设置“text/plain” binder: defaultRabbit # 设置要绑定的消息服务的具体设置 eureka: client: # 客户端进行Eureka注册的配置 service-url: defaultZone: http://localhost:7001/eureka instance: lease-renewal-interval-in-seconds: 2 # 设置心跳的时间间隔（默认是30秒） lease-expiration-duration-in-seconds: 5 # 如果现在超过了5秒的间隔（默认是90秒） instance-id: send-8801.com # 在信息列表时显示主机名称 prefer-ip-address: true # 访问的路径变为IP地址 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class StreamMQMain8801 { public static void main(String[] args) { SpringApplication.run (StreamMQMain8801.class, args); } } 5、业务类1、接口package com.kk.springcloud.service; public interface IMessageProvider { String send(); } 2、接口实现package com.kk.springcloud.service.impl; import com.kk.springcloud.service.IMessageProvider; import org.springframework.cloud.stream.annotation.EnableBinding; import org.springframework.cloud.stream.messaging.Source; import org.springframework.messaging.MessageChannel; import org.springframework.integration.support.MessageBuilder; import javax.annotation.Resource; import java.util.UUID; @EnableBinding(Source.class) // 可以理解为是一个消息的发送管道的定义 public class MessageProviderImpl implements IMessageProvider { @Resource private MessageChannel output; // 消息的发送管道 @Override public String send() { String serial = UUID.randomUUID ( ).toString ( ); this.output.send (MessageBuilder.withPayload (serial).build ( )); // 创建并发送消息 System.out.println (\"***serial: \" + serial); return serial; } } 3、controllerpackage com.kk.springcloud.controller; import com.kk.springcloud.service.IMessageProvider; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; @RestController public class SendMessageController { @Resource private IMessageProvider messageProvider; @GetMapping(value = \"/sendMessage\") public String sendMessage() { return messageProvider.send ( ); } } 6、测试 启动eureka，以及rabbitMq，以及8801 访问：http://localhost:8801/sendMessage 4、消息驱动之消费者1、新建Modulecloud-stream-rabbitmq-consumer8802 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-stream-rabbitmq-consumer8802&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--基础配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 8802 spring: application: name: cloud-stream-consumer cloud: stream: binders: # 在此处配置要绑定的rabbitmq的服务信息； defaultRabbit: # 表示定义的名称，用于于binding整合 type: rabbit # 消息组件类型 environment: # 设置rabbitmq的相关的环境配置 spring: rabbitmq: host: 101.34.180.133 port: 5672 username: guest password: guest bindings: # 服务的整合处理 input: # 这个名字是一个通道的名称 destination: studyExchange # 表示要使用的Exchange名称定义 content-type: application/json # 设置消息类型，本次为对象json，如果是文本则设置“text/plain” binder: defaultRabbit # 设置要绑定的消息服务的具体设置 eureka: client: # 客户端进行Eureka注册的配置 service-url: defaultZone: http://localhost:7001/eureka instance: lease-renewal-interval-in-seconds: 2 # 设置心跳的时间间隔（默认是30秒） lease-expiration-duration-in-seconds: 5 # 如果现在超过了5秒的间隔（默认是90秒） instance-id: receive-8802.com # 在信息列表时显示主机名称 prefer-ip-address: true # 访问的路径变为IP地址 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class StreamMQMain8802 { public static void main(String[] args) { SpringApplication.run (StreamMQMain8802.class, args); } } 5、业务类package com.kk.springcloud.service; import org.springframework.beans.factory.annotation.Value; import org.springframework.cloud.stream.annotation.EnableBinding; import org.springframework.cloud.stream.annotation.StreamListener; import org.springframework.cloud.stream.messaging.Sink; import org.springframework.messaging.Message; import org.springframework.stereotype.Component; @Component @EnableBinding(Sink.class) public class ReceiveMessageListener { @Value(\"${server.port}\") private String serverPort; @StreamListener(Sink.INPUT) public void input(Message&lt;String&gt; message) { System.out.println (\"消费者1号，-------&gt;接收到的消息：\" + message.getPayload ( ) + \"\\t port: \" + serverPort); } } 6、测试url：http://localhost:8801/sendMessage 5、分组消费与持久化1、依照8802，clone出来一份运行8803 cloud-stream-rabbitmq-consumer8803 @SpringBootApplication public class StreamMQMain8803 { public static void main(String[] args) { SpringApplication.run (StreamMQMain8803.class, args); } } - ```java @Component @EnableBinding(Sink.class) public class ReceiveMessageListener { @Value(\"${server.port}\") private String serverPort; @StreamListener(Sink.INPUT) public void input(Message&lt;String&gt; message) { System.out.println (\"消费者2号，-------&gt;接收到的消息：\" + message.getPayload ( ) + \"\\t port: \" + serverPort); } } 2、启动 3、运行后有两个问题 有重复消费问题 消息持久化问题 4、重复消费问题目前是8802/8803同时都收到了，存在重复消费问题 如何解决：分组和持久化属性group比如在如下场景中，订单系统我们做集群部署，都会从RabbitMQ中获取订单信息，那如果一个订单同时被两个服务获取到，那么就会造成数据错误，我们得避免这种情况。这时我们就可以使用Stream中的消息分组来解决 注意在Stream中处于同一个group中的多个消费者是竞争关系，就能够保证消息只会被其中一个应用消费一次。不同组是可以全面消费的(重复消费)， 同一组内会发生竞争关系，只有其中一个可以消费。 5、分组1、原理微服务应用放置于同一个group中，就能够保证消息只会被其中一个应用消费一次。不同的组是可以消费的，同一个组内会发生竞争关系，只有其中一个可以消费。 2、划分组(不同组) 8802/8803都变成不同组，group两个不同组（kkA,kkB） 8802修改YML group: kkA 8803修改YML group: kkB 3、结论(不同组)不同组的还是重复消费 4、划分组(不同组)两边都配置为：kkA 5、结论(不同组)同一个组的多个微服务实例，每次只会有一个拿到。（解决重复消费问题） 6、持久化目前两个消费者8802/8803都是归类于 kkA分组 1、下面要做的是将 8802分组配置注释 2、关闭8002/8003服务 3、8801先发送4条消息到rabbitmq 4、启动8802（无分组），没有任何打印 5、启动8803（有分组），接收离线数据","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"消息驱动","slug":"消息驱动","permalink":"https://mykkto.github.io/tags/%E6%B6%88%E6%81%AF%E9%A9%B1%E5%8A%A8/"},{"name":"stream","slug":"stream","permalink":"https://mykkto.github.io/tags/stream/"}],"author":"mykk"},{"title":"SpringCloud-Bus分布式节点链接","slug":"03-java分布式/01-springcloud/11_SpringCloud-Bus","date":"2022-02-06T03:49:12.000Z","updated":"2022-11-12T15:07:08.093Z","comments":true,"path":"posts/699f8954.html","link":"","permalink":"https://mykkto.github.io/posts/699f8954.html","excerpt":"","text":"1、概述1、是什么Bus支持两种消息代理：RabbitMQ 和 Kafka Spring Cloud Bus 配合 Spring Cloud Config 使用可以实现配置的动态刷新。 Spring Cloud Bus是用来将分布式系统的节点与轻量级消息系统链接起来的框架，它整合了Java的事件处理机制和消息中间件的功能。 Spring Clud Bus目前支持RabbitMQ和Kafka。 2、能干嘛Spring Cloud Bus能管理和传播分布式系统间的消息，就像一个分布式执行器，可用于广播状态更改、事件推送等，也可以当作微服务间的通信通道。 3、为何被称为总线什么是总线在微服务架构的系统中，通常会使用轻量级的消息代理来构建一个共用的消息主题，并让系统中所有微服务实例都连接上来。由于该主题中产生的消息会被所有实例监听和消费，所以称它为消息总线。在总线上的各个实例，都可以方便地广播一些需要让其他连接在该主题上的实例都知道的消息。 基本原理ConfigClient实例都监听MQ中同一个topic(默认是springCloudBus)。当一个服务刷新数据的时候，它会把这个信息放入到Topic中，这样其它监听同一Topic的服务就能得到通知，然后去更新自身的配置。 2、RabbitMQ环境配置1、安装安装docker：https://www.jianshu.com/p/f554c85b25c1 1、拉取docker pull rabbitmq:3.7.7-management 2、创建容器并启动docker run -d --hostname localhost --name myrabbit -p 15672:15672 -p 5672:5672 rabbitmq:3.7.7-management -d 后台运行容器； –name 指定容器名； -p 指定服务运行的端口（5672：应用访问端口；15672：控制台Web端口号）； -v 映射目录或文件； –hostname 主机名（RabbitMQ的一个重要注意事项是它根据所谓的 “节点名称” 存储数据，默认为主机名）； -e 指定环境变量； 默认的用户名：guest； 默认用户名的密码：guest） 3、访问http://localhost:15672/ （换成自己服务器的IP） 3、SpringCloud Bus 动态刷新全局广播1、演示广播效果，增加复杂度以3355为模板再制作一个3366 1、建modelcloud-config-client-3366 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-config-client-3366-2&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、bootstrap.ymlserver: port: 3366 spring: application: name: config-client cloud: #Config客户端配置 config: label: master #分支名称 name: config #配置文件名称 profile: dev #读取后缀名称 上述3个综合：master分支上config-dev.yml的配置文件被读取http://config-3344.com:3344/master/config-dev.yml uri: http://localhost:3344 #配置中心地址 eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; @SpringBootApplication @EnableEurekaClient public class ConfigClientMain3366 { public static void main(String[] args) { SpringApplication.run (ConfigClientMain3366.class,args); } } 5、业务类package com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Value; import org.springframework.cloud.context.config.annotation.RefreshScope; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController @RefreshScope public class ConfigClientController { @Value(\"${server.port}\") private String serverPort; @Value(\"${mytest.info}\") private String configInfo; @GetMapping(\"/configInfo\") public String configInfo() { return \"serverPort: \" + serverPort + \"\\t\\n\\n configInfo: \" + configInfo; } } 2、给cloud-config-center-3344配置中心服务端添加消息总线支持1、pom&lt;!--添加消息总线RabbitMQ支持--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt; &lt;/dependency&gt; 2、yml##rabbitmq相关配置,暴露bus刷新配置的端点 management: endpoints: #暴露bus刷新配置的端点 web: exposure: include: 'bus-refresh' 3、给cloud-config-client-3355客户端添加消息总线支持1、pom&lt;!--添加消息总线RabbitMQ支持--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt; &lt;/dependency&gt; 2、bootstrap.yml#rabbitmq相关配置 15672是Web管理界面的端口；5672是MQ访问的端口 rabbitmq: host: localhost port: 5672 username: guest password: guest server: port: 3355 spring: application: name: config-client cloud: #Config客户端配置 config: label: master #分支名称 name: config #配置文件名称 profile: dev #读取后缀名称 上述3个综合：master分支上config-dev.yml的配置文件被读取http://config-3344.com:3344/master/config-dev.yml uri: http://localhost:3344 #配置中心地址 #rabbitmq相关配置 15672是Web管理界面的端口；5672是MQ访问的端口 rabbitmq: host: 106.xx.xx.xx port: 5672 username: guest password: guest eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ # 暴露监控端点 management: endpoints: web: exposure: include: \"*\" 4、给cloud-config-client-3366客户端添加消息总线支持同上5、测试1、修改Github上配置文件增加版本号 2、发送 post 请求curl -X POST \"http://localhost:3344/actuator/bus-refresh 3、配置中心http://config-3344.com:3344/config-dev.yml 同步更新了配置信息 4、客户端http://localhost:3355/configInfo 发现并没有更新，运行指定 定点试试：curl -X POST \"http://localhost:3355/actuator/bus-refresh 运行后发现就更新了，很奇怪哦 5、结论一次修改，广播通知，处处生效（目前只有服务端是这样的，客户端只能手动，问题原因未知） 4、SpringCloud Bus 动态刷新定点(局部)通知1、概念指定具体某一个实例生效而不是全部 2、公式http://localhost:配置中心的端口号/actuator/bus-refresh/{destination} /bus/refresh请求不再发送到具体的服务实例上，而是发给config server并通过destination参数类指定需要更新配置的服务或实例 3、案例只刷新 3355 curl -X POST \"http://localhost:3344/actuator/bus-refresh/config-client:3355\" 参考：https://blog.csdn.net/haoweng4800/article/details/102946846 https://www.cnblogs.com/huanshilang/p/12585877.html https://www.jianshu.com/p/efac7bd8941f","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"bus","slug":"bus","permalink":"https://mykkto.github.io/tags/bus/"},{"name":"节点链接","slug":"节点链接","permalink":"https://mykkto.github.io/tags/%E8%8A%82%E7%82%B9%E9%93%BE%E6%8E%A5/"}],"author":"mykk"},{"title":"SpringCloud-Config分布式配置","slug":"03-java分布式/01-springcloud/10_SpringCloud-Config","date":"2022-02-04T01:33:12.000Z","updated":"2023-02-15T14:19:43.271Z","comments":true,"path":"posts/fc38d8b7.html","link":"","permalink":"https://mykkto.github.io/posts/fc38d8b7.html","excerpt":"","text":"1、概述1、官网https://docs.spring.io/spring-cloud-config/docs/2.2.8.RELEASE/reference/html/ 2、分布式系统面临的—配置问题 微服务意味着要将单体应用中的业务拆分成一个个子服务，每个服务的粒度相对较小，因此系统中会出现大量的服务。由于每个服务都需要必要的配置信息才能运行，所以一套集中式的、动态的配置管理设施是必不可少的。 ​ SpringCloud提供了ConfigServer来解决这个问题，我们每一个微服务自己带着一个application.yml，上百个配置文件的管理。 3、是什么 SpringCloud Config为微服务架构中的微服务提供集中化的外部配置支持，配置服务器为各个不同微服务应用的所有环境提供了一个中心化的外部配置。 4、怎么玩SpringCloud Config分为服务端和客户端两部分。 服务端也称为分布式配置中心，它是一个独立的微服务应用，用来连接配置服务器并为客户端提供获取配置信息，加密/解密信息等访问接口 客户端则是通过指定的配置中心来管理应用资源，以及与业务相关的配置内容，并在启动的时候从配置中心获取和加载配置信息配置服务器默认采用git来存储配置信息，这样就有助于对环境配置进行版本管理，并且可以通过git客户端工具来方便的管理和访问配置内容。 5、能干嘛 集中管理配置文件 不同环境不同配置，动态化的配置更新，分环境部署比如dev/test/prod/beta/release 运行期间动态调整配置，不再需要在每个服务部署的机器上编写配置文件，服务会向配置中心统一拉取配置自己的信息 当配置发生变动时，服务不需要重启即可感知到配置的变化并应用新的配置 将配置信息以REST接口的形式暴露，post、curl访问刷新均可…… 6、与GitHub整合配置由于SpringCloud Config默认使用Git来存储配置文件(也有其它方式,比如支持SVN和本地文件)，但最推荐的还是Git，而且使用的是http/https访问的形式 2、Config服务端配置1、创建github仓库1、新建仓库用你自己的账号在GitHub/gitee 上新建一个名为springcloud-config的新Repository 2、获得刚新建的git地址https://gitee.com/TK_LIMR/spring-cloud-config.git 3、本地硬盘目录上新建git仓库并clonegit clone https://gitee.com/TK_LIMR/spring-cloud-config.git 4、编辑application.yml环境# 不同的开发环境，不同的微服务名字 spring: profiles: active: - dev --- spring: profiles: dev #开发环境 application: name: microservicecloud-config-kk-dev config: info: version1 --- spring: profiles: test #测试环境 application: name: microservicecloud-config-kk-test # 请保存为UTF-8格式 5、上传到gitee上（1）git add . （2）git commit -m \"init yml\" （3）git push origin master 2、项目搭建1、建model新建Module模块cloud-config-center-3344 2、pom&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-config-center-3344&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 3344 spring: application: name: cloud-config-center #注册进Eureka服务器的微服务名 cloud: config: server: git: uri: https://gitee.com/TK_LIMR/spring-cloud-config.git #GitHub上面的git仓库名字 ####权限登录(这里填写自己的) force-pull: true username: xxxxxxxx@163.com password: xxxxxxxx ####搜索目录 search-paths: - springcloud-config ####读取分支 label: master #服务注册到eureka地址 eureka: client: service-url: defaultZone: http://localhost:7001/eureka 4、主启动@EnableConfigServer package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.config.server.EnableConfigServer; @SpringBootApplication @EnableConfigServer public class ConfigCenterMain3344 { public static void main(String[] args) { SpringApplication.run (ConfigCenterMain3344.class,args); } } 5、本地hosts配置127.0.0.1 config-3344.com 6、启动测试生产：http://config-3344.com:3344/master/config-prod.yml 开发：http://config-3344.com:3344/master/config-dev.yml 测试：http://config-3344.com:3344/master/config-test.yml 3、配置读取规则1、官网 2、/{label}/{application}-{profile}.yml参数说明：/分支/服务名/环境 1、master分支http://config-3344.com:3344/master/config-dev.yml http://config-3344.com:3344/master/config-test.yml http://config-3344.com:3344/master/config-prod.yml 2、dev分支http://config-3344.com:3344/dev/config-dev.yml http://config-3344.com:3344/dev/config-test.yml http://config-3344.com:3344/dev/config-prod.yml 3、/{application}-{profile}.yml参数说明：/服务名/环境 http://config-3344.com:3344/config-dev.yml http://config-3344.com:3344/config-test.yml http://config-3344.com:3344/config-prod.yml http://config-3344.com:3344/config-xxxx.yml(不存在的配置) 4、/{application}/{profile}[/{label}]参数说明：/服务名/环境/分支 http://config-3344.com:3344/config/dev/master http://config-3344.com:3344/config/test/master http://config-3344.com:3344/config/test/dev 5、参数说明/{label}-{name}-{profiles}.yml label：分支(branch)name ：服务名profiles：环境(dev/test/prod) 3、Config客户端配置1、建model和测试1、建model新建cloud-config-client-3355 2、pom&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-config-client-3355&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、bootstrap.ymlapplicaiton.yml 是用户级的资源配置项bootstrap.yml 是系统级的，优先级更加高 server: port: 3355 spring: application: name: config-client cloud: #Config客户端配置 config: label: master #分支名称 name: config #配置文件名称 profile: dev #读取后缀名称 上述3个综合：master分支上config-dev.yml的配置文件被读取http://config-3344.com:3344/master/config-dev.yml uri: http://localhost:3344 #配置中心地址 eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; @SpringBootApplication @EnableEurekaClient public class ConfigClientMain3355 { public static void main(String[] args) { SpringApplication.run (ConfigClientMain3355.class,args); } } 5、业务类package com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class ConfigClientController { @Value(\"${config.info}\") private String configInfo; @GetMapping(\"/configInfo\") public String getConfigInfo() { return configInfo; } } 6、测试1、启动Config配置中心3344微服务并自测 http://config-3344.com:3344/master/config-prod.yml http://config-3344.com:3344/master/config-dev.yml 2、启动3355作为Client准备访问 http://localhost:3355/configInfo 2、动态刷新问题 Linux运维修改GitHub上的配置文件内容做调整 刷新3344，发现ConfigServer配置中心立刻响应 刷新3355，发现ConfigClient客户端没有任何响应 3355没有变化除非自己重启或者重新加载 难到每次运维修改配置文件，客户端都需要重启？？噩梦 4、Config客户端之动态刷新操作3355模块 1、POM引入actuator监控&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; 2、修改YML，暴露监控端口# 暴露监控端点 management: endpoints: web: exposure: include: \"*\" 3、业务类Controller修改@RefreshScope package com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Value; import org.springframework.cloud.context.config.annotation.RefreshScope; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController @RefreshScope public class ConfigClientController { @Value(\"${spring.application.name}\") private String configInfo; @GetMapping(\"/configInfo\") public String getConfigInfo() { return configInfo; } } 4、此时修改github—&gt; 3344 —-&gt;33551、添加一个版本号为1 2、此时看下3344（config服务端），没有重启的状态下 没有更新！ 3、此时看下3355（config客户端），没有重启的状态下 没有更新！ 4、总结：是不会更新的 5、解决：需要运维人员运行解决 必须是POST请求 curl -X POST \"http://localhost:3355/actuator/refresh\" 5、还存在的问题 每个微服务都要执行一次post请求，手动刷新？ 写循环代码解决（shell脚本） 可否广播，一次通知，处处生效？ 鸡肋所在 可以使用阿里的nacos 替换解决 整合SpringCloud-Bus解决","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"配置中心","slug":"配置中心","permalink":"https://mykkto.github.io/tags/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"},{"name":"config","slug":"config","permalink":"https://mykkto.github.io/tags/config/"}],"author":"mykk"},{"title":"SpringCloud-Gateway路由网关","slug":"03-java分布式/01-springcloud/09_SpringCloud-GateWay","date":"2022-02-02T01:22:13.000Z","updated":"2023-02-15T14:13:06.995Z","comments":true,"path":"posts/faa2de28.html","link":"","permalink":"https://mykkto.github.io/posts/faa2de28.html","excerpt":"","text":"一、概述简介1、官网1、上一代zuul 1.Xhttps://github.com/Netflix/zuul/wiki 2、Gatewayhttps://cloud.spring.io/spring-cloud-static/spring-cloud-gateway/2.2.1.RELEASE/reference/html/ 2、是什么1、概述Gateway是在Spring生态系统之上构建的API网关服务，基于Spring 5，Spring Boot 2和 Project Reactor等技术。Gateway旨在提供一种简单而有效的方式来对API进行路由，以及提供一些强大的过滤器功能， 例如：熔断、限流、重试等 2、一句话SpringCloud Gateway 使用的Webflux中的reactor-netty响应式编程组件，底层使用了Netty通讯框架。 3、能干嘛 反向代理 鉴权 流量控制 熔断 日志监控 …… 4、网关在微服务的位置 5、GateWay优于Zuul的地方1、我们为什么选择Gateway？1、neflix不太靠谱，zuul2.0一直跳票，迟迟不发布2、SpringCloud Gateway具有如下特性 基于Spring Framework 5, Project Reactor 和 Spring Boot 2.0 进行构建； 动态路由：能够匹配任何请求属性； 可以对路由指定 Predicate（断言）和 Filter（过滤器）； 集成Hystrix的断路器功能； 集成 Spring Cloud 服务发现功能； 易于编写的 Predicate（断言）和 Filter（过滤器）； 请求限流功能； 支持路径重写。 3、SpringCloud Gateway 与 Zuul的区别 Zuul 1.x，是一个基于 阻塞 I/ O 的 API Gateway Zuul 1.x 基于Servlet 2. 5使用阻塞架构它不支持任何长连接(如 WebSocket) Zuul 的设计模式和Nginx较像，每次 I/ O 操作都是从工作线程中选择一个执行，请求线程被阻塞到工作线程完成，但是差别是Nginx 用C++ 实现，Zuul 用 Java 实现，而 JVM 本身会有第一次加载较慢的情况，使得Zuul 的性能相对较差。 Zuul 2.x理念更先进，想基于Netty非阻塞和支持长连接，但SpringCloud目前还没有整合。 Zuul 2.x的性能较 Zuul 1.x 有较大提升。在性能方面，根据官方提供的基准测试， Spring Cloud Gateway 的 RPS（每秒请求数）是Zuul 的 1. 6 倍。 Spring Cloud Gateway 建立 在 Spring Framework 5、 Project Reactor 和 Spring Boot 2 之上， 使用非阻塞 API。 Spring Cloud Gateway 还 支持 WebSocket， 并且与Spring紧密集成拥有更好的开发体验 2、Zuul1.x模型Springcloud中所集成的Zuul版本，采用的是Tomcat容器，使用的是传统的Servlet IO处理模型。 Servlet的生命周期?servlet由servlet container进行生命周期管理。 container启动时构造servlet对象并调用servlet init()进行初始化； container运行时接受请求，并为每个请求分配一个线程（一般从线程池中获取空闲线程）然后调用service()。 container关闭时调用servlet destory()销毁servlet； 3、GateWay模型WebFlux是什么 https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html#webflux-new-framework 传统的Web框架，比如说：struts2，springmvc等都是基于Servlet API与Servlet容器基础之上运行的。但是在Servlet3.1之后有了异步非阻塞的支持。而WebFlux是一个典型非阻塞异步的框架，它的核心是基于Reactor的相关API实现的。相对于传统的web框架来说，它可以运行在诸如Netty，Undertow及支持Servlet3.1的容器上。非阻塞式+函数式编程（Spring5必须让你使用java8） 二、三大核心概念1、Route(路由)路由是构建网关的基本模块，它由ID，目标URI，一系列的断言和过滤器组成，如果断言为true则匹配该路由 2、Predicate(断言)参考的是Java8的java.util.function.Predicate开发人员可以匹配HTTP请求中的所有内容(例如请求头或请求参数)，如果请求与断言相匹配则进行路由 3、Filter(过滤)指的是Spring框架中GatewayFilter的实例，使用过滤器，可以在请求被路由前或者之后对请求进行修改。 4、总体web请求，通过一些匹配条件，定位到真正的服务节点。并在这个转发过程的前后，进行一些精细化控制。predicate就是我们的匹配条件；而filter，就可以理解为一个无所不能的拦截器。有了这两个元素，再加上目标uri，就可以实现一个具体的路由了 三、Gateway工作流程1、官网客户端向 Spring Cloud Gateway 发出请求。然后在 Gateway Handler Mapping 中找到与请求相匹配的路由，将其发送到 Gateway Web Handler。 Handler 再通过指定的过滤器链来将请求发送到我们实际的服务执行业务逻辑，然后返回。过滤器之间用虚线分开是因为过滤器可能会在发送代理请求之前（“pre”）或之后（“post”）执行业务逻辑。 Filter在“pre”类型的过滤器可以做参数校验、权限校验、流量监控、日志输出、协议转换等，在“post”类型的过滤器中可以做响应内容、响应头的修改，日志的输出，流量监控等有着非常重要的作用。 2、核心逻辑路由转发+执行过滤器链 四、入门案例1、模块创建步骤1、建modelcloud-gateway-gateway9527 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-gateway-gateway9527&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--gateway--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--eureka-client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--一般基础配置类--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 9527 spring: application: name: cloud-gateway eureka: instance: hostname: cloud-gateway-service client: #服务提供者provider注册进eureka服务列表内 service-url: register-with-eureka: true fetch-registry: true defaultZone: http://eureka7001.com:7001/eureka 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; @SpringBootApplication @EnableEurekaClient public class GatewayMain9527 { public static void main(String[] args) { SpringApplication.run (GatewayMain9527.class,args); } } 2、网关映射配置1、yml配置spring: application: name: cloud-gateway cloud: gateway: routes: - id: payment_routh #payment_route #路由的ID，没有固定规则但要求唯一，建议配合服务名 uri: http://localhost:8001 #匹配后提供服务的路由地址 predicates: - Path=/payment/get/** # 断言，路径相匹配的进行路由 - id: payment_routh2 #payment_route #路由的ID，没有固定规则但要求唯一，建议配合服务名 uri: http://localhost:8001 #匹配后提供服务的路由地址 predicates: - Path=/payment/lb/** # 断言，路径相匹配的进行路由 2、配置说明 4、测试1、启动 eureka集群，启动8001/8002，启动网关9527 添加网关前uri：http://localhost:8001/payment/get/1 添加网关后uri：http://localhost:9527/payment/get/1 3、YML配置说明Gateway网关路由有两种配置方式： 1、方式一：在配置文件yml中配置既上面案例的方式 1、方式二：代码中注入RouteLocator的Beanpackage com.kk.springcloud.config; import org.springframework.cloud.gateway.route.RouteLocator; import org.springframework.cloud.gateway.route.builder.RouteLocatorBuilder; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class GatewayConfig { /** * 配置了一个id为route-name的路由规则， * 当访问地址 http://localhost:9527/kk时会自动转发到地址：http://news.baidu.com/ * * @param builder * @return */ @Bean public RouteLocator customRouteLocator(RouteLocatorBuilder builder) { RouteLocatorBuilder.Builder routes = builder.routes ( ); routes.route (\"path_route_mykk\", r -&gt; r.path (\"/kk\").uri (\"http://www.baidu.com/\")).build ( ); return routes.build ( ); } @Bean public RouteLocator customRouteLocator2(RouteLocatorBuilder builder) { RouteLocatorBuilder.Builder routes = builder.routes ( ); routes.route (\"path_route_mykk2\", r -&gt; r.path (\"/kkz\").uri (\"http://www.weibo.com/kkz\")).build ( ); return routes.build ( ); } } 五、微服务名实现动态路由1、概述默认情况下Gateway会根据注册中心注册的服务列表，以注册中心上微服务名为路径创建动态路由进行转发，从而实现动态路由的功能 2、启动一个eureka7001 + 两个服务提供者8001/8002 4、yml1、需要注意的是uri的协议为lb，表示启用Gateway的负载均衡功能。 2、lb://serviceName是spring cloud gateway在微服务中自动为我们创建的负载均衡uri server: port: 9527 spring: application: name: cloud-gateway cloud: gateway: discovery: locator: enabled: true #开启从注册中心动态创建路由的功能，利用微服务名进行路由 routes: - id: payment_routh #payment_route #路由的ID，没有固定规则但要求唯一，建议配合服务名 # uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service #匹配后提供服务的路由地址 predicates: - Path=/payment/get/** # 断言，路径相匹配的进行路由 - id: payment_routh2 #payment_route #路由的ID，没有固定规则但要求唯一，建议配合服务名 # uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service #匹配后提供服务的路由地址 predicates: - Path=/payment/lb/** # 断言，路径相匹配的进行路由 eureka: instance: hostname: cloud-gateway-service client: #服务提供者provider注册进eureka服务列表内 service-url: register-with-eureka: true fetch-registry: true defaultZone: http://eureka7001.com:7001/eureka 5、测试url：http://localhost:9527/payment/lb 六、Predicate(断言)的使用1、启动看下日志 2、Route Predicate FactoriesSpring Cloud Gateway 创建 Route 对象时， 使用 RoutePredicateFactory 创建 Predicate 对象，Predicate 对象可以赋值给 Route。 Spring Cloud Gateway 包含许多内置的Route Predicate Factories。 所有这些谓词是都匹配HTTP请求的不同属性。多种谓词工厂可以组合，并通过逻辑 and 组合。 3、常用的Route Predicate1、After Route Predicate必须要在配置断言的时区的时间之后对应的uri请求才能生效 package com.kk.test; import java.time.ZonedDateTime; public class Test { public static void main(String[] args) { ZonedDateTime zbj = ZonedDateTime.now ( ); // 默认时区 System.out.println (zbj); // ZonedDateTime zny = ZonedDateTime.now(ZoneId.of(\"America/New_York\")); // 用指定时区获取当前时间 // System.out.println(zny); } } - After=2022-02-03T13:53:16.164+08:00[Asia/Shanghai] # 断言，路径相匹配的进行路由 spring: application: name: cloud-gateway cloud: gateway: discovery: locator: enabled: true #开启从注册中心动态创建路由的功能，利用微服务名进行路由 routes: - id: payment_routh #payment_route #路由的ID，没有固定规则但要求唯一，建议配合服务名 # uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service #匹配后提供服务的路由地址 predicates: - Path=/payment/get/** # 断言，路径相匹配的进行路由 - After=2022-02-03T13:53:16.164+08:00[Asia/Shanghai] # 断言，路径相匹配的进行路由 - id: payment_routh2 #payment_route #路由的ID，没有固定规则但要求唯一，建议配合服务名 # uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service #匹配后提供服务的路由地址 predicates: - Path=/payment/lb/** # 断言，路径相匹配的进行路由 2、Before Route Predicate必须要在配置断言的时区的时间之前对应的uri请求才能生效 - Before=2022-02-03T13:53:16.164+08:00[Asia/Shanghai] # 断言，路径相匹配的进行路由 3、Between Route Predicate必须要在配置断言的时区的时间范围内对应的uri请求才能生效 - Between=2022-02-03T13:53:16.164+08:00[Asia/Shanghai],2022-12-03T13:53:16.164+08:00[Asia/Shanghai] # 断言，路径相匹配的进行路由 4、Cookie Route Predicate必须显示的指定携带的cookie信息，才能访问对应的uri - Cookie=username,mykk # 断言，路径相匹配的进行路由 1、不带cookie的情况 curl http://localhost:9527/payment/get/1 2、携带cookie的情况 curl http://localhost:9527/payment/get/1 --cookie \"username=mykk\" 5、Header Route Predicate必须显示的指定携带的请求头Header 信息，才能访问对应的uri。 两个参数：一个是属性名称和一个正则表达式，这个属性值和正则表达式匹配则执行。 - Header=X-Request-Id, \\d+ # 请求头要有X-Request-Id属性并且值为整数的正则表达式 1、不带Header的情况 curl http://localhost:9527/payment/get/1 2、携带Header的情况 curl http://localhost:9527/payment/get/1 -H \"X-Request-Id:123\" 6、Host Route Predicate必须显示的携带指定规则的主机地址 Host信息 ，才能访问对应的uri。 - Host=**.mykk.com 访问测试 curl http://localhost:9527/payment/get/1 -H \"Host:www.mykk.com\" curl http://localhost:9527/payment/get/1 -H \"Host:news.mykk.com\" 7、Method Route Predicate必须显示的指定请求方式 ，才能访问对应的uri。 - Method=GET # 请求方式 8、Path Route Predicate路由到指定的路径 9、Query Route Predicate必须显示的携带指定规则的 请求参数 ，才能访问对应的uri。 说明：支持传入两个参数，一个是属性名，一个为属性值，属性值可以是正则表达式。 测试： url：curl http://localhost:9527/payment/get/1?username=111 七、Filter的使用1、概述路由过滤器可用于修改进入的HTTP请求和返回的HTTP响应，路由过滤器只能指定路由进行使用。 Spring Cloud Gateway 内置了多种路由过滤器，他们都由GatewayFilter的工厂类来产生 1、生命周期前置：pre 后置：post 2、种类单一：GatewayFilter https://cloud.spring.io/spring-cloud-static/spring-cloud-gateway/2.2.1.RELEASE/reference/html/#the-addrequestparameter-gatewayfilter-factory 31种之多 全局：GlobalFilter 2、常用的GatewayFilterAddRequestParameter filters: - AddRequestParameter=X-Request-Id,1024 #过滤器工厂会在匹配的请求头加上一对请求头，名称为X-Request-Id值为1024 server: port: 9527 spring: application: name: cloud-gateway cloud: gateway: discovery: locator: enabled: true #开启从注册中心动态创建路由的功能，利用微服务名进行路由 routes: - id: payment_routh #payment_route #路由的ID，没有固定规则但要求唯一，建议配合服务名 # uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service #匹配后提供服务的路由地址 filters: - AddRequestParameter=X-Request-Id,1024 #过滤器工厂会在匹配的请求头加上一对请求头，名称为X-Request-Id值为1024 predicates: - Path=/payment/get/** # 断言，路径相匹配的进行路由 - After=2022-02-03T13:53:16.164+08:00[Asia/Shanghai] # 断言，路径相匹配的进行路由 # - Cookie=username,mykk # - Header=X-Request-Id, \\d+ # 请求头要有X-Request-Id属性并且值为整数的正则表达式 # - Host=**.mykk.com # - Method=GET # 请求方式 - Query=username, \\d+ # 要有参数名username并且值还要是整数才能路由 - id: payment_routh2 #payment_route #路由的ID，没有固定规则但要求唯一，建议配合服务名 # uri: http://localhost:8001 #匹配后提供服务的路由地址 uri: lb://cloud-payment-service #匹配后提供服务的路由地址 predicates: - Path=/payment/lb/** # 断言，路径相匹配的进行路由 eureka: instance: hostname: cloud-gateway-service client: #服务提供者provider注册进eureka服务列表内 service-url: register-with-eureka: true fetch-registry: true defaultZone: http://eureka7001.com:7001/eureka 3、自定义过滤器自定义全局GlobalFilter 1、两个主要接口介绍implements GlobalFilter,Ordered 2、能干嘛 全局日志记录 统一网关鉴权 …… 3、代码package com.kk.springcloud.config.config; import org.springframework.cloud.gateway.filter.GatewayFilterChain; import org.springframework.cloud.gateway.filter.GlobalFilter; import org.springframework.core.Ordered; import org.springframework.http.HttpStatus; import org.springframework.stereotype.Component; import org.springframework.web.server.ServerWebExchange; import reactor.core.publisher.Mono; import java.util.Date; @Component public class MyLogGateWayFilter implements GlobalFilter, Ordered { @Override // 过滤逻辑 public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { System.out.println(\"time:\"+new Date ()+\"\\t 执行了自定义的全局过滤器: \"+\"MyLogGateWayFilter\"+\"hello\"); String uname = exchange.getRequest().getQueryParams().getFirst(\"uname\"); if (uname == null) { System.out.println(\"****用户名为null，无法登录\"); exchange.getResponse().setStatusCode(HttpStatus.NOT_ACCEPTABLE); return exchange.getResponse().setComplete(); } return chain.filter(exchange); } // 优先级，越少越大 @Override public int getOrder() { return 0; } } 测试：curl http://localhost:9527/payment/get/1?uname=11","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"路由网关","slug":"路由网关","permalink":"https://mykkto.github.io/tags/%E8%B7%AF%E7%94%B1%E7%BD%91%E5%85%B3/"},{"name":"alibaba","slug":"alibaba","permalink":"https://mykkto.github.io/tags/alibaba/"},{"name":"Gateway","slug":"Gateway","permalink":"https://mykkto.github.io/tags/Gateway/"}],"author":"mykk"},{"title":"mysql开启远程连接","slug":"04-基础/03mysql/01_Mysql_smallPosture","date":"2022-01-27T14:27:39.000Z","updated":"2022-11-12T15:07:08.042Z","comments":true,"path":"posts/bf62bc57.html","link":"","permalink":"https://mykkto.github.io/posts/bf62bc57.html","excerpt":"","text":"1、前言最近快过年了，回去肯定是要敲代码，写博文的，近期在写SpringCloud全家桶，数据库一直是在本地，想着还有几台云机在云上运行着，于是连接了下，出现了如下问题： 之前还是好的，可能挺久没用的权限自己关闭了，安装是docker 可以参考之前博主的简书文章 ： https://www.jianshu.com/p/f554c85b25c1 版本顺便说下5.7.35 MySQL Community Server (GPL) 2、开启远程连接#开启远程连接 GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'a1b2c3' WITH GRANT OPTION; #root 用户名 #a1b2c3 密码 #刷新权限，立即生效 flush privileges; 3、修改密码#修改密码(5.7.35) set password = password ('a1b2c3'); #修改密码（高版本 8.0+） update mysql.user set authentication_string=password('a1b2c3') where user='a1b2c3'; #刷新权限，立即生效 flush privileges;","categories":[{"name":"数据库","slug":"数据库","permalink":"https://mykkto.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"小姿势","slug":"小姿势","permalink":"https://mykkto.github.io/tags/%E5%B0%8F%E5%A7%BF%E5%8A%BF/"},{"name":"linux","slug":"linux","permalink":"https://mykkto.github.io/tags/linux/"},{"name":"mysql","slug":"mysql","permalink":"https://mykkto.github.io/tags/mysql/"}],"author":"mykk"},{"title":"SpringCloud-Zuul路由网关","slug":"03-java分布式/01-springcloud/08_SpringCloud_Zuul","date":"2022-01-25T13:38:21.000Z","updated":"2022-11-12T15:07:08.043Z","comments":true,"path":"posts/d633875f.html","link":"","permalink":"https://mykkto.github.io/posts/d633875f.html","excerpt":"","text":"1、概述1、官网https://cloud.spring.io/spring-cloud-static/spring-cloud-netflix/2.2.1.RELEASE/reference/html/#router-and-filter-zuul 2、是什么Zuul是一种提供动态路由、监视、弹性、安全性等功能的边缘服务。 Zuul是Netflix出品的一个基于JVM路由和服务端的负载均衡器。 API网关为微服务架构中的服务提供了统一的访问入口，客户端通过API网关访问相关服务。API网关的定义类似于设计模式中的门面模式，它相当于整个微服务架构中的门面，所有客户端的访问都通过它来进行路由及过滤。它实现了请求路由、负载均衡、校验过滤、服务容错、服务聚合等功能。 Zuul包含了如下最主要的功能：代理+路由+过滤三大功能 3、能干嘛1、路由2、过滤3、负载均衡4、灰度发布（金丝雀发布）起源是，矿井工人发现，金丝雀对瓦斯气体很敏感，矿工会在下井之前，先放一只金丝雀到井中，如果金丝雀不叫了，就代表瓦斯浓度高。 在灰度发布开始后，先启动一个新版本应用，但是并不直接将流量切过来，而是测试人员对新版本进行线上测试，启动的这个新版本应用，就是我们的金丝雀。如果没有问题，那么可以将少量的用户流量导入到新版本上，然后再对新版本做运行状态观察，收集各种运行时数据，如果此时对新旧版本做各种数据对比，就是所谓的A/B测试。新版本没什么问题，那么逐步扩大范围、流量，把所有用户都迁移到新版本上面来。 2、路由基本配置路由功能负责将外部请求转发到具体的服务实例上去，是实现统一访问入口的基础 1、建Modelcloud-zuul-gateway9527 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-zuul-gateway9527&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 9527 spring: application: name: cloud-zuul-gateway eureka: client: service-url: #defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka,http://eureka7003.com:7003/eureka defaultZone: http://eureka7001.com:7001/eureka instance: instance-id: gateway-9527.com prefer-ip-address: true 4、hosts修改(本地环境)因为是本地环境，服务器，域名等资源有限 添加配置项：C:\\Windows\\System32\\drivers\\etc 127.0.0.1 myzuul.com 5、主启动注意：@EnableZuulProxy package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.zuul.EnableZuulProxy; @SpringBootApplication @EnableZuulProxy public class ZuulMain9527 { public static void main(String[] args) { SpringApplication.run (ZuulMain9527.class,args); } } 6、启动顺序1、eureka集群 2、8006生产者 3、9527网关 7、测试1、不用路由http://localhost:8001/payment/consul controller @GetMapping(\"/payment/consul\") public String paymentInfo() { return \"springcloud with consul: \" + serverPort + \"\\t\\t\" + UUID.randomUUID ( ).toString ( ); } 2、路由（1）zuul映射配置+注册中心注册后对外暴露的服务名称+rest调用地址 （2）url： http://myzuul.com:9527/cloud-payment-service/payment/consul ![](C:\\Users\\my_kk\\Documents\\Tencent Files\\763856958\\FileRecv_posts\\03javafenbushi\\01springcloud\\20220201141019.png) 3、路由访问映射规则1、名称代理1、yml详解zuul: routes: # 路由映射配置 mypayment.path: /mypayment/** #IE地址栏输入的路径 mypayment.serviceId: cloud-payment-service # 指定服务端的名称 server: port: 9527 spring: application: name: cloud-zuul-gateway eureka: client: service-url: #defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka,http://eureka7003.com:7003/eureka defaultZone: http://eureka7001.com:7001/eureka instance: instance-id: gateway-9527.com prefer-ip-address: true zuul: routes: # 路由映射配置 mypayment.path: /mypayment/** #IE地址栏输入的路径 mypayment.serviceId: cloud-payment-service # 指定服务端的名称 2、测试1、路由访问：OKhttp://myzuul.com:9527/mypayment/payment/consul 2、原路径访问：OKhttp://myzuul.com:9527/cloud-payment-service/payment/consul 2、忽略原有真实服务名1、yml配置zuul: ignored-services: cloud-payment-service #忽略服务名 2、测试1、使用服务名访问（失败）：http://myzuul.com:9527/cloud-payment-service/payment/consul ![](C:\\Users\\my_kk\\Documents\\Tencent Files\\763856958\\FileRecv_posts\\03javafenbushi\\01springcloud\\20220201165024.png) 2、映射访问：依旧可以！ 五角星：批量忽略zuul: ignored-services: \"*\" 3、路由转发和负载均衡功能1、生产者：SMS短信模块(8008)1、建modelcloud-provider-sms8008 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-provider-sms8008&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 8008 ###服务名称(服务注册到eureka名称) spring: application: name: cloud-provider-sms eureka: client: #服务提供者provider注册进eureka服务列表内 service-url: register-with-eureka: true fetch-registry: true defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka,http://eureka7003.com:7003/eureka #defaultZone: http://127.0.0.1:7001/eureka,http://127.0.0.1:7002/eureka #defaultZone: http://eureka7001.com:7001/eureka # eureka集群加@老本版 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; @SpringBootApplication @EnableEurekaClient public class SMSMain8008 { public static void main(String[] args) { SpringApplication.run (SMSMain8008.class,args); } } 5、业务类package com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class SMSController { @Value(\"${server.port}\") private String serverPort; @GetMapping(\"/sms\") public String sms() { return \"sms provider service: \"+\"\\t\"+serverPort; } } 6、启动服务 2、网关：zuul（9527）1、ymlzuul: # ignored-services: cloud-payment-service #忽略服务名 routes: # 路由映射配置 mysms.path: /mysms/** # IE地址栏输入的路径 mysms.serviceId: cloud-provider-sms # 指定服务端的名称 server: port: 9527 spring: application: name: cloud-zuul-gateway eureka: client: service-url: #defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka,http://eureka7003.com:7003/eureka defaultZone: http://eureka7001.com:7001/eureka instance: instance-id: gateway-9527.com prefer-ip-address: true zuul: # ignored-services: cloud-payment-service #忽略服务名 routes: # 路由映射配置 mysms.path: /mysms/** # IE地址栏输入的路径 mysms.serviceId: cloud-provider-sms # 指定服务端的名称 mypayment.path: /mypayment/** # IE地址栏输入的路径 mypayment.serviceId: cloud-payment-service # 指定服务端的名称 2、说明由于Zuul自动集成了Ribbon和Hystrix，所以Zuul天生就有负载均衡和服务容错能力 3、测试负载效果url： 4、设置统一公共前缀yml配置zuul: prefix: /mykk server: port: 9527 spring: application: name: cloud-zuul-gateway eureka: client: service-url: #defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka,http://eureka7003.com:7003/eureka defaultZone: http://eureka7001.com:7001/eureka instance: instance-id: gateway-9527.com prefer-ip-address: true zuul: prefix: /mykk # ignored-services: cloud-payment-service #忽略服务名 routes: # 路由映射配置 mysms.path: /mysms/** # IE地址栏输入的路径 mysms.serviceId: cloud-provider-sms # 指定服务端的名称 mypayment.path: /mypayment/** # IE地址栏输入的路径 mypayment.serviceId: cloud-payment-service # 指定服务端的名称 测试url（1）http://myzuul.com:9527/mykk/mypayment/payment/consul （2）http://myzuul.com:9527/mykk/mysms/sms 4、查看路由信息1、POM&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; 2、yml# 开启查看路由的端点 management: endpoints: web: exposure: include: 'routes' 3、查看路由详细信息url：http://localhost:9527/actuator/routes 5、过滤器1、功能过滤功能负责对请求过程进行额外的处理，是请求校验过滤及服务聚合的基础。 2、过滤器的生命周期 3、ZuulFilter1、过滤类型 pre：在请求被路由到目标服务前执行，比如权限校验、打印日志等功能； routing：在请求被路由到目标服务时执行 post：在请求被路由到目标服务后执行，比如给目标服务的响应添加头信息，收集统计数据等功能； error：请求在其他阶段发生错误时执行。 2、过滤顺序数字小的先执行 3、过滤是否开启shouldFilter方法为true走 4、执行逻辑自己的业务逻辑 4、案例Case1、说明前置过滤器，用于在请求路由到目标服务前打印请求日志 2、自定义过滤器过滤器代码： package com.kk.springcloud.filter; import com.netflix.zuul.ZuulFilter; import com.netflix.zuul.context.RequestContext; import com.netflix.zuul.exception.ZuulException; import lombok.extern.slf4j.Slf4j; import org.springframework.stereotype.Component; import javax.servlet.http.HttpServletRequest; import java.util.Date; @Component @Slf4j public class PreLogFilter extends ZuulFilter { /** * 定义过滤器的类型 * pre:在请求被路由之前执行 * route:在路由请求的时候执行 * post:请求路由以后执行 * error:处理请求时发生错误的时候执行 * * @return 过滤器的类型 */ @Override public String filterType() { return \"pre\"; } /** * 过滤器执行的顺序，配置多个有顺序的过滤 * 执行顺序从小到大 * * @return 执行顺序 */ @Override public int filterOrder() { // 优先级为0，数字越大，优先级越低 return 1; } /** * 是否开启过滤器 * true:开启 * false:禁用 * * @return 是否开启过滤器 */ @Override public boolean shouldFilter() { // 是否开启 return true; } /** * 过滤器的业务实现 * * @return null 没有意义 * @throws ZuulException 异常信息 */ @Override public Object run() throws ZuulException { // 业务逻辑代码 RequestContext requestContext = RequestContext.getCurrentContext ( ); HttpServletRequest request = requestContext.getRequest ( ); String host = request.getRemoteHost ( ); String method = request.getMethod ( ); String uri = request.getRequestURI ( ); log.info(\"=====&gt; Remote host:{},method:{},uri:{}\", host, method, uri); System.out.println (\"********\" + new Date ( ).getTime ( )); return null; } } 3、测试(1)url：http://myzuul.com:9527/mykk/mysms/sms (2)在调用8008之前会打印日志 4、yml 配置开关★这里需要特别注意：开启这里之后，per配置失效，不清楚为什么，博主搞了很久尝试才发现是这个问题，建议使用硬编码，在java上配置开关zuul: prefix: /mykk # ignored-services: cloud-payment-service #忽略服务名 routes: # 路由映射配置 mysms.path: /mysms/** # IE地址栏输入的路径 mysms.serviceId: cloud-provider-sms # 指定服务端的名称 mypayment.path: /mypayment/** # IE地址栏输入的路径 mypayment.serviceId: cloud-payment-service # 指定服务端的名称 #yml配置开关 # PreLogFilter: # pre: # disable: true 参考文章链接1、限制IP过滤博文https://www.jianshu.com/p/20d77ca5cfbc","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"netflix","slug":"netflix","permalink":"https://mykkto.github.io/tags/netflix/"},{"name":"路由网关","slug":"路由网关","permalink":"https://mykkto.github.io/tags/%E8%B7%AF%E7%94%B1%E7%BD%91%E5%85%B3/"},{"name":"zuul","slug":"zuul","permalink":"https://mykkto.github.io/tags/zuul/"}],"author":"mykk"},{"title":"SpringCloud-Hystrix断路器","slug":"03-java分布式/01-springcloud/07_SpringCloud_Hystrix","date":"2022-01-23T13:19:18.000Z","updated":"2022-11-12T15:07:08.072Z","comments":true,"path":"posts/b0ab6264.html","link":"","permalink":"https://mykkto.github.io/posts/b0ab6264.html","excerpt":"","text":"1、概述1、分布式系统面临的问题复杂分布式体系结构中的应用程序有数十个依赖关系，每个依赖关系在某些时候将不可避免地失败。 服务雪崩 多个微服务之间调用的时候，假设微服务A调用微服务B和微服务C，微服务B和微服务C又调用其它的微服务，这就是所谓的“扇出”。如果扇出的链路上某个微服务的调用响应时间过长或者不可用，对微服务A的调用就会占用越来越多的系统资源，进而引起系统崩溃，所谓的“雪崩效应”. 对于高流量的应用来说，单一的后端依赖可能会导致所有服务器上的所有资源都在几秒钟内饱和。比失败更糟糕的是，这些应用程序还可能导致服务之间的延迟增加，备份队列，线程和其他系统资源紧张，导致整个系统发生更多的级联故障。这些都表示需要对故障和延迟进行隔离和管理，以便单个依赖关系的失败，不能取消整个应用程序或系统。 所以，通常当你发现一个模块下的某个实例失败后，这时候这个模块依然还会接收流量，然后这个有问题的模块还调用了其他的模块，这样就会发生级联故障，或者叫雪崩。 2、是什么 Hystrix是一个用于处理分布式系统的延迟和容错的开源库，在分布式系统里，许多依赖不可避免的会调用失败，比如超时、异常等，Hystrix能够保证在一个依赖出问题的情况下，不会导致整体服务失败，避免级联故障，以提高分布式系统的弹性。 “断路器”本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控（类似熔断保险丝），向调用方返回一个符合预期的、可处理的备选响应（FallBack），而不是长时间的等待或者抛出调用方无法处理的异常，这样就保证了服务调用方的线程不会被长时间、不必要地占用，从而避免了故障在分布式系统中的蔓延，乃至雪崩。 3、能干嘛 服务降级 服务熔断 接近实时的监控 ……….. 4、官网文档https://github.com/Netflix/Hystrix/wiki/How-To-Use 5、Hystrix停更https://github.com/Netflix/Hystrix 被动修复bugs 不再接受合并请求 不再发布新版本 2、Hystrix重要概念1、服务降级1、操作服务器忙，请稍后再试，不让客户端等待并立刻返回一个友好提示，fallback 2、哪些情况会出发降级 程序运行异常 超时 服务熔断触发服务降级 线程池/信号量打满也会导致服务降级 2、服务熔断类比保险丝达到最大服务访问后，直接拒绝访问，拉闸限电，然后调用服务降级的方法并返回友好提示 就是保险丝：服务的降级-&gt;进而熔断-&gt;恢复调用链路 3、服务限流秒杀高并发等操作，严禁一窝蜂的过来拥挤，大家排队，一秒钟N个，有序进行 3、hystrix案例1、构建1、建model新建cloud-provider-hystrix-payment8001 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-provider-hystrix-payment8001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--hystrix--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--eureka client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 8001 spring: application: name: cloud-provider-hystrix-payment eureka: client: register-with-eureka: true fetch-registry: true service-url: #defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka defaultZone: http://eureka7001.com:7001/eureka 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; @SpringBootApplication @EnableEurekaClient //本服务启动后会自动注册进eureka服务中 public class PaymentHystrixMain8001 { public static void main(String[] args) { SpringApplication.run (PaymentHystrixMain8001.class,args); } } 5、业务类1、servicepackage com.kk.springcloud.service.imp; import com.kk.springcloud.service.PaymentHystrixServoce; import org.springframework.stereotype.Service; import java.util.concurrent.TimeUnit; @Service public class PaymentHystrixServoceImpl implements PaymentHystrixServoce { /** * 正常访问，一切OK * * @param id * @return */ public String paymentInfo_OK(Integer id) { return \"线程池:\" + Thread.currentThread ( ).getName ( ) + \"paymentInfo_OK,id: \" + id + \"\\t\" + \"O(∩_∩)O\"; } /** * 超时访问，演示降级 * * @param id * @return */ public String paymentInfo_TimeOut(Integer id) { try { TimeUnit.SECONDS.sleep (3); } catch (InterruptedException e) { e.printStackTrace ( ); } return \"线程池:\" + Thread.currentThread ( ).getName ( ) + \"paymentInfo_TimeOut,id: \" + id + \"\\t\" + \"O(∩_∩)O，耗费3秒\"; } } 2、controllerpackage com.kk.springcloud.controller; import com.kk.springcloud.service.imp.PaymentHystrixServoceImpl; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; @RestController @Slf4j public class PaymentHystrixController { @Autowired private PaymentHystrixServoceImpl paymentService; @Value(\"${server.port}\") private String serverPort; @GetMapping(\"/payment/hystrix/ok/{id}\") public String paymentInfo_OK(@PathVariable(\"id\") Integer id) { String result = paymentService.paymentInfo_OK(id); log.info(\"****result: \"+result); return result; } @GetMapping(\"/payment/hystrix/timeout/{id}\") public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id) throws InterruptedException { String result = paymentService.paymentInfo_TimeOut(id); log.info(\"****result: \"+result); return result; } } 6、测试1、启动顺序先启动eureka，再启动hystrix 8001 2、访问 success的方法： http://localhost:8001/payment/hystrix/ok/1 每次调用耗费3 秒钟 http://localhost:8001/payment/hystrix/timeout/1 2、高并发测试上述在非高并发情形下，还能勉强满足 1、Jmeter压测测试1、开启Jmeter，来20000个并发压死8001，20000个请求都去访问paymentInfo_TimeOut服务 2、再来一个访问从3秒到不止3秒 http://localhost:8001/payment/hystrix/timeout/1 从秒回到延迟一秒多 http://localhost:8001/payment/hystrix/ok/1 3、看演示结果两个都在自己转圈圈 为什么会被卡死：tomcat的默认的工作线程数被打满 了，没有多余的线程来分解压力和处理。 2、Jmeter压测结论上面还是服务提供者8001自己测试，假如此时外部的消费者80也来访问，那消费者只能干等，最终导致消费端80不满意，服务端8001直接被拖死 3、看热闹不嫌弃事大，80新建加入cloud-consumer-feign-hystrix-order80 1、POM&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-consumer-feign-hystrix-order80&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--hystrix--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--eureka client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--一般基础通用配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 2、YMLserver: port: 80 eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ 3、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.openfeign.EnableFeignClients; @SpringBootApplication @EnableFeignClients public class OrderHystrixMain80 { public static void main(String[] args) { SpringApplication.run (OrderHystrixMain80.class,args); } } 4、业务类 service package com.kk.springcloud.service; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.stereotype.Component; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; @Component @FeignClient(value = \"CLOUD-PROVIDER-HYSTRIX-PAYMENT\") public interface PaymentHystrixService { @GetMapping(\"/payment/hystrix/ok/{id}\") String paymentInfo_OK(@PathVariable(\"id\") Integer id); @GetMapping(\"/payment/hystrix/timeout/{id}\") String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id); } controller package com.kk.springcloud.controller; import com.kk.springcloud.service.PaymentHystrixService; import lombok.extern.slf4j.Slf4j; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; @RestController @Slf4j public class OrderHystirxController { @Resource private PaymentHystrixService paymentHystrixService; @GetMapping(\"/consumer/payment/hystrix/ok/{id}\") public String paymentInfo_OK(@PathVariable(\"id\") Integer id) { String result = paymentHystrixService.paymentInfo_OK (id); return result; } @GetMapping(\"/consumer/payment/hystrix/timeout/{id}\") public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id) { String result = paymentHystrixService.paymentInfo_TimeOut (id); return result; } } 5、测试 需要启动的服务 url http://localhost/consumer/payment/hystrix/ok/1 6、高并发测试 2W个线程压8001 消费端80微服务再去访问正常的Ok微服务8001地址，http://localhost/consumer/payment/hystrix/ok/1 消费者80，o(╥﹏╥)o 要么转圈圈等待（2W个并发） 要么消费端报超时错误（20W个并发，冲垮） 3、故障现象和导致原因 8001同一层次的其它接口服务被困死，因为tomcat线程池里面的工作线程已经被挤占完毕 80此时调用8001，客户端访问响应缓慢，转圈圈 4、上诉结论正因为有上述故障或不佳表现，才有我们的降级/容错/限流等技术诞生 5、如何解决？解决的要求1、超时导致服务器变慢(转圈)超时不再等待 2、出错(宕机或程序运行出错)出错要有兜底（降级） 3、解决 对方服务(8001)超时了，调用者(80)不能一直卡死等待，必须有服务降级 对方服务(8001)down机了，调用者(80)不能一直卡死等待，必须有服务降级 对方服务(8001)OK，调用者(80)自己出故障或有自我要求（自己的等待时间小于服务提供者），自己处理降级 3-1实战：服务降级1、降级配置注解@HystrixCommand 2、8001先从自身找问题设置自身调用超时时间的峰值，峰值内可以正常运行，超过了需要有兜底的方法处理，作服务降级fallback。 3、8001fallback1、业务类启用1、代码8001（8002）PaymentServiceImpl @HystrixCommand(fallbackMethod = \"paymentInfo_TimeOutHandler\", commandProperties = { @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"3000\") }) ----------------------- public String paymentInfo_TimeOutHandler(Integer id) { return \"/(ㄒoㄒ)/调用支付接口超时或异常：\\t\" + \"\\t当前线程池名字\" + Thread.currentThread ( ).getName ( ); } package com.kk.springcloud.service.imp; import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand; import com.netflix.hystrix.contrib.javanica.annotation.HystrixProperty; import org.springframework.stereotype.Service; import java.util.concurrent.TimeUnit; @Service public class PaymentHystrixServoceImpl { /** * 正常访问，一切OK * * @param id * @return */ public String paymentInfo_OK(Integer id) { return \"线程池:\" + Thread.currentThread ( ).getName ( ) + \"paymentInfo_OK,id: \" + id + \"\\t\" + \"O(∩_∩)O\"; } /** * 超时访问，演示降级 * * @param id * @return */ @HystrixCommand(fallbackMethod = \"paymentInfo_TimeOutHandler\", commandProperties = { @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"3000\") }) public String paymentInfo_TimeOut(Integer id) { int age = 10/0; try { TimeUnit.SECONDS.sleep (3); } catch (InterruptedException e) { e.printStackTrace ( ); } return \"线程池:\" + Thread.currentThread ( ).getName ( ) + \"paymentInfo_TimeOut,id: \" + id + \"\\t\" + \"O(∩_∩)O，耗费3秒\"; } public String paymentInfo_TimeOutHandler(Integer id) { return \"/(ㄒoㄒ)/调用支付接口超时或异常：\\t\" + \"\\t当前线程池名字\" + Thread.currentThread ( ).getName ( ); } } 2、@HystrixCommand报异常后如何处理一旦调用服务方法失败并抛出了错误信息后，会自动调用@HystrixCommand标注好的 fallbackMethod调用类中的指定方法 2、主启动类激活添加新注解@EnableCircuitBreaker 3、制造问题：测试降级效果 上图故意制造两个异常： 1 int age = 10/0; 计算异常 2 我们能接受3秒钟，它运行5秒钟，超时异常。 当前服务不可用了，做服务降级，兜底的方案都是 paymentInfo_TimeOutHandler 无论是延迟指定时间还是异常，都会到对应方法降级 4、80fallback1、说明80订单微服务，也可以更好的保护自己，自己也依样画葫芦进行客户端降级保护 2、注意点我们自己配置过的热部署方式对java代码的改动明显，但对@HystrixCommand内属性的修改建议重启微服务 3、ymlfeign: hystrix: enabled: true server: port: 80 eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ feign: hystrix: enabled: true 4、主启动@EnableHystrix package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.hystrix.EnableHystrix; import org.springframework.cloud.openfeign.EnableFeignClients; @SpringBootApplication @EnableFeignClients @EnableHystrix public class OrderHystrixMain80 { public static void main(String[] args) { SpringApplication.run (OrderHystrixMain80.class,args); } } 5、业务类 @HystrixCommand(fallbackMethod = \"paymentTimeOutFallbackMethod\", commandProperties = { @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"1500\") }) ------------------ public String paymentTimeOutFallbackMethod(@PathVariable(\"id\") Integer id) { return \"我是消费者80,对方支付系统繁忙请10秒钟后再试或者自己运行出错请检查自己,o(╥﹏╥)o\"; } package com.kk.springcloud.controller; import com.kk.springcloud.service.PaymentHystrixService; import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand; import com.netflix.hystrix.contrib.javanica.annotation.HystrixProperty; import lombok.extern.slf4j.Slf4j; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; @RestController @Slf4j public class OrderHystirxController { @Resource private PaymentHystrixService paymentHystrixService; @GetMapping(\"/consumer/payment/hystrix/ok/{id}\") @HystrixCommand(fallbackMethod = \"paymentTimeOutFallbackMethod\", commandProperties = { @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"1500\") }) public String paymentInfo_OK(@PathVariable(\"id\") Integer id) { String result = paymentHystrixService.paymentInfo_OK (id); return result; } public String paymentTimeOutFallbackMethod(@PathVariable(\"id\") Integer id) { return \"我是消费者80,对方支付系统繁忙请10秒钟后再试或者自己运行出错请检查自己,o(╥﹏╥)o\"; } @GetMapping(\"/consumer/payment/hystrix/timeout/{id}\") public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id) { String result = paymentHystrixService.paymentInfo_TimeOut (id); return result; } } 6、测试url：http://localhost//consumer/payment/hystrix/ok/1 5、目前问题 每个业务方法对应一个兜底的方法，代码膨胀 统一和自定义的分开 6、问题解决1、每个方法配置一个？？？膨胀（feign接口系列）@DefaultProperties(defaultFallback = \"\") 每个方法配置一个服务降级方法，技术上可以，实际上傻X 除了个别重要核心业务有专属，其它普通的可以通过@DefaultProperties(defaultFallback = “”) 统一跳转到统一处理结果页面 通用的和独享的各自分开，避免了代码膨胀，合理减少了代码量，O(∩_∩)O哈哈~ ----------------- @DefaultProperties(defaultFallback = \"payment_Global_FallbackMethod\") ----------------- @HystrixCommand //加了@DefaultProperties属性注解，并且没有写具体方法名字，就用统一全局的 ----------------- public String payment_Global_FallbackMethod() { return \"Global异常处理信息，请稍后再试，/(ㄒoㄒ)/~~\"; } package com.kk.springcloud.controller; import com.kk.springcloud.service.PaymentHystrixService; import com.netflix.hystrix.contrib.javanica.annotation.DefaultProperties; import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand; import com.netflix.hystrix.contrib.javanica.annotation.HystrixProperty; import lombok.extern.slf4j.Slf4j; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; @RestController @Slf4j @DefaultProperties(defaultFallback = \"payment_Global_FallbackMethod\") public class OrderHystirxController { @Resource private PaymentHystrixService paymentHystrixService; @GetMapping(\"/consumer/payment/hystrix/ok/{id}\") @HystrixCommand(fallbackMethod = \"paymentTimeOutFallbackMethod\", commandProperties = { @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"1500\") }) public String paymentInfo_OK(@PathVariable(\"id\") Integer id) { String result = paymentHystrixService.paymentInfo_OK (id); return result; } public String paymentTimeOutFallbackMethod(@PathVariable(\"id\") Integer id) { return \"我是消费者80,对方支付系统繁忙请10秒钟后再试或者自己运行出错请检查自己,o(╥﹏╥)o\"; } @GetMapping(\"/consumer/payment/hystrix/timeout/{id}\") @HystrixCommand //加了@DefaultProperties属性注解，并且没有写具体方法名字，就用统一全局的 public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id) { String result = paymentHystrixService.paymentInfo_TimeOut (id); return result; } public String payment_Global_FallbackMethod() { return \"Global异常处理信息，请稍后再试，/(ㄒoㄒ)/~~\"; } } 2、和业务逻辑混一起？？？混乱原因：服务降级，客户端去调用服务端，碰上服务端宕机或关闭 本次案例服务降级处理是在客户端80实现完成的，与服务端8001没有关系只需要为Feign客户端定义的接口添加一个服务降级处理的实现类即可实现解耦 未来我们要面对的异常 运行 超时 宕机 根据cloud-consumer-feign-hystrix-order80已经有的PaymentHystrixService接口，重新新建一个类(PaymentFallbackService)实现该接口，统一为接口里面的方法进行异常处理 service统一处理异常业务 package com.kk.springcloud.service.impl; import com.kk.springcloud.service.PaymentHystrixService; import org.springframework.stereotype.Component; @Component public class PaymentFallbackService implements PaymentHystrixService { // 如果下游的服务接口挂掉，则进入这个实现类 @Override public String paymentInfo_OK(Integer id) { return \"服务调用失败，提示来自：cloud-consumer-feign-order80\"; } @Override public String paymentInfo_TimeOut(Integer id) { return \"服务调用失败，提示来自：cloud-consumer-feign-order80\"; } } yml # 用于服务降级 在注解@FeignClient中添加fallbackFactory属性值 feign: hystrix: enabled: true #在Feign中开启Hystrix openFeign：调用下游的接口 fallback = PaymentFallbackService.class package com.kk.springcloud.service; import com.kk.springcloud.service.impl.PaymentFallbackService; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.stereotype.Component; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; @Component @FeignClient(value = \"CLOUD-PROVIDER-HYSTRIX-PAYMENT\",fallback = PaymentFallbackService.class) public interface PaymentHystrixService { @GetMapping(\"/payment/hystrix/ok/{id}\") String paymentInfo_OK(@PathVariable(\"id\") Integer id); @GetMapping(\"/payment/hystrix/timeout/{id}\") String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id); } 测试：http://localhost/consumer/payment/hystrix/ok/1 正常访问： 故意关闭微服务8001后访问： 3-2实战：服务熔断1、断路器一句话就是家里的保险丝 2、熔断是什么熔断机制概述：熔断机制是应对雪崩效应的一种微服务链路保护机制。当扇出链路的某个微服务出错不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回错误的响应信息。当检测到该节点微服务调用响应正常后，恢复调用链路。 在Spring Cloud框架里，熔断机制通过Hystrix实现。Hystrix会监控微服务间调用的状况，当失败的调用到一定阈值，缺省是5秒内20次调用失败，就会启动熔断机制。熔断机制的注解是@HystrixCommand。 3、实操修改cloud-provider-hystrix-payment8001 1、PaymentService//服务熔断 @HystrixCommand(fallbackMethod = \"paymentCircuitBreaker_fallback\", commandProperties = { @HystrixProperty(name = \"circuitBreaker.enabled\", value = \"true\"),//是否开启断路器 @HystrixProperty(name = \"circuitBreaker.requestVolumeThreshold\", value = \"10\"),//请求次数 @HystrixProperty(name = \"circuitBreaker.sleepWindowInMilliseconds\", value = \"10000\"),//时间范围 @HystrixProperty(name = \"circuitBreaker.errorThresholdPercentage\", value = \"60\"),//失败率达到多少后跳闸 }) public String paymentCircuitBreaker(@PathVariable(\"id\") Integer id) { if (id &lt; 0) { throw new RuntimeException (\"******id 不能负数\"); } String serialNumber = IdUtil.simpleUUID ( ); return Thread.currentThread ( ).getName ( ) + \"\\t\" + \"调用成功，流水号: \" + serialNumber; } public String paymentCircuitBreaker_fallback(@PathVariable(\"id\") Integer id) { return \"id 不能负数，请稍后再试，/(ㄒoㄒ)/~~ id: \" + id; } 2、PaymentController@GetMapping(\"/payment/circuit/{id}\") public String paymentCircuitBreaker(@PathVariable(\"id\") Integer id) { String result = paymentService.paymentCircuitBreaker (id); log.info (\"****result: \" + result); return result; } 4、测试正确：http://localhost:8001/payment/circuit/1 错误：http://localhost:8001/payment/circuit/-1 5、原理(小总结)1、熔断类型 熔断打开 请求不再进行调用当前服务，内部设置时钟一般为MTTR（平均故障处理时间)，当打开时长达到所设时钟则进入半熔断状态 熔断关闭 熔断关闭不会对服务进行熔断 熔断半开 部分请求根据规则调用当前服务，如果请求成功且符合规则则认为当前服务恢复正常，关闭熔断 2、官网断路器流程图1、断路器在什么情况下开始起作用涉及到断路器的三个重要参数：快照时间窗、请求总数阀值、错误百分比阀值。1：快照时间窗：断路器确定是否打开需要统计一些请求和错误数据，而统计的时间范围就是快照时间窗，默认为最近的10秒。 2：请求总数阀值：在快照时间窗内，必须满足请求总数阀值才有资格熔断。默认为20，意味着在10秒内，如果该hystrix命令的调用次数不足20次，即使所有的请求都超时或其他原因失败，断路器都不会打开。 3：错误百分比阀值：当请求总数在快照时间窗内超过了阀值，比如发生了30次调用，如果在这30次调用中，有15次发生了超时异常，也就是超过50%的错误百分比，在默认设定50%阀值情况下，这时候就会将断路器打开 2、断路器开启或者关闭的条件 当满足一定的阀值的时候（默认10秒内超过20个请求次数） 当失败率达到一定的时候（默认10秒内超过50%的请求失败） 到达以上阀值，断路器将会开启 当开启的时候，所有请求都不会进行转发 一段时间之后（默认是5秒），这个时候断路器是半开状态，会让其中一个请求进行转发。如果成功，断路器会关闭，若失败，继续开启。重复4和5 3、断路器打开之后1：再有请求调用的时候，将不会调用主逻辑，而是直接调用降级fallback。通过断路器，实现了自动地发现错误并将降级逻辑切换为主逻辑，减少响应延迟的效果。 2：原来的主逻辑要如何恢复呢？对于这一问题，hystrix也为我们实现了自动恢复功能。当断路器打开，对主逻辑进行熔断之后，hystrix会启动一个休眠时间窗，在这个时间窗内，降级逻辑是临时的成为主逻辑，当休眠时间窗到期，断路器将进入半开状态，释放一次请求到原来的主逻辑上，如果此次请求正常返回，那么断路器将继续闭合，主逻辑恢复，如果这次请求依然有问题，断路器继续进入打开状态，休眠时间窗重新计时。 4、★ All配置//========================All @HystrixCommand(fallbackMethod = \"str_fallbackMethod\", groupKey = \"strGroupCommand\", commandKey = \"strCommand\", threadPoolKey = \"strThreadPool\", commandProperties = { // 设置隔离策略，THREAD 表示线程池 SEMAPHORE：信号池隔离 @HystrixProperty(name = \"execution.isolation.strategy\", value = \"THREAD\"), // 当隔离策略选择信号池隔离的时候，用来设置信号池的大小（最大并发数） @HystrixProperty(name = \"execution.isolation.semaphore.maxConcurrentRequests\", value = \"10\"), // 配置命令执行的超时时间 @HystrixProperty(name = \"execution.isolation.thread.timeoutinMilliseconds\", value = \"10\"), // 是否启用超时时间 @HystrixProperty(name = \"execution.timeout.enabled\", value = \"true\"), // 执行超时的时候是否中断 @HystrixProperty(name = \"execution.isolation.thread.interruptOnTimeout\", value = \"true\"), // 执行被取消的时候是否中断 @HystrixProperty(name = \"execution.isolation.thread.interruptOnCancel\", value = \"true\"), // 允许回调方法执行的最大并发数 @HystrixProperty(name = \"fallback.isolation.semaphore.maxConcurrentRequests\", value = \"10\"), // 服务降级是否启用，是否执行回调函数 @HystrixProperty(name = \"fallback.enabled\", value = \"true\"), // 是否启用断路器 @HystrixProperty(name = \"circuitBreaker.enabled\", value = \"true\"), // 该属性用来设置在滚动时间窗中，断路器熔断的最小请求数。例如，默认该值为 20 的时候， // 如果滚动时间窗（默认10秒）内仅收到了19个请求， 即使这19个请求都失败了，断路器也不会打开。 @HystrixProperty(name = \"circuitBreaker.requestVolumeThreshold\", value = \"20\"), // 该属性用来设置在滚动时间窗中，表示在滚动时间窗中，在请求数量超过 // circuitBreaker.requestVolumeThreshold 的情况下，如果错误请求数的百分比超过50, // 就把断路器设置为 \"打开\" 状态，否则就设置为 \"关闭\" 状态。 @HystrixProperty(name = \"circuitBreaker.errorThresholdPercentage\", value = \"50\"), // 该属性用来设置当断路器打开之后的休眠时间窗。 休眠时间窗结束之后， // 会将断路器置为 \"半开\" 状态，尝试熔断的请求命令，如果依然失败就将断路器继续设置为 \"打开\" 状态， // 如果成功就设置为 \"关闭\" 状态。 @HystrixProperty(name = \"circuitBreaker.sleepWindowinMilliseconds\", value = \"5000\"), // 断路器强制打开 @HystrixProperty(name = \"circuitBreaker.forceOpen\", value = \"false\"), // 断路器强制关闭 @HystrixProperty(name = \"circuitBreaker.forceClosed\", value = \"false\"), // 滚动时间窗设置，该时间用于断路器判断健康度时需要收集信息的持续时间 @HystrixProperty(name = \"metrics.rollingStats.timeinMilliseconds\", value = \"10000\"), // 该属性用来设置滚动时间窗统计指标信息时划分\"桶\"的数量，断路器在收集指标信息的时候会根据 // 设置的时间窗长度拆分成多个 \"桶\" 来累计各度量值，每个\"桶\"记录了一段时间内的采集指标。 // 比如 10 秒内拆分成 10 个\"桶\"收集这样，所以 timeinMilliseconds 必须能被 numBuckets 整除。否则会抛异常 @HystrixProperty(name = \"metrics.rollingStats.numBuckets\", value = \"10\"), // 该属性用来设置对命令执行的延迟是否使用百分位数来跟踪和计算。如果设置为 false, 那么所有的概要统计都将返回 -1。 @HystrixProperty(name = \"metrics.rollingPercentile.enabled\", value = \"false\"), // 该属性用来设置百分位统计的滚动窗口的持续时间，单位为毫秒。 @HystrixProperty(name = \"metrics.rollingPercentile.timeInMilliseconds\", value = \"60000\"), // 该属性用来设置百分位统计滚动窗口中使用 “ 桶 ”的数量。 @HystrixProperty(name = \"metrics.rollingPercentile.numBuckets\", value = \"60000\"), // 该属性用来设置在执行过程中每个 “桶” 中保留的最大执行次数。如果在滚动时间窗内发生超过该设定值的执行次数， // 就从最初的位置开始重写。例如，将该值设置为100, 滚动窗口为10秒，若在10秒内一个 “桶 ”中发生了500次执行， // 那么该 “桶” 中只保留 最后的100次执行的统计。另外，增加该值的大小将会增加内存量的消耗，并增加排序百分位数所需的计算时间。 @HystrixProperty(name = \"metrics.rollingPercentile.bucketSize\", value = \"100\"), // 该属性用来设置采集影响断路器状态的健康快照（请求的成功、 错误百分比）的间隔等待时间。 @HystrixProperty(name = \"metrics.healthSnapshot.intervalinMilliseconds\", value = \"500\"), // 是否开启请求缓存 @HystrixProperty(name = \"requestCache.enabled\", value = \"true\"), // HystrixCommand的执行和事件是否打印日志到 HystrixRequestLog 中 @HystrixProperty(name = \"requestLog.enabled\", value = \"true\"), }, threadPoolProperties = { // 该参数用来设置执行命令线程池的核心线程数，该值也就是命令执行的最大并发量 @HystrixProperty(name = \"coreSize\", value = \"10\"), // 该参数用来设置线程池的最大队列大小。当设置为 -1 时，线程池将使用 SynchronousQueue 实现的队列， // 否则将使用 LinkedBlockingQueue 实现的队列。 @HystrixProperty(name = \"maxQueueSize\", value = \"-1\"), // 该参数用来为队列设置拒绝阈值。 通过该参数， 即使队列没有达到最大值也能拒绝请求。 // 该参数主要是对 LinkedBlockingQueue 队列的补充,因为 LinkedBlockingQueue // 队列不能动态修改它的对象大小，而通过该属性就可以调整拒绝请求的队列大小了。 @HystrixProperty(name = \"queueSizeRejectionThreshold\", value = \"5\"), } ) public String strConsumer() { return \"hello 2020\"; } public String str_fallbackMethod() { return \"*****fall back str_fallbackMethod\"; } 3-3实战：服务限流采用alibaba的Sentinel，后面扩展 4、hystrix工作流程 1 创建 HystrixCommand（用在依赖的服务返回单个操作结果的时候） 或 HystrixObserableCommand（用在依赖的服务返回多个操作结果的时候） 对象。2 命令执行。其中 HystrixComand 实现了下面前两种执行方式；而 HystrixObservableCommand 实现了后两种执行方式：execute()：同步执行，从依赖的服务返回一个单一的结果对象， 或是在发生错误的时候抛出异常。queue()：异步执行， 直接返回 一个Future对象， 其中包含了服务执行结束时要返回的单一结果对象。observe()：返回 Observable 对象，它代表了操作的多个结果，它是一个 Hot Obserable（不论 “事件源” 是否有 “订阅者”，都会在创建后对事件进行发布，所以对于 Hot Observable 的每一个 “订阅者” 都有可能是从 “事件源” 的中途开始的，并可能只是看到了整个操作的局部过程）。toObservable()： 同样会返回 Observable 对象，也代表了操作的多个结果，但它返回的是一个Cold Observable（没有 “订阅者” 的时候并不会发布事件，而是进行等待，直到有 “订阅者” 之后才发布事件，所以对于 Cold Observable 的订阅者，它可以保证从一开始看到整个操作的全部过程）。3 若当前命令的请求缓存功能是被启用的， 并且该命令缓存命中， 那么缓存的结果会立即以 Observable 对象的形式 返回。4 检查断路器是否为打开状态。如果断路器是打开的，那么Hystrix不会执行命令，而是转接到 fallback 处理逻辑（第 8 步）；如果断路器是关闭的，检查是否有可用资源来执行命令（第 5 步）。5 线程池/请求队列/信号量是否占满。如果命令依赖服务的专有线程池和请求队列，或者信号量（不使用线程池的时候）已经被占满， 那么 Hystrix 也不会执行命令， 而是转接到 fallback 处理逻辑（第8步）。6 Hystrix 会根据我们编写的方法来决定采取什么样的方式去请求依赖服务。HystrixCommand.run() ：返回一个单一的结果，或者抛出异常。HystrixObservableCommand.construct()： 返回一个Observable 对象来发射多个结果，或通过 onError 发送错误通知。7 Hystrix会将 “成功”、”失败”、”拒绝”、”超时” 等信息报告给断路器， 而断路器会维护一组计数器来统计这些数据。断路器会使用这些统计数据来决定是否要将断路器打开，来对某个依赖服务的请求进行 “熔断/短路”。8 当命令执行失败的时候， Hystrix 会进入 fallback 尝试回退处理， 我们通常也称该操作为 “服务降级”。而能够引起服务降级处理的情况有下面几种：第4步： 当前命令处于”熔断/短路”状态，断路器是打开的时候。第5步： 当前命令的线程池、 请求队列或 者信号量被占满的时候。第6步：HystrixObservableCommand.construct() 或 HystrixCommand.run() 抛出异常的时候。9 当Hystrix命令执行成功之后， 它会将处理结果直接返回或是以Observable 的形式返回。 tips：如果我们没有为命令实现降级逻辑或者在降级处理逻辑中抛出了异常， Hystrix 依然会返回一个 Observable 对象， 但是它不会发射任何结果数据， 而是通过 onError 方法通知命令立即中断请求，并通过onError()方法将引起命令失败的异常发送给调用者。 5、服务监控HystrixDashboard1、概述除了隔离依赖服务的调用以外，Hystrix还提供了准实时的调用监控（Hystrix Dashboard），Hystrix会持续地记录所有通过Hystrix发起的请求的执行信息，并以统计报表和图形的形式展示给用户，包括每秒执行多少请求多少成功，多少失败等。Netflix通过hystrix-metrics-event-stream项目实现了对以上指标的监控。Spring Cloud也提供了Hystrix Dashboard的整合，对监控内容转化成可视化界面。 2、仪表盘90011、建model新建cloud-consumer-hystrix-dashboard9001 2、POM&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt; &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-consumer-hystrix-dashboard9001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 9001 4、@EnableHystrixDashboardpackage com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.hystrix.dashboard.EnableHystrixDashboard; @SpringBootApplication @EnableHystrixDashboard public class HystrixDashboardMain9001 { public static void main(String[] args) { SpringApplication.run (HystrixDashboardMain9001.class,args); } } 5、所有Provider微服务提供类(8001/8002/8003)都需要监控依赖配置 &lt;!-- actuator监控信息完善 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; 6、进入面板http://localhost:9001/hystrix 3、断路器演示(服务监控hystrixDashboard)1、修改cloud-provider-hystrix-payment80011、注意新版本注意:新版本Hystrix需要在主启动类MainAppHystrix8001中指定监控路径 报错信息：Unable to connect to Command Metric Stream. /** *此配置是为了服务监控而配置，与服务容错本身无关，springcloud升级后的坑 *ServletRegistrationBean因为springboot的默认路径不是\"/hystrix.stream\"， *只要在自己的项目里配置上下面的servlet就可以了 */ @Bean public ServletRegistrationBean getServlet() { HystrixMetricsStreamServlet streamServlet = new HystrixMetricsStreamServlet(); ServletRegistrationBean registrationBean = new ServletRegistrationBean(streamServlet); registrationBean.setLoadOnStartup(1); registrationBean.addUrlMappings(\"/hystrix.stream\"); registrationBean.setName(\"HystrixMetricsStreamServlet\"); return registrationBean; } package com.kk.springcloud; import com.netflix.hystrix.contrib.metrics.eventstream.HystrixMetricsStreamServlet; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.boot.web.servlet.ServletRegistrationBean; import org.springframework.cloud.client.circuitbreaker.EnableCircuitBreaker; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; import org.springframework.context.annotation.Bean; @SpringBootApplication @EnableEurekaClient //本服务启动后会自动注册进eureka服务中 @EnableCircuitBreaker public class PaymentHystrixMain8001 { public static void main(String[] args) { SpringApplication.run (PaymentHystrixMain8001.class, args); } /** * 此配置是为了服务监控而配置，与服务容错本身无关，springcloud升级后的坑 * ServletRegistrationBean因为springboot的默认路径不是\"/hystrix.stream\"， * 只要在自己的项目里配置上下面的servlet就可以了 */ @Bean public ServletRegistrationBean getServlet() { HystrixMetricsStreamServlet streamServlet = new HystrixMetricsStreamServlet ( ); ServletRegistrationBean registrationBean = new ServletRegistrationBean (streamServlet); registrationBean.setLoadOnStartup (1); registrationBean.addUrlMappings (\"/hystrix.stream\"); registrationBean.setName (\"HystrixMetricsStreamServlet\"); return registrationBean; } } 2、监控测试1、9001监控8001http://localhost:8001/hystrix.stream 1：Delay：该参数用来控制服务器上轮询监控信息的延迟时间，默认为2000毫秒，可以通过配置该属性来降低客户端的网络和CPU消耗。 2：Title：该参数对应了头部标题Hystrix Stream之后的内容，默认会使用具体监控实例的URL，可以通过配置该信息来展示更合适的标题。 2、访问正确：http://localhost:8001/payment/circuit/1 错误：http://localhost:8001/payment/circuit/-1 3、★ 如何看仪表盘 4、搞懂一个才能看懂复杂的","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"netflix","slug":"netflix","permalink":"https://mykkto.github.io/tags/netflix/"},{"name":"断路器","slug":"断路器","permalink":"https://mykkto.github.io/tags/%E6%96%AD%E8%B7%AF%E5%99%A8/"},{"name":"Hystrix","slug":"Hystrix","permalink":"https://mykkto.github.io/tags/Hystrix/"}],"author":"mykk"},{"title":"SpringCloud-OpenFeign远程调用服务","slug":"03-java分布式/01-springcloud/06_SpringCloud_OpenFeign","date":"2022-01-21T13:32:13.000Z","updated":"2022-11-12T15:07:08.072Z","comments":true,"path":"posts/a723ac51.html","link":"","permalink":"https://mykkto.github.io/posts/a723ac51.html","excerpt":"","text":"1、概述1、是什么https://github.com/spring-cloud/spring-cloud-openfeign Feign是一个声明式的Web服务客户端，让编写Web服务客户端变得非常容易，只需创建一个接口并在接口上添加注解即可 2、能干嘛1、 Feign能干什么Feign旨在使编写Java Http客户端变得更容易。前面在使用Ribbon+RestTemplate时，利用RestTemplate对http请求的封装处理，形成了一套模版化的调用方法。但是在实际开发中，由于对服务依赖的调用可能不止一处，往往一个接口会被多处调用，所以通常都会针对每个微服务自行封装一些客户端类来包装这些依赖服务的调用。所以，Feign在此基础上做了进一步封装，由他来帮助我们定义和实现依赖服务接口的定义。在Feign的实现下，我们只需创建一个接口并使用注解的方式来配置它(以前是Dao接口上面标注Mapper注解,现在是一个微服务接口上面标注一个Feign注解即可)，即可完成对服务提供方的接口绑定，简化了使用Spring cloud Ribbon时，自动封装服务调用客户端的开发量。 2、Feign集成了Ribbon利用Ribbon维护了Payment的服务列表信息，并且通过轮询实现了客户端的负载均衡。而与Ribbon不同的是，通过feign只需要定义服务绑定接口且以声明式的方法，优雅而简单的实现了服务调用 3、区别1、feignFeign是Spring Cloud组件中的一个轻量级RESTful的HTTP服务客户端Feign内置了Ribbon，用来做客户端负载均衡，去调用服务注册中心的服务。Feign的使用方式是：使用Feign的注解定义接口，调用这个接口，就可以调用服务注册中心的服务 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt; &lt;/dependency&gt; 2、openfeignOpenFeign是Spring Cloud 在Feign的基础上支持了SpringMVC的注解，如@RequesMapping等等。OpenFeign的@FeignClient可以解析SpringMVC的@RequestMapping注解下的接口，并通过动态代理的方式产生实现类，实现类中做负载均衡并调用其他服务 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; 2、OpenFeign使用步骤1、建model新建cloud-consumer-feign-order80 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-consumer-feign-order80&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--eureka client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--一般基础通用配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、ymlserver: port: 80 eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.openfeign.EnableFeignClients; @SpringBootApplication @EnableFeignClients public class OrderFeignMain80 { public static void main(String[] args) { SpringApplication.run (OrderFeignMain80.class,args); } } 5、业务类1、新建PaymentFeignService接口并新增注解@FeignClientpackage com.kk.springcloud.service; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.stereotype.Component; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; @Component @FeignClient(value = \"CLOUD-PAYMENT-SERVICE\") public interface PaymentFeignService { @GetMapping(value = \"/payment/get/{id}\") CommonResult&lt;Payment&gt; getPaymentById(@PathVariable(\"id\") Long id); } 2、控制层Controllerpackage com.kk.springcloud.controller; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import com.kk.springcloud.service.PaymentFeignService; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; @RestController public class OrderFeignController { @Resource private PaymentFeignService paymentFeignService; @GetMapping(value = \"consumer/payment/get/{id}\") public CommonResult&lt;Payment&gt; getPaymentById(@PathVariable(\"id\") Long id){ return paymentFeignService.getPaymentById (id); } } 6、测试1、启动顺序 启动 7001/7002 eureka集群 启动 8001/8002 生产者集群 启动 OpenFeign:80 消费者 2、访问http://localhost/consumer/payment/get/1 3、Feign自带负载均衡配置项 7、小结 3、OpenFeign超时控制1、模拟超时超时设置，故意设置超时演示出错情况 1、服务提供方8001故意写暂停程序com.kk.springcloud.controller.PaymentController; @GetMapping(value = \"/payment/feign/timeout\") public String paymentFeignTimeOut() { System.out.println (\"*****paymentFeignTimeOut from port: \" + serverPort); //暂停几秒钟线程 try { TimeUnit.SECONDS.sleep (3); } catch (InterruptedException e) { e.printStackTrace ( ); } return serverPort; } 2、服务消费方80添加超时方法PaymentFeignServicecom.kk.springcloud.service.PaymentFeignService @GetMapping(value = \"/payment/feign/timeout\") String paymentFeignTimeOut(); 3、服务消费方80添加超时方法OrderFeignControllercom.kk.springcloud.controller.OrderFeignController @GetMapping(value = \"/consumer/payment/feign/timeout\") public String paymentFeignTimeOut() { return paymentFeignService.paymentFeignTimeOut ( ); } 4、测试url：http://localhost/consumer/payment/feign/timeout 5、小结OpenFeign默认等待1秒钟，超过后报错 2、是什么1、概述默认Feign客户端只等待一秒钟，但是服务端处理需要超过1秒钟，导致Feign客户端不想等待了，直接返回报错。为了避免这样的情况，有时候我们需要设置Feign客户端的超时控制。 2、默认支持Ribbon 3、超时时间配置#设置feign客户端超时时间(OpenFeign默认支持ribbon) ribbon: #指的是建立连接所用的时间，适用于网络状况正常的情况下,两端连接所用的时间 ReadTimeout: 5000 #指的是建立连接后从服务器读取到可用资源所用的时间 ConnectTimeout: 5000 4、OpenFeign日志打印功能1、是什么Feign 提供了日志打印功能，我们可以通过配置来调整日志级别，从而了解 Feign 中 Http 请求的细节。说白了就是对Feign接口的调用情况进行监控和输出 2、日志级别 NONE：默认的，不显示任何日志； BASIC：仅记录请求方法、URL、响应状态码及执行时间； HEADERS：除了 BASIC 中定义的信息之外，还有请求和响应的头信息； FULL：除了 HEADERS 中定义的信息之外，还有请求和响应的正文及元数据。 3、配置日志 beanpackage com.kk.springcloud.config; import feign.Logger; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class OpenFeignConfig { @Configuration public class FeignConfig { @Bean Logger.Level feignLoggerLevel() { return Logger.Level.FULL; } } } 4、yml中配置logging: level: # feign日志以什么级别监控哪个接口 com.kk.springcloud.service.PaymentFeignService: debug server: port: 80 eureka: client: register-with-eureka: false service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ #设置feign客户端超时时间(OpenFeign默认支持ribbon) ribbon: #指的是建立连接所用的时间，适用于网络状况正常的情况下,两端连接所用的时间 ReadTimeout: 5000 #指的是建立连接后从服务器读取到可用资源所用的时间 ConnectTimeout: 5000 logging: level: # feign日志以什么级别监控哪个接口 com.kk.springcloud.service.PaymentFeignService: debug 5、后台启动查看","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"netflix","slug":"netflix","permalink":"https://mykkto.github.io/tags/netflix/"},{"name":"远程调用服务","slug":"远程调用服务","permalink":"https://mykkto.github.io/tags/%E8%BF%9C%E7%A8%8B%E8%B0%83%E7%94%A8%E6%9C%8D%E5%8A%A1/"},{"name":"openfeign","slug":"openfeign","permalink":"https://mykkto.github.io/tags/openfeign/"}],"author":"mykk"},{"title":"SpringCloud- Ribbon负载均衡服务","slug":"03-java分布式/01-springcloud/05_SpringCloud_Ribbon","date":"2022-01-17T14:42:11.000Z","updated":"2022-11-12T15:07:08.043Z","comments":true,"path":"posts/9091e07b.html","link":"","permalink":"https://mykkto.github.io/posts/9091e07b.html","excerpt":"","text":"1、概述1、是什么 Spring Cloud Ribbon是基于Netflix Ribbon实现的一套客户端负载均衡的工具。 简单的说，Ribbon是Netflix发布的开源项目，主要功能是提供客户端的软件负载均衡算法和服务调用。Ribbon客户端组件提供一系列完善的配置项如连接超时，重试等。简单的说，就是在配置文件中列出Load Balancer（简称LB）后面所有的机器，Ribbon会自动的帮助你基于某种规则（如简单轮询，随机连接等）去连接这些机器。我们很容易使用Ribbon实现自定义的负载均衡算法。 2、官网资料1、文档https://github.com/Netflix/ribbon/wiki/Getting-Started 2、Ribbon目前也进入维护模式 未来替换方案： 3、能干吗1、LB（负载均衡）简单的说就是将用户的请求平摊的分配到多个服务上，从而达到系统的HA（高可用）。常见的负载均衡有软件Nginx，LVS，硬件 F5等。 总结：Ribbon = 负载均衡+RestTemplate调用 2、区别（ribbon VS nginx） Ribbon本地负载均衡，在调用微服务接口时候，会在注册中心上获取注册信息服务列表之后缓存到JVM本地，从而在本地实现RPC远程服务调用技术。 3、划分1、集中式LB 即在服务的消费方和提供方之间使用独立的LB设施(可以是硬件，如F5, 也可以是软件，如nginx), 由该设施负责把访问请求通过某种策略转发至服务的提供方； 2、进程内LB 将LB逻辑集成到消费方，消费方从服务注册中心获知有哪些地址可用，然后自己再从这些地址中选择出一个合适的服务器。 Ribbon就属于进程内LB，它只是一个类库，集成于消费方进程，消费方通过它来获取到服务提供方的地址。 2、Ribbon案例1、架构说明 Ribbon在工作时分成两步 第一步先选择 EurekaServer ,它优先选择在同一个区域内负载较少的server. 第二步再根据用户指定的策略，在从server取到的服务注册列表中选择一个地址。其中Ribbon提供了多种策略：比如轮询、随机和根据响应时间加权。 总结：Ribbon其实就是一个软负载均衡的客户端组件，他可以和其他所需请求的客户端结合使用，和eureka结合只是其中的一个实例。 2、POM1、坐标&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; 2、eureka-client 自带 ribbon证明如下： 可以看到spring-cloud-starter-netflix-eureka-client 确实引入了Ribbon 3、二说RestTemplate的使用1、官网https://docs.spring.io/spring-framework/docs/5.2.2.RELEASE/javadoc-api/org/springframework/web/client/RestTemplate.html 2、getForObject方法/getForEntity（读） 返回对象为响应体中数据转化成的对象，基本上可以理解为Json 返回对象为ResponseEntity对象，包含了响应中的一些重要信息，比如响应头、响应状态码、响应体等 3、postForObject/postForEntity(写)写一个单元测试用例，测试用例的内容是向指定的URL提交一个Post(帖子). @Test void testSimple() { // 请求地址 String url = \"http://jsonplaceholder.typicode.com/posts\"; // 要发送的数据对象 PostDTO postDTO = new PostDTO(); postDTO.setUserId(110); postDTO.setTitle(\"zimug 发布文章\"); postDTO.setBody(\"zimug 发布文章 测试内容\"); // 发送post请求，并输出结果 PostDTO result = restTemplate.postForObject(url, postDTO, PostDTO.class); System.out.println(result); } 上面的所有的postForObject请求传参方法，postForEntity都可以使用，使用方法上也几乎是一致的，只是在返回结果接收的时候略有差别。使用ResponseEntity&lt;T&gt; responseEntity来接收响应结果。用responseEntity.getBody()获取响应体。响应体内容同postForObject方法返回结果一致。剩下的这些响应信息就是postForEntity比postForObject多出来的内容 HttpStatus statusCode = responseEntity.getStatusCode(); 获取整体的响应状态信息 int statusCodeValue = responseEntity.getStatusCodeValue(); 获取响应码值 HttpHeaders headers = responseEntity.getHeaders(); 获取响应头等 @Test public void testEntityPoJo() { // 请求地址 String url = \"http://jsonplaceholder.typicode.com/posts\"; // 要发送的数据对象 PostDTO postDTO = new PostDTO(); postDTO.setUserId(110); postDTO.setTitle(\"zimug 发布文章\"); postDTO.setBody(\"zimug 发布文章 测试内容\"); // 发送post请求，并输出结果 ResponseEntity&lt;String&gt; responseEntity = restTemplate.postForEntity(url, postDTO, String.class); String body = responseEntity.getBody(); // 获取响应体 System.out.println(\"HTTP 响应body：\" + postDTO.toString()); //以下是postForEntity比postForObject多出来的内容 HttpStatus statusCode = responseEntity.getStatusCode(); // 获取响应码 int statusCodeValue = responseEntity.getStatusCodeValue(); // 获取响应码值 HttpHeaders headers = responseEntity.getHeaders(); // 获取响应头 System.out.println(\"HTTP 响应状态：\" + statusCode); System.out.println(\"HTTP 响应状态码：\" + statusCodeValue); System.out.println(\"HTTP Headers信息：\" + headers); } 4、GET请求方法&lt;T&gt; T getForObject(String url, Class&lt;T&gt; responseType, Object... uriVariables); &lt;T&gt; T getForObject(String url, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables); &lt;T&gt; T getForObject(URI url, Class&lt;T&gt; responseType); &lt;T&gt; ResponseEntity&lt;T&gt; getForEntity(String url, Class&lt;T&gt; responseType, Object... uriVariables); &lt;T&gt; ResponseEntity&lt;T&gt; getForEntity(String url, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables); &lt;T&gt; ResponseEntity&lt;T&gt; getForEntity(URI var1, Class&lt;T&gt; responseType); 5、POST请求方法 &lt;T&gt; T postForObject(String url, @Nullable Object request, Class&lt;T&gt; responseType, Object... uriVariables); &lt;T&gt; T postForObject(String url, @Nullable Object request, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables); &lt;T&gt; T postForObject(URI url, @Nullable Object request, Class&lt;T&gt; responseType); &lt;T&gt; ResponseEntity&lt;T&gt; postForEntity(String url, @Nullable Object request, Class&lt;T&gt; responseType, Object... uriVariables); &lt;T&gt; ResponseEntity&lt;T&gt; postForEntity(String url, @Nullable Object request, Class&lt;T&gt; responseType, Map&lt;String, ?&gt; uriVariables); &lt;T&gt; ResponseEntity&lt;T&gt; postForEntity(URI url, @Nullable Object request, Class&lt;T&gt; responseType); 3、Ribbon核心组件IRule1、IRule：根据特定算法中从服务列表中选取一个要访问的服务 轮询: com.netflix.loadbalancer.RoundRobinRule 随机: com.netflix.loadbalancer.RandomRule com.netflix.loadbalancer.RetryRule 先按照RoundRobinRule的策略获取服务，如果获取服务失败则在指定时间内会进行重试，获取可用的服务 WeightedResponseTimeRule 对RoundRobinRule的扩展，响应速度越快的实例选择权重越大，越容易被选择 BestAvailableRule 会先过滤掉由于多次访问故障而处于断路器跳闸状态的服务，然后选择一个并发量最小的服务 AvailabilityFilteringRule 先过滤掉故障实例，再选择并发较小的实例 ZoneAvoidanceRule 默认规则,复合判断server所在区域的性能和server的可用性选择服务器 2、案例修改cloud-consumer-order801、细节说明官方文档明确给出了警告：这个自定义配置类不能放在@ComponentScan所扫描的当前包下以及子包下，否则我们自定义的这个配置类就会被所有的Ribbon客户端所共享，达不到特殊化定制的目的了。 2、新建packagecom.kk.myrule 3、新建MySelfRule规则类package com.kk.myrule; import com.netflix.loadbalancer.IRule; import com.netflix.loadbalancer.RandomRule; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class MySelfRule { @Bean public IRule myRule() { return new RandomRule ( );//定义为随机 } } 4、主启动类添加@RibbonClient@RibbonClient(name = \"CLOUD-PAYMENT-SERVICE\",configuration=MySelfRule.class) 5、测试启动：（1）eureka（单个或者集群都行），（2）生产者8001（单个或者集群都行），（3）消费者80 http://localhost/consumer/payment/get/1 4、Ribbon负载均衡算法1、原理负载均衡算法：rest接口第几次请求数 % 服务器集群总数量 = 实际调用服务器位置下标 ，每次服务重启动后rest接口计数从1开始。 List instances = discoveryClient.getInstances(“CLOUD-PAYMENT-SERVICE”); 如： List [0] instances = 127.0.0.1:8002 List [1] instances = 127.0.0.1:8001 8001+ 8002 组合成为集群，它们共计2台机器，集群总数为2， 按照轮询算法原理： 当总请求数为1时： 1 % 2 =1 对应下标位置为1 ，则获得服务地址为127.0.0.1:8001当总请求数位2时： 2 % 2 =0 对应下标位置为0 ，则获得服务地址为127.0.0.1:8002当总请求数位3时： 3 % 2 =1 对应下标位置为1 ，则获得服务地址为127.0.0.1:8001当总请求数位4时： 4 % 2 =0 对应下标位置为0 ，则获得服务地址为127.0.0.1:8002如此类推…… 2、RoundRobinRule源码 这里不是死循环，而是自旋锁，compareAndSet（CAS操作，JUC中乐观锁的底层实现） 3、手写1、8001和8002分别加入 @Value(\"${server.port}\") private String serverPort; @GetMapping(value = \"/payment/lb\") public String getPaymentLB() { return serverPort; } 2、去掉注解@LoadBalanced 3、新建LoadBalancer接口package com.kk.springcloud.lb; import org.springframework.cloud.client.ServiceInstance; import java.util.List; public interface LoadBalancer { ServiceInstance instances(List&lt;ServiceInstance&gt; serviceInstances); } 4、新建MyLBpackage com.kk.springcloud.lb; import org.springframework.cloud.client.ServiceInstance; import org.springframework.stereotype.Component; import java.util.List; import java.util.concurrent.atomic.AtomicInteger; @Component public class MyLB implements LoadBalancer { private AtomicInteger atomicInteger = new AtomicInteger (0); @Override public ServiceInstance instances(List&lt;ServiceInstance&gt; serviceInstances) { int index = getAndIncrement ( ) % serviceInstances.size ( ); return serviceInstances.get (index); } public final int getAndIncrement() { int current; int next; do { current = this.atomicInteger.get ( ); next = current &gt;= 2147483647 ? 0 : current + 1; } while (!this.atomicInteger.compareAndSet (current, next)); System.out.println (\"*****next: \" + next); return next; } } 5、OrderController@Resource private LoadBalancer loadBalancer; @GetMapping(\"/consumer/payment/lb\") public String getPaymentLB() { List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances (\"CLOUD-PAYMENT-SERVICE\"); if (instances == null || instances.size ( ) &lt;= 0) { return null; } ServiceInstance serviceInstance = loadBalancer.instances (instances); URI uri = serviceInstance.getUri ( ); return restTemplate.getForObject (uri + \"/payment/lb\", String.class); } package com.kk.springcloud.controller; import com.kk.springcloud.lb.LoadBalancer; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import lombok.extern.slf4j.Slf4j; import org.springframework.cloud.client.ServiceInstance; import org.springframework.cloud.client.discovery.DiscoveryClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import javax.annotation.Resource; import java.net.URI; import java.util.List; @RestController @Slf4j public class OrderController { //public static final String PAYMENT_URL = \"http://localhost:8001\"; public static final String PAYMENT_URL = \"http://cloud-payment-service\"; //可以获取注册中心上的服务列表 @Resource private DiscoveryClient discoveryClient; @Resource private LoadBalancer loadBalancer; @GetMapping(\"/consumer/payment/lb\") public String getPaymentLB() { List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances (\"CLOUD-PAYMENT-SERVICE\"); if (instances == null || instances.size ( ) &lt;= 0) { return null; } ServiceInstance serviceInstance = loadBalancer.instances (instances); URI uri = serviceInstance.getUri ( ); return restTemplate.getForObject (uri + \"/payment/lb\", String.class); } @Resource private RestTemplate restTemplate; @GetMapping(\"/consumer/payment/create\") public CommonResult&lt;Payment&gt; create(Payment payment) { return restTemplate.postForObject (PAYMENT_URL + \"/payment/create\", payment, CommonResult.class); //写操作 } @GetMapping(\"/consumer/payment/get/{id}\") public CommonResult&lt;Payment&gt; getPayment(@PathVariable(\"id\") Long id) { return restTemplate.getForObject (PAYMENT_URL + \"/payment/get/\" + id, CommonResult.class); } } 6、测试http://localhost/consumer/payment/lb 注意：8001和8002别名配置都要配好否则自定义算法 获取的url会报错","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"netflix","slug":"netflix","permalink":"https://mykkto.github.io/tags/netflix/"},{"name":"负载均衡","slug":"负载均衡","permalink":"https://mykkto.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"ribbon","slug":"ribbon","permalink":"https://mykkto.github.io/tags/ribbon/"}],"author":"mykk"},{"title":"hexo + github 在百度和谷歌 SEO站点收录","slug":"00-blog/01_seo","date":"2022-01-16T14:41:15.000Z","updated":"2022-11-12T15:07:08.028Z","comments":true,"path":"posts/f1d997d.html","link":"","permalink":"https://mykkto.github.io/posts/f1d997d.html","excerpt":"","text":"1、百度 seo1、登陆百度站长管理https://ziyuan.baidu.com/linksubmit/url?sitename=http://site:abc.github.io 2、填写自己的blog地址 3、hexo设置校验C:\\Users\\Administrator\\Desktop\\myblog\\mykkTo.github.io\\themes\\matery\\layout\\_partial 4、成功 5、站点收录https://mykkto.github.io/baidu_urls.txt 2、谷歌 seo参考https://www.jianshu.com/p/9be9b4786f97","categories":[{"name":"博客","slug":"博客","permalink":"https://mykkto.github.io/categories/%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://mykkto.github.io/tags/hexo/"},{"name":"github","slug":"github","permalink":"https://mykkto.github.io/tags/github/"},{"name":"seo","slug":"seo","permalink":"https://mykkto.github.io/tags/seo/"},{"name":"百度","slug":"百度","permalink":"https://mykkto.github.io/tags/%E7%99%BE%E5%BA%A6/"},{"name":"谷歌","slug":"谷歌","permalink":"https://mykkto.github.io/tags/%E8%B0%B7%E6%AD%8C/"}],"author":"mykk"},{"title":"SpringCloud-Consul","slug":"03-java分布式/01-springcloud/04_SpringCloud_Consul","date":"2022-01-16T13:42:11.000Z","updated":"2022-11-12T15:07:08.072Z","comments":true,"path":"posts/51c7125f.html","link":"","permalink":"https://mykkto.github.io/posts/51c7125f.html","excerpt":"","text":"1、Consul简介1、是什么 Consul 是一套开源的分布式服务发现和配置管理系统，由 HashiCorp 公司用 Go 语言开发。 提供了微服务系统中的服务治理、配置中心、控制总线等功能。这些功能中的每一个都可以根据需要单独使用，也可以一起使用以构建全方位的服务网格，总之Consul提供了一种完整的服务网格解决方案。 它具有很多优点。包括： 基于 raft 协议，比较简洁； 支持健康检查, 同时支持 HTTP 和 DNS 协议 支持跨数据中心的 WAN 集群 提供图形界面 跨平台，支持 Linux、Mac、Windows 2、能干嘛1、服务发现提供HTTP和DNS两种发现方式。 2、健康监测支持多种方式，HTTP、TCP、Docker、Shell脚本定制化监控 3、KV存储Key、Value的存储方式 4、多数据中心Consul支持多数据中心 5、可视化Web界面3、官网文档1、下载地址https://www.consul.io/downloads.html 2、学习文档https://www.springcloud.cc/spring-cloud-consul.html 2、安装并运行Consul1、官网安装https://www.consul.io/downloads 2、安装说明下载完成后只有一个consul.exe文件，硬盘路径下双击运行，查看版本号信息 3、使用开发模式启动（1）命令：consul agent -dev （2）通过以下地址可以访问Consul的首页：http://localhost:8500 （3）效果： 3、服务提供者1、建modelcloud-providerconsul-payment8006 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-providerconsul-payment8006&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--SpringCloud consul-server --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- SpringBoot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--日常通用jar包配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、yml###consul服务端口号 server: port: 8006 spring: application: name: consul-provider-payment ####consul注册中心地址 cloud: consul: host: localhost port: 8500 discovery: #hostname: 127.0.0.1 service-name: ${spring.application.name} 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class Payment8006 { public static void main(String[] args) { SpringApplication.run (Payment8006.class,args); } } 5、业务类package com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; import java.util.UUID; @RestController public class PaymentController { @Value(\"${server.port}\") private String serverPort; @GetMapping(\"/payment/consul\") public String paymentInfo() { return \"springcloud with consul: \" + serverPort + \"\\t\\t\" + UUID.randomUUID ( ).toString ( ); } } 5、测试1、访问http://localhost:8006/payment/consul 2、控制台 4、服务消费者1、建modelcloud-consumerconsul-order82 2、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-consumerconsul-order82&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--SpringCloud consul-server --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- SpringBoot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--日常通用jar包配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、yml###consul服务端口号 server: port: 82 spring: application: name: cloud-consumer-order ####consul注册中心地址 cloud: consul: host: localhost port: 8500 discovery: #hostname: 127.0.0.1 service-name: ${spring.application.name} 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @SpringBootApplication @EnableDiscoveryClient public class OrderConsulMain82 { public static void main(String[] args) { SpringApplication.run (OrderConsulMain82.class,args); } } 5、业务类1、Bean配置类package com.kk.springcloud.config; import org.springframework.cloud.client.loadbalancer.LoadBalanced; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.web.client.RestTemplate; @Configuration public class ApplicationContextBean { @Bean @LoadBalanced public RestTemplate getRestTemplate() { return new RestTemplate ( ); } } 2、Controllerpackage com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; @RestController public class OrderConsulController { public static final String INVOKE_URL = \"http://cloud-provider-payment\"; //consul-provider-payment @Autowired private RestTemplate restTemplate; @GetMapping(value = \"/consumer/payment/consul\") public String paymentInfo() { String result = restTemplate.getForObject (INVOKE_URL + \"/payment/consul\", String.class); System.out.println (\"消费者调用支付服务(consule)---&gt;result:\" + result); return result; } } 6、测试1、客户端 2、访问http://localhost/consumer/payment/consul 5、三个注册中心异同点1、CAPCAP理论关注粒度是数据，而不是整体系统设计的策略 C:Consistency（强一致性） A:Availability（可用性） P:Partition tolerance（分区容错性） 2、CAP图最多只能同时较好的满足两个。 CAP理论的核心是：一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求，因此，根据 CAP 原理将 NoSQL 数据库分成了满足 CA 原则、满足 CP 原则和满足 AP 原则三 大类：CA - 单点集群，满足一致性，可用性的系统，通常在可扩展性上不太强大。CP - 满足一致性，分区容忍必的系统，通常性能不是特别高。AP - 满足可用性，分区容忍性的系统，通常可能对一致性要求低一些。 3、AP-CP架构图1、AP(Eureka)AP架构 当网络分区出现后，为了保证可用性，系统B可以返回旧值，保证系统的可用性。结论：违背了一致性C的要求，只满足可用性和分区容错，即AP 2、CP(Zookeeper/Consul)CP架构 当网络分区出现后，为了保证一致性，就必须拒接请求，否则无法保证一致性结论：违背了可用性A的要求，只满足一致性和分区容错，即CP","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"服务注册与发现","slug":"服务注册与发现","permalink":"https://mykkto.github.io/tags/%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0/"},{"name":"Consul","slug":"Consul","permalink":"https://mykkto.github.io/tags/Consul/"}],"author":"mykk"},{"title":"Springcloud-Zookeeper(快速入门)","slug":"03-java分布式/01-springcloud/03_SpringCloud-Zookeeper","date":"2022-01-15T15:01:12.000Z","updated":"2022-11-12T15:07:08.043Z","comments":true,"path":"posts/c0125b8a.html","link":"","permalink":"https://mykkto.github.io/posts/c0125b8a.html","excerpt":"","text":"安装参考【后面写】https://blog.csdn.net/zhou_fan_xi/article/details/103275955 安装完，windown访问测试 telnet 106.52.23.202 2181 1、注册中心Zookeeper基本概述 zookeeper是一个分布式协调工具，可以实现注册中心功能 关闭Linux服务器防火墙后才能启动zookeeper服务器 zookeeper服务器取代Eureka服务器，zk作为服务注册中心 2、服务提供者1、建model新建cloud-provider-payment8004 2、写pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-provider-payment8004&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!-- SpringBoot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- SpringBoot整合zookeeper客户端 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zookeeper-discovery&lt;/artifactId&gt; &lt;!--先排除自带的zookeeper3.5.3--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!--添加zookeeper3.4.9版本--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.9&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、改yml#8004表示注册到zookeeper服务器的支付服务提供者端口号 server: port: 8004 #服务别名----注册zookeeper到注册中心名称 spring: application: name: cloud-provider-payment cloud: zookeeper: connect-string: 106.52.23.202:2181 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @SpringBootApplication @EnableDiscoveryClient//该注解用于向使用consul或者zookeeper作为注册中心时注册服务 public class PaymentMain8004 { public static void main(String[] args) { SpringApplication.run (PaymentMain8004.class,args); } } 5、业务类package com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import java.util.UUID; @RestController public class PaymentController { @Value(\"${server.port}\") private String serverPort; @RequestMapping(value = \"/payment/zk\") public String paymentzk() { return \"springcloud with zookeeper: \" + serverPort + \"\\t\" + UUID.randomUUID ( ).toString ( ); } } 6、启动8004注册进zookeeper1、liunx启动 zookeeper#查看执行路径 [root@VM-0-13-centos bin]# pwd /root/zookeeper-3.4.9/bin #启动 [root@VM-0-13-centos bin]# ./zkServer.sh start #停止 [root@VM-0-13-centos bin]# ./zkServer.sh stop #重启 [root@VM-0-13-centos bin]# ./zkServer.sh restart 7、测试1、访问服务http://localhost:8004/payment/zk 2、查看服务端被是否被注册#进入 zookeeper客户端 [root@VM-0-13-centos bin]# ./zkCli.sh WatchedEvent state:SyncConnected type:None path:null #查看序列 [zk: localhost:2181(CONNECTED) 0] ls /services/cloud-provider-payment [a6293666-45c1-490e-adb8-bee63f121983] #查看详细信息 [zk: localhost:2181(CONNECTED) 1] ls /services/cloud-provider-payment/a6293666-45c1-490e-adb8-bee63f121983 [] [zk: localhost:2181(CONNECTED) 2] get /services/cloud-provider-payment/a6293666-45c1-490e-adb8-bee63f121983 {\"name\":\"cloud-provider-payment\",\"id\":\"a6293666-45c1-490e-adb8-bee63f121983\",\"address\":\"FYYX-2020GVNPLA\",\"port\":8004,\"sslPort\":null,\"payload\":{\"@class\":\"org.springframework.cloud.zookeeper.discovery.ZookeeperInstance\",\"id\":\"application-1\",\"name\":\"cloud-provider-payment\",\"metadata\":{}},\"registrationTimeUTC\":1642423897607,\"serviceType\":\"DYNAMIC\",\"uriSpec\":{\"parts\":[{\"value\":\"scheme\",\"variable\":true},{\"value\":\"://\",\"variable\":false},{\"value\":\"address\",\"variable\":true},{\"value\":\":\",\"variable\":false},{\"value\":\"port\",\"variable\":true}]}} 8、思考服务节点是临时节点还是持久节点？？ （1）当我关闭 8004节点后，zookeeper 依旧会持续发心跳，当有接收到反馈则还有序列号，没有则返回空[] （2）然后再次启动，则返回一个新的序列，由此说明这是一个临时节点 3、服务消费者1、建model新建cloud-consumerzk-order81 2、写pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-consumerzk-order81&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!-- SpringBoot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- SpringBoot整合zookeeper客户端 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zookeeper-discovery&lt;/artifactId&gt; &lt;!--先排除自带的zookeeper--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!--添加zookeeper3.4.9版本--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.9&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、改yml#81表示注册到zookeeper服务器的支付服务提供者端口号 server: port: 81 #服务别名----注册zookeeper到注册中心名称 spring: application: name: cloud-consumer-order cloud: zookeeper: connect-string: 106.52.23.202:2181 4、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @SpringBootApplication @EnableDiscoveryClient public class OrderZK81 { public static void main(String[] args) { SpringApplication.run (OrderZK81.class,args); } } 5、业务类1、配置Beanpackage com.kk.springcloud.config; import org.springframework.cloud.client.loadbalancer.LoadBalanced; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.web.client.RestTemplate; @Configuration public class ApplicationContextBean { @Bean @LoadBalanced// 给予 RestTemplate 负载均衡的能力 public RestTemplate getRestTemplate() { return new RestTemplate ( ); } } 2、Controllerpackage com.kk.springcloud.controller; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; @RestController public class OrderZKController81 { public static final String INVOKE_URL = \"http://cloud-provider-payment\"; @Autowired private RestTemplate restTemplate; @RequestMapping(value = \"/consumer/payment/zk\") public String paymentInfo() { String result = restTemplate.getForObject (INVOKE_URL + \"/payment/zk\", String.class); System.out.println (\"消费者调用支付服务(zookeeper)---&gt;result:\" + result); return result; } } 6、测试1、zookeeper[zk: localhost:2181(CONNECTED) 21] ls /services [cloud-provider-payment, cloud-consumer-order] 2、访问http://localhost:81/consumer/payment/zk","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"服务注册与发现","slug":"服务注册与发现","permalink":"https://mykkto.github.io/tags/%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://mykkto.github.io/tags/Zookeeper/"}],"author":"mykk"},{"title":"SpringCloud-Eureka","slug":"03-java分布式/01-springcloud/02_SpringCloud-Eureka","date":"2022-01-14T14:35:22.000Z","updated":"2022-11-12T15:07:08.072Z","comments":true,"path":"posts/402d692e.html","link":"","permalink":"https://mykkto.github.io/posts/402d692e.html","excerpt":"","text":"1、Eureka基础知识1、什么是服务治理 Spring Cloud 封装了 Netflix 公司开发的 Eureka 模块来实现服务治理 在传统的rpc远程调用框架中，管理每个服务与服务之间依赖关系比较复杂，管理比较复杂，所以需要使用服务治理，管理服务于服务之间依赖关系，可以实现服务调用、负载均衡、容错等，实现服务发现与注册。 2、什么是服务注册1、概念 Eureka采用了CS的设计架构，Eureka Server 作为服务注册功能的服务器，它是服务注册中心。而系统中的其他微服务，使用 Eureka的客户端连接到 Eureka Server并维持心跳连接。这样系统的维护人员就可以通过 Eureka Server 来监控系统中各个微服务是否正常运行。 在服务注册与发现中，有一个注册中心。当服务器启动的时候，会把当前自己服务器的信息 比如 服务地址通讯地址等以别名方式注册到注册中心上。另一方（消费者|服务提供者），以该别名的方式去注册中心上获取到实际的服务通讯地址，然后再实现本地RPC调用RPC远程调用框架核心设计思想：在于注册中心，因为使用注册中心管理每个服务与服务之间的一个依赖关系(服务治理概念)。在任何rpc远程框架中，都会有一个注册中心(存放服务地址相关信息(接口地址)) 2、图解 3、Eureka两组件1、EurekaServer提供服务注册服务各个微服务节点通过配置启动后，会在EurekaServer中进行注册，这样EurekaServer中的服务注册表中将会存储所有可用服务节点的信息，服务节点的信息可以在界面中直观看到。 2、EurekaClient通过注册中心进行访问是一个Java客户端，用于简化Eureka Server的交互，客户端同时也具备一个内置的、使用轮询(round-robin)负载算法的负载均衡器。在应用启动后，将会向Eureka Server发送心跳(默认周期为30秒)。如果Eureka Server在多个心跳周期内没有接收到某个节点的心跳，EurekaServer将会从服务注册表中把这个服务节点移除（默认90秒） 2、单机Eureka构建步骤1、eurekaServer端服务注册中心1、建modelcloud-eureka-server7001 2、写pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-eureka-server7001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--eureka-server--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--boot web actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--一般通用配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、改ymlserver: port: 7001 eureka: instance: hostname: localhost #eureka服务端的实例名称 client: #false表示不向注册中心注册自己。 register-with-eureka: false #false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务 fetch-registry: false service-url: #设置与Eureka Server交互的地址查询服务和注册服务都需要依赖这个地址。 defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 4、主启动@SpringBootApplication @EnableEurekaServer public class EurekaMain7001 { public static void main(String[] args) { SpringApplication.run (EurekaMain7001.class,args); } } 5、测试1、访问：http://localhost:7001/ 2、返回结果页面 No application available 没有服务被发现 O(∩_∩)O因为没有注册服务进来当然不可能有服务被发现 2、EurekaClient端provider-80011、建model(不变)cloud-provider-payment8001 2、写pom（增加）以前老版本，别再使用 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; 现在新版本,当前使用 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; 3、改yml(增加)eureka: client: #表示是否将自己注册进EurekaServer默认为true。 register-with-eureka: true #是否从EurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetchRegistry: true service-url: defaultZone: http://localhost:7001/eureka 4、主启动(添加)@EnableEurekaClient 5、测试（1）先要启动EurekaServer，再启动8001 （2）访问：http://localhost:7001/ 6、自我保护机制 3、EurekaClient端consumer-801、建model（不变）2、写pom（同上） &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--引入公共部分--&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; 3、改yml（同上）eureka: client: #表示是否将自己注册进EurekaServer默认为true。 register-with-eureka: true #是否从EurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetchRegistry: true service-url: defaultZone: http://localhost:7001/eureka 4、主启动（同上）@SpringBootApplication @EnableEurekaClient public class PaymentMain8001 { public static void main(String[] args) { SpringApplication.run (PaymentMain8001.class, args); } } 5、测试（1）先要启动EurekaServer，再启动80 （2）访问：http://localhost/consumer/payment/get/1 3、集群Eureka构建步骤1、Eureka集群原理说明1、图解 2、问题：微服务RPC远程服务调用最核心的是什么3、解决方案：高可用，试想你的注册中心只有一个only one，会导致整个为服务环境不可用，所以 解决办法：搭建Eureka注册中心集群 ，实现负载均衡+故障容错 2、EurekaServer集群环境构建步骤1、建model新建cloud-eureka-server7002，参考7001 2、写pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-eureka-server7002&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--eureka-server--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--boot web actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--一般通用配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 3、修配置由于本地主机只有一台，为了模拟两台（多台)，则将 多个ip（域名eureka7001.com,eureka7002.com) 指向本地(127.0.0.1) 1、找到对应的配置目录C:\\Windows\\System32\\drivers\\etc 2、写入配置文件 127.0.0.1 eureka7001.com127.0.0.1 eureka7002.com 4、改yml1、7001server: port: 7001 eureka: instance: hostname: eureka7001.com #eureka服务端的实例名称 client: register-with-eureka: false #false表示不向注册中心注册自己。 fetch-registry: false #false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务 service-url: defaultZone: http://eureka7002.com:7002/eureka/ 2、7002server: port: 7002 eureka: instance: hostname: eureka7002.com #eureka服务端的实例名称 client: register-with-eureka: false #false表示不向注册中心注册自己。 fetch-registry: false #false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务 service-url: defaultZone: http://eureka7001.com:7001/eureka/ 5、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer; @SpringBootApplication @EnableEurekaServer public class EurekaMain7002 { public static void main(String[] args) { SpringApplication.run (EurekaMain7002.class,args); } } 3、支付8001发布到Eureka集群1、修改yml主要修改一处：defaultZone: server: port: 8001 spring: application: name: cloud-payment-service datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: jdbc:mysql://localhost:3306/spring_cloud?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: a1b2c3 eureka: client: #表示是否将自己注册进EurekaServer默认为true。 register-with-eureka: true #是否从EurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetchRegistry: true service-url: #defaultZone: http://localhost:7001/eureka defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka # 集群版 mybatis: mapperLocations: classpath:mapper/*.xml type-aliases-package: com.kk.springclond.entities 4、订单80发布到Eureka集群1、修改yml主要修改一处：defaultZone: server: port: 80 spring: application: name: cloud-consumer-service eureka: client: #表示是否将自己注册进EurekaServer默认为true。 register-with-eureka: true #是否从EurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetchRegistry: true service-url: #defaultZone: http://localhost:7001/eureka defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka # 集群版 5、测试流程测试以上配置是否生效 1、启动集群先要启动EurekaServer，7001/7002服务 2、启动生产者再要启动服务提供者provider，8001 3、启动消费者再要启动消费者，80 4、测试http://localhost/consumer/payment/get/1 6、支付8001集群构建【8002】1、方式一：直接把整份8001 copy出一个新的，需改yml ，port即可【推荐】 server: port: 8002 2、方式二：（1）打开idea配置，取消勾选单一服务按钮 （2）修改yml server: port: 8002 （3）启动 7、负载均衡1、订单80调用调整在调用的时候不能写死成ip+端口，需要使用服务名：cloud-payment-service 2、@LoadBalanced注解使用@LoadBalanced注解赋予RestTemplate负载均衡的能力 修改配置信息添加注解【80端口】 8、测试负载均衡1、启动顺序说明（1）先要启动EurekaServer，7001/7002服务 （2）再要启动服务提供者provider，8001/8002服务 2、访问http://localhost/consumer/payment/get/1 3、结果（1）达到负载效果 （2）8001/8002端口交替出现 4、小结Ribbon和Eureka整合后Consumer可以直接调用服务而不用再关心地址和端口号，且该服务还有负载功能了 4、actuator微服务信息完善1、主机名称:服务名称修改1、当前问题含有主机名名称 2、修改8001instance: instance-id: payment8001 完整 yml server: port: 8001 spring: application: name: cloud-payment-service datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: jdbc:mysql://localhost:3306/spring_cloud?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: a1b2c3 eureka: client: #表示是否将自己注册进EurekaServer默认为true。 register-with-eureka: true #是否从EurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetchRegistry: true service-url: #defaultZone: http://localhost:7001/eureka defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka # 集群版 instance: instance-id: payment8001 mybatis: mapperLocations: classpath:mapper/*.xml type-aliases-package: com.kk.springclond.entities 3、效果其实就是取别名 2、访问信息有IP信息提示1、问题：没有IP提示 2、修改8001prefer-ip-address: true #访问路径可以显示IP地址 3、效果 5、服务发现Discovery1、概述对于注册进eureka里面的微服务，可以通过服务发现来获得该服务的信息 2、修改8001的Controller1、增加@Resource private DiscoveryClient discoveryClient; @Value(\"${server.port}\") private String serverPort; /** * 查看注册服务的信息 * @return */ @GetMapping(value = \"/payment/discovery\") public Object discovery() { // 目前已经注册的微服务列表 List&lt;String&gt; services = discoveryClient.getServices ( ); for (String element : services) { log.info (element); } // 根据名称获取的微服务实例（就像类和对象的关系） List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances (\"CLOUD-PAYMENT-SERVICE\"); for (ServiceInstance element : instances) { log.info (element.getServiceId ( ) + \"\\t\" + element.getHost ( ) + \"\\t\" + element.getPort ( ) + \"\\t\" + element.getUri ( )); } return this.discoveryClient; } 2、全部package com.kk.springcloud.controller; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import com.kk.springcloud.service.PaymentService; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Value; import org.springframework.cloud.client.ServiceInstance; import org.springframework.cloud.client.discovery.DiscoveryClient; import org.springframework.web.bind.annotation.*; import javax.annotation.Resource; import java.util.List; @RestController @Slf4j /* * @Description: * @Author: 阿K * @CreateDate: 2022/1/16 18:11 * @Param: * @Return: **/ public class PaymentController { @Resource private PaymentService paymentService; @Resource private DiscoveryClient discoveryClient; @Value(\"${server.port}\") private String serverPort; /** * 查看注册服务的信息 * * @return */ @GetMapping(value = \"/payment/discovery\") public Object discovery() { // 目前已经注册的微服务列表 List&lt;String&gt; services = discoveryClient.getServices ( ); for (String element : services) { log.info (element); } // 根据名称获取的微服务实例（就像类和对象的关系） List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances (\"CLOUD-PAYMENT-SERVICE\"); for (ServiceInstance element : instances) { log.info (element.getServiceId ( ) + \"\\t\" + element.getHost ( ) + \"\\t\" + element.getPort ( ) + \"\\t\" + element.getUri ( )); } return this.discoveryClient; } @PostMapping(value = \"/payment/create\") public CommonResult create(@RequestBody Payment payment) { int result = paymentService.create (payment); log.info (\"*****插入结果1：\" + result + \"111\"); if (result &gt; 0) { //成功 return new CommonResult (200, \"插入数据库成功\", result); } else { return new CommonResult (444, \"插入数据库失败\", null); } } @GetMapping(value = \"/payment/get/{id}\") public CommonResult getPaymentById(@PathVariable(\"id\") Long id) { Payment payment = paymentService.getPaymentById (id); log.info (\"*****查询结果：\" + payment); if (payment != null) { //说明有数据，能查询成功 return new CommonResult (200, \"查询成功8081\", payment); } else { return new CommonResult (444, \"没有对应记录，查询ID：\" + id, null); } } } 3、8001主启动1、增加@EnableDiscoveryClient 2、全部package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; @SpringBootApplication @EnableEurekaClient// 此注解后期若是不用 Eureka，将被下方注解所代替 @EnableDiscoveryClient// 服务注册发现 public class PaymentMain8001 { public static void main(String[] args) { SpringApplication.run (PaymentMain8001.class, args); } } 4、测试1、启动顺序先要启动EurekaServer，再启动8001主启动类，需要稍等一会儿 2、访问http://localhost:8001/payment/discovery 6、Eureka自我保护1、故障现象保护模式主要用于一组客户端和Eureka Server之间存在网络分区场景下的保护。一旦进入保护模式，Eureka Server将会尝试保护其服务注册表中的信息，不再删除服务注册表中的数据，也就是不会注销任何微服务。 如果在Eureka Server的首页看到以下这段提示，则说明Eureka进入了保护模式：EMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY’RE NOT.RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE 2、导致原因此举属于CAP里面的AP分支 一句话：某时刻某一个微服务不可用了，Eureka不会立刻清理，依旧会对该微服务的信息进行保存 1、问题一：为什么会产生Eureka自我保护机制？ 为了防止EurekaClient可以正常运行，但是 与 EurekaServer网络不通情况下，EurekaServer不会立刻将EurekaClient服务剔除 2、问题二：什么是自我保护模式？ 默认情况下，如果EurekaServer在一定时间内没有接收到某个微服务实例的心跳，EurekaServer将会注销该实例（默认90秒）。但是当网络分区故障发生(延时、卡顿、拥挤)时，微服务与EurekaServer之间无法正常通信，以上行为可能变得非常危险了——因为微服务本身其实是健康的，此时本不应该注销这个微服务。Eureka通过“自我保护模式”来解决这个问题——当EurekaServer节点在短时间内丢失过多客户端时（可能发生了网络分区故障），那么这个节点就会进入自我保护模式。 3、怎么禁止自我保护1、注册中心7001（1）出厂默认，自我保护机制是开启的 eureka.server.enable-self-preservation=true （2）使用eureka.server.enable-self-preservation = false 可以禁用自我保护模式 server: port: 7001 eureka: instance: hostname: eureka7001.com #eureka服务端的实例名称 client: register-with-eureka: false #false表示不向注册中心注册自己。 fetch-registry: false #false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务 service-url: defaultZone: http://eureka7002.com:7002/eureka/ server: #关闭自我保护机制，保证不可用服务被及时踢除 enable-self-preservation: false eviction-interval-timer-in-ms: 2000 （3）效果 2、生产者80011、默认（1）单位为秒(默认是30秒) eureka.instance.lease-renewal-interval-in-seconds=30 （2）单位为秒(默认是90秒) eureka.instance.lease-expiration-duration-in-seconds=90 2、配置 server: port: 8001 spring: application: name: cloud-payment-service datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: jdbc:mysql://localhost:3306/spring_cloud?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: a1b2c3 eureka: client: #表示是否将自己注册进EurekaServer默认为true。 register-with-eureka: true #是否从EurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡 fetchRegistry: true service-url: #defaultZone: http://localhost:7001/eureka defaultZone: http://eureka7001.com:7001/eureka,http://eureka7002.com:7002/eureka # 集群版 instance: instance-id: payment8001 prefer-ip-address: true #访问路径可以显示IP地址 #心跳检测与续约时间 #开发时设置小些，保证服务关闭后注册中心能即使剔除服务 #Eureka客户端向服务端发送心跳的时间间隔，单位为秒(默认是30秒) lease-renewal-interval-in-seconds: 1 #Eureka服务端在收到最后一次心跳后等待时间上限，单位为秒(默认是90秒)，超时将剔除服务 lease-expiration-duration-in-seconds: 2 mybatis: mapperLocations: classpath:mapper/*.xml type-aliases-package: com.kk.springclond.entities 3、测试（1）先启动7001，在启动8001 （2）再关闭8001，发现服务已经被删除了 7、Eureka停更``https://github.com/Netflix/eureka/wiki` 技术选型可以考虑 zookeeper、nacos(alibaba)","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"服务注册与发现","slug":"服务注册与发现","permalink":"https://mykkto.github.io/tags/%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0/"},{"name":"Eureka","slug":"Eureka","permalink":"https://mykkto.github.io/tags/Eureka/"}],"author":"mykk"},{"title":"SpringCloud 项目构建 and 技术选型","slug":"03-java分布式/01-springcloud/01_SpringCloud-Build","date":"2022-01-12T15:42:15.000Z","updated":"2022-11-12T15:07:08.072Z","comments":true,"path":"posts/9df20094.html","link":"","permalink":"https://mykkto.github.io/posts/9df20094.html","excerpt":"","text":"1、版本 2、官网地址【Spring Cloud】1、英文https://cloud.spring.io/spring-cloud-static/Hoxton.SR1/reference/htmlsingle/ 2、中文https://www.bookstack.cn/read/spring-cloud-docs/docs-index.md 3、springboothttps://docs.spring.io/spring-boot/docs/2.2.2.RELEASE/reference/htmlsingle/ 3、项目搭建-父工程构建 父工程坐标 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;!-- 统一管理jar包版本 --&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt; &lt;lombok.version&gt;1.16.18&lt;/lombok.version&gt; &lt;mysql.version&gt;5.1.47&lt;/mysql.version&gt; &lt;druid.version&gt;1.1.16&lt;/druid.version&gt; &lt;mybatis.spring.boot.version&gt;1.3.0&lt;/mybatis.spring.boot.version&gt; &lt;/properties&gt; &lt;!-- 子模块继承之后，提供作用：锁定版本+子modlue不用写groupId和version --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--spring boot 2.2.2--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--spring cloud Hoxton.SR1--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--spring cloud alibaba 2.1.0.RELEASE--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;${mysql.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;${druid.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${mybatis.spring.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;${junit.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;${log4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;${lombok.version}&lt;/version&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;addResources&gt;true&lt;/addResources&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 4、项目搭建-Rest微服务工程构建1、坐标&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-provider-payment8001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.alibaba/druid --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-jdbc --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-devtools --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.projectlombok/lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-test --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 2、ymlserver: port: 8001 spring: application: name: cloud-payment-service datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: jdbc:mysql://localhost:3306/spring_cloud?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: a1b2c3 mybatis: mapperLocations: classpath:mapper/*.xml type-aliases-package: com.kk.springclond.entities 3、主启动@SpringBootApplication public class PaymentMain8001 { public static void main(String[] args) { SpringApplication.run (PaymentMain8001.class, args); } } 4、业务类1、建表CREATE TABLE `payment` ( `id` bigint NOT NULL AUTO_INCREMENT , `serial` varchar(255) NULL , PRIMARY KEY (`id`) ) 2、实体（entity）（1）通用返回结果实体@Data @AllArgsConstructor @NoArgsConstructor public class CommonResult&lt;T&gt; { private Integer code; private String message; private T data; public CommonResult(Integer code, String message) { this(code,message,null); } } （2）Payment@Data @AllArgsConstructor @NoArgsConstructor public class Payment { private Long id; private String serial; } 3、dao层1、接口PaymentDao编写package com.kk.springcloud.dao; import com.kk.springcloud.entities.Payment; import org.apache.ibatis.annotations.Mapper; import org.apache.ibatis.annotations.Param; @Mapper public interface PaymentDao { public int create(Payment payment); //写 public Payment getPaymentById(@Param(\"id\") Long id); //读取 } 2、mybatis的映射文件PaymentMapper.xml（1）路径src\\main\\resources\\mapper\\PaymentMapper.xml （2）头文件&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;mapper namespace=\"com.kk.springcloud.dao.PaymentDao\"&gt; &lt;insert id=\"create\" parameterType=\"com.kk.springcloud.entities.Payment\" useGeneratedKeys=\"true\" keyProperty=\"id\"&gt; insert into payment(serial) values(${serial}); &lt;/insert&gt; &lt;resultMap id=\"BaseResultMap\" type=\"com.kk.springcloud.entities.Payment\"&gt; &lt;id column=\"id\" property=\"id\" jdbcType=\"BIGINT\"&gt;&lt;/id&gt; &lt;id column=\"serial\" property=\"serial\" jdbcType=\"VARCHAR\"&gt;&lt;/id&gt; &lt;/resultMap&gt; &lt;select id=\"getPaymentById\" parameterType=\"Long\" resultMap=\"BaseResultMap\"&gt; select * from payment where id=#{id} &lt;/select&gt; &lt;/mapper&gt; 4、service1、接口package com.kk.springcloud.service; import com.kk.springcloud.entities.Payment; import org.apache.ibatis.annotations.Param; public interface PaymentService { public int create(Payment payment); //写 public Payment getPaymentById(@Param(\"id\") Long id); //读取 } 2、实现类package com.kk.springcloud.service.impl; import com.kk.springcloud.dao.PaymentDao; import com.kk.springcloud.entities.Payment; import com.kk.springcloud.service.PaymentService; import org.springframework.stereotype.Service; import javax.annotation.Resource; @Service public class PaymentServiceImpl implements PaymentService { @Resource private PaymentDao paymentDao; public int create(Payment payment) { return paymentDao.create (payment); } public Payment getPaymentById(Long id) { return paymentDao.getPaymentById (id); } } 5、controllerpackage com.kk.springcloud.controller; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import com.kk.springcloud.service.PaymentService; import lombok.extern.slf4j.Slf4j; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; @RestController @Slf4j public class PaymentController { @Resource private PaymentService paymentService; @PostMapping(value = \"/payment/create\") public CommonResult create(Payment payment) { int result = paymentService.create (payment); log.info (\"*****插入结果：\" + result); if (result &gt; 0) { //成功 return new CommonResult (200, \"插入数据库成功\", result); } else { return new CommonResult (444, \"插入数据库失败\", null); } } @GetMapping(value = \"/payment/get/{id}\") public CommonResult getPaymentById(@PathVariable(\"id\") Long id) { Payment payment = paymentService.getPaymentById (id); log.info (\"*****查询结果：\" + payment); if (payment != null) { //说明有数据，能查询成功 return new CommonResult (200, \"查询成功\", payment); } else { return new CommonResult (444, \"没有对应记录，查询ID：\" + id, null); } } } 5、测试1、插入：使用post请求才能被插入，所以在url上无效，可以使用postmanhttp://localhost:8001/payment/create?serial=mykk02 2、查询：get请求，url，postman皆可http://localhost:8001/payment/get/1 5、热部署1、子工程 pom上面的依赖已经有加了，是这个 2、父工程 pom插件上面的依赖已经有加了，是这个 3、设置自动编译 4、开启自动更新1、打开设置面板ctrl + shift + alt + /同时按住，点击第一个Registry... 2、两个打勾 5、重启 IDEA6、项目搭建-Order订单微服务构建1、坐标&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-consumer-order80&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-devtools --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.projectlombok/lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-test --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 2、ymlserver: port: 80 3、主启动package com.kk.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class OrderMain80 { public static void main(String[] args) { SpringApplication.run (OrderMain80.class,args); } } 4、业务类1、创建entities 将cloud-provider-payment8001工程下的entities包下的两个实体类复制过来 2、RestTemplate1、官网： https://docs.spring.io/spring-framework/docs/5.2.2.RELEASE/javadoc-api/org/springframework/web/client/RestTemplate.html 2、是什么 3、怎么用 3、配置类ApplicationContextConfig package com.kk.springcloud.config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.web.client.RestTemplate; @Configuration public class ApplicationContextConfig { @Bean public RestTemplate getRestTemplate(){ return new RestTemplate(); } } 4、创建 controllerpackage com.kk.springcloud.controller; import com.kk.springcloud.entities.CommonResult; import com.kk.springcloud.entities.Payment; import lombok.extern.slf4j.Slf4j; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import javax.annotation.Resource; @RestController @Slf4j public class OrderController { public static final String PAYMENT_URL = \"http://localhost:8001\"; @Resource private RestTemplate restTemplate; @GetMapping(\"/consumer/payment/create\") public CommonResult&lt;Payment&gt; create(Payment payment) { return restTemplate.postForObject (PAYMENT_URL + \"/payment/create\", payment, CommonResult.class); //写操作 } @GetMapping(\"/consumer/payment/get/{id}\") public CommonResult&lt;Payment&gt; getPayment(@PathVariable(\"id\") Long id) { return restTemplate.getForObject (PAYMENT_URL + \"/payment/get/\" + id, CommonResult.class); } } 5、测试1、先启动cloud-provider-payment80012、再启动cloud-consumer-order803、测试消费者接口http://localhost/consumer/payment/get/1 注意点：被调用的生产者接口传参记得加注解 7、项目重构1、观察问题1、系统中有重复部分，重构 2、新建公共模块【cloud-api-commons】1、pom&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud2021to2022&lt;/artifactId&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-devtools --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/cn.hutool/hutool-all --&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;5.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 2、实体将订单模块和支付模块公共实体放到这里 3、改造订单和支付1、删除各自的原先有过的entities文件夹2、各自分别引入公共模块&lt;!--引入公共部分--&gt; &lt;dependency&gt; &lt;groupId&gt;com.kk&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; 7、项目模块结构图","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"搭建","slug":"搭建","permalink":"https://mykkto.github.io/tags/%E6%90%AD%E5%BB%BA/"}],"author":"mykk"},{"title":"南城故人","slug":"02-技术之外/01-段子/01_nanchengguren","date":"2022-01-10T17:33:22.000Z","updated":"2022-01-11T12:37:38.397Z","comments":true,"path":"posts/f2c0d8e3.html","link":"","permalink":"https://mykkto.github.io/posts/f2c0d8e3.html","excerpt":"","text":"摘自：南城故人 第8期内容： 18岁，你读了大学。20岁，你大二结束，开始悔恨自己前两年幼稚的行为于是开始努力22岁你大学毕业了，却发现找不到一份令自己满意的工作26岁，你看着身边的人都结了婚婚礼的份子钱逐年递增春节回家，父母从带你串亲戚变成了带你去见相亲对象见了十几个姑娘你每次都觉得和那个她比差了一点28岁那年，你遇到了一个和你遭遇差不多的姑娘你们有一搭没一搭的聊着她说：你还不错你喝了一口可乐说：你也是你还不确定喜不喜欢她双方家长就已经摆好了订婚宴结婚的前一周，你和朋友出去喝酒你说，不想结婚朋友说，你啊，就是想太多。谁不是这么过来的？ 29岁，你们终于结了婚婚礼办的不大不小，朋友来的不多不少攒了几年想要去实现理想的钱搭在了这一场百人的私人庙会上婚礼进行到中间司仪带着标准的商业化微笑对着台下的亲朋喊道要不要让他们亲一个！台下那些人跟着一起起哄不知道为什么你简简单单的亲了一口俩人恢复到了一开始的站位你小声说了一句：我爱你那个昨天还看不惯你倒腾模型的新娘愣了一下说：我也爱你你不确定她是不是对你说的就像你不确定是不是对她说的一样婚礼结束后，并没有你想象的浪漫你听着外屋的新娘一笔一笔的算着份子钱想着不过才两年，怎么就变成这样了想着想着，洞房夜就睡着了 30岁，她怀孕了辞掉了工作，在家养胎你在公司逐渐有了点地位手里管着十来个人独立负责一个项目结婚前陪嫁的那辆20万左右的车也变成了你一个人的独享但你依然不敢放松每次加班电话那头都是抱怨与委屈但你不能争辩什么谁让她怀了你的孩子在这一刻不论是她的父母还是你的父母都无条件的站在这一边31岁，孩子落地了前前后后连孕检带住院费花了10万块钱不过无所谓你看着你的孩子，怎么看怎么喜欢高兴的仿佛这是你的新生32岁，这是人生最不愿意重复的一年平均睡眠3小时孩子每一个小时都要闹腾一次第二天拖着睡不醒的眼睛去上班老板说你上班不干活回家媳妇说你不干活你想了半天不明白，那谁干活呢？那辆开了3年的车成为了你真正的家你不在抱怨路上拥堵的交通你甚至开始希望再多堵一会回到家，你关了发动机在车上点了一根烟这是你每天最幸福的十分钟车前是功名利禄，车尾是柴米油盐 35岁 你因为身体越来越差加班越来越少晋升的速度也越来越缓慢那天下班，媳妇告诉你孩子要上幼儿园了双语的一个月3000你皱了皱眉头，那边就已经不耐烦了“四单元的老王家孩子，一个月6000”“你已经这样了，你想让孩子也输？”你没说话，回屋给媳妇转了6000块钱这笔钱，你原本打算给自己过个生日，买个新电脑 38岁，孩子上了一年级老师说一年级最关键，打好基础很重要你笑着说，是是是，老师您多照顾新生接待的老师看着你不明事理的脸给你指了一条明路“课外辅导班，一个月2200”40岁的时候，孩子上了三年级老师说，三年级，最关键，承上启下很重要你笑着说：是是是，正打算再报个补习班 44岁，孩子上了初中有一天回到家，她对你说爸爸，我想学钢琴你没什么犹豫的你以为这些年，你已经习惯了但那句“爸爸现在买不起”你始终说不出口好在孩子比较懂事她说：爸爸没事，要不我先学陶笛也可以你看着这么懂事的孩子，却开心不起来 46岁，孩子上了一个不好不差的高中有一天你在开会，接到了老师的电话电话里说你的孩子在学校打架了叫你去一趟你唯唯诺诺的和那个比你还小5岁的领导请了个假到学校又被老师训了一通无非台词就是那一句你们做家长的就知道工作，能不能陪陪孩子你看着这个老师，有点可笑好像当时说：家长在外辛苦点多赚点钱让孩子多补补课的和他不是一个人 50岁，孩子上了大学很争气，是一个一本他学的专业你有点看不懂你只知道工作不一定好找而且学费还死贵你和他深夜想聊聊准备了半斤白酒，一碟花生米你说着那些曾经你最讨厌的话还是要为以后工作着想挑个热门的专业活着比热爱重要你们从交流变成了争吵你发现，你老了老到可能都打不过这个18岁的孩子你说不过他，只能说一句：我是你爸爸！孩子看着你，知道再怎么争辩都没用这场确立你最后威严的酒局不欢而散你听的不真切在孩子回自己屋的路上好像叨叨了一句“我不想活的像你一样”怎么就哭了呢？50岁的人了一定是酒太辣了，对不对一定是酒太辣了 55岁，孩子工作了，似乎有一点理解你了但你却反了过来，你说不要妥协56岁，孩子也结婚了你问他喜欢那个姑娘么他愣了愣说：喜欢吧60岁，辛苦了一辈子，想出去走走身边的那个人过了30年你依旧分不清到底喜不喜欢你们开始规划旅游路线这么多年了你们还是存在分歧，还是在争吵某个瞬间，你觉得这样可能也挺好一切都准备好了儿子说：爸妈，我工作太忙了可以帮我照顾一下孩子么你们退了机票，又回到了30年前 70岁，孩子的孩子也长大了，不用天天操心了你下定决心说：一定要去玩一趟可是手边的拐杖只能支持你走到楼下的花园75岁，你在医院的病床上身边聚满了人，你迷迷糊糊的看见医生摇了摇头周围那些人神情肃穆你明白了，你要死掉了你没有感到一丝害怕你突然问自己，我到底是什么时候死掉的呢？你想起来30岁的那场婚礼原来，那时候，你就死掉了吧 依照惯例死前的3秒，你的大脑要走马灯倒叙你这75个年头的一生画面一张一张的过1秒2秒两秒过去了你面无表情的看着这两秒内的回忆第3秒突然你笑了原来已经回到了15岁的那一年 你看见一个男孩他叼着一袋牛奶，背着书包从另一个女孩家的阳台下跑过那个男孩朝窗户里看了看那是15岁的你暗恋的那个女孩子你想不起来她长什么样子了最后一秒你努力的回忆着然后终于笑了出来3秒过去了身边的人突然间开始嚎啕大哭你可能听不清了你最后听到的嘈杂的声音是一群十五六的少年 起着哄说的答应他答应他答应他不爱你，不度生 热评：取一位账号已注销的评论：“有些人27岁就死了，直到72岁才被埋上”。能够想清楚过去，抓得住现在，放眼在未来吧，做一个能活到72岁的糊涂蛋。","categories":[{"name":"生活碎片化-段子","slug":"生活碎片化-段子","permalink":"https://mykkto.github.io/categories/%E7%94%9F%E6%B4%BB%E7%A2%8E%E7%89%87%E5%8C%96-%E6%AE%B5%E5%AD%90/"}],"tags":[{"name":"生活","slug":"生活","permalink":"https://mykkto.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"段子","slug":"段子","permalink":"https://mykkto.github.io/tags/%E6%AE%B5%E5%AD%90/"},{"name":"感慨","slug":"感慨","permalink":"https://mykkto.github.io/tags/%E6%84%9F%E6%85%A8/"}],"author":"mykk"},{"title":"SpringCloud and Alibaba合集","slug":"03-java分布式/01-springcloud/00_SpringCloud","date":"2022-01-10T16:42:15.000Z","updated":"2022-11-12T15:07:08.072Z","comments":true,"path":"posts/58914314.html","link":"","permalink":"https://mykkto.github.io/posts/58914314.html","excerpt":"","text":"案例代码仓库https://gitee.com/TK_LIMR/springcloud2021To2021.git 分解的目录1、项目构建and技术选型2、Eureka服务注册与发现4、Consul服务注册与发现5、Ribbon负载均衡服务调用6、OpenFeign服务接口调用7、Hystrix断路器8、zuul路由网关9、Gateway新一代网关10、Seata处理分布式事务11、Sentinel实现熔断与限流12、Nacos服务注册和配置中心13、Sleuth分布式请求链路追踪14、Stream消息驱动15、Bus 消息总线16、config分布式配置中心食用技巧1、同时启动多个SpringbootIDEA SpringBoot多个项目 开启 RunDashboard， 在项目根目录 .idea 文件夹 中 workspace.xml文件中加入 &lt;component name=\"RunDashboard\"&gt; &lt;option name=\"configurationTypes\"&gt; &lt;set&gt; &lt;option value=\"SpringBootApplicationConfigurationType\" /&gt; &lt;/set&gt; &lt;/option&gt; &lt;/component&gt; 2、本地hosts配置windown 10位置：C:\\Windows\\System32\\drivers\\etc","categories":[{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"springcloud-alibaba","slug":"springcloud-alibaba","permalink":"https://mykkto.github.io/tags/springcloud-alibaba/"},{"name":"合集","slug":"合集","permalink":"https://mykkto.github.io/tags/%E5%90%88%E9%9B%86/"}],"author":"mykk"},{"title":"KK语录（日记）","slug":"02-技术之外/02_语录","date":"2022-01-10T15:12:19.000Z","updated":"2022-01-11T13:41:21.196Z","comments":true,"path":"posts/bd37926a.html","link":"","permalink":"https://mykkto.github.io/posts/bd37926a.html","excerpt":"","text":"","categories":[{"name":"生活碎片化","slug":"生活碎片化","permalink":"https://mykkto.github.io/categories/%E7%94%9F%E6%B4%BB%E7%A2%8E%E7%89%87%E5%8C%96/"}],"tags":[{"name":"语录","slug":"语录","permalink":"https://mykkto.github.io/tags/%E8%AF%AD%E5%BD%95/"},{"name":"日记","slug":"日记","permalink":"https://mykkto.github.io/tags/%E6%97%A5%E8%AE%B0/"},{"name":"话痨","slug":"话痨","permalink":"https://mykkto.github.io/tags/%E8%AF%9D%E7%97%A8/"}],"author":"mykk"},{"title":"美文","slug":"02-技术之外/01_美文","date":"2022-01-10T14:33:12.000Z","updated":"2022-01-11T14:21:18.841Z","comments":true,"path":"posts/c3e91221.html","link":"","permalink":"https://mykkto.github.io/posts/c3e91221.html","excerpt":"","text":"","categories":[{"name":"生活碎片化","slug":"生活碎片化","permalink":"https://mykkto.github.io/categories/%E7%94%9F%E6%B4%BB%E7%A2%8E%E7%89%87%E5%8C%96/"}],"tags":[{"name":"美文","slug":"美文","permalink":"https://mykkto.github.io/tags/%E7%BE%8E%E6%96%87/"}],"author":"mykk"},{"title":"散列生活碎片","slug":"01-菜单/03_随笔（语录）","date":"2022-01-10T13:22:55.000Z","updated":"2023-02-27T14:12:32.053Z","comments":true,"path":"posts/1565718c.html","link":"","permalink":"https://mykkto.github.io/posts/1565718c.html","excerpt":"","text":"2022年07月30日 每天上班前，从一双绿色拖鞋切换到黑色，仿佛成了我的肌肉记忆 2022年08月02日 当信念也要去依托他人之时，多半就完了 2022年08月07日 立秋： 莆田人似乎不擅长说谎，酸掉变质的食材，总能说是做工手法导致的口感问题。 2022年08月10日 二期核酸的人流已经大到需要用竞技的方式，还好我跑得快，也有些插队的天赋。（旁边的大喇叭：跑的快的先做，慢的靠边） 2022年08月13日 秩序是用来搪塞下层阶级的谎言 2022年08月17日 原则： 不追高：宁可错失一次，不亏误入一回不追高！不追高！不追高！3点以上不追！ 2022年08月19日 我是个懒惰的人，买早餐坐车也不步行 我是个倔强的人，乘一站也不在楼下买 2022年08月19日 我想，我并没有完全摆烂 2022年09月10日 我时常同友人提到：“打工时看不到未来的”， 但是遇到那些不太靠谱的年轻人想创业时，我也试着劝他们三思 或许只是我自己没勇气罢了。 2022年09月17日 好久没吃雪糕，不是我没钱，也不是我讨厌，只是似乎没那么想了 2022年09月20日 人群中用充斥着不同刺鼻的味道，在她们称为香味的东西，与我而言不过是不同度数的酒精 2022年11月25日 我依然是个话唠，只是现实中讲的少了，写的多了 2022年12月21日 如果一些误解对我的利益不影响，我也便不会解释","categories":[{"name":"文章菜单合集","slug":"文章菜单合集","permalink":"https://mykkto.github.io/categories/%E6%96%87%E7%AB%A0%E8%8F%9C%E5%8D%95%E5%90%88%E9%9B%86/"}],"tags":[{"name":"生活","slug":"生活","permalink":"https://mykkto.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"随记","slug":"随记","permalink":"https://mykkto.github.io/tags/%E9%9A%8F%E8%AE%B0/"},{"name":"语录","slug":"语录","permalink":"https://mykkto.github.io/tags/%E8%AF%AD%E5%BD%95/"}],"author":"mykk"},{"title":"★本站核心文章目录★","slug":"01-菜单/02_新菜单集合","date":"2022-01-09T14:55:55.000Z","updated":"2023-02-17T06:15:54.567Z","comments":true,"path":"posts/f747eac7.html","link":"","permalink":"https://mykkto.github.io/posts/f747eac7.html","excerpt":"","text":"一、SpringCloud全家桶(not only)- 1、注册中心篇（1）SpringCloud-Eureka =============SpringCloud-Eureka============== （2）Springcloud-Zookeeper =============Springcloud-Zookeeper=========== （3）SpringCloud-Consul =============SpringCloud-Consul============== （4）SpringCloud-Alibaba-Nacos（注册中心+配置中心） =============SpringCloud-Alibaba-Nacos======== - 2、服务调用篇（1）SpringCloud-OpenFeign =============SpringCloud-OpenFeign============= - 3、负载均衡篇（1）SpringCloud-Ribbon =============SpringCloud-Ribbon================ - 4、熔断限流篇（1）SpringCloud-Hystrix =============SpringCloud-Hystrix================ （2）SpringCloud-Alibaba-Sentinel =============SpringCloud-Alibaba-Sentinel======= - 5、路由网关篇（1）SpringCloud-Zuul =============SpringCloud-Zuul=================== （2）SpringCloud-Gateway =============SpringCloud-Gateway================= - 6、分布式事务（1）SpringCloud-Alibaba-Seata =============SpringCloud-Alibaba-Seata=========== - 7、配置中心篇（1）SpringCloud-Config =============SpringCloud-Config=================== - 8、搜索引擎篇（1）ES =============SpringCloud-Config=================== - N、老技术(待淘汰)（1）SpringCloud-Bus分布式节点链接 =============SpringCloud-Bus======================= （2）SpringCloud-Stream消息驱动 =============SpringCloud-Stream==================== （3）SpringCloud-Sleuth分布式请求链路跟踪 =============SpringCloud-Sleuth====================","categories":[{"name":"文章菜单合集","slug":"文章菜单合集","permalink":"https://mykkto.github.io/categories/%E6%96%87%E7%AB%A0%E8%8F%9C%E5%8D%95%E5%90%88%E9%9B%86/"}],"tags":[{"name":"技术总纲","slug":"技术总纲","permalink":"https://mykkto.github.io/tags/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BA%B2/"},{"name":"spring全家桶","slug":"spring全家桶","permalink":"https://mykkto.github.io/tags/spring%E5%85%A8%E5%AE%B6%E6%A1%B6/"}],"author":"mykk"},{"title":"(旧)简书文章过往两年纲要","slug":"01-菜单/01_旧菜单合集","date":"2022-01-09T11:19:19.000Z","updated":"2022-11-12T15:07:08.072Z","comments":true,"path":"posts/c3e91221.html","link":"","permalink":"https://mykkto.github.io/posts/c3e91221.html","excerpt":"","text":"1、技术（较为系统编排）1、java数据结构与算法 ★https://www.jianshu.com/p/929ca9e209e8 2、java设计模式https://www.jianshu.com/p/63df8cd03619 8、java单体架构技术栈https://www.jianshu.com/p/0a4a1ced23c7 9、java分布式架构技术栈https://www.jianshu.com/p/00aa796bb5b8 10、框架之外技术栈汇总https://www.jianshu.com/p/d0167f082cbf N1、内力篇汇总0-java内力——总纲 - 简书 (jianshu.com) 11、Liunxhttps://www.jianshu.com/p/409970d8d0f1 12、前端大杂烩https://www.jianshu.com/p/82fa0c99e019 13、各项目整合分解大杂烩https://www.jianshu.com/p/d30b07569dc3 14、面试题汇总：技术=面试题+项目总结 ★https://www.jianshu.com/p/5e3b81aef034 15、一些不错的网站：https://www.jianshu.com/p/53bf0d4a930d 16、随性记录一小点随性记录一小点 2021-07-15至未来 7、工具代码备份UT-工具代码 JDK各版本演变 4、netty 5、JVM【重量级】 n、大数据n、前端n、golangn、以太坊n、区块链n、scala 2、工作，博客，公众号等所学技术汇总3、心得（工作）4、语录（感悟）","categories":[{"name":"文章菜单合集","slug":"文章菜单合集","permalink":"https://mykkto.github.io/categories/%E6%96%87%E7%AB%A0%E8%8F%9C%E5%8D%95%E5%90%88%E9%9B%86/"}],"tags":[{"name":"简书","slug":"简书","permalink":"https://mykkto.github.io/tags/%E7%AE%80%E4%B9%A6/"},{"name":"技术总纲","slug":"技术总纲","permalink":"https://mykkto.github.io/tags/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BA%B2/"}],"author":"mykk"}],"categories":[{"name":"面试题","slug":"面试题","permalink":"https://mykkto.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"专刊篇","slug":"专刊篇","permalink":"https://mykkto.github.io/categories/%E4%B8%93%E5%88%8A%E7%AF%87/"},{"name":"分布式技术栈","slug":"分布式技术栈","permalink":"https://mykkto.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E6%A0%88/"},{"name":"消息中间件","slug":"消息中间件","permalink":"https://mykkto.github.io/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"内力篇","slug":"内力篇","permalink":"https://mykkto.github.io/categories/%E5%86%85%E5%8A%9B%E7%AF%87/"},{"name":"docker","slug":"docker","permalink":"https://mykkto.github.io/categories/docker/"},{"name":"大数据","slug":"大数据","permalink":"https://mykkto.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"项目-金融","slug":"项目-金融","permalink":"https://mykkto.github.io/categories/%E9%A1%B9%E7%9B%AE-%E9%87%91%E8%9E%8D/"},{"name":"高阶篇","slug":"高阶篇","permalink":"https://mykkto.github.io/categories/%E9%AB%98%E9%98%B6%E7%AF%87/"},{"name":"中间件","slug":"中间件","permalink":"https://mykkto.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"计算机语言","slug":"计算机语言","permalink":"https://mykkto.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%AF%AD%E8%A8%80/"},{"name":"博客","slug":"博客","permalink":"https://mykkto.github.io/categories/%E5%8D%9A%E5%AE%A2/"},{"name":"数据库","slug":"数据库","permalink":"https://mykkto.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"生活碎片化-段子","slug":"生活碎片化-段子","permalink":"https://mykkto.github.io/categories/%E7%94%9F%E6%B4%BB%E7%A2%8E%E7%89%87%E5%8C%96-%E6%AE%B5%E5%AD%90/"},{"name":"生活碎片化","slug":"生活碎片化","permalink":"https://mykkto.github.io/categories/%E7%94%9F%E6%B4%BB%E7%A2%8E%E7%89%87%E5%8C%96/"},{"name":"文章菜单合集","slug":"文章菜单合集","permalink":"https://mykkto.github.io/categories/%E6%96%87%E7%AB%A0%E8%8F%9C%E5%8D%95%E5%90%88%E9%9B%86/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"https://mykkto.github.io/tags/springcloud/"},{"name":"面试","slug":"面试","permalink":"https://mykkto.github.io/tags/%E9%9D%A2%E8%AF%95/"},{"name":"juc","slug":"juc","permalink":"https://mykkto.github.io/tags/juc/"},{"name":"面试题","slug":"面试题","permalink":"https://mykkto.github.io/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"gateway","slug":"gateway","permalink":"https://mykkto.github.io/tags/gateway/"},{"name":"灰度发布","slug":"灰度发布","permalink":"https://mykkto.github.io/tags/%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83/"},{"name":"nginx","slug":"nginx","permalink":"https://mykkto.github.io/tags/nginx/"},{"name":"事务","slug":"事务","permalink":"https://mykkto.github.io/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"spring-tx","slug":"spring-tx","permalink":"https://mykkto.github.io/tags/spring-tx/"},{"name":"amqp","slug":"amqp","permalink":"https://mykkto.github.io/tags/amqp/"},{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://mykkto.github.io/tags/rabbitmq/"},{"name":"netty","slug":"netty","permalink":"https://mykkto.github.io/tags/netty/"},{"name":"nio","slug":"nio","permalink":"https://mykkto.github.io/tags/nio/"},{"name":"网络编程","slug":"网络编程","permalink":"https://mykkto.github.io/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"},{"name":"技术","slug":"技术","permalink":"https://mykkto.github.io/tags/%E6%8A%80%E6%9C%AF/"},{"name":"记录","slug":"记录","permalink":"https://mykkto.github.io/tags/%E8%AE%B0%E5%BD%95/"},{"name":"docker-compose","slug":"docker-compose","permalink":"https://mykkto.github.io/tags/docker-compose/"},{"name":"dockerfile","slug":"dockerfile","permalink":"https://mykkto.github.io/tags/dockerfile/"},{"name":"docker网络","slug":"docker网络","permalink":"https://mykkto.github.io/tags/docker%E7%BD%91%E7%BB%9C/"},{"name":"Flink","slug":"Flink","permalink":"https://mykkto.github.io/tags/Flink/"},{"name":"hadoop","slug":"hadoop","permalink":"https://mykkto.github.io/tags/hadoop/"},{"name":"kafka","slug":"kafka","permalink":"https://mykkto.github.io/tags/kafka/"},{"name":"springboot","slug":"springboot","permalink":"https://mykkto.github.io/tags/springboot/"},{"name":"vue","slug":"vue","permalink":"https://mykkto.github.io/tags/vue/"},{"name":"jvm","slug":"jvm","permalink":"https://mykkto.github.io/tags/jvm/"},{"name":"字节码","slug":"字节码","permalink":"https://mykkto.github.io/tags/%E5%AD%97%E8%8A%82%E7%A0%81/"},{"name":"原理","slug":"原理","permalink":"https://mykkto.github.io/tags/%E5%8E%9F%E7%90%86/"},{"name":"java","slug":"java","permalink":"https://mykkto.github.io/tags/java/"},{"name":"分布式","slug":"分布式","permalink":"https://mykkto.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"数据库","slug":"数据库","permalink":"https://mykkto.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"ShardingSphere","slug":"ShardingSphere","permalink":"https://mykkto.github.io/tags/ShardingSphere/"},{"name":"分库分表","slug":"分库分表","permalink":"https://mykkto.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"},{"name":"jdbc","slug":"jdbc","permalink":"https://mykkto.github.io/tags/jdbc/"},{"name":"lua","slug":"lua","permalink":"https://mykkto.github.io/tags/lua/"},{"name":"openresty","slug":"openresty","permalink":"https://mykkto.github.io/tags/openresty/"},{"name":"springcloud-alibaba","slug":"springcloud-alibaba","permalink":"https://mykkto.github.io/tags/springcloud-alibaba/"},{"name":"seata","slug":"seata","permalink":"https://mykkto.github.io/tags/seata/"},{"name":"分布式事务","slug":"分布式事务","permalink":"https://mykkto.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"},{"name":"blog","slug":"blog","permalink":"https://mykkto.github.io/tags/blog/"},{"name":"部署","slug":"部署","permalink":"https://mykkto.github.io/tags/%E9%83%A8%E7%BD%B2/"},{"name":"小姿势","slug":"小姿势","permalink":"https://mykkto.github.io/tags/%E5%B0%8F%E5%A7%BF%E5%8A%BF/"},{"name":"熔断器","slug":"熔断器","permalink":"https://mykkto.github.io/tags/%E7%86%94%E6%96%AD%E5%99%A8/"},{"name":"sentinel","slug":"sentinel","permalink":"https://mykkto.github.io/tags/sentinel/"},{"name":"限流","slug":"限流","permalink":"https://mykkto.github.io/tags/%E9%99%90%E6%B5%81/"},{"name":"nacos","slug":"nacos","permalink":"https://mykkto.github.io/tags/nacos/"},{"name":"集群","slug":"集群","permalink":"https://mykkto.github.io/tags/%E9%9B%86%E7%BE%A4/"},{"name":"AQS","slug":"AQS","permalink":"https://mykkto.github.io/tags/AQS/"},{"name":"多线程","slug":"多线程","permalink":"https://mykkto.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"JUC","slug":"JUC","permalink":"https://mykkto.github.io/tags/JUC/"},{"name":"oracle","slug":"oracle","permalink":"https://mykkto.github.io/tags/oracle/"},{"name":"docker","slug":"docker","permalink":"https://mykkto.github.io/tags/docker/"},{"name":"安装","slug":"安装","permalink":"https://mykkto.github.io/tags/%E5%AE%89%E8%A3%85/"},{"name":"服务注册与发现","slug":"服务注册与发现","permalink":"https://mykkto.github.io/tags/%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0/"},{"name":"配置中心","slug":"配置中心","permalink":"https://mykkto.github.io/tags/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"},{"name":"服务跟踪","slug":"服务跟踪","permalink":"https://mykkto.github.io/tags/%E6%9C%8D%E5%8A%A1%E8%B7%9F%E8%B8%AA/"},{"name":"sleuth","slug":"sleuth","permalink":"https://mykkto.github.io/tags/sleuth/"},{"name":"消息驱动","slug":"消息驱动","permalink":"https://mykkto.github.io/tags/%E6%B6%88%E6%81%AF%E9%A9%B1%E5%8A%A8/"},{"name":"stream","slug":"stream","permalink":"https://mykkto.github.io/tags/stream/"},{"name":"bus","slug":"bus","permalink":"https://mykkto.github.io/tags/bus/"},{"name":"节点链接","slug":"节点链接","permalink":"https://mykkto.github.io/tags/%E8%8A%82%E7%82%B9%E9%93%BE%E6%8E%A5/"},{"name":"config","slug":"config","permalink":"https://mykkto.github.io/tags/config/"},{"name":"路由网关","slug":"路由网关","permalink":"https://mykkto.github.io/tags/%E8%B7%AF%E7%94%B1%E7%BD%91%E5%85%B3/"},{"name":"alibaba","slug":"alibaba","permalink":"https://mykkto.github.io/tags/alibaba/"},{"name":"Gateway","slug":"Gateway","permalink":"https://mykkto.github.io/tags/Gateway/"},{"name":"linux","slug":"linux","permalink":"https://mykkto.github.io/tags/linux/"},{"name":"mysql","slug":"mysql","permalink":"https://mykkto.github.io/tags/mysql/"},{"name":"netflix","slug":"netflix","permalink":"https://mykkto.github.io/tags/netflix/"},{"name":"zuul","slug":"zuul","permalink":"https://mykkto.github.io/tags/zuul/"},{"name":"断路器","slug":"断路器","permalink":"https://mykkto.github.io/tags/%E6%96%AD%E8%B7%AF%E5%99%A8/"},{"name":"Hystrix","slug":"Hystrix","permalink":"https://mykkto.github.io/tags/Hystrix/"},{"name":"远程调用服务","slug":"远程调用服务","permalink":"https://mykkto.github.io/tags/%E8%BF%9C%E7%A8%8B%E8%B0%83%E7%94%A8%E6%9C%8D%E5%8A%A1/"},{"name":"openfeign","slug":"openfeign","permalink":"https://mykkto.github.io/tags/openfeign/"},{"name":"负载均衡","slug":"负载均衡","permalink":"https://mykkto.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"ribbon","slug":"ribbon","permalink":"https://mykkto.github.io/tags/ribbon/"},{"name":"hexo","slug":"hexo","permalink":"https://mykkto.github.io/tags/hexo/"},{"name":"github","slug":"github","permalink":"https://mykkto.github.io/tags/github/"},{"name":"seo","slug":"seo","permalink":"https://mykkto.github.io/tags/seo/"},{"name":"百度","slug":"百度","permalink":"https://mykkto.github.io/tags/%E7%99%BE%E5%BA%A6/"},{"name":"谷歌","slug":"谷歌","permalink":"https://mykkto.github.io/tags/%E8%B0%B7%E6%AD%8C/"},{"name":"Consul","slug":"Consul","permalink":"https://mykkto.github.io/tags/Consul/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://mykkto.github.io/tags/Zookeeper/"},{"name":"Eureka","slug":"Eureka","permalink":"https://mykkto.github.io/tags/Eureka/"},{"name":"搭建","slug":"搭建","permalink":"https://mykkto.github.io/tags/%E6%90%AD%E5%BB%BA/"},{"name":"生活","slug":"生活","permalink":"https://mykkto.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"段子","slug":"段子","permalink":"https://mykkto.github.io/tags/%E6%AE%B5%E5%AD%90/"},{"name":"感慨","slug":"感慨","permalink":"https://mykkto.github.io/tags/%E6%84%9F%E6%85%A8/"},{"name":"合集","slug":"合集","permalink":"https://mykkto.github.io/tags/%E5%90%88%E9%9B%86/"},{"name":"语录","slug":"语录","permalink":"https://mykkto.github.io/tags/%E8%AF%AD%E5%BD%95/"},{"name":"日记","slug":"日记","permalink":"https://mykkto.github.io/tags/%E6%97%A5%E8%AE%B0/"},{"name":"话痨","slug":"话痨","permalink":"https://mykkto.github.io/tags/%E8%AF%9D%E7%97%A8/"},{"name":"美文","slug":"美文","permalink":"https://mykkto.github.io/tags/%E7%BE%8E%E6%96%87/"},{"name":"随记","slug":"随记","permalink":"https://mykkto.github.io/tags/%E9%9A%8F%E8%AE%B0/"},{"name":"技术总纲","slug":"技术总纲","permalink":"https://mykkto.github.io/tags/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BA%B2/"},{"name":"spring全家桶","slug":"spring全家桶","permalink":"https://mykkto.github.io/tags/spring%E5%85%A8%E5%AE%B6%E6%A1%B6/"},{"name":"简书","slug":"简书","permalink":"https://mykkto.github.io/tags/%E7%AE%80%E4%B9%A6/"}]}